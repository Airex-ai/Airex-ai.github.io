<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Airex Yu">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://example.com/2023/04/13/j5/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="J5 ISP软硬件总体介绍ISP名词解释ISP（Image Signal Processor）：是一种专门用于处理图像信号的芯片或软件模块，它通常用于数字相机、智能手机、平板电脑和其他各种图像设备中。ISP可以对从图像传感器中读取的原始图像数据进行处理，包括去噪、白平衡、色彩校正、曝光控制、锐化和其他一些图像处理算法，以产生更高质量的图像。ISP还可以支持不同的图像格式和压缩算法，以便在存储和传输">
<meta property="og:type" content="article">
<meta property="og:title" content="J5">
<meta property="og:url" content="http://example.com/2023/04/13/J5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="J5 ISP软硬件总体介绍ISP名词解释ISP（Image Signal Processor）：是一种专门用于处理图像信号的芯片或软件模块，它通常用于数字相机、智能手机、平板电脑和其他各种图像设备中。ISP可以对从图像传感器中读取的原始图像数据进行处理，包括去噪、白平衡、色彩校正、曝光控制、锐化和其他一些图像处理算法，以产生更高质量的图像。ISP还可以支持不同的图像格式和压缩算法，以便在存储和传输">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413095502144.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413100008288.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413100641601.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413100847090.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413101558584.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413102356479.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413102619436.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413103326548.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413104118516.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413104411602.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413104718792.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413104835498.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413105227373.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413105748121.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413110012436.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413141440552.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413141950166.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413142430330.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413142924688.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413143449313.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413143747621.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413144303859.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413145208674.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413145942257.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413150709408.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413151331021.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413152206939.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413153249502.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413153256246.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413153545992.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413154243974.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413154841706.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413155947281.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413160926541.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413162559842.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413164354215.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413190222405.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413190239065.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413191906143.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413191917441.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413192524229.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413193303925.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413202351846.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413203431146.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413203610737.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413205313414.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413205449483.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413205457968.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413205808655-16813906889561.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413210047533.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413210614098.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230413210812784.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414081802204-16814314824862.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414081944807.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414082107058.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414090204749.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414090744026.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414091506525.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414091515257.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414092121709.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414092812821.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414093656150.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414093750378.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414093814731.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414094036665.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414094240554.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414150130688.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414150325417.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414150440962.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414150603960.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414150705375.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414150851796.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414151011131.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414151311362.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414191305397.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414191332944.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414191457449.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414191618474.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414191705921.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414192726981.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414193205759.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414193443284.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230414194156836.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111219563.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111318104.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111350861.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111405353.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111416759.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111447163.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230415111506865.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230417100729900.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230417100729900.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230417110135342.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508083610568.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508083658725.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508083721413.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508083807175-16835062874561.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508083839507.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508105126487.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508105624157.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508105637087.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508143642837.png">
<meta property="og:image" content="http://example.com/J5/image-20230508144405157.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508153214469.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508153238553.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508153303552.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508160041194.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508162216452.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508163604194.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508163753480.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508182313277.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508183501325.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508185808895.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508193519478.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508193533794.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508193547284.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230508210604846.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509081114868.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509082134522.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509082954384.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509085125392.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509142108471.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509154920761.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509161118772.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509163550937.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509163811644.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230509180655936.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230510101919593.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230510102108014.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230510110605591.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511144012726.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511151319223.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511152328296.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163529466.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163541846.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163640082.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163652416.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163706141.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163716860.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163732112.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163745405.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511163951063.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511165306052.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511165319688.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511165339651.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511170356933.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511170406799.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230511170417646.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230512090436547.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230512102422982.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230512140850527.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230512140907489.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230512140915597.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230704120423250.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230518135248836.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523141923963.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523142304073.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523145446009.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523145458269.png">
<meta property="og:image" content="http://example.com/J5/image-20230523145847126.png">
<meta property="og:image" content="http://example.com/J5/image-20230523145906154.png">
<meta property="og:image" content="http://example.com/J5/image-20230523145919210.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523145932256.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523154854692.png">
<meta property="og:image" content="http://example.com/J5/image-20230523154924792.png">
<meta property="og:image" content="http://example.com/J5/image-20230523154943236.png">
<meta property="og:image" content="http://example.com/2023/04/13/J5/image-20230523161450735.png">
<meta property="article:published_time" content="2023-04-13T07:49:21.000Z">
<meta property="article:modified_time" content="2023-07-04T04:04:28.595Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="ONNX">
<meta property="article:tag" content="J5">
<meta property="article:tag" content="ISP">
<meta property="article:tag" content="项目">
<meta property="article:tag" content="烧写镜像">
<meta property="article:tag" content="PTQ">
<meta property="article:tag" content="Docker">
<meta property="article:tag" content="嵌入式开发">
<meta property="article:tag" content="浮点模型转定点模型">
<meta property="article:tag" content="地平线">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/04/13/J5/image-20230413095502144.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/%E9%B1%BC.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/%E9%B1%BC.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/%E9%B1%BC.svg">
    <!--- Page Info-->
    
    <title>
        
            J5 -
        
        Airex-Daily
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/assets/fonts.css">

    <!--- Font Part-->
    
    
    
        <link href="" rel="stylesheet">
    
    
        <link href="" rel="stylesheet">
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"example.com","root":"/","language":"zh-CN"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":true,"family":null,"url":null},"english":{"enable":true,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fix","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-rry6gw.png"},"title":"伸手也握不住彩虹🌈","subtitle":{"text":["——我期待"],"hitokoto":{"enable":true,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/Airex-ai","instagram":null,"zhihu":null,"twitter":null,"email":"airex.yu@foxmail.com"}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":"https://music.163.com/song?id=1501530173&userid=253099352","cover":null}]},"mermaid":{"enable":true,"version":"9.3.0"}},"version":"2.1.5","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"About":{"icon":"fa-regular fa-user","submenus":{"Github":"https://github.com/Airex-ai?tab=repositories"}},"随记":{"icon":"fa-solid fa-tree-palm","path":"/masonry/"}},"search":{"enable":true,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"},"Categories":{"path":"/categories","icon":"fa-regular fa-folder"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}}};
    Global.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Airex-Daily
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        首页
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        归档
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-user"></i>
                                        
                                        关于&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://github.com/Airex-ai?tab=repositories">GITHUB
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/masonry/"  >
                                    
                                        
                                            <i class="fa-solid fa-tree-palm"></i>
                                        
                                        随记
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                        <li class="navbar-item search search-popup-trigger">
                            <i class="fa-solid fa-magnifying-glass"></i>
                        </li>
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div>
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                首页
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                归档
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-user"></i>
                                
                                关于&nbsp;<i class="fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://github.com/Airex-ai?tab=repositories">GITHUB</a>
                            </li>
                        
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/masonry/"  >
                             
                                
                                    <i class="fa-solid fa-tree-palm"></i>
                                
                                随记
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
             
                <div class="article-title">         
                    <img src="/images/J5.png" alt="J5" />
                    <h1 class="article-title-cover">J5</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/%E5%A4%B4%E5%83%8F.JPG">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Airex Yu</span>
                            
                                <span class="author-label">Lv3</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-04-13 15:49:21</span>
        <span class="mobile">2023-04-13 15:49</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-07-04 12:04:28</span>
            <span class="mobile">2023-07-04 12:04</span>
            <span class="hover-info">更新</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
                    </li>
                
                    <li>
                        &gt; <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/">自动驾驶</a>&nbsp;
                    </li>
                
                    <li>
                        &gt; <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/%E5%9C%B0%E5%B9%B3%E7%BA%BF/">地平线</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/ONNX/">ONNX</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/J5/">J5</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/ISP/">ISP</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E9%A1%B9%E7%9B%AE/">项目</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E7%83%A7%E5%86%99%E9%95%9C%E5%83%8F/">烧写镜像</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/PTQ/">PTQ</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Docker/">Docker</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%BC%80%E5%8F%91/">嵌入式开发</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E6%B5%AE%E7%82%B9%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%AE%9A%E7%82%B9%E6%A8%A1%E5%9E%8B/">浮点模型转定点模型</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/%E5%9C%B0%E5%B9%B3%E7%BA%BF/">地平线</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="J5-ISP软硬件总体介绍"><a href="#J5-ISP软硬件总体介绍" class="headerlink" title="J5 ISP软硬件总体介绍"></a><em>J5 ISP软硬件总体介绍</em></h1><h2 id="ISP名词解释"><a href="#ISP名词解释" class="headerlink" title="ISP名词解释"></a><em>ISP名词解释</em></h2><p><em><strong>ISP（Image Signal Processor）</strong>：是一种专门用于处理图像信号的芯片或软件模块，它通常用于数字相机、智能手机、平板电脑和其他各种图像设备中。ISP可以对从图像传感器中读取的原始图像数据进行处理，包括去噪、白平衡、色彩校正、曝光控制、锐化和其他一些图像处理算法，以产生更高质量的图像。ISP还可以支持不同的图像格式和压缩算法，以便在存储和传输图像时节省带宽和存储空间。在现代数字相机和智能手机中，ISP是一个非常重要的组成部分，它可以帮助用户轻松地拍摄高质量的照片和视频。</em></p>
<p><em><strong>Camera Interface Manager（相机接口管理器）</strong>：是一种软件组件，它负责管理设备上的相机硬件和应用程序之间的通信。它提供了一个接口，让应用程序可以访问设备上的相机，并控制它的各种功能，如焦距、曝光、闪光灯等。此外，相机接口管理器还可以处理相机硬件和软件之间的兼容性问题，确保相机硬件能够与应用程序正常通信。</em></p>
<p><em><strong>PYM（Pyramid）</strong>：Pyramid是一个流行的Python Web框架。它是一个开源的框架，使用简单，适用于开发各种规模的Web应用程序。Pyramid的特点之一是它的灵活性，它允许开发人员使用各种工具和库来构建Web应用程序。Pyramid还具有可扩展性和可定制性，因此可以根据需要进行自定义配置和扩展。</em></p>
<p><em><strong>VPS（Video Processing System）（视频处理系统）</strong>：是一种用于处理视频信号的计算机系统或设备。它通常由硬件和软件组成，可以对视频信号进行不同的操作，例如编码、解码、压缩、解压、滤波、降噪、增强、分析和渲染等。</em></p>
<p><em><strong>DRCD：</strong>Dynamic Range Compression（动态范围压缩）和Dynamic Range Decompression（动态范围解压）是一种信号处理技术，通常用于音频和视频处理中。在音频处理中，Dynamic Range Compression被用来控制音量的变化，使得音频中的响度变化更加平滑，从而提高音频的质量。在视频处理中，Dynamic Range Compression被用来控制亮度的变化，使得视频中的亮度变化更加平滑，从而提高视频的质量。</em></p>
<ul>
<li><p><em>Dynamic Range Compression的主要思想是通过压缩信号的动态范围来控制信号的响度变化。具体来说，它会将信号的较大幅度部分压缩到较小的幅度范围内，从而使得整个信号的动态范围变小。这样做的好处是可以使得信号的响度变化更加平滑，从而提高信号的质量。</em></p>
</li>
<li><p><em>Dynamic Range Decompression则是将压缩后的信号恢复到原来的动态范围。这个过程通常是通过对压缩后的信号进行放大来实现的。</em></p>
</li>
<li><p><em>在音频处理中，Dynamic Range Compression和Dynamic Range Decompression通常被用来控制音频的响度变化，从而提高音频的质量。在视频处理中，Dynamic Range Compression和Dynamic Range Decompression则被用来控制视频的亮度变化，从而提高视频的质量。</em></p>
</li>
</ul>
<p><em><strong>Color Correction Matrix：</strong>在计算机编程中，Chromatic Aberration（色差）是指透镜或镜头无法将所有颜色的光线聚焦在同一点上，从而导致图像出现色差。Chromatic Aberration Correction（色差校正）是一种技术，旨在通过对图像进行处理来减少或消除色差的影响。在图像处理中，色差校正可以通过对图像进行后期处理来实现。这通常涉及到对图像进行颜色平衡，即调整图像中不同颜色的亮度和饱和度，以便它们看起来更加自然和平衡。此外，一些图像处理软件还提供了特定的工具，例如Adobe Photoshop中的Lens Correction（镜头校正）工具，可以帮助用户减少或消除色差。</em></p>
<p><em><strong>Color Correction Matrix：</strong>在计算机编程中，Color Correction Matrix（颜色校正矩阵）是一种用于调整图像颜色的技术。它通常用于在显示器或打印机等设备上校正颜色，以便它们能够更准确地显示或打印颜色。Color Correction Matrix是一个矩阵，通常是3x3的，用于将输入图像的RGB值转换为输出图像的RGB值。这个矩阵可以根据需要进行调整，以实现不同的颜色校正效果。例如，可以使用Color Correction Matrix来增加或减少图像中的红色、绿色或蓝色成分，或者调整亮度和对比度等。在实际应用中，Color Correction Matrix通常作为图像处理库或软件中的一个选项提供，例如Adobe Photoshop或GIMP等。程序员可以使用这些库或软件来创建自己的Color Correction Matrix，或者使用预定义的矩阵来实现特定的颜色校正效果。</em></p>
<p><em><strong>Color Space Conversion：</strong>在计算机编程中，Color Space Conversion（颜色空间转换）是指将一种颜色空间中的颜色值转换为另一种颜色空间中的颜色值的过程。颜色空间是一种用于表示颜色的数学模型，它定义了一组颜色值及其在色彩空间中的排列方式。常见的颜色空间包括RGB、CMYK、HSV、HSL等。RGB是一种基于红、绿、蓝三原色构成的颜色空间，常用于显示器、照明等领域；CMYK是一种基于青、品红、黄、黑四种颜料构成的颜色空间，常用于印刷领域；HSV和HSL则是一种基于色相、饱和度、亮度或明度的颜色空间，常用于图形处理等领域。颜色空间转换在很多领域都有应用，例如图像处理、计算机视觉、计算机图形学等。在编程中，我们可以使用各种编程语言和库来实现颜色空间转换，例如Python中的OpenCV库、Java中的Java Advanced Imaging库等。</em></p>
<p><em><strong>Mutil-Context backend：</strong>在计算机编程中，Multi-Context backend是指一种支持在多个上下文环境中执行计算的后端。这种后端通常用于处理大规模的计算任务，例如深度学习模型训练。在深度学习中，通常使用图形计算框架（如TensorFlow或PyTorch）来定义计算图，然后使用后端来执行计算。Multi-Context backend具有多个上下文环境，可以同时执行多个计算图，从而提高计算效率。例如，可以将多个小型模型放在同一块GPU上执行，或者将一个大型模型拆分成多个部分，分别在多个GPU上执行。Multi-Context backend通常需要硬件支持，例如多GPU、多核CPU或分布式系统。在使用Multi-Context backend时，需要仔细设计计算图和任务分配，以充分利用硬件资源并避免瓶颈。</em></p>
<h2 id="ISP-pipeline介绍"><a href="#ISP-pipeline介绍" class="headerlink" title="ISP pipeline介绍"></a><em>ISP pipeline介绍</em></h2><h3 id="J5流程"><a href="#J5流程" class="headerlink" title="J5流程"></a><em>J5流程</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413095502144.png"
                      class="" title="image-20230413095502144"
                ></em></p>
<h3 id="J5-ISP-feature"><a href="#J5-ISP-feature" class="headerlink" title="J5 ISP feature"></a><em>J5 ISP feature</em></h3><p><em>1、支持Online&#x2F;Offline并行多样格式的数据输出。、</em></p>
<p><em>2、支持输入&#x2F;输出数据Crop功能。</em></p>
<p><em>3、支持Sensor Linear模式、Sensor Native(built-in)宽动态模式、以及支持最大4:1的HDR模式。</em></p>
<p><em>4、支持多类型的CFA pattern: RGGB, RCCC,RGBIR, RCCB,RYYCy,and RCCG</em></p>
<p><em>5、支持灵活多样的statistics data，包括:9 instances of 1024-bin fixed histograms、1 instance of an AE 5-bin configurable histogram、1 instance of an AWB ratio meter、16 instances of ROl pixel croppers。</em></p>
<p><em>6、支持Spatial NR(sinter)、Local&#x2F;Global Tone-mapping Engine(iridix)、Gamma、Chromatic Aberration Correction、Colour Correction Matrix、Green Equalisation、Shading Correction、Defect Pixel Correction. Black Level Correction、Digital Gain、White Balance等ISP处理功能。</em></p>
<p><em>7、ISP支持Function safety相关功能，包括BIST(Built in self-test)、Continuous Checking with Dedicated Safety Circuits、Fault Report等。</em></p>
<h3 id="J5-ISP性能"><a href="#J5-ISP性能" class="headerlink" title="J5 ISP性能"></a><em>J5 ISP性能</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413100008288.png"
                      class="" title="image-20230413100008288"
                ></em></p>
<h2 id="ISP硬件原理"><a href="#ISP硬件原理" class="headerlink" title="ISP硬件原理"></a><em>ISP硬件原理</em></h2><h3 id="ISP工作原理"><a href="#ISP工作原理" class="headerlink" title="ISP工作原理"></a><em>ISP工作原理</em></h3><ol>
<li><em>ISP通过MCFE进行多路调度raw data进ISP pipeline处理，可以是从input中调入，也可以是从Raw buffer中调入</em></li>
<li><em>MCBE控制ISP的DDR输出和output输出</em></li>
<li><em>MCFE控制多路ISP配置的切换</em></li>
<li><em>多路数据流的ISP配置相互独立，寸于cdma_space</em></li>
<li><em>当需要处理某路数据流时，ISP先load对应的cdma space到register space，处理完该路数据时，将相应的statistics从register space写到cdma space</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413100641601.png"
                      class="" title="image-20230413100641601"
                ></em></p>
<h3 id="ISP调度模式"><a href="#ISP调度模式" class="headerlink" title="ISP调度模式"></a><em>ISP调度模式</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413100847090.png"
                      class="" title="image-20230413100847090"
                ></em></p>
<h3 id="ISP典型中断时序"><a href="#ISP典型中断时序" class="headerlink" title="ISP典型中断时序"></a><em>ISP典型中断时序</em></h3><p><em>FE_START：图片的一帧的第一行流经该位置产生的中断</em></p>
<p><em>FE_END：图片的一帧流经最后一行流经该位置产生的终端</em></p>
<p><em>注意：CIM_DMA不经过pipeline，所以不会产生上述中断</em></p>
<p><em>与上述描述类似，输出图片的一帧的第一行流经的位置产生的中断称为BE_START，最后一行流经的位置产生的中断称为BE_END</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413101558584.png"
                      class="" title="image-20230413101558584"
                ></em></p>
<h2 id="ISP软件架构"><a href="#ISP软件架构" class="headerlink" title="ISP软件架构"></a><em>ISP软件架构</em></h2><h3 id="ISP-软件架构overview"><a href="#ISP-软件架构overview" class="headerlink" title="ISP 软件架构overview"></a><em>ISP 软件架构overview</em></h3><p><em>ISP软件firmware包括：</em></p>
<ol>
<li><em>ISP driver：实现对isp hardware的访问、isp调度管理、isp中断处理、buffer管理、calibration加载、sensor回调、isp fsm处理、tuning  tool connection、ISP工作线程、ISP回灌与dump、功能安全、ISP debug等</em></li>
<li><em><strong>ISP hal（API库）</strong>：实现ISP API LIB、2A LIB、Calibration LIB、Tuning server等</em></li>
<li><em>ISP user：实现对VPS interface提供API，以及对user app提供ISP API，为用户提供ISP控制接口</em></li>
<li><em>Tuning tool：tuning tool包括Control Tool、Calibration Tool、Hobotplaer</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413102356479.png"
                      class="" title="image-20230413102356479"
                ></em></p>
<h3 id="ISP软件feature"><a href="#ISP软件feature" class="headerlink" title="ISP软件feature"></a><em>ISP软件feature</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413102619436.png"
                      class="" title="image-20230413102619436"
                ></em></p>
<h3 id="ISP软件数据流与控制流"><a href="#ISP软件数据流与控制流" class="headerlink" title="ISP软件数据流与控制流"></a><em>ISP软件数据流与控制流</em></h3><ol>
<li><p><em>Tuning tool提供对sensor、hw、sw的访问</em></p>
</li>
<li><p><em>ISP SW与CIM_DMAi提供raw buffer交换、</em></p>
</li>
<li><p><em>ISP SW与PYM提供frame id &amp; timestamps的传递以及多路对应参数的同步交换、</em></p>
</li>
<li><p><em>ISP SW为VPS &amp; user APP提供访问接口</em></p>
</li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413103326548.png"
                      class="" title="image-20230413103326548"
                ></em></p>
<h3 id="ISP-firmware相互关系"><a href="#ISP-firmware相互关系" class="headerlink" title="ISP firmware相互关系"></a><em>ISP firmware相互关系</em></h3><ol>
<li><p><em>PC端运行Hobotplayer、Control Tool、Calibration tool。</em></p>
<ul>
<li><p><em>Hobotplayer通过VPS Streaming获取数据流、实现在线显示、snapshot、统计数据分析等功能</em></p>
</li>
<li><p><em>Control Tool通过Tuning package访问Tuning server，实现对ISP的在线调试</em></p>
</li>
</ul>
</li>
<li><p><em>J5 board运行VPS Streaming、Tuningpackage等应用</em></p>
</li>
<li><p><em>ISP SW为VPS Streaming、Tuning package提供ISP各项tuning 所需功能</em></p>
</li>
</ol>
<h2 id="ISP软件流程"><a href="#ISP软件流程" class="headerlink" title="ISP软件流程"></a><em>ISP软件流程</em></h2><h3 id="ISP软件初始化与工作流程"><a href="#ISP软件初始化与工作流程" class="headerlink" title="ISP软件初始化与工作流程"></a><em>ISP软件初始化与工作流程</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413104118516.png"
                      class="" title="image-20230413104118516"
                ></em></p>
<h3 id="ISP-2A-amp-ISP-kernel-drv的交互流程"><a href="#ISP-2A-amp-ISP-kernel-drv的交互流程" class="headerlink" title="ISP 2A &amp; ISP kernel drv的交互流程"></a><em>ISP 2A &amp; ISP kernel drv的交互流程</em></h3><ol>
<li><em>ISP kernel drv通过sbuf上送统计数据给2A</em>  </li>
<li><em>2A算法利用统计数据计算2A调target，并通过uf下发计算结果给ISP kernel drv</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413104411602.png"
                      class="" title="image-20230413104411602"
                ></em></p>
<h3 id="ISP对外API使用流程"><a href="#ISP对外API使用流程" class="headerlink" title="ISP对外API使用流程"></a><em>ISP对外API使用流程</em></h3><ol>
<li><em>ISP API为用户应用提供接口，实现用户应用对ISP的访问与控制</em></li>
<li><em>对外API的访问与数据流控制进程可以分离，方便用户多进程访问</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413104718792.png"
                      class="" title="image-20230413104718792"
                ></em></p>
<h3 id="ISP对外API"><a href="#ISP对外API" class="headerlink" title="ISP对外API"></a><em>ISP对外API</em></h3><p><em><strong>1切换2A模式为auto，2切换2A模式 为manual。需要调2A的参数时，需要将2A模式切换为manual</strong></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413104835498.png"
                      class="" title="image-20230413104835498"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413105227373.png"
                      class="" title="image-20230413105227373"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413105748121.png"
                      class="" title="image-20230413105748121"
                ></em></p>
<h3 id="JSP在线tuning流程"><a href="#JSP在线tuning流程" class="headerlink" title="JSP在线tuning流程"></a><em>JSP在线tuning流程</em></h3><ol>
<li><em>PC端运行Control Tool，通过GUI界面进行tuning操作，并通过Ethernet下发访问控制命令，访问J5 ISP</em></li>
<li><em>Hobotplayer通过Ethernet获取数据流、实现在线显示，snapshot、统计数据分析等功能</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413110012436.png"
                      class="" title="image-20230413110012436"
                ></em></p>
<h1 id="J5-ISP系统驱动实现介绍"><a href="#J5-ISP系统驱动实现介绍" class="headerlink" title="J5 ISP系统驱动实现介绍"></a><em>J5 ISP系统驱动实现介绍</em></h1><h2 id="ISP驱动软件整体框架"><a href="#ISP驱动软件整体框架" class="headerlink" title="ISP驱动软件整体框架"></a><em>ISP驱动软件整体框架</em></h2><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413141440552.png"
                      class="" title="image-20230413141440552"
                ></em></p>
<h3 id="ISP驱动框架"><a href="#ISP驱动框架" class="headerlink" title="ISP驱动框架"></a><em>ISP驱动框架</em></h3><ul>
<li><em>ISP driver负责加载ISP系统资源，并通过api实现对ISP状态机的轮转，确保系统正常运行</em></li>
<li><em>同时支持control tools或者通过command api实现对ISP软硬件控制</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413141950166.png"
                      class="" title="image-20230413141950166"
                ></em></p>
<h3 id="ISP-设备接入总体通路"><a href="#ISP-设备接入总体通路" class="headerlink" title="ISP 设备接入总体通路"></a><em>ISP 设备接入总体通路</em></h3><ul>
<li><em>支持local sensor和remote sensor两种连接方式接入ISP，接入的方式不同处理的流程也不一样。具体来说local sensor的数据要通过input放到raw buffer；而Rremote sensor会直接将数据放到buffer中</em></li>
<li><em>通过建立client&#x2F;server socket通信，支持control tools的tuning调试</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413142430330.png"
                      class="" title="image-20230413142430330"
                ></em></p>
<blockquote>
<p><em>local  sensor的数据处理流程</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413142924688.png"
                      class="" title="image-20230413142924688"
                ></em></p>
<p><em>注意：ISP out buffer：除了支持单独的数据输出外，还可支持同时输入raw和YUV数据，便于调试问题</em></p>
<h2 id="ISP驱动事件、状态机、线程调度介绍"><a href="#ISP驱动事件、状态机、线程调度介绍" class="headerlink" title="ISP驱动事件、状态机、线程调度介绍"></a><em>ISP驱动事件、状态机、线程调度介绍</em></h2><h3 id="ISP驱动中断事件"><a href="#ISP驱动中断事件" class="headerlink" title="ISP驱动中断事件"></a><em>ISP驱动中断事件</em></h3><p><em>ISP支持的中断如下图：</em></p>
<ul>
<li><em>实际上只使用了mcfe和mcbe的中断</em></li>
<li><em>统计数据的中断挂载在mcbe end中一起触发事件。<strong>打开以后会增加cpu的负担</strong></em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413143449313.png"
                      class="" title="image-20230413143449313"
                ></em></p>
<p><em>ISP的事件如下图：</em></p>
<p><em>ISP的工作通过事件来推动各模块的状态机轮转</em></p>
<p><em>后台线程每隔1ms或者有信号来时会处理event queue事件，通过事件推动ISP所有模块的状态机轮转</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413143747621.png"
                      class="" title="image-20230413143747621"
                ></em></p>
<h3 id="ISP-FSM状态机轮转"><a href="#ISP-FSM状态机轮转" class="headerlink" title="ISP FSM状态机轮转"></a><em>ISP FSM状态机轮转</em></h3><ul>
<li><em>下图的状态机仅是基础的状态机</em></li>
<li><em>初始化过程会将每个子模块的状态推进ready状态后，ISP则可实时的对输入的数据进行处理</em></li>
<li><em>每个子模块的状态机不完全一致</em></li>
<li><em>只有模块需要调整的时候才在对应状态机下进行处理</em></li>
</ul>
<p> <em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413144303859.png"
                      class="" title="image-20230413144303859"
                ></em></p>
<h3 id="ISP事件轮转"><a href="#ISP事件轮转" class="headerlink" title="ISP事件轮转"></a><em>ISP事件轮转</em></h3><ul>
<li><em>事件的轮转是同ing过软件的方式来实现</em></li>
<li><em>软件根据收到的事件响应对应的处理流程】</em></li>
<li><em>图中以初始化和MCBE END事件举例说明</em></li>
</ul>
<p><em>流程：ISP Driver会首先通过config和start事件初始化HW和reload  calibration，再通过其他事件对sensor或者buffer等进行调整</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413145208674.png"
                      class="" title="image-20230413145208674"
                ></em></p>
<h3 id="ISP驱动线程"><a href="#ISP驱动线程" class="headerlink" title="ISP驱动线程"></a><em>ISP驱动线程</em></h3><ul>
<li><p><em>ISP初始化后，除了运行的主线程外还会运行3个后台线程：isp_process_thread，isp_connection_thread，中断下半部线程（进行阻塞自检）</em></p>
</li>
<li><p><em>ISP_process_thread线程由信号量驱动，会每隔1ms从message queue获取event并对event进行处理</em></p>
</li>
<li><p><em>isp_connect_thread：初始化socket，并监听端口信息，当收到信息后，解析并处理信息，主要是给control tool使用的</em></p>
</li>
<li><p><em>中断下半部线程会根据中断事件下发不同的event给isp process thread进行处理</em></p>
</li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413145942257.png"
                      class="" title="image-20230413145942257"
                ></em></p>
<h2 id="ISP内存管理"><a href="#ISP内存管理" class="headerlink" title="ISP内存管理"></a><em>ISP内存管理</em></h2><h3 id="ISP驱动内存空间"><a href="#ISP驱动内存空间" class="headerlink" title="ISP驱动内存空间"></a><em>ISP驱动内存空间</em></h3><ul>
<li><em>ISP内存使用主要有2部分：存放数据的buffer，存放不同slot的配置的CDMA控制内存</em></li>
<li><em>数据buffer：</em><ul>
<li><em>raw  buffer和output buffer，通过ion的方式分配出来，分配的个数与模式一一对应</em></li>
<li><em>Passthru模式为online模式，不需要申请raw buffer，output buffer可配置</em></li>
<li><em>local sensor通路需要raw buffer2快，output buffer可配置</em></li>
<li><em>remote sensor通路需要raw buffer8块，涉及到前几模块的轮转，output buffer可配置</em></li>
</ul>
</li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413150709408.png"
                      class="" title="image-20230413150709408"
                ></em></p>
<ul>
<li><em><strong>CDMA：</strong></em><ul>
<li><em>通过ION buffer，驱动加载时分配</em> </li>
<li><em>单个ISP可以支持8路数据，每一路数据会有一个私有的cdma空间</em></li>
<li><em>用于在ISP对不同的ctx进行切换处理时，存放处理当前对应ctx的寄存器空间值</em></li>
</ul>
</li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413151331021.png"
                      class="" title="image-20230413151331021"
                ></em></p>
<h2 id="ISP数据处理流程"><a href="#ISP数据处理流程" class="headerlink" title="ISP数据处理流程"></a><em>ISP数据处理流程</em></h2><h3 id="ISP统计数据更新流程"><a href="#ISP统计数据更新流程" class="headerlink" title="ISP统计数据更新流程"></a><em>ISP统计数据更新流程</em></h3><p><em>数据通路流程：</em></p>
<ol>
<li><em>统计数据中断事件上报后会触发对应的软件事件，ISP process queue会处理对应的事件</em></li>
<li><em>2a通过sbuf read到对应的数据后进行计算，计算完成后通过write对应结果，同时触发对应的事件</em></li>
<li><em>事件推动后续的流程最终通过注册的sensor callback函数将结果下发到sensor Hw</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413152206939.png"
                      class="" title="image-20230413152206939"
                ></em></p>
<h3 id="ISP-command-API流程（推动事件，添加事件）"><a href="#ISP-command-API流程（推动事件，添加事件）" class="headerlink" title="ISP command API流程（推动事件，添加事件）"></a><em>ISP command API流程（推动事件，添加事件）</em></h3><ul>
<li><em>context_params.c中出注册了所有支持的api数据</em></li>
<li><em>每个对象包含如下参数</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413153249502.png"
                      class="" title="image-20230413153249502"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413153256246.png"
                      class="" title="image-20230413153256246"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413153545992.png"
                      class="" title="image-20230413153545992"
                ></em></p>
<h3 id="ISP-command-api类型"><a href="#ISP-command-api类型" class="headerlink" title="ISP command api类型"></a><em>ISP command api类型</em></h3><ul>
<li><em>Command api中的id时需要转换的，如果需要额外添加command api的转换的关系如下</em></li>
<li><em>对外暴露的接口为command list，command list通过id转换函数，将对应的id转化能ISP id或者context id</em></li>
<li><em>将获取到的对应的id调用不同的方法进行设置和处理</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413154243974.png"
                      class="" title="image-20230413154243974"
                ></em></p>
<h3 id="ISP驱动处理时序流程"><a href="#ISP驱动处理时序流程" class="headerlink" title="ISP驱动处理时序流程"></a><em>ISP驱动处理时序流程</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413154841706.png"
                      class="" title="image-20230413154841706"
                ></em></p>
<h1 id="J5-Tuning准备工作介绍"><a href="#J5-Tuning准备工作介绍" class="headerlink" title="J5 Tuning准备工作介绍"></a><em>J5 Tuning准备工作介绍</em></h1><h2 id="AE-x2F-AWB介绍"><a href="#AE-x2F-AWB介绍" class="headerlink" title="AE&#x2F;AWB介绍"></a><em>AE&#x2F;AWB介绍</em></h2><h3 id="统计数据"><a href="#统计数据" class="headerlink" title="统计数据"></a><em>统计数据</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413155947281.png"
                      class="" title="image-20230413155947281"
                ></em></p>
<p><em>AWB 、AE-5bin数据：分块数据，可以从多个节点输出，且具有不同的特性</em></p>
<p><em>AE-1024bin：分块分配权重，从而控制不同的测光模式</em></p>
<h3 id="AE介绍"><a href="#AE介绍" class="headerlink" title="AE介绍"></a><em>AE介绍</em></h3><p><em>自动曝光算法的目的是根据场景的光线条件自动调整摄像机的曝光时间，以获得最佳的图像质量。</em></p>
<ol>
<li><em>获取统计数据</em></li>
<li><em>估计当前画面亮度</em></li>
<li><em>调整当前target目标</em></li>
<li><em>根据target及画面亮度计算ev值</em></li>
<li><em>根据补充调整ev值</em></li>
<li><em>根据partion_lut表分配gain和line</em></li>
<li><em>控制sensor曝光</em></li>
</ol>
<p><em><strong>注意：AE曝光参数写触发条件为frame_start（图片来的时候），frame_out获取统计数据</strong></em> </p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413160926541.png"
                      class="" title="image-20230413160926541"
                ></em></p>
<h3 id="AE测光方式"><a href="#AE测光方式" class="headerlink" title="AE测光方式"></a><em>AE测光方式</em></h3><p><em>将画面分成M</em>N个小区块，每个区域可以设置不同的权重进行直方图统计（根据权重重复统计，0表示不参与统计，1代表统计1次，2代表统计2次，以此类推，<strong>但15表示统计16次</strong>），用户修改不同的权重达到修改测光方式目的。测光方式可选：中心测光，平均测光，区域测光。*</p>
<p><em>注意：J5最多支持15</em>15分块，<strong>区域中的每一个小块有不同的权重，通过调整各个小块的权重来调整测光方式</strong>*</p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413162559842.png"
                      class="" title="image-20230413162559842"
                ></em></p>
<h3 id="AWB介绍"><a href="#AWB介绍" class="headerlink" title="AWB介绍"></a><em>AWB介绍</em></h3><p><em>自动白平衡（AWB）算法是一种用于数字图像处理中的算法，旨在消除图像中的颜色偏差，使其看起来更自然。</em></p>
<p><em>awb计算方法：</em></p>
<ol>
<li><em>根据预先标定参数确定白点权重（<strong>计算图像中亮度最高的区域的RGB值的平均值</strong>）</em></li>
<li><em>根据统计和权重计算rgain和bgain（<strong>根据白平衡点的值来计算每个通道的增益</strong>）</em></li>
<li><em>根据rgain和bgain计算cct（<strong>将每个通道的增益应用于图像中的像素</strong>）</em></li>
</ol>
<p><em>注意：</em></p>
<p><em>(1)rgbgw由mesh_rgbg_weight插值得到的权重</em></p>
<p><em>(2)s.由mesh_ls_ weight插值得到的权重</em></p>
<p><em><strong>(3)cct由mesh_color_temper插值得到的色温</strong></em></p>
<p><em>(4)用户可以通过修改calibration切换选择isp-awb&#x2F;sensor-awb</em></p>
<p><em>(5)AMB算法计算的rgain&#x2F;bgain为4.8format,256表示1x</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413164354215.png"
                      class="" title="image-20230413164354215"
                ></em></p>
<h2 id="sensor驱动开发和验证"><a href="#sensor驱动开发和验证" class="headerlink" title="sensor驱动开发和验证"></a><em>sensor驱动开发和验证</em></h2><h3 id="sensor驱动实现"><a href="#sensor驱动实现" class="headerlink" title="sensor驱动实现"></a><em>sensor驱动实现</em></h3><p><em>对于RAW类型的模组，还需进行tuning适配，实现AE&#x2F;AWB等控制功能，以配合ISP完成效果调节。VIN提供有2种机制，根据sensor功能选择并实现。</em></p>
<p><em>驱动层控制：标准化控制方式（LUT配置形式）：Sensor初始化时ioctl下发sensor_trning_dat_t；</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413190222405.png"
                      class="" title="image-20230413190222405"
                ></em></p>
<p><em>用户层控制：定制化控制方式（API操作形式）：Sensor库userpace_control使能并实现API</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413190239065.png"
                      class="" title="image-20230413190239065"
                ></em></p>
<h3 id="sensor驱动介绍"><a href="#sensor驱动介绍" class="headerlink" title="sensor驱动介绍"></a><em>sensor驱动介绍</em></h3><p> <em>类型一：该类型sensor仅需要设置长帧（或短帧）的line和gain，其他帧的曝光参数根据固定的ratio计算且awd不需要考虑不同色温下调整参数。该型sensor建议使用驱动层控制方式</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413191906143.png"
                      class="" title="image-20230413191906143"
                ></em></p>
<p><em>类型二：该类型sensor需要设置的三帧的line和gain都需要用户设置，其他帧的曝光参数根据长帧或短帧根据一定的计算方式得出，或awd需要考虑不同色温下调整参数。该型sensor建议使用用户层控制方式</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413191917441.png"
                      class="" title="image-20230413191917441"
                ></em></p>
<p><em><strong>sensor驱动有一些关键字段表征该sensor在该配置下的硬件特性，ISP使用驱动时必须遵循以下参数</strong></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413192524229.png"
                      class="" title="image-20230413192524229"
                ></em></p>
<h3 id="驱动层控制实现"><a href="#驱动层控制实现" class="headerlink" title="驱动层控制实现"></a><em>驱动层控制实现</em></h3><p> <em><strong>驱动层控制sensor-ae&#x2F;awd需要建立isp算法计算得出的ae&#x2F;awd参数与sensor寄存器映射转换</strong></em></p>
<p><em>sensor lut表：不同gain_index对应的寄存器值，again_index取值范围[0，255]，的gainindex取值范围[0,255]</em></p>
<p><em>sensor line配置：行转换寄存器值计算方式（<strong>将ae的行参数转换为sensor实际的寄存器参数</strong>）：*<em>x表示ae算法计算的曝光行，y表示该行对应的寄存器参数</em></em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413193303925.png"
                      class="" title="image-20230413193303925"
                >*</p>
<h3 id="用户层控制实现"><a href="#用户层控制实现" class="headerlink" title="用户层控制实现"></a><em>用户层控制实现</em></h3><p><em>API函数：</em></p>
<ul>
<li><em>module：名称字符串，用于区分不同的sensor</em><ul>
<li><em>userpace_control：使能hal层控制模块</em></li>
<li><em>aexp_line_gain_control：hal层ae控制，获取短帧（长帧）的控制参数gain和line，转换为sensor控制参数</em></li>
<li><em>wb_cct_control：hal层awb控制，获取awb信息转换为sensor控制参数</em></li>
<li><em>注意：aexp_line_gain_control和wb_cct_control函数的长帧&#x2F;短帧需要tuning策略决定，计算方式需要fae提供手册</em></li>
</ul>
</li>
</ul>
<h3 id="sensor驱动验证"><a href="#sensor驱动验证" class="headerlink" title="sensor驱动验证"></a><em>sensor驱动验证</em></h3><p> <em>驱动层实现或用户层实现控制后，需要对AE驱动和AWB驱动的运行结果进行验证</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413202351846.png"
                      class="" title="image-20230413202351846"
                ></em></p>
<h2 id="Tuning工具使用介绍"><a href="#Tuning工具使用介绍" class="headerlink" title="Tuning工具使用介绍"></a><em>Tuning工具使用介绍</em></h2><p><em>tuning工具包括calibration tool。control tool和Hobotplayer工具</em></p>
<ul>
<li><em>Calibration Tool 工具为静态标定工具，用于参数标定生成static.json</em></li>
<li><em>Control Tool为在线调试工具，用户使用该工具查看&#x2F;修改参数</em></li>
<li><em>HobotPlayer为在线调试工具，用户使用该工具查看实施效果，保存图像</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413203431146.png"
                      class="" title="image-20230413203431146"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413203610737.png"
                      class="" title="image-20230413203610737"
                ></em></p>
<h3 id="Control-Tool"><a href="#Control-Tool" class="headerlink" title="Control Tool"></a><em>Control Tool</em></h3><p><em>模块：</em></p>
<ul>
<li><em>Hardware：查看&#x2F;修改各子模块参数</em></li>
<li><em>API：查看&#x2F;修改Fireware参数</em></li>
<li><em>Calibration：查看&#x2F;修改Calibration-lut参数</em></li>
</ul>
<p><em>功能描述：</em></p>
<ul>
<li><em>参数保存：存储hardware寄存器参数、存储Fireware API参数、存储calibration-lut表</em></li>
<li><em>页面重建：Upload New XML File；Upload New Software APi</em></li>
<li><em>索引：搜索关键词</em></li>
<li><em>标记：标记相关项，在标记页统一显示</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413205313414.png"
                      class="" title="image-20230413205313414"
                ></em></p>
<h3 id="HobotPlayer"><a href="#HobotPlayer" class="headerlink" title="HobotPlayer"></a><em>HobotPlayer</em></h3><p><em>用于实时查看视频流数据，同时包含简单的数据分析功能</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413205449483.png"
                      class="" title="image-20230413205449483"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413205457968.png"
                      class="" title="image-20230413205457968"
                ></em></p>
<h2 id="Tuning参数部署"><a href="#Tuning参数部署" class="headerlink" title="Tuning参数部署"></a><em>Tuning参数部署</em></h2><h3 id="Tuning参数"><a href="#Tuning参数" class="headerlink" title="Tuning参数"></a><em>Tuning参数</em></h3><p><em>ISP算法使用lut表记录调试参数，不同调试参数具有不同命名</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413205808655-16813906889561.png"
                      class="" title="image-20230413205808655"
                ></em></p>
<p><em>注意：</em></p>
<ol>
<li><em>value种元素的个数等于row</em>cols*</li>
<li><em>width字段的数据格式需要与系统匹配，不可任意修改</em></li>
<li><em>参数获取：</em><ul>
<li><em>根据字段含义，修改</em>_ static.json和 <em>_ dymanic.json</em></li>
<li><em>通过control_tool导出调试完成的calibration参数</em></li>
</ul>
</li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413210047533.png"
                      class="" title="image-20230413210047533"
                ></em></p>
<h3 id="Tuning参数编译"><a href="#Tuning参数编译" class="headerlink" title="Tuning参数编译"></a><em>Tuning参数编译</em></h3><ul>
<li><em>编译目录：<code>j5_dvb/hbre/libisp/j5/tuning/caldata/generate_lib</code></em></li>
<li><em>编译准备：control_tool导出的文件名称称为dynamic.json和static.json，编译时系统会索引参数库名称的前缀命名动态库名称</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413210614098.png"
                      class="" title="image-20230413210614098"
                ></em></p>
<ul>
<li><em>编译检查：参数编译时会自动检查calibration_width定义是否正确，当定义不正确时需要手动修改，避免影响系统稳定性。用户执行make后需要检查编译log是否包含error错误</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230413210812784.png"
                      class="" title="image-20230413210812784"
                ></em></p>
<h3 id="Tuning参数部署-1"><a href="#Tuning参数部署-1" class="headerlink" title="Tuning参数部署"></a><em>Tuning参数部署</em></h3><ul>
<li><em>参数部署：编译完成参数库lib</em>.so后放入J5板侧（board），在启动json中指定绝对路径和参数库名称（vpm_config.json中的ISP配置部分）并开启功能（calib_mode&#x3D;1），系统启动时则自动加载该calibration参数库*</li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414081802204-16814314824862.png"
                      class="" title="image-20230414081802204"
                ></em></p>
<ul>
<li><em>参数核对：系统启动后打开control_tool工具查看version_info，检查是否是用户指定的参数库</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414081944807.png"
                      class="" title="image-20230414081944807"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414082107058.png"
                      class="" title="image-20230414082107058"
                ></em></p>
<h1 id="Tuning实战经验分享"><a href="#Tuning实战经验分享" class="headerlink" title="Tuning实战经验分享"></a><em>Tuning实战经验分享</em></h1><h2 id="ISP-Feature-x2F-Pipeline及客观矫正"><a href="#ISP-Feature-x2F-Pipeline及客观矫正" class="headerlink" title="ISP Feature&#x2F;Pipeline及客观矫正"></a><em>ISP Feature&#x2F;Pipeline及客观矫正</em></h2><h3 id="ISP-Feature"><a href="#ISP-Feature" class="headerlink" title="ISP Feature"></a><em>ISP Feature</em></h3><ul>
<li><em>内置图像信号处理器(Isp)支持RAW到YUV转换</em></li>
<li><em>高动态范围(HDR)传感器支持</em><ul>
<li><em>数字重叠(DOL)HDR传感器支持(最多4次曝光)</em></li>
<li><em>线性化HDR传感器支持</em></li>
<li><em>原生(on传感器)压缩HDR传感器支持</em></li>
</ul>
</li>
<li><em>支持自动曝光，自动白平衡，直方图统计</em></li>
<li><em>支持数字动态</em></li>
<li><em>支持镜头阴影校正</em></li>
<li><em>支持缺陷像素校正(DPC)</em></li>
<li><em>支持空间降噪(SINTER)</em></li>
<li><em>支持锐化和边缘增强</em></li>
<li><em>支持伽玛校正</em></li>
<li><em>在PC机上支持GDC和FISHEYE校正ISP调优工具</em></li>
</ul>
<h3 id="ISP-Algorithm-block-diagram-part"><a href="#ISP-Algorithm-block-diagram-part" class="headerlink" title="ISP Algorithm block diagram-part"></a><em>ISP Algorithm block diagram-part</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414090204749.png"
                      class="" title="image-20230414090204749"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414090744026.png"
                      class="" title="image-20230414090744026"
                ></em></p>
<h3 id="J5-调试环境及基本操作介绍"><a href="#J5-调试环境及基本操作介绍" class="headerlink" title="J5 调试环境及基本操作介绍"></a><em>J5 调试环境及基本操作介绍</em></h3><ol>
<li><em>采集Raw图像</em></li>
<li><em>导入对应的Raw图像，使用Calibration tool分模块校正，并产生静态校正参数</em></li>
<li><em>将静态矫正参数upload系统软件后生效</em></li>
<li><em>在PC端使用control_tool工具实时调试模块参数验证图像效果</em></li>
<li><em>重复之前步骤至效果达到需求</em></li>
</ol>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414091506525.png"
                      class="" title="image-20230414091506525"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414091515257.png"
                      class="" title="image-20230414091515257"
                ></em></p>
<h3 id="Hobot-player"><a href="#Hobot-player" class="headerlink" title="Hobot player"></a><em>Hobot player</em></h3><blockquote>
<p><em>启动数据流程;</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414092121709.png"
                      class="" title="image-20230414092121709"
                ></em></p>
<blockquote>
<p><em>主界面</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414092812821.png"
                      class="" title="image-20230414092812821"
                ></em></p>
<blockquote>
<p><em>实时RAW预览</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414093656150.png"
                      class="" title="image-20230414093656150"
                ></em></p>
<blockquote>
<p><em>Dump RAW</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414093750378.png"
                      class="" title="image-20230414093750378"
                ></em></p>
<blockquote>
<p><em>静态RAW预览</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414093814731.png"
                      class="" title="image-20230414093814731"
                ></em></p>
<h3 id="Control-Tool-1"><a href="#Control-Tool-1" class="headerlink" title="Control Tool"></a><em>Control Tool</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414094036665.png"
                      class="" title="image-20230414094036665"
                ></em></p>
<p>** </p>
<blockquote>
<p><em>gain setting</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414094240554.png"
                      class="" title="image-20230414094240554"
                ></em></p>
<blockquote>
<p><em>calibration tool</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414150130688.png"
                      class="" title="image-20230414150130688"
                ></em></p>
<blockquote>
<p><em>RAW格式设置</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414150325417.png"
                      class="" title="image-20230414150325417"
                ></em></p>
<blockquote>
<p><em>Black level</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414150440962.png"
                      class="" title="image-20230414150440962"
                ></em></p>
<blockquote>
<p><em>Gamma FE</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414150603960.png"
                      class="" title="image-20230414150603960"
                ></em></p>
<blockquote>
<p><em>Mesh Shading</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414150705375.png"
                      class="" title="image-20230414150705375"
                ></em></p>
<blockquote>
<p><em>Gamma</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414150851796.png"
                      class="" title="image-20230414150851796"
                ></em></p>
<blockquote>
<p><em>CCM</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414151011131.png"
                      class="" title="image-20230414151011131"
                ></em></p>
<blockquote>
<p><em>AWB</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414151311362.png"
                      class="" title="image-20230414151311362"
                ></em></p>
<blockquote>
<p><em>NP(Noise Profile)</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414191305397.png"
                      class="" title="image-20230414191305397"
                ></em></p>
<blockquote>
<p><em>CA（色差矫正）</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414191332944.png"
                      class="" title="image-20230414191332944"
                ></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414191457449.png"
                      class="" title="image-20230414191457449"
                ></em></p>
<h3 id="Tuning参数编译-1"><a href="#Tuning参数编译-1" class="headerlink" title="Tuning参数编译"></a><em>Tuning参数编译</em></h3><blockquote>
<p><em>1.保存calibration矫正结果</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414191618474.png"
                      class="" title="image-20230414191618474"
                ></em></p>
<blockquote>
<p><em>2.将保存的JSON文件汇总到编译路径下，make即可生成so</em>	</p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414191705921.png"
                      class="" title="image-20230414191705921"
                ></em></p>
<h2 id="Color模块-AWB-x2F-CCM"><a href="#Color模块-AWB-x2F-CCM" class="headerlink" title="Color模块-AWB&#x2F;CCM"></a><em>Color模块-AWB&#x2F;CCM</em></h2><p><em>AWB：</em></p>
<ul>
<li><em>AWB静态校正</em></li>
<li><em>R&#x2F;G，B&#x2F;G在不同的光源及典型场景下的响应</em></li>
<li><em>Color-preference - 偏色喜好</em></li>
<li><em>Mixed-light混光处理</em></li>
<li><em>Corner case场景处理</em></li>
<li><em>AWB parameter</em></li>
</ul>
<p><em>CCM &amp; Shading：</em></p>
<ul>
<li><em>shading参数及CCM参数与AWB返回色温相关性</em></li>
</ul>
<h3 id="AWB-Auto-white-balance-algorithm"><a href="#AWB-Auto-white-balance-algorithm" class="headerlink" title="AWB - Auto white balance algorithm"></a><em>AWB - Auto white balance algorithm</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414192726981.png"
                      class="" title="image-20230414192726981"
                ></em></p>
<blockquote>
<p><em>calibration parameter</em></p>
</blockquote>
<ul>
<li><em>可选择在’Demosaic’或’CCM’两个模块之后进行AWB统计</em></li>
<li><em>修改位置：control_tool—-Hardware—-Pipeline—-WAB switch</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414193205759.png"
                      class="" title="image-20230414193205759"
                ></em></p>
<blockquote>
<p><em>Metering zones and tap point</em></p>
</blockquote>
<ul>
<li><em>左边框grid信息：存储average R&#x2F;G、B&#x2F;G或者average G&#x2F;R、G&#x2F;B</em></li>
<li><em>右边框是对应的Grid权重值。该权重值用于global rgain&#x2F;rgain的计算</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414193443284.png"
                      class="" title="image-20230414193443284"
                ></em></p>
<blockquote>
<p><em>statist boundaries</em></p>
</blockquote>
<p><em>基于color ration对不想要统计的区域或像素剔除，通过配置Control tool-Hardware-statics中如下寄存器限制</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230414194156836.png"
                      class="" title="image-20230414194156836"
                ></em></p>
<h1 id="x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D"><a href="#x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D" class="headerlink" title="&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;"></a><em>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</em></h1><h1 id="J5-EVM开发套件用户手册"><a href="#J5-EVM开发套件用户手册" class="headerlink" title="J5 EVM开发套件用户手册"></a><em>J5 EVM开发套件用户手册</em></h1><h2 id="硬件平台介绍"><a href="#硬件平台介绍" class="headerlink" title="硬件平台介绍"></a><em>硬件平台介绍</em></h2><h3 id="芯片框图"><a href="#芯片框图" class="headerlink" title="芯片框图"></a><em>芯片框图</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111219563.png"
                      class="" title="image-20230415111219563"
                ></em></p>
<ul>
<li><em>支持4路2.5G MIPI CSI RX接口</em></li>
<li><em>支持2路2.5G MIPI CSI TX接口</em></li>
<li><em>支持1路DVP接口</em></li>
<li><em>支持8路I2C接口</em></li>
<li><em>支持4路SPI master接口和2路SPI slave接口，其中1路SPI master和1路SPI slave复用</em></li>
<li><em>支持4路UART接口</em></li>
<li><em>支持4路CANF-FD接口</em></li>
<li><em>支持2路1Gb Ethernet接口，支持TSN（时间敏感网络）</em></li>
<li><em>支持1路PCIe Gen3 2Lane接口</em></li>
<li><em>支持16路LPWM接口和2路PWM接口</em></li>
<li><em>支持1路EMMC和1路SD&#x2F;SDIO接口</em></li>
<li><em>支持1路OSPI接口连接nor&#x2F;hyper&#x2F; flash</em></li>
<li><em>支持64bit LPDDR4&#x2F;4X memory接口</em></li>
</ul>
<h3 id="开发板实物图"><a href="#开发板实物图" class="headerlink" title="开发板实物图"></a><em>开发板实物图</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111318104.png"
                      class="" title="image-20230415111318104"
                ></em></p>
<table>
<thead>
<tr>
<th><em>编号</em></th>
<th><em>功能介绍</em></th>
</tr>
</thead>
<tbody><tr>
<td><em>1</em></td>
<td><em>Sockets of RX sub-board</em></td>
</tr>
<tr>
<td><em>2</em></td>
<td><em>Socket of TX sub-board</em></td>
</tr>
<tr>
<td><em>3</em></td>
<td><em>DVP</em></td>
</tr>
<tr>
<td><em>4</em></td>
<td><em>DIP switch</em></td>
</tr>
<tr>
<td><em>5</em></td>
<td><em>JTAG</em></td>
</tr>
<tr>
<td><em>6</em></td>
<td><em>Ethernet port</em></td>
</tr>
<tr>
<td><em>7</em></td>
<td><em>SD card</em></td>
</tr>
<tr>
<td><em>8</em></td>
<td><em>Serial</em></td>
</tr>
<tr>
<td><em>9</em></td>
<td><em>Back board connector</em></td>
</tr>
<tr>
<td><em>10</em></td>
<td><em>Power</em></td>
</tr>
</tbody></table>
<h3 id="外设安装"><a href="#外设安装" class="headerlink" title="外设安装"></a><em>外设安装</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111350861.png"
                      class="" title="image-20230415111350861"
                ></em></p>
<p><em>请按照以下顺序安装：</em></p>
<ol>
<li><em>在上述实物图位置，找到serial插口，插入Micro-USB线，Micro-USB线另一头与PC连接</em></li>
<li><em>在上述实物图位置，找到网口，插入符合要求的网线，网线另一头与PC连接</em></li>
<li><em>如有需要，在上述实物图中找到Micro SD卡槽位置，插入Micro SD卡</em></li>
</ol>
<p><em>如有需求，请按照如下步骤配置摄像头及显示输出子板，所有显示输出子板配备防反插。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111405353.png"
                      class="" title="image-20230415111405353"
                ></em></p>
<p><em>在上述实物图中，找到摄像头子板插口，并根据应用需要，接入传感器及其匹配转换子板。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111416759.png"
                      class="" title="image-20230415111416759"
                ></em></p>
<p><em>启动模式DIP具体配置如下，DIP开关下拨为关闭状态，请根据具体需要，依据下表调整。 左侧DIP开关配置信息：</em></p>
<table>
<thead>
<tr>
<th><em>DIP编号</em></th>
<th><em>名称</em></th>
<th><em>默认值</em></th>
<th><em>功能描述</em></th>
</tr>
</thead>
<tbody><tr>
<td><em>1</em></td>
<td><em>保留</em></td>
<td><em>0</em></td>
<td><em>保留</em></td>
</tr>
<tr>
<td><em>[4:2]</em></td>
<td><em>2NDBOOT_SEL</em></td>
<td><em>0</em></td>
<td><em>000: 2NDBOOT 来自 EMMC</em></td>
</tr>
<tr>
<td><em>010: 2NDBOOT 来自 UART XMODEM</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>011: 2NDBOOT 来自 SPI FLASH(SPI NOR FLASH)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>100: 2NDBOOT 来自 SD</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>101: 2NDBOOT 来自 AP SPI</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>110: 2NDBOOT 来自 SPI FLASH(SPI HYPER FLASH)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>111: 2NDBOOT 来自 SPI FLASH(SPI NOR FALSH 8LINE DDR MODE)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>5</em></td>
<td><em>保留</em></td>
<td><em>0</em></td>
<td><em>保留</em></td>
</tr>
<tr>
<td><em>6</em></td>
<td><em>DEVICE_MODE</em></td>
<td><em>0</em></td>
<td><em>当 2NDBOOT&#x3D;EMMC&#x2F;SD 时0&#x3D;PIO 模式1&#x3D;DMA 模式</em></td>
</tr>
<tr>
<td><em>当2NDBOOT&#x3D;SPI NOR FLASH时0&#x3D;32bit 地址模式1&#x3D;24bit 地址模式</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>当2NDBOOT&#x3D;SPI Hyper FLASH时，没有含义</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>当2NDBOOT&#x3D;AP-SPI&#x2F;UART-XMODEM时，没有含义</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>[8:7]</em></td>
<td><em>FASTBOOT_SEL</em></td>
<td><em>0</em></td>
<td><em>CPU&#x2F;BUS 切频选择</em></td>
</tr>
<tr>
<td><em>00: 最高频</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>01: 次高频</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>10: 第三档频率</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>11: 全 24M 频率</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>部分DIP开关与软件无关，详情请参考硬件设计文档</em></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><em>右侧DIP开关配置信息：</em></p>
<table>
<thead>
<tr>
<th><em>DIP编号</em></th>
<th><em>名称</em></th>
<th><em>默认值</em></th>
<th><em>功能描述</em></th>
</tr>
</thead>
<tbody><tr>
<td><em>1</em></td>
<td><em>UART_BAUD_RATE</em></td>
<td><em>0</em></td>
<td><em>0: 921600bps</em></td>
</tr>
<tr>
<td><em>1: 115200bps</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>2</em></td>
<td><em>保留</em></td>
<td><em>0</em></td>
<td><em>保留</em></td>
</tr>
<tr>
<td><em>3</em></td>
<td><em>SPI_FLASH_RESET</em></td>
<td><em>0</em></td>
<td><em>当2NDBOOT&#x3D;SPI FLASH时0: 无操作1: 读取NOR&#x2F;Hyper FLASH之前首先执行一次RESET命令操作</em></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>当2NDBOOT&#x3D;EMMC&#x2F;SD时该位代表sdmmc_input_delay[0]</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>4</em></td>
<td><em>DISABLE_WDOG</em></td>
<td><em>0</em></td>
<td><em>0: 使能WatchDog进行切频保护，切频之前使能WatchDog，切频成功之后予以关闭，如果切频失败导致死机，则WatchDog生效复位整个系统</em></td>
</tr>
<tr>
<td><em>1: 不使用WatchDog</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>5</em></td>
<td><em>SDMMC_DELAY[1]</em></td>
<td><em>0</em></td>
<td><em>当2NDBOOT&#x3D;EMMC&#x2F;SD时该位代表sdmmc_input_delay[1]</em></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>6</em></td>
<td><em>SDMMC_DELAY[2]</em></td>
<td><em>0</em></td>
<td><em>当2NDBOOT&#x3D;EMMC&#x2F;SD时该位代表sdmmc_input_delay[2]</em></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>7</em></td>
<td><em>保留</em></td>
<td><em>0</em></td>
<td><em>保留</em></td>
</tr>
<tr>
<td><em>8</em></td>
<td><em>SKIP_CHECKSUM</em></td>
<td><em>0</em></td>
<td><em>0: 校对各项checksum</em></td>
</tr>
<tr>
<td><em>1: 不校对各项checksum (easy for debug)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><em>部分DIP开关与软件无关，详情请参考硬件设计文档</em></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="软件开发工具"><a href="#软件开发工具" class="headerlink" title="软件开发工具"></a><em>软件开发工具</em></h2><h3 id="系统框图"><a href="#系统框图" class="headerlink" title="系统框图"></a><em>系统框图</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111447163.png"
                      class="" title="image-20230415111447163"
                ></em></p>
<h3 id="开发工具目录结构"><a href="#开发工具目录结构" class="headerlink" title="开发工具目录结构"></a><em>开发工具目录结构</em></h3><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230415111506865.png"
                      class="" title="image-20230415111506865"
                ></em></p>
<p><em>J5现有的基础方案：A Core上直接运行Linux操作系统，Safety M Core上没有软件操作系统。 Safety M Core 上的软件对A Core上的软件进行监控，处理安全故障同时向SoC外部报错。VDSP Core上运行的是XOS VDSP算法软件，负责传统的CV运算。L2-L3域控制器上的 ASIL-D相 关任务，都由外部ASIL-D MCU完成。</em></p>
<table>
<thead>
<tr>
<th><em><strong>软件目录名</strong></em></th>
<th><em><strong>目录说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>build</em></td>
<td><em>编译环境与执行脚本目录</em></td>
</tr>
<tr>
<td><em>external&#x2F;android-tools</em></td>
<td><em>Rootfs中init执行程序源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;camera</em></td>
<td><em>Camera中间件API源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;hbutils</em></td>
<td><em>Hbutils工具包源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;hobotsdk</em></td>
<td><em>Hobotsdk源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;libdisp</em></td>
<td><em>Display中间件API源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;libhbpcie</em></td>
<td><em>Pcie中间件API源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;libion</em></td>
<td><em>Ion（物理内存管理）中间件API源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;liblog</em></td>
<td><em>Logcat（用户态log记录）源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;librpmsg</em></td>
<td><em>核间通信中间件API源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;libsecchip</em></td>
<td><em>Security中间件API源代码目录</em></td>
</tr>
<tr>
<td><em>hbre&#x2F;openssl-engine</em></td>
<td><em>Openssl硬件加速引擎源代码目录</em></td>
</tr>
<tr>
<td><em>uboot</em></td>
<td><em>Spl和uboot源代码目录</em></td>
</tr>
<tr>
<td><em>kernel</em></td>
<td><em>Linux kernel源代码</em></td>
</tr>
<tr>
<td><em>prebuilts&#x2F;root</em></td>
<td><em>Rootfs目录，build后包含在kernel Image中</em></td>
</tr>
<tr>
<td><em>tools&#x2F;autotest</em></td>
<td><em>自动化测试执行python脚本目录</em></td>
</tr>
<tr>
<td><em>unittest&#x2F;testapp</em></td>
<td><em>测试代码目录</em></td>
</tr>
<tr>
<td><em>unittest&#x2F;utest</em></td>
<td><em>自动化测试用例json脚本目录</em></td>
</tr>
</tbody></table>
<p><em>用户到手的是如下的包：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dev-j5-k5-LNX5.10_GCC9.3_REL_PL3.0_2022072603.zip</span><br></pre></td></tr></table></figure></div>

<p><em>这里对代码的目录结构简单做下介绍，方便给开发人员一个初步的认识。 注释：由于具体情况根据具体使用为准，这里只对经常使用的目录进行说明，细节根据使用情 况变动，以下仅供参考。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Makefile  build  certs  external  hbre  kernel  mcore  out  prebuilts  tools  uboot  unittest</span><br></pre></td></tr></table></figure></div>

<h4 id="build"><a href="#build" class="headerlink" title="build"></a><em>build</em></h4><p><em>编译相关的参数配置，以及升级镜像的目录。 下表介绍了经常使用的几个工作目录及文件：</em></p>
<table>
<thead>
<tr>
<th><em>文件目录名</em></th>
<th><em>文件目录功能说明</em></th>
</tr>
</thead>
<tbody><tr>
<td><em>build.sh</em></td>
<td><em>编译镜像时候的执行脚本。</em></td>
</tr>
<tr>
<td><em>envsetup.sh</em></td>
<td><em>编译镜像的配置脚本。</em></td>
</tr>
<tr>
<td><em>core</em></td>
<td><em>build环境配置脚本目录。</em></td>
</tr>
<tr>
<td><em>device</em></td>
<td><em>各平台编译时所用的配置文件：env.sh, gpt.conf, rootfs.manifest, fstab, init.rc, ubi.cfg等。</em></td>
</tr>
<tr>
<td><em>Makefile</em></td>
<td><em>完整编译所用Makefile。</em></td>
</tr>
<tr>
<td><em>ota_tools</em></td>
<td><em>ota升级包生成所需的相关工具脚本目录: sbl_package_maker,mcore_package_maker,bl31_package_maker,uboot_package_maker,kernel_package_maker,system_package_maker,app_package_maker, diff_tools, all等。</em></td>
</tr>
<tr>
<td><em>scripts</em></td>
<td><em>编译打包所需的各种脚本。</em></td>
</tr>
<tr>
<td><em>tools</em></td>
<td><em>编译打包工具所在目录: avbtools, cramfsmkbooting, pkgtool, squashfs, key_management_toolkits等。</em></td>
</tr>
</tbody></table>
<h4 id="external"><a href="#external" class="headerlink" title="external"></a><em>external</em></h4><p><em>第三方代码目录，目前存放Rootfs中init执行程序源代码目录。</em></p>
<h4 id="hbre"><a href="#hbre" class="headerlink" title="hbre"></a><em>hbre</em></h4><p><em>地平线定制化用户库源码，如Camera等。 下表介绍了几个经常使用的用户库源码工作目录：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>camera</em></td>
<td><em>Camera中间件API源代码目录。</em></td>
</tr>
<tr>
<td><em>hbutils</em></td>
<td><em>Hbutils工具包源代码目录。</em></td>
</tr>
<tr>
<td><em>hobotsdk</em></td>
<td><em>Hobotsdk源代码目录。</em></td>
</tr>
<tr>
<td><em>libdisp</em></td>
<td><em>Display中间件API源代码目录。</em></td>
</tr>
<tr>
<td><em>libhbpcie</em></td>
<td><em>Pcie中间件API源代码目录。</em></td>
</tr>
<tr>
<td><em>libion</em></td>
<td><em>Ion（物理内存管理）中间件API源代码目录。</em></td>
</tr>
<tr>
<td><em>liblog</em></td>
<td><em>Logcat（用户态log记录）源代码目录。</em></td>
</tr>
<tr>
<td><em>librpmsg</em></td>
<td><em>核间通信中间件API源代码目录。</em></td>
</tr>
<tr>
<td><em>libsecchip</em></td>
<td><em>Security中间件API源代码目录。</em></td>
</tr>
<tr>
<td><em>openssl-engine</em></td>
<td><em>Openssl硬件加速引擎源代码目录。</em></td>
</tr>
</tbody></table>
<h4 id="kernel"><a href="#kernel" class="headerlink" title="kernel"></a><em>kernel</em></h4><p><em>Linux内核相关代码，包含J5 SoC的驱动代码和体系架构代码。 下表介绍了J5 SoC Linux内核中几个主要模块的源码目录及文件：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>arch</em></td>
<td><em>SoC体系架构代码，J5使用8核A55（Arm-V8体系架构）CPU，主要体系架构代码在arch&#x2F;arm64目录中，Linux内核编译配置在arch&#x2F;arm64&#x2F; configs目录中，J5 SoC dts相关配置在arch&#x2F;arm64&#x2F;boot&#x2F;dts&#x2F;hobot目录中。</em></td>
</tr>
<tr>
<td><em>block</em></td>
<td><em>此文件夹包含块设备驱动程序的代码，该目录用于实现块设备的基本框架和块设备的I&#x2F;O调度算法。块设备是以数据块方式接收和发送的数据的设备，数据块都是一块一块的数据而不是持续的数据流。</em></td>
</tr>
<tr>
<td><em>crypto</em></td>
<td><em>这个文件夹包含许多加密算法的源代码。例如，“sha1_generic.c”这个文件包含了sha1加密算法的代码。</em></td>
</tr>
<tr>
<td><em>drivers</em></td>
<td><em>该目录包含驱动代码。驱动是一个控制硬件的软件，例如，要让J5知道pcie总线并使其可用，pcie rc&#x2F;ep驱动是必要的。这个文件夹中存在许多文件夹，每个文件夹都以硬件的种类或者型号命名。</em></td>
</tr>
<tr>
<td><em>fs</em></td>
<td><em>这是文件系统的文件夹。在这个文件夹里，每种文件系统都有自己的文件夹。例如，ext4文件系统的代码在ext4文件夹内。在fs文件夹内，除了文件系统各自的文件夹，还有不属于任何文件系统的文件。这些文件用来控制整个文件系统，例如，mount.h中会包含挂载文件系统的代码。</em></td>
</tr>
<tr>
<td><em>kernel</em></td>
<td><em>Linux内核的核心框架代码，比如：调度子系统、时间子系统、功耗管理子系统、中断管理子系统等。</em></td>
</tr>
<tr>
<td><em>lib</em></td>
<td><em>Linux内核的软件库代码，比如：checksum,crc,fdt,zlib等。</em></td>
</tr>
<tr>
<td><em>sound</em></td>
<td><em>Linux内核Audio子系统源代码目录。</em></td>
</tr>
<tr>
<td><em>Net</em></td>
<td><em>Linux内核网络协议栈源代码目录。</em></td>
</tr>
<tr>
<td><em>Makefile</em></td>
<td><em>这个脚本是编译内核的主要文件。这个文件将编译参数和编译所需的文件和必要的信息传给编译器。</em></td>
</tr>
</tbody></table>
<h4 id="mcore"><a href="#mcore" class="headerlink" title="mcore"></a><em>mcore</em></h4><p><em>J5 SoC M核运行的是baremetal代码，如下为Mcore源代码树。 下表介绍了J5 SoC Mcore内核中几个主要模块的源码目录及文件：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>build.sh</em></td>
<td><em>mcore编译镜像时候的执行脚本。</em></td>
</tr>
<tr>
<td><em>debug</em></td>
<td><em>调试功能相关的代码。</em></td>
</tr>
<tr>
<td><em>driver</em></td>
<td><em>外设驱动代码（i2c, spi, pvt, wdg, gpio等）。</em></td>
</tr>
<tr>
<td><em>include</em></td>
<td><em>头文件。</em></td>
</tr>
<tr>
<td><em>middleware</em></td>
<td><em>中间件（核间通信、任务调度框架、spi传输协议等）。</em></td>
</tr>
<tr>
<td><em>system</em></td>
<td><em>系统运行的基础功能（启动代码、异常处理、systick等）。</em></td>
</tr>
<tr>
<td><em>task</em></td>
<td><em>各任务的实现代码。</em></td>
</tr>
<tr>
<td><em>customer.c</em></td>
<td><em>用户定制代码。</em></td>
</tr>
</tbody></table>
<h4 id="out"><a href="#out" class="headerlink" title="out"></a><em>out</em></h4><p><em>编译过程完成时的镜像输出位置。 下表介绍了J5系统软件编译生成结果：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>log</em></td>
<td><em>编译log生成在该目录下。</em></td>
</tr>
<tr>
<td><em>build</em></td>
<td><em>编译中间文件放在这里。</em></td>
</tr>
<tr>
<td><em>target</em></td>
<td><em>所有编译后生成的最终镜像都放在out&#x2F;target&#x2F;product&#x2F;packages 目录中，Linux内核编译生成的ko和符号表放在out&#x2F;target&#x2F;product&#x2F;symbols 目录中。</em></td>
</tr>
<tr>
<td><em>tmpunittest</em></td>
<td><em>J5系统软件测试APP镜像生成目录。</em></td>
</tr>
<tr>
<td><em>prerootfs</em></td>
<td><em>Prebuilt&#x2F;root内包含的rootfs镜像再增加一些hrut的工具镜像。</em></td>
</tr>
<tr>
<td><em>tmprootfs</em></td>
<td><em>hbre编译生成的rootfs镜像，会包含在system.img中。</em></td>
</tr>
</tbody></table>
<h4 id="prebuilts"><a href="#prebuilts" class="headerlink" title="prebuilts"></a><em>prebuilts</em></h4><p><em>编译好的用于根文件系统的二进制文件。 下表介绍了prebuilts下的几个主要模块的源码目录：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>boot</em></td>
<td><em>J5系统软件整体编译和打包过程中需要的一些二进制镜像，包含：bl31镜像、bpu模型镜像、ddr镜像和Mcore镜像。</em></td>
</tr>
<tr>
<td><em>host</em></td>
<td><em>交叉编译工具链目录。</em></td>
</tr>
<tr>
<td><em>root</em></td>
<td><em>编译好的用于根文件系统的二进制文件。</em></td>
</tr>
<tr>
<td><em>mcore</em></td>
<td><em>编译好的mcore的obj文件。</em></td>
</tr>
<tr>
<td><em>root_hijack</em></td>
<td><em>自定义的根文件系统相关脚本、二进制文件。</em></td>
</tr>
</tbody></table>
<h4 id="tools"><a href="#tools" class="headerlink" title="tools"></a><em>tools</em></h4><p><em>工具目录，目前仅包含自动化测试脚本。</em></p>
<h4 id="uboot"><a href="#uboot" class="headerlink" title="uboot"></a><em>uboot</em></h4><blockquote>
<p><em>U-Boot 是一个开源的嵌入式系统引导加载程序</em></p>
</blockquote>
<p><em>启动bootloader相关文件。 下表介绍了J5 uboot中几个主要模块的源码目录：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>api</em></td>
<td><em>uboot中的接口函数。</em></td>
</tr>
<tr>
<td><em>arch</em></td>
<td><em>uboot中有关处理器架构相关的代码。</em></td>
</tr>
<tr>
<td><em>board</em></td>
<td><em>为开发板定制的相关代码。</em></td>
</tr>
<tr>
<td><em>common</em></td>
<td><em>通用代码，大部分与命令行有关。</em></td>
</tr>
<tr>
<td><em>disk</em></td>
<td><em>磁盘分区相关代码。</em></td>
</tr>
<tr>
<td><em>doc</em></td>
<td><em>有关README.txt相关代码。</em></td>
</tr>
<tr>
<td><em>drivers</em></td>
<td><em>与驱动程序相关代码。</em></td>
</tr>
<tr>
<td><em>examples</em></td>
<td><em>示例程序。</em></td>
</tr>
<tr>
<td><em>fs</em></td>
<td><em>文件系统，适合大部分开发板上的文件系统。</em></td>
</tr>
<tr>
<td><em>include</em></td>
<td><em>包含全局的头文件。</em></td>
</tr>
<tr>
<td><em>lib</em></td>
<td><em>通用库文件。</em></td>
</tr>
<tr>
<td><em>net</em></td>
<td><em>网络相关的代码，小型的协议栈。</em></td>
</tr>
<tr>
<td><em>post</em></td>
<td><em>Power On Self Test，上电自检程序。</em></td>
</tr>
<tr>
<td><em>tools</em></td>
<td><em>辅助程序，用于编译和检查uboot目标文件。</em></td>
</tr>
</tbody></table>
<h4 id="unittest"><a href="#unittest" class="headerlink" title="unittest"></a><em>unittest</em></h4><blockquote>
<p><em>unittest 是 Python 内置的一个用于编写单元测试的框架。它可以自动化执行测试用例，比较测试结果并生成测试报告。</em></p>
</blockquote>
<p><em>unittest 提供了用于测试的 TestCase 类和一系列的断言方法，以及 setUp() 和 tearDown() 方法用于测试前的初始化和测试完后的清理工作。通过这些工具，开发者可以方便地编写、执行和管理测试用例。</em></p>
<p><em>unittest 支持模块化测试，可以将测试用例分别放在不同的测试文件中，并通过 TestSuite 类和 TestLoader 类将它们组合在一起执行。此外，unittest 还支持测试覆盖率的计算。</em></p>
<p><em>简单的测试用例源码和用于自动化测试的json配置文件。 下表介绍了J5 unittest中几个主要模块的源码目录：</em></p>
<table>
<thead>
<tr>
<th><em><strong>文件目录名</strong></em></th>
<th><em><strong>文件目录功能说明</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>build</em></td>
<td><em>unittest 编译脚本。</em></td>
</tr>
<tr>
<td><em>prebuilts</em></td>
<td><em>编译所需预建目录。</em></td>
</tr>
<tr>
<td><em>testapp</em></td>
<td><em>测试源代码目录，编译生成的库和可执行文件会包含在out&#x2F;tmpunittest目录中。</em></td>
</tr>
<tr>
<td><em>utest</em></td>
<td><em>用于自动化测试的json配置文件目录，包含所有的自动化测试case配置文件。</em></td>
</tr>
</tbody></table>
<h2 id="板端连接方法"><a href="#板端连接方法" class="headerlink" title="板端连接方法"></a><em>板端连接方法</em></h2><h3 id="网口连接"><a href="#网口连接" class="headerlink" title="网口连接"></a><em>网口连接</em></h3><p><em>通过网口以ssh协议与开发板通讯的软件。</em></p>
<h3 id="串口接口"><a href="#串口接口" class="headerlink" title="串口接口"></a><em>串口接口</em></h3><p><em>当使用windows通过串口连接J5 dvb板时，需安装对应驱动，驱动下载链接：<a class="link"   target="_blank" rel="noopener" href="http://www.ftdichip.cn/Drivers/VCP.htm%EF%BC%8C%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85%E5%90%8E%E8%AF%86%E5%88%AB%E5%87%BA%E7%9A%84%E5%9B%9B%E4%B8%AACOM%E5%8F%A3%EF%BC%8C%E9%80%89%E6%8B%A9%E9%A1%BA%E5%BA%8F%E7%AC%AC%E4%B8%89%E4%B8%AACOM%E5%8F%A3%EF%BC%8C%E4%B8%B2%E5%8F%A3%E6%B3%A2%E7%89%B9%E7%8E%87%EF%BC%9A921600%E3%80%82" >http://www.ftdichip.cn/Drivers/VCP.htm，驱动安装后识别出的四个COM口，选择顺序第三个COM口，串口波特率：921600。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> J5芯片支持串口，软件缺省登录串口控制台，在PC端可以用SecureCRT, minicom，picocom 等软件登录。（注：目前镜像仅支持串口控制台波特率为921600，如配置其他的波特率需要修改镜像）</em></p>
<blockquote>
<p><em>补充：</em></p>
<p><em>串行COM端口是一种用于串行通信的接口，也称为RS-232接口。它是计算机与其他设备进行串行通信的一种标准接口，通常用于连接调制解调器、打印机、传感器、执行器等设备。</em></p>
<p><em>虚拟COM端口（VCP）驱动程序是一种软件程序，它可以将计算机的USB接口模拟成标准的串行COM端口。</em></p>
<p><em>将计算机的USB接口模拟成标准的串行COM端口有以下几个原因：</em></p>
<ol>
<li><em>兼容性：许多老旧的设备只支持串行COM端口，而不支持USB接口。通过将计算机的USB接口模拟成串行COM端口，可以使这些老旧的设备能够与计算机进行通信，从而延长设备的使用寿命。</em></li>
<li><em>简化设计：一些新的设备需要与计算机进行串行通信，但是没有内置的串行COM端口，只有USB接口。在这种情况下，将计算机的USB接口模拟成串行COM端口可以简化设备的设计，同时也可以提高设备的兼容性。</em></li>
<li><em>可靠性：串行COM端口是一种成熟的标准接口，具有广泛的应用和测试经验。通过将计算机的USB接口模拟成串行COM端口，可以保证通信的稳定性和可靠性。</em></li>
</ol>
</blockquote>
<h4 id="SecureCRT"><a href="#SecureCRT" class="headerlink" title="SecureCRT"></a><em>SecureCRT</em></h4><ol>
<li><em>windows上需要安装虚拟COM端口（VCP）驱动程序，驱动下载地址： <a class="link"   target="_blank" rel="noopener" href="http://www.ftdichip.cn/Drivers/VCP.htm" >http://www.ftdichip.cn/Drivers/VCP.htm <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></li>
<li><em>在protocol下拉菜单中选择serial</em></li>
<li><em>选择port口为板子连接到电脑上的com口，可在我的电脑&gt;右键属性&gt;硬件&gt;设备管理器中查看，波特率选择921600；板子连接到电脑上会有4个COM口，选择第三个</em></li>
<li><em>连接登录</em></li>
</ol>
<h4 id="Minicom"><a href="#Minicom" class="headerlink" title="Minicom"></a><em>Minicom</em></h4><p><em>连接串口命令参考如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">minicom –b 921600 –D /dev/tty*</span><br></pre></td></tr></table></figure></div>

<h4 id="Picocom"><a href="#Picocom" class="headerlink" title="Picocom"></a><em>Picocom</em></h4><p><em>连接串口命令参考如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">picocom –b 921600 /dev/tty*</span><br></pre></td></tr></table></figure></div>

<h4 id="ADB"><a href="#ADB" class="headerlink" title="ADB"></a><em>ADB</em></h4><p><em>板上系统默认开始ADB调试，在Micro-USB连接pc后，设备管理器自动识别设备。 板上配置&#x2F;查看ip地址：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth1 XX.XX.XX.XX</span><br><span class="line">ifconfig -a</span><br></pre></td></tr></table></figure></div>

<p><em>pc端连接板上系统，进入adb shell。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">adb connect XX.XX.XX.XX:5555</span><br><span class="line">adb shell</span><br></pre></td></tr></table></figure></div>

<h2 id="编译镜像说明"><a href="#编译镜像说明" class="headerlink" title="编译镜像说明"></a><em>编译镜像说明</em></h2><h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a><em>环境搭建</em></h3><h4 id="工具链配置"><a href="#工具链配置" class="headerlink" title="工具链配置"></a><em>工具链配置</em></h4><p><em>由于编译的镜像使用到板子上，需要使用交叉编译工具链，才能使编译后的镜像在板子上正常运行，这里介绍下交叉编译工具链的选择和配置。 交叉编译工具链有很多版本，根据实际需求使用的是 gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu 这个版本。Build系统自带一套交叉编译环境如下图所示:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ARCH=&quot;arm64&quot;</span><br><span class="line">CROSS_COMPILE=&quot;/home/user.name/platform_sdk/prebuilts/host/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-&quot;</span><br><span class="line">TARGET_VENDOR=&quot;horizon&quot;</span><br><span class="line">TARGET_PROJECT=&quot;j5&quot;</span><br><span class="line">TARGET_MODE=&quot;debug&quot;</span><br><span class="line">TARGET_BIT=&quot;64&quot;</span><br><span class="line">ENABLE_BUILD_DEPENDENCY=&quot;false&quot;</span><br><span class="line">N=&quot;24&quot;</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>交叉编译工具链是一种工具，<strong>它可以在一个操作系统上生成可在另一个操作系统上运行的程序</strong>。这种技术通常用于嵌入式系统开发，因为嵌入式系统通常使用的处理器和操作系统与常规计算机不同。<strong>交叉编译工具链包括编译器、链接器和库等工具</strong>，这些工具可以生成可在目标平台上运行的可执行文件或库。这些工具链通常由开发人员自己构建，因为每个目标平台都有不同的要求和限制。</em></p>
</blockquote>
<blockquote>
<p><em><code>gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu</code> 是一个交叉编译工具链，用于在x86_64架构的Ubuntu系统上编译生成可在aarch64架构的Linux系统上运行的程序。</em></p>
</blockquote>
<p><em>例如，ubuntu上可以使用以下命令编译一个C语言程序：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bashCopy code</span><br><span class="line">aarch64-linux-gnu-gcc -o hello hello.c</span><br></pre></td></tr></table></figure></div>

<p><em><strong>这个命令将编译名为hello.c的源文件，并生成一个名为hello的可执行文件，该文件可以在aarch64架构的Linux系统上运行。</strong></em></p>
<h5 id="Ubuntu-18-04"><a href="#Ubuntu-18-04" class="headerlink" title="Ubuntu 18.04"></a><em>Ubuntu 18.04</em></h5><p><em>对于Ubuntu18.04，需要按照以下命令搭建开发环境：如果有其它报错，补充安装缺的包。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential		//安装了一组编译工具，包括GCC编译器、make、libc-dev等。这些工具可以用于编译和构建各种C/C++程序。</span><br><span class="line"></span><br><span class="line">sudo apt-get install make				//安装了GNU Make工具，它是一个用于自动化构建程序的工具，可以根据Makefile文件来自动编译、链接和生成可执行文件。</span><br><span class="line"></span><br><span class="line">sudo apt install cmake					//安装了CMake工具，它是一个跨平台的自动化构建工具，可以生成各种不同的构建系统，如Makefile、Visual Studio项目等。</span><br><span class="line"></span><br><span class="line">sudo apt install bison					//安装了Bison工具，它是一个用于生成语法分析器的工具，可以用于编写编译器、解释器等程序。</span><br><span class="line"></span><br><span class="line">sudo apt install flex					//安装了Flex工具，它是一个用于生成词法分析器的工具，可以用于编写编译器、解释器等程序。</span><br><span class="line"></span><br><span class="line">sudo apt-get install python-numpy		</span><br><span class="line">sudo apt install android-tools-fsutils		//安装了Android系统的文件系统工具，包括adb、fastboot等工具，可以用于与Android设备进行交互和调试。</span><br><span class="line"></span><br><span class="line">sudo apt install mtd-utils				//安装了Linux MTD（Memory Technology Device）工具集，包括nanddump、nandwrite等工具，可以用于与闪存设备进行交互和管理。</span><br><span class="line"></span><br><span class="line">sudo apt install zlib1g-dev				//安装了zlib压缩库的开发文件，可以用于在程序中使用zlib库进行数据压缩和解压缩。</span><br><span class="line"></span><br><span class="line">sudo apt install kmod					//安装了Linux内核模块工具，包括modprobe、insmod等工具，可以用于加载和卸载内核模块。</span><br><span class="line"></span><br><span class="line">sudo apt install liblz4-tool			//安装了LZ4压缩库的命令行工具，可以用于在终端中对数据进行LZ4压缩和解压缩。</span><br><span class="line"></span><br><span class="line">sudo apt install libssl-dev				//安装了OpenSSL加密库的开发文件，可以用于在程序中使用OpenSSL库进行数据加密和解密。</span><br><span class="line"></span><br><span class="line">sudo apt install python3-openpyxl		//安装了Python openpyxl库，它是一个用于读写Excel文件的Python库，可以用于处理Excel文件的数据。</span><br></pre></td></tr></table></figure></div>

<h5 id="CentOS-7-0"><a href="#CentOS-7-0" class="headerlink" title="CentOS 7.0"></a><em>CentOS 7.0</em></h5><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum install glib cmake gcc bison flex minicom python-pip</span><br><span class="line">pip install numpy</span><br><span class="line">yum install make_ext4fs-1.0.0-1.el7.x86_64.rpm</span><br><span class="line">yum install zlib-devel</span><br><span class="line">yum install mtd-utils-1.5.0-2.el6.nux.x86_64.rpm</span><br><span class="line">yum install kmod</span><br><span class="line">yum install liblz4-tool</span><br></pre></td></tr></table></figure></div>

<h4 id="服务器（TFTP）建立与文档传输"><a href="#服务器（TFTP）建立与文档传输" class="headerlink" title="服务器（TFTP）建立与文档传输"></a><em>服务器（TFTP）建立与文档传输</em></h4><blockquote>
<p><em>FTP的特点包括：</em></p>
<ol>
<li><em>简单：TFTP的协议设计非常简单，只有几个命令和参数，易于实现和使用。</em></li>
<li><em>快速：TFTP使用UDP协议，没有连接建立和断开的过程，因此传输速度比TCP协议快。</em></li>
<li><em>易于实现：TFTP的实现非常简单，只需要一个标准的网络套接字和几个命令即可。</em></li>
<li><em>安全性较差：TFTP没有加密和认证机制，因此传输的数据容易被窃听和篡改。</em></li>
</ol>
<p><em>TFTP相对于FTP来说功能较为简单，传输速度较快但可靠性较差，安全性较差。FTP功能更为丰富，传输速度较慢但可靠性更高，安全性更好。选择哪种协议取决于具体的应用场景和需求。</em></p>
</blockquote>
<h5 id="windows"><a href="#windows" class="headerlink" title="windows"></a><em>windows</em></h5><p><em>Windows可以使用：tftp_win32、tftpd64或任意Windows下的tftp服务器程序。</em></p>
<h5 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a><em>Linux</em></h5><p><em>Linux下需要搭建tftp server环境：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install tftpd-hpa</span><br><span class="line">sudo mkdir /tftpboot</span><br><span class="line"># 编辑tftpd-hpa设置</span><br><span class="line">sudo vi /etc/default/tftpd-hpa					//这个命令用vi编辑器打开文件 /etc/default/tftpd-hpa，这是tftpd-hpa的配置文件。在这个文件中，你可以设置TFTP服务器的一些选项，如TFTP服务器的根目录，IP地址和端口等</span><br></pre></td></tr></table></figure></div>

<p><em>进入vi编辑界面后，将以下内容键入文件，服务器根文件夹将会被设置为：“&#x2F;tftpboot”</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TFTP_USERNAME=&quot;tftp&quot;</span><br><span class="line">TFTP_DIRECTORY=&quot;/tftpboot&quot;</span><br><span class="line">TFTP_ADDRESS=&quot;[::]:69&quot;		//这个变量设置TFTP服务器监听的IP地址和端口号。在这个例子中，TFTP服务器将监听所有可用的IPv4和IPv6地址，并使用标准TFTP端口号69。</span><br><span class="line"></span><br><span class="line">TFTP_OPTIONS=&quot;-l -c -s&quot;		// 这个变量设置TFTP服务器的一些选项。在这个例子中，选项 -l 表示启用日志记录，选项 -c 表示允许客户端上传文件，选项 -s 表示将TFTP服务器视为一个“安全”服务器，这意味着它只会允许访问TFTP根目录下的文件。</span><br></pre></td></tr></table></figure></div>

<p><em>配置pc端ip为xx.xx.xx.xx：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig xx.xx.xx.xx</span><br></pre></td></tr></table></figure></div>

<p><em>重启tftp服务器并应用配置：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service tftpd-hpa restart</span><br></pre></td></tr></table></figure></div>

<p><em>内核相关镜像放到&#x2F;tftpboot目录。 <strong>在板端UBoot中：</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenv serverip xx.xx.xx.xx</span><br><span class="line">setenv ipaddr xx.xx.xx.yy /*与主机同网段ip*/</span><br></pre></td></tr></table></figure></div>

<p><em>设置tftp传输文件储存的DDR地址：<strong>这些命令是用于通过TFTP服务器将文件写入嵌入式设备的MMC存储器中，并重启设备。</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">setenv target_addr 0x6000000		//这个命令设置变量 target_addr 的值为 0x6000000。这个变量将用于存储从TFTP服务器下载的文件的内存地址。</span><br><span class="line"></span><br><span class="line">tftp $&#123;target_addr&#125; &lt;目标文件在tftp服务器目录的相对路径&gt;		//这个命令使用TFTP协议从TFTP服务器下载文件，并将文件存储到变量 target_addr 指定的内存地址中。</span><br><span class="line"></span><br><span class="line">mmc write $&#123;target_addr&#125; 0x0 &lt;文件总块数（512B为一块）&gt;		//这个命令将从TFTP服务器下载的文件写入嵌入式设备的MMC存储器中。$&#123;target_addr&#125; 是从TFTP服务器下载的文件的内存地址，0x0 是MMC存储器中写入文件的起始块地址，</span><br><span class="line"></span><br><span class="line">reset								//这个命令重启嵌入式设备。</span><br></pre></td></tr></table></figure></div>

<h4 id="服务器（NFS）建立与文档传输"><a href="#服务器（NFS）建立与文档传输" class="headerlink" title="服务器（NFS）建立与文档传输"></a><em>服务器（NFS）建立与文档传输</em></h4><blockquote>
<p><em>NFS（Network File System）是一种分布式文件系统协议，它允许在网络上的不同计算机之间共享文件和目录。</em></p>
</blockquote>
<p><em>在板子上执行应用程序，用这种方式很便捷。把应用程序放到 pc 机的某个目录，比如 &#x2F;home&#x2F;$USER&#x2F;nfs目录，板子侧挂载完以后，可以看到pc机上的内容，可以直接执行应用 程序（需要库的话拷贝到&#x2F;lib目录下）。</em></p>
<h5 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a><em>Windows</em></h5><p><em>在PC内配置nfs服务器，下载安装nfs1169–.zip。</em></p>
<h5 id="Linux-1"><a href="#Linux-1" class="headerlink" title="Linux"></a><em>Linux</em></h5><p><em>安装NFS：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nfs-kernel-server</span><br></pre></td></tr></table></figure></div>

<p><em>配置：这些命令的效果是将 <code>/home/$USER/nfs</code> 目录共享给所有IP地址以 <code>xx.xx</code> 开头的客户端，这些客户端将具有读写访问权限，并且root用户将具有访问这个共享资源的权限。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">mkdir nfs</span><br><span class="line">sudo vim /etc/exports</span><br><span class="line"></span><br><span class="line">/home/$USER/nfs xx.xx.*.*(sync,rw,no_root_squash)		///home/$USER/nfs 目录被指定为要共享的目录，xx.xx.*.* 是允许访问这个目录的客户端IP地址的通配符，sync,rw,no_root_squash 是指定NFS共享选项的设置，其中 sync 表示同步写入，rw 表示读写访问，</span><br><span class="line"></span><br><span class="line">sudo exportfs -a									//这个命令将在NFS服务器上启用所有在 /etc/exports 文件中定义的共享资源。</span><br></pre></td></tr></table></figure></div>

<p><em>重启rpcbind服务：</em></p>
<blockquote>
<p><em>rpcbind服务通常在Unix&#x2F;Linux操作系统中与NFS（Network File System）一起使用，因为NFS使用RPC协议进行通信。在NFS中，客户端需要知道NFS服务器上的共享目录和文件的RPC程序号和端口号，以便能够访问它们。rpcbind服务可以提供这些信息，使得客户端可以连接到NFS服务器并访问共享资源。</em></p>
<p><em>在NFS中，rpcbind服务还可以管理NFS服务的注册和注销，以及处理NFS服务的版本控制。</em></p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service rpcbind restart</span><br></pre></td></tr></table></figure></div>

<p><em>重启nfs服务：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service nfs-kernel-server restart</span><br></pre></td></tr></table></figure></div>

<p><em>配置ip：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth1 xx.xx.xx.xx netmask 255.255.255.0</span><br></pre></td></tr></table></figure></div>

<p><em>挂载PC服务器文件夹于“&#x2F;mnt&#x2F;nfs”</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /mnt/nfs</span><br><span class="line">mount -t nfs -o nolock xx.xx.xx.xx:/home/$USER/nfs /mnt/nfs</span><br></pre></td></tr></table></figure></div>

<p><em>挂载成功后，PC上nfs文件夹内文件可以直接在板端进行读取&#x2F;写入&#x2F;执行等操作（配置权限后）</em></p>
<h3 id="编译命令"><a href="#编译命令" class="headerlink" title="编译命令"></a><em>编译命令</em></h3><p><em>搭建好开发环境后，下载代码到你的开发环境中，使用如下命令进行整体编译。</em></p>
<p><em><strong>这些指令是用于在Linux系统上编译一个名为 <code>platform_sdk</code> 的软件开发工具包。</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">user.name@server-1:~/work/pull/platform_sdk$ source build/envsetup.sh		//这个命令运行 envsetup.sh 脚本，它会设置一些环境变量和函数，以便编译工作正常进行。在这个例子中，envsetup.sh 脚本被运行在 /home/user.name/work/pull/platform_sdk 目录下。</span><br><span class="line"></span><br><span class="line">TOPDIR: /home/user.name/work/pull/platform_sdk		//这个命令输出变量 TOPDIR 的值，它是指编译工具包的顶级目录。</span><br><span class="line"></span><br><span class="line">including device/horizon/j5/vendorsetup.sh		// 这个命令包含 vendorsetup.sh 脚本，它会设置一些环境变量和函数，以便编译特定的设备。在这个例子中，vendorsetup.sh 脚本被包含在 device/horizon/j5 目录下。</span><br><span class="line"></span><br><span class="line">including device/horizon/matrix5/vendorsetup.sh		//这个命令包含 vendorsetup.sh 脚本，它会设置一些环境变量和函数，以便编译特定的设备。在这个例子中，vendorsetup.sh 脚本被包含在 device/horizon/matrix5 目录下。</span><br><span class="line"></span><br><span class="line">. /home/user.name/work/pull/platform_sdk/build/core/mainenv.sh		//这个命令运行 mainenv.sh 脚本，它会设置一些环境变量和函数，以便编译工作正常进行。</span><br><span class="line"></span><br><span class="line">user.name@server-1:~/work/pull/platform_sdk/build$ lunch		//这个命令运行 lunch 脚本，它会显示一个菜单，让用户选择要编译的目标设备和编译选项。</span><br><span class="line"></span><br><span class="line">You&#x27;re building on Linux echo</span><br><span class="line">Lunch menu... pick a combo:</span><br><span class="line">     1. horizon_j5-debug_gcc9.64</span><br><span class="line">     2. horizon_j5-release_gcc9.64</span><br><span class="line">     3. horizon_matrix5-debug_gcc9.64</span><br><span class="line">     4. horizon_matrix5-release_gcc9.64</span><br><span class="line"></span><br><span class="line">Which would you like?  1</span><br><span class="line">64-bit</span><br><span class="line">Debug_gcc9.3 Mode</span><br><span class="line">. /home/user.name/work/pull/platform_sdk/build/device/horizon/j5/debug_gcc9-env.sh</span><br><span class="line">******************************</span><br><span class="line">start to make tools</span><br><span class="line">make: Entering directory &#x27;/home/user.name/work/pull/platform_sdk/build/tools/pkgtool&#x27;</span><br><span class="line">make: &#x27;j5-imgpkg&#x27; is up to date.</span><br><span class="line">make: Leaving directory &#x27;/home/user.name/work/pull/platform_sdk/build/tools/pkgtool&#x27;</span><br><span class="line">has extracted gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu</span><br><span class="line">end make tools</span><br><span class="line">******************************</span><br><span class="line">=========================================</span><br><span class="line">ARCH=&quot;arm64&quot;</span><br><span class="line">CROSS_COMPILE=&quot;/home/user.name/work/pull/platform_sdk/prebuilts/host/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-&quot;</span><br><span class="line">TARGET_VENDOR=&quot;horizon&quot;</span><br><span class="line">TARGET_PROJECT=&quot;j5&quot;</span><br><span class="line">TARGET_MODE=&quot;debug&quot;</span><br><span class="line">TARGET_BIT=&quot;64&quot;</span><br><span class="line">ENABLE_BUILD_DEPENDENCY=&quot;false&quot;</span><br><span class="line">N=&quot;24&quot;</span><br><span class="line">=========================================</span><br><span class="line"></span><br><span class="line">user.name@CP:~/work/pull/platform_sdk/build$ ./build.sh -e all		//这个命令运行 build.sh 脚本，它会开始编译工作。-e all 参数表示要编译所有的目标文件和库。</span><br></pre></td></tr></table></figure></div>

<p><em><strong>生成的文件在out&#x2F;target&#x2F;product&#x2F;packages&#x2F;中。</strong></em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230417100729900.png"
                      class="" title="image-20230417100729900"
                ></em></p>
<h3 id="编译参数"><a href="#编译参数" class="headerlink" title="编译参数"></a><em>编译参数</em></h3><ul>
<li><em>J5-dvb板通用镜像(包含emmc和nor-flash镜像)</em></li>
</ul>
<blockquote>
<p><em>eMMC（Embedded MultiMediaCard）是一种内置式多媒体卡，它是一种针对嵌入式系统的存储设备。eMMC存储器通常被用于嵌入式系统中，例如智能手机、平板电脑、智能电视、机顶盒等设备。eMMC存储器通常包括一个闪存存储芯片和一个控制器芯片，它们一起组成了一个存储设备。</em></p>
<p><em>eMMC镜像是指将一个完整的系统镜像写入到eMMC存储器中的过程。通常，这个过程是通过一个专门的工具或者一个命令行工具来完成的。eMMC镜像包括操作系统、驱动程序、应用程序和其他相关文件，这些文件被写入到eMMC存储器中，以便在嵌入式系统中启动和运行。</em></p>
<p><em>在嵌入式系统中，eMMC存储器通常被用作主要的存储设备，因为它具有高速、低功耗、小尺寸等优点。通过将系统镜像写入到eMMC存储器中，可以方便地进行系统的备份和恢复，也可以方便地进行系统的升级和更新。</em></p>
</blockquote>
<blockquote>
<p><em>Nor Flash是一种非易失性存储器，它通常被用于嵌入式系统中，例如路由器、物联网设备、工控设备等。</em></p>
<p><em>与eMMC存储器相比，<strong>Nor Flash存储器的主要优点是读取速度更快，而且可以直接在系统中执行代码</strong>。Nor Flash存储器通常被用作嵌入式系统的启动设备，因为它可以提供快速的启动时间和可靠的启动过程。通过将系统镜像写入到Nor Flash存储器中，可以方便地进行系统的备份和恢复，也可以方便地进行系统的升级和更新</em></p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1  # horizon_j5-debug_gcc9.64</span><br><span class="line">./build.sh -e all</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em><code>source</code>命令会读取指定的脚本文件，并将其中的命令和变量加载到当前shell环境中。这意味着，如果你在脚本文件中设置了环境变量，那么在执行完<code>source</code>命令后，这些环境变量就会在当前shell会话中生效。</em></p>
<p><em><code>source</code>命令也可以用<code>.</code>来代替，它们的作用是完全相同的。例如，如果你有一个名为<code>my_script.sh</code>的脚本文件，用<code>. my_script.sh</code>执行脚本</em></p>
<p><em>需要注意的是，<code>source</code>命令只对当前shell会话有效。如果你在一个子shell中执行<code>source</code>命令，那么其中的环境变量和其他配置只会在该子shell中生效，而不会影响到父shell或其他shell会话。</em></p>
</blockquote>
<p><em>结果如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230417100729900.png"
                      class="" title="image-20230417100729900"
                ></em></p>
<ul>
<li><em>J5-dvb板nor-flash镜像</em></li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1   # horizon_j5-debug_gcc9.64</span><br><span class="line">./build.sh -e all –b j5dvb_nor</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em>J5-dvb板hyper-flash镜像</em></li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1    # horizon_j5-debug_gcc9.64				//命令用于选择要构建的目标设备和构建类型。在这个例子中，horizon_j5-debug_gcc9.64是一个构建类型，它指定了一个名为horizon_j5的设备，并使用debug构建类型和gcc9.64编译器。这个命令会设置一些环境变量，以便在后续的构建过程中使用。</span><br><span class="line"></span><br><span class="line">./build.sh -e all –b j5dvb_hyper			//-e all选项指定要构建的模块，–b j5dvb_hyper选项指定要构建的目标平台。</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em>J5-dvb板编译客户自定义app</em></li>
</ul>
<p><em>需要客户在源码根目录下创建一个目录，存放已经编译好的程序，比如vendor目录，编译打包如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1    # horizon_j5-debug_gcc9.64</span><br><span class="line">./build.sh -e all –a vendor			//-a vendor指的是将编译好的程序存放在vendor中</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em>RT和非RT版本编译</em></li>
</ul>
<blockquote>
<p><em>RT和非RT版本编译通常是指基于实时操作系统（RTOS）和普通操作系统的编译方式。</em></p>
<p><em>RT表示Real-Time（实时），RTOS表示实时操作系统。实时操作系统是一种特殊的操作系统，它能够保证系统对外部事件的响应时间，在特定时间内完成任务的执行。RTOS通常用于嵌入式系统、工业自动化、医疗设备等领域，要求系统对外部事件的响应时间非常快。RT版本编译通常指基于实时操作系统的编译方式，它可以保证系统对外部事件的响应时间，提高系统的实时性和可靠性。在RT版本编译中，编译器和链接器会使用特殊的选项和库文件，以便生成适合实时操作系统的可执行文件。</em></p>
<p><em>非RT版本编译通常指基于普通操作系统的编译方式，它不需要考虑实时性和可靠性等因素。在非RT版本编译中，编译器和链接器会使用普通的选项和库文件，以便生成适合普通操作系统的可执行文件。需要注意的是，RT版本编译和非RT版本编译的区别主要在于编译器和链接器的选项和库文件的不同，以及对实时性和可靠性等因素的考虑。在实际应用中，选择RT版本编译还是非RT版本编译，取决于系统的实际需求和应用场景。</em></p>
</blockquote>
<p><em>platform_sdk支持rt和非rt编译，开关是ENABLE_RT_PATCH环境变量，设置为true表示开RT；设置为false表示关闭RT，默认RT打开(可以通过ENABLE_RT_PATCH环境变量的值进行确认)，关RT编译如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1    # horizon_j5-debug_gcc9.64</span><br><span class="line">export ENABLE_RT_PATCH=false</span><br><span class="line">./build.sh -e all –a vendor</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em>编译时添加version</em></li>
</ul>
<p><em>编译时，为了方便追述板子上的代码，可以指定version信息，如下编译：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1    # horizon_j5-debug_gcc9.64</span><br><span class="line">./build.sh -e all –a vendor -v xx_20220815</span><br></pre></td></tr></table></figure></div>

<p><em>可以在板子上执行，如下命令进行查看：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb:/# cat /etc/version</span><br><span class="line">xxx_20220815 debug</span><br></pre></td></tr></table></figure></div>

<h3 id="编译配置"><a href="#编译配置" class="headerlink" title="编译配置"></a><em>编译配置</em></h3><h4 id="分区编译"><a href="#分区编译" class="headerlink" title="分区编译"></a><em>分区编译</em></h4><p><em>在build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;下有debug-gpt.conf配置文件。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">1:veeprom:none:34s:37s:1</span><br><span class="line">1:reserved:none:38s:1023s:1</span><br><span class="line">1:binfo1:none:1024s:2047s:1</span><br><span class="line">1:binfo2:none:2048s:3071s:1</span><br><span class="line">1:binfo3:none:3072s:4095s:1</span><br><span class="line">1:sbl/$&#123;UBOOT_SPL_NAME&#125;:none:4096s:4351s:1</span><br><span class="line">1:sblbak0/$&#123;UBOOT_SPL_NAME&#125;:none:4352s:4607s:1</span><br><span class="line">1:sblbak1/$&#123;UBOOT_SPL_NAME&#125;:none:4608s:4863s:1</span><br><span class="line">1:sblbak2/$&#123;UBOOT_SPL_NAME&#125;:none:4864s:5119s:1</span><br><span class="line">1:ddrc_a/ddrc.img.bin:none:5120s:5631s:1</span><br><span class="line">1:ddrc_b/ddrc.img.bin:none:5632s:6143s:1</span><br><span class="line">1:ddrp_a/ddrp.img.bin:none:6144s:8447s:1</span><br><span class="line">1:ddrp_b/ddrp.img.bin:none:8448s:10751s:1</span><br><span class="line">1:uboot_a/$&#123;UBOOT_IMAGE_NAME&#125;:none:10752s:14847s:1</span><br><span class="line">1:uboot_b/$&#123;UBOOT_IMAGE_NAME&#125;:none:14848s:18943s:1</span><br><span class="line">1:bl31_a/$&#123;BL31_IMAGE_NAME&#125;:none:18944s:20991s:1</span><br><span class="line">1:bl31_b/$&#123;BL31_IMAGE_NAME&#125;:none:20992s:23039s:1</span><br><span class="line">1:mcore_a:none:23040s:23295s:1</span><br><span class="line">1:mcore_b:none:23296s:23551s:1</span><br><span class="line">1:misc:none:23552s:23807s:1</span><br><span class="line">1:ubootenv:none:23808s:23815s:1</span><br><span class="line">1:HB_APDP:none:23816s:24063s:1</span><br><span class="line">1:veeprombak:none:24064s:25087s:1</span><br><span class="line">1:vbmeta_a/$&#123;VBMETA_IMAGE_NAME&#125;:none:25088s:25343s:1</span><br><span class="line">1:vbmeta_b/$&#123;VBMETA_IMAGE_NAME&#125;:none:25344s:25599s:1</span><br><span class="line">1:boot_a/$&#123;BOOT_PART_IMAGE_NAME&#125;:none:25600s:66559s:1</span><br><span class="line">1:boot_b/$&#123;BOOT_PART_IMAGE_NAME&#125;:none:66560s:107519s:1</span><br><span class="line">1:bpu_a:none:107520s:369663s:1</span><br><span class="line">1:bpu_b:none:369664s:631807s:1</span><br><span class="line">1:system_a:ext4:631808s:2728959s:0</span><br><span class="line">1:system_b:ext4:2728960s:4826111s:0</span><br><span class="line">1:app:ext4:4826112s:9020415s:0</span><br><span class="line">1:userdata:ext4:9020416s:13214719s:0</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>分区表是指计算机硬盘或其他存储设备上的分区信息表，它记录了存储设备上每个分区的起始位置、结束位置、大小等信息。分区表的作用是将一个物理硬盘或存储设备划分为多个逻辑分区，以便更有效地利用存储空间和管理数据。</em></p>
</blockquote>
<p><em>配置文件说明：</em></p>
<ul>
<li><em>分区使能:分区名:分区文件系统格式:起始分区位置:结束分区位置</em></li>
<li><em>分区使能:表示这一行是否需要建立真正的分区表，1表示需要建立分区，0不需要建立</em></li>
<li><em>分区名:分区表的名称，也是作为建立好后拷贝进分区的img名字</em></li>
<li><em>分区文件系统格式:可以支持下面格式（ubuntu14.04）如果为none，则表示不需要建立文件系统，当前为仅支持ext4</em></li>
<li><em>分区起始地址:分区起始地址一定要是512字节的整数倍，s代表的是emmc 的一个section 的缩写即512B</em></li>
<li><em>分区结束地址:分区结束地址一定要是512字节的整数倍，s代表的是emmc 的一个section 的缩写即512B</em></li>
<li><em>分区结束地址 - 分区起始地址 &#x3D; 分区大小</em></li>
<li><em>禁止出现小数和负数</em></li>
</ul>
<p><em>注意：起始位置和结束分区位置之间的大小计算方式为，结束分区位置-起始位置+1s。例 如最后一行，162017s - 62018s + 1s &#x3D; 100000s。</em></p>
<table>
<thead>
<tr>
<th><em><strong>序号</strong></em></th>
<th><em><strong>分区名</strong></em></th>
<th><em><strong>大小</strong></em></th>
<th><em><strong>文件系统</strong></em></th>
<th><em><strong>用途</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>1</em></td>
<td><em>veeprom</em></td>
<td><em>2K</em></td>
<td><em>none</em></td>
<td><em>存储OTA标志</em></td>
</tr>
<tr>
<td><em>2</em></td>
<td><em>reserved</em></td>
<td><em>493K</em></td>
<td><em>none</em></td>
<td><em>分区对齐使用</em></td>
</tr>
<tr>
<td><em>3</em></td>
<td><em>binfo1</em></td>
<td><em>512K</em></td>
<td><em>none</em></td>
<td><em>地平线启动标志</em></td>
</tr>
<tr>
<td><em>4</em></td>
<td><em>binfo2</em></td>
<td><em>512K</em></td>
<td><em>none</em></td>
<td><em>地平线启动标志</em></td>
</tr>
<tr>
<td><em>5</em></td>
<td><em>binfo3</em></td>
<td><em>512K</em></td>
<td><em>none</em></td>
<td><em>地平线启动标志</em></td>
</tr>
<tr>
<td><em>6</em></td>
<td><em>sbl</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>第二级bootloader</em></td>
</tr>
<tr>
<td><em>7</em></td>
<td><em>sblbak0</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>第二级bootloader</em></td>
</tr>
<tr>
<td><em>8</em></td>
<td><em>sblbak1</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>第二级bootloader</em></td>
</tr>
<tr>
<td><em>9</em></td>
<td><em>sblbak2</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>第二级bootloader</em></td>
</tr>
<tr>
<td><em>10</em></td>
<td><em>ddrc_a</em></td>
<td><em>256K</em></td>
<td><em>none</em></td>
<td><em>ddr controller的配置代码</em></td>
</tr>
<tr>
<td><em>11</em></td>
<td><em>ddrc_b</em></td>
<td><em>256K</em></td>
<td><em>none</em></td>
<td><em>ddr controller的配置代码</em></td>
</tr>
<tr>
<td><em>12</em></td>
<td><em>ddrp_a</em></td>
<td><em>1152K</em></td>
<td><em>none</em></td>
<td><em>是ddr controller的参数信息，目前预留</em></td>
</tr>
<tr>
<td><em>13</em></td>
<td><em>ddrp_b</em></td>
<td><em>1152K</em></td>
<td><em>none</em></td>
<td><em>是ddr controller的参数信息，目前预留</em></td>
</tr>
<tr>
<td><em>14</em></td>
<td><em>uboot_a</em></td>
<td><em>2048K</em></td>
<td><em>none</em></td>
<td><em>uboot镜像</em></td>
</tr>
<tr>
<td><em>15</em></td>
<td><em>uboot_b</em></td>
<td><em>2048K</em></td>
<td><em>none</em></td>
<td><em>uboot镜像</em></td>
</tr>
<tr>
<td><em>16</em></td>
<td><em>bl31_a</em></td>
<td><em>1024K</em></td>
<td><em>none</em></td>
<td><em>Arm trust environment firmware，运行在EL3状态，处理security相关操作</em></td>
</tr>
<tr>
<td><em>17</em></td>
<td><em>bl31_b</em></td>
<td><em>1024K</em></td>
<td><em>none</em></td>
<td><em>Arm trust environment firmware，运行在EL3状态，处理security相关操作</em></td>
</tr>
<tr>
<td><em>18</em></td>
<td><em>mcore_a</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>签名后的mcore 的镜像</em></td>
</tr>
<tr>
<td><em>19</em></td>
<td><em>mcore_b</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>签名后的mcore 的镜像</em></td>
</tr>
<tr>
<td><em>20</em></td>
<td><em>misc</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>存储AB分区标志</em></td>
</tr>
<tr>
<td><em>21</em></td>
<td><em>ubootenv</em></td>
<td><em>4K</em></td>
<td><em>none</em></td>
<td><em>存储uboot环境变量</em></td>
</tr>
<tr>
<td><em>22</em></td>
<td><em>HB_APDP</em></td>
<td><em>124K</em></td>
<td><em>none</em></td>
<td><em>内部调试使用</em></td>
</tr>
<tr>
<td><em>23</em></td>
<td><em>veeprombak</em></td>
<td><em>512K</em></td>
<td><em>none</em></td>
<td><em>存储IP 和网关</em></td>
</tr>
<tr>
<td><em>24</em></td>
<td><em>vbmeta_a</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>用于系统AVB启动校验的签名镜像</em></td>
</tr>
<tr>
<td><em>25</em></td>
<td><em>vbmeta_b</em></td>
<td><em>128K</em></td>
<td><em>none</em></td>
<td><em>用于系统AVB启动校验的签名镜像</em></td>
</tr>
<tr>
<td><em>26</em></td>
<td><em>boot_a</em></td>
<td><em>20M</em></td>
<td><em>none</em></td>
<td><em>kernel镜像（image+dtb）和rootfs</em></td>
</tr>
<tr>
<td><em>27</em></td>
<td><em>boot_b</em></td>
<td><em>20M</em></td>
<td><em>none</em></td>
<td><em>kernel镜像（image+dtb）和rootfs</em></td>
</tr>
<tr>
<td><em>28</em></td>
<td><em>bpu_a</em></td>
<td><em>128M</em></td>
<td><em>none</em></td>
<td><em>BPU 模型文件</em></td>
</tr>
<tr>
<td><em>29</em></td>
<td><em>bpu_b</em></td>
<td><em>128M</em></td>
<td><em>none</em></td>
<td><em>BPU 模型文件</em></td>
</tr>
<tr>
<td><em>30</em></td>
<td><em>system_a</em></td>
<td><em>1024M</em></td>
<td><em>ext4</em></td>
<td><em>系统运行必要的库、命令等，rootfs运行时被挂载到system目录，dm-verity只读分区</em></td>
</tr>
<tr>
<td><em>31</em></td>
<td><em>system_b</em></td>
<td><em>1024M</em></td>
<td><em>ext4</em></td>
<td><em>系统运行必要的库、命令等，rootfs运行时被挂载到system目录，dm-verity只读分区</em></td>
</tr>
<tr>
<td><em>32</em></td>
<td><em>app</em></td>
<td><em>2048M</em></td>
<td><em>ext4</em></td>
<td><em>app 分区镜像，rootfs运行是被挂载到app 目录，dm-verity只读分区</em></td>
</tr>
<tr>
<td><em>33</em></td>
<td><em>userdata</em></td>
<td><em>other</em></td>
<td><em>ext4</em></td>
<td><em>存储用户数据</em></td>
</tr>
</tbody></table>
<blockquote>
<p><em>挂载是指将设备连接到文件系统的过程。在挂载过程中，操作系统将设备与一个目录关联起来，这个目录称为挂载点。一旦设备被挂载到文件系统中，它就可以像其他文件一样被访问和操作。如果不挂载设备，系统就无法访问设备中的文件和目录。</em></p>
<p><em>因此，文件系统需要挂载才能在Linux系统中使用。在挂载文件系统时，需要指定挂载点以及其他一些选项，例如读写权限、文件系统类型等。这些选项将影响文件系统的访问方式和性能。</em></p>
<p><em><code>fstab</code>是一个文件系统表文件，它是Linux系统中用于自动挂载文件系统的配置文件之一。<code>fstab</code>中列出了系统上所有需要自动挂载的文件系统的详细信息，包括文件系统类型、设备名称、挂载点、挂载选项等。当系统启动时，<code>fstab</code>中列出的文件系统会自动挂载到指定的挂载点上。</em></p>
<p><em><code>fstab</code>文件通常位于<code>/etc/fstab</code>路径下，它是一个纯文本文件，可以使用任何文本编辑器进行编辑。在编辑<code>fstab</code>文件时，需要小心，因为错误的配置可能会导致系统启动失败，甚至无法启动。因此，在编辑<code>fstab</code>文件之前，最好备份一下原始文件。</em></p>
</blockquote>
<h4 id="文件系统设置"><a href="#文件系统设置" class="headerlink" title="文件系统设置"></a><em>文件系统设置</em></h4><p><em>文件系统配置表存放路径： build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;j5dvb.emmc.release.fstab build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;j5dvb.emmc.debug.fstab 根据4.1 章节中lunch 的选项是release还是debug，build 系统会选择对应的fstab，通过自 定义 fstab 文件可以设置你需要的文件系统配置，系统在启动的时候，会调用 mount –at 命 令，完成对&#x2F;etc&#x2F;fstab 文件的解析，从而挂载设置的文件系统。</em></p>
<blockquote>
<p><em><code>mount -a</code>命令的作用是挂载&#x2F;etc&#x2F;fstab文件中列出的所有文件系统。</em></p>
<p><em><strong>当系统启动时，操作系统会自动挂载<code>/etc/fstab</code>文件中列出的文件系统</strong>。但是，在某些情况下，可能需要手动挂载某个文件系统，或者在修改了<code>/etc/fstab</code>文件后需要重新挂载所有文件系统。此时，可以使用<code>mount -a</code>命令来挂载<code>/etc/fstab</code>文件中列出的所有文件系统。</em></p>
<p><em>需要注意的是，<strong>使用<code>mount -a</code>命令会挂载<code>/etc/fstab</code>文件中列出的所有文件系统，包括那些已经挂载的文件系统。</strong>因此，在使用<code>mount -a</code>命令之前，应该确保所有的文件系统都已经正确挂载，以免出现重复挂载或其他错误。</em></p>
</blockquote>
<h4 id="文件系统权限"><a href="#文件系统权限" class="headerlink" title="文件系统权限"></a><em>文件系统权限</em></h4><table>
<thead>
<tr>
<th><em><strong>序号</strong></em></th>
<th><em><strong>目录</strong></em></th>
<th><em><strong>权限</strong></em></th>
<th><em><strong>用途</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>1</em></td>
<td><em>&#x2F;system</em></td>
<td><em>只读</em></td>
<td><em>系统system镜像</em></td>
</tr>
<tr>
<td><em>2</em></td>
<td><em>&#x2F;app</em></td>
<td><em>只读</em></td>
<td><em>应用程序的镜像</em></td>
</tr>
<tr>
<td><em>3</em></td>
<td><em>&#x2F;userdata</em></td>
<td><em>读写</em></td>
<td><em>存放用户数据等</em></td>
</tr>
</tbody></table>
<h4 id="文件系统修改"><a href="#文件系统修改" class="headerlink" title="文件系统修改"></a><em>文件系统修改</em></h4><p><em>根文件系统路径：prebuilts&#x2F;root_hijack&#x2F;hobot&#x2F;，想要增减根文件系统文件，需要两步操作：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">user.name@hz-server-1:~/work/pull/platform_sdk$ ls prebuilts/root_hijack/hobot/</span><br><span class="line">etc  init.normal.rc  init.rc  init.recovery.rc  lib  sbin  usr  verity_key</span><br></pre></td></tr></table></figure></div>

<ol>
<li><em>在prebuilts&#x2F;root_hijack&#x2F;hobot&#x2F; 目录下增减相应的文件</em></li>
</ol>
<p><em>b. 文件增加到rootfs，在build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;debug-rootfs.manifest中，增加-文件，在 build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;debug-kernel-rootfs.manifest中，增加+文件 文件增加到system，在build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;debug-rootfs.manifest中，不操作，在 build&#x2F;device&#x2F;horizon&#x2F;j5&#x2F;debug-kernel-rootfs.manifest中，不操作。</em></p>
<h3 id="编译输出"><a href="#编译输出" class="headerlink" title="编译输出"></a><em>编译输出</em></h3><p><em>目前由编译系统编译生成的系统镜像如下表所示：</em></p>
<table>
<thead>
<tr>
<th><em><strong>镜像名字</strong></em></th>
<th><em><strong>对应分区</strong></em></th>
<th><em><strong>用途说明</strong></em></th>
<th><em><strong>镜像生成位置</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td><em>&#x2F;</em></td>
<td><em>veeprom</em></td>
<td><em>存储OTA标志</em></td>
<td><em>&#x2F;</em></td>
</tr>
<tr>
<td><em>gpt_main-secure.img</em></td>
<td><em>binfo1binfo2binfo3</em></td>
<td><em>地平线启动标志.&#x2F;build.sh –e all命令才会生成</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>binfo-nor-secure.img</em></td>
<td><em>binfo1binfo2binfo3</em></td>
<td><em>地平线启动标志.&#x2F;build.sh –e all –b j5dvb_nor 命令才会生成</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>binfo-hyper-secure.img</em></td>
<td><em>binfo1binfo2binfo3</em></td>
<td><em>地平线启动标志.&#x2F;build.sh –e all –b j5dvb_hyper 命令才会生成</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>spl.img0.bin</em></td>
<td><em>sblsblbak0sblbak1sblbak2</em></td>
<td><em>第二级bootloader</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>ddrc.img.bin</em></td>
<td><em>ddrc_addrc_b</em></td>
<td><em>ddrc.img.bin是ddr controller的配置代码。</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>&#x2F;</em></td>
<td><em>ddrp_addrp_b</em></td>
<td><em>是ddr controller的参数信息，目前预留</em></td>
<td><em>&#x2F;</em></td>
</tr>
<tr>
<td><em>uboot.img.bin</em></td>
<td><em>uboot_auboot_b</em></td>
<td><em>运行在EL1状态的第3级bootloader，下载boot.img或recovery.img到DDR，启动kernel和ramdisk。</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>bl31.img.bin</em></td>
<td><em>bl31_abl31_b</em></td>
<td><em>Arm trust environment firmware，运行在EL3状态，初始化arm，gic和syscounter，处理security相关操作，管理power和clock等功能。</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>mcore.img.bin</em></td>
<td><em>mcore_amcore_b</em></td>
<td><em>签名后的mcore的镜像</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>&#x2F;</em></td>
<td><em>misc</em></td>
<td><em>存储AB分区标志</em></td>
<td><em>&#x2F;</em></td>
</tr>
<tr>
<td><em>&#x2F;</em></td>
<td><em>ubootenv</em></td>
<td><em>存储uboot环境变量</em></td>
<td><em>&#x2F;</em></td>
</tr>
<tr>
<td><em>&#x2F;</em></td>
<td><em>HB_APDP</em></td>
<td><em>内部调试使用</em></td>
<td><em>&#x2F;</em></td>
</tr>
<tr>
<td><em>&#x2F;</em></td>
<td><em>veeprombak</em></td>
<td><em>存储IP 和网关</em></td>
<td><em>&#x2F;</em></td>
</tr>
<tr>
<td><em>vbmeta.img</em></td>
<td><em>vbmeta_avbmeta_b</em></td>
<td><em>用于系统AVB启动校验的签名镜像</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>boot.img</em></td>
<td><em>boot_aboot_b</em></td>
<td><em>用于系统正常模式下的kernel镜像（image+dtb）和ramdisk（最小rootfs）</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>bpu_image.bin</em></td>
<td><em>bpu_abpu_b</em></td>
<td><em>BPU 模型文件</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>system.img</em></td>
<td><em>system_asystem_b或者是system</em></td>
<td><em>系统rootfs镜像，在boot.img中的ramdisk运行时被mount。</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>app.img</em></td>
<td><em>app</em></td>
<td><em>app 分区镜像，在系统启动后会挂载到app 分区中</em></td>
<td><em>out&#x2F;target&#x2F;product&#x2F;packages</em></td>
</tr>
<tr>
<td><em>&#x2F;</em></td>
<td><em>userdata</em></td>
<td><em>存储用户数据</em></td>
<td><em>&#x2F;</em></td>
</tr>
</tbody></table>
<h3 id="签名加密"><a href="#签名加密" class="headerlink" title="签名加密"></a><em>签名加密</em></h3><p><em>前提：之前所有镜像都已经编译完成，还需要经过镜像签名后才能生成可用的镜像文件， 直接执行build&#x2F;目录下的Makefile，即可完成下面所有的镜像文件加密签名。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd build/</span><br><span class="line">make</span><br></pre></td></tr></table></figure></div>

<h3 id="模块编译"><a href="#模块编译" class="headerlink" title="模块编译"></a><em>模块编译</em></h3><p><em>模块单独编译产生的是未签名的镜像，还需要再进行镜像签名，才能烧录使用，否则启动会失败。 首先建立编译环境:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source build/envsetup.sh</span><br><span class="line">lunch 1   # horizon_j5-debug_gcc9.64</span><br></pre></td></tr></table></figure></div>

<h4 id="Uboot"><a href="#Uboot" class="headerlink" title="Uboot"></a><em>Uboot</em></h4><blockquote>
<p><em>U-Boot（Universal Bootloader）是一款开源的、广泛使用的引导加载程序（bootloader），它可以在嵌入式系统中加载和运行操作系统。</em></p>
<p><em>U-Boot的主要功能是加载和启动操作系统内核，但它还具有许多其他功能，例如配置硬件参数、下载和烧写固件、更新操作系统、启动网络等。U-Boot可以通过串口、以太网、USB等多种方式进行交互和配置，从而方便了系统的调试和维护。</em></p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd uboot/</span><br><span class="line">./build.sh -o emmc/nor/hyper</span><br></pre></td></tr></table></figure></div>

<h4 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a><em>Kernel</em></h4><blockquote>
<p><em>Kernel（内核）是操作系统的核心部分，它是操作系统与计算机硬件之间的接口，负责管理计算机的硬件资源和提供基本的系统服务。Kernel通常被称为操作系统的“心脏”，它是操作系统的最底层部分，直接运行在计算机的硬件上。</em></p>
<p><em>Kernel的主要功能包括管理计算机的内存、处理器、输入输出设备、文件系统等硬件资源，提供进程管理、内存管理、文件管理、网络通信等基本的系统服务。Kernel还负责处理中断、异常、系统调用等系统事件，并将它们分配给适当的进程进行处理。</em></p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd kernel/</span><br><span class="line">./build.sh all</span><br></pre></td></tr></table></figure></div>

<h4 id="MCore"><a href="#MCore" class="headerlink" title="MCore"></a><em>MCore</em></h4><blockquote>
<p><em>多核处理器是在单个物理芯片上集成了多个处理核心的处理器，可以同时执行多个线程或进程，从而提高系统的性能和效率。每个处理核心都可以独立运行，具有自己的寄存器、缓存、执行单元等硬件资源，并且可以共享系统资源，如内存、总线等。</em></p>
<p><em>MCore是一种多核处理器架构，由英特尔公司开发。MCore架构的处理器可以包含多个处理核心，每个核心都可以独立运行，同时共享系统资源。MCore架构的处理器通常用于高性能嵌入式系统中，例如路由器、交换机、网络存储设备等。</em></p>
</blockquote>
<p><em>进入 repo根目录&#x2F;mcore，执行build.sh，即可得到Mcore.bin与Mcore.elf。 编译成功会提示如下信息</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230417110135342.png"
                      class="" title="image-20230417110135342"
                ></em></p>
<h2 id="烧写镜像说明"><a href="#烧写镜像说明" class="headerlink" title="烧写镜像说明"></a><em>烧写镜像说明</em></h2><h3 id="地平线烧写工具"><a href="#地平线烧写工具" class="headerlink" title="地平线烧写工具"></a><em>地平线烧写工具</em></h3><p><em>地平线烧写工具将用于给开发板上的核心板烧写系统。目前烧写工具支持windows 64位系统和ubuntu14.04以上系统。用户需将系统对应的烧写 文件压缩包下载并解压，按镜像烧写流程介绍进行操作。其中不同选项对应具体含义请参 考“MU-3020-15-J5-开发板升级工具使用手册.docx”。</em></p>
<ul>
<li><em>Windows：解压hbupdate_win64_v</em>.zip文件，双击执行解压后目录里的hbupdate.exe。log文件存 放在解压后的log目录中。*</li>
<li><em>Linux：解压hbupdate_linux</em> v* .tgz文件，其中 * gui <em>为图形用户接口， * cli</em>为命令行用户接 口。在终端运行：*</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd hbupdate-linux</span><br><span class="line">sudo ./hbupdate-linux</span><br></pre></td></tr></table></figure></div>

<p><em>log文件存放在hbupdate-linux&#x2F;log目录。</em></p>
<h4 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a><em>使用流程</em></h4><blockquote>
<p><em>选择产品类型</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508083610568.png"
                      class="" title="image-20230508083610568"
                ></em></p>
<blockquote>
<p><em>选择升级配置，包括产品名称、下载模式、下载方式、内存类型</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508083658725.png"
                      class="" title="image-20230508083658725"
                ></em></p>
<blockquote>
<p><em>选择升级文件及升级文件选项</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508083721413.png"
                      class="" title="image-20230508083721413"
                ></em></p>
<blockquote>
<p><em>配置产品与PC连接参数：板端ip信息、PC端串口、网口等</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508083807175-16835062874561.png"
                      class="" title="image-20230508083807175"
                ></em></p>
<blockquote>
<p><em>开始升级，并按照弹窗信息进行相应操作</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508083839507.png"
                      class="" title="image-20230508083839507"
                ></em></p>
<h4 id="使用建议"><a href="#使用建议" class="headerlink" title="使用建议"></a><em>使用建议</em></h4><ul>
<li><em>使用之前务必仔细阅读使用手册</em></li>
<li><em>镜像的文件名不支持中文，不能有空格，最好是简单的全英文加下划线</em></li>
<li><em>为了增加镜像下载的速度和成功率，使用板子与PC直连，尤其不要用无线网络与板通讯</em></li>
<li><em>配置网络的时候要仔细确认板子的网络和pc的网卡地址是在一个子网</em></li>
<li><em>若网络不通，请关闭防火墙再尝试</em></li>
<li><em>当单板无法启动时，可以使用uart下载模式烧录救砖</em></li>
</ul>
<h3 id="UART"><a href="#UART" class="headerlink" title="UART"></a><em>UART</em></h3><blockquote>
<p><em>UART全称为Universal Asynchronous Receiver&#x2F;Transmitter，是一种可编程的串行通信接口，通常被用于将计算机和微控制器、传感器等外部设备进行通信。</em></p>
<p><em>UART通过将数据以固定的速率和格式转换为串行数据流，实现计算机和外部设备之间的通信。在UART通信中，发送数据的设备会将数据位逐个转换为二进制形式，然后将其传送给接收设备。接收设备会将串行数据流转换为并行数据，恢复原本的数据位格式。</em></p>
<p><em>UART有以下几个主要特点：</em></p>
<ol>
<li><em>双向通信。UART可以同时进行发送和接收数据。</em></li>
<li><em>异步通信。UART不需要在发送数据前和接收数据时进行时钟同步，而是通过规定的波特率来进行数据传输。</em></li>
<li><em>可编程波特率和数据位数。可以根据需要设置波特率、数据位数、校验位、停止位等参数来适应不同的应用场合。</em></li>
<li><em>数据传输可靠性高。UART通信采用双向数据传输，数据传输可靠性高，具有自动重发机制，能够保证数据的完整性。</em></li>
</ol>
<p><em>UART被广泛应用于各种设备和系统中，比如串口通信、嵌入式系统、物联网设备等等。</em></p>
</blockquote>
<blockquote>
<p><em>eMMC启动是指通过eMMC（embedded MultiMediaCard）闪存芯片来进行启动程序的过程。eMMC是一种用于移动设备和嵌入式系统的存储器标准，通常包括一个闪存芯片和一个控制器芯片，可以用于存储操作系统、应用程序、数据等。</em></p>
<p><em>在一些嵌入式系统中，比如Android手机、智能电视等设备，使用eMMC作为启动设备来加载操作系统和引导程序。启动过程可以分为预启动和引导两个阶段。</em></p>
<p><em>在预启动阶段，设备首先会加载引导固件（Bootloader），并初始化eMMC驱动程序，以确保可以正确地访问eMMC存储器。然后，引导固件会寻找并加载操作系统内核和内核所需的驱动程序等。在这个过程中，eMMC存储器会被作为一个块设备来访问，通过eMMC总线协议从闪存芯片中读取数据。</em></p>
<p><em>在引导阶段，设备会从eMMC中加载操作系统内核，并将系统控制权交给内核来完成启动过程。此时，eMMC仍然可以被用来访问更多的应用程序和数据。整个过程需要通过设备的引导方式和引导分区来指定，以确保可以正确地从eMMC中启动和加载数据。</em></p>
<p><em>总之，eMMC启动是指通过eMMC存储器来进行启动程序的过程，是嵌入式系统和移动设备中广泛采用的一种启动方式。</em></p>
</blockquote>
<p><em>a. 烧录准备 调整板上DIP开关至UART启动模式，波特率921600，下载并解压发布包。 b. 烧录命令</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">python3 x-modem-download/uart-load.py --secboot -d /dev/tty* -b 921600 -i *.*.*.* -p */packages/ flash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">python3：使用Python 3来运行后面的脚本。</span><br><span class="line">x-modem-download/uart-load.py：指定要运行的 Python 脚本，即 uart-load.py。x-modem-download 是脚本所在的目录。</span><br><span class="line">–secboot：表示在下载文件之前进行芯片验证（secure boot）。</span><br><span class="line">-d /dev/tty*：指定本地串行通信端口，* 通配符表示该参数可以是符合要求的任何字符串，例如 /dev/ttyS0 或 /dev/ttyUSB0。</span><br><span class="line">-b 921600：指定波特率（即数据传输速度），代表每秒可以传输 921600 个数据位。</span><br><span class="line">-i *.*.*.*：指定要下载数据的目标 IP 地址，* 通配符表示该参数可以是符合要求的任何字符串，例如 192.168.0.1。</span><br><span class="line">-p /packages/：指定要发送的数据所在的路径， 通配符表示该参数可以是符合要求的任何字符串，例如 /home/user/files/。</span><br><span class="line">flash：指定数据存储的位置，具体含义要看设备本身的存储结构，这里表示存储到设备的 flash 存储器中。</span><br></pre></td></tr></table></figure></div>

<p><em>星号部分分别修改为单板串口设备、单板配置ip、发布包packages路径。</em></p>
<h4 id="SecureCRT-1"><a href="#SecureCRT-1" class="headerlink" title="SecureCRT"></a><em>SecureCRT</em></h4><blockquote>
<p><em>SecureCRT是一款网络终端仿真软件，可以通过SSH、Telnet、Rlogin、Serial、TAPI和RAW协议连接到远程服务器，提供安全、稳定、高效的远程访问体验。</em></p>
<p><em>SecureCRT包含了各种常用的终端仿真功能，如会话管理、多标签窗口、多机位、动态端口转发、自动化脚本、重要会话的备份和日志记录等，同时还支持扩展插件、自定义快捷键、自动按键记录等便捷的操作方式，方便用户进行管理和配置。</em></p>
</blockquote>
<p><em>在菜单里选择对应传输协议。</em></p>
<h4 id="Minicom-1"><a href="#Minicom-1" class="headerlink" title="Minicom"></a><em>Minicom</em></h4><blockquote>
<p><em>Minicom是一款常用的串口通信工具，通常用于在Linux系统中连接到串口设备进行通信、调试等操作。Minicom支持多种串口、USB-to-serial适配器、以及远程终端，是一款功能强大的串口终端工具。</em></p>
<p><em>Minicom可以通过命令行方式启动，并提供了方便的菜单界面和快捷键操作。它支持串口设置、通信协议、硬件流控等常见的串口通讯设置，并可以保存多个会话连接，方便用户切换和管理。此外，Minicom还支持自动化脚本，可以通过脚本功能实现串口自动测试、设备自动化测试等功能。</em></p>
<p><em>Minicom相对于其他串口终端工具具有以下特点：</em></p>
<ol>
<li><em>开源免费：Minicom是一款完全开源的软件，用户可以免费下载使用，且提供源代码，用户可自由进行修改和定制。</em></li>
<li><em>易于安装和使用：Minicom通常在Linux系统中预安装，用户可直接使用命令行启动进行通信，界面简洁易用。</em></li>
<li><em>支持脚本编写：Minicom提供了自动化脚本编写功能，可以支持用户完成一些自动化测试和配置。</em></li>
</ol>
</blockquote>
<p><em>Ctrl-A+S 可选择具体协议。 前往输入目录，【空格】键可选择哪个文件，然后OK确认，执行下载。 注意：ROM阶段先用XModem协议传输SPL，其余镜像使用YModem协议传输： 上电提示从串口启动后，通过串口XMODEM协议下载spl</em>.bin到SRAM； 按照提示通过串口YMODEM协议下载boot.pkg，下载完成进入u-boot console进行后续烧写。*</p>
<h4 id="Linux命令行"><a href="#Linux命令行" class="headerlink" title="Linux命令行"></a><em>Linux命令行</em></h4><ol>
<li><em>调整板上DIP开关至UART启动模式，波特率921600</em></li>
<li><em>下载并解压发布包</em></li>
<li><em>烧录命令：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 x-modem-download/uart-load.py -d /dev/tty* -b 921600 -i *.*.*.* -p */packages/ flash</span><br></pre></td></tr></table></figure></div>

<p><em>备注：部分分别修改为单板串口设备、单板配置ip、发布包packages路径</em></p>
<h3 id="Uboot-1"><a href="#Uboot-1" class="headerlink" title="Uboot"></a><em>Uboot</em></h3><h4 id="烧写完整镜像"><a href="#烧写完整镜像" class="headerlink" title="烧写完整镜像"></a><em>烧写完整镜像</em></h4><p><em>在UBoot内：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">setenv ipaddr xx.xx.xx.yy /*开发板IP地址*/</span><br><span class="line">setenv serverip xx.xx.xx.xx /*主机ip地址*/</span><br><span class="line">tftp 0xa0000000 disk.img</span><br><span class="line">mmc write 0xa0000000 0 $&#123;filesize&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tftp 0xa0000000 disk.img：这个命令使用TFTP协议从主机下载文件 disk.img 并存储到开发板的内存地址 0xa0000000 处。TFTP是一种简单的文件传输协议，通常用于在嵌入式系统中从远程主机下载文件。</span><br><span class="line"></span><br><span class="line">mmc write 0xa0000000 0 $&#123;filesize&#125;：这个命令将内存地址 0xa0000000 处的数据写入到MMC（多媒体卡）设备的第一个扇区（偏移量为0）。$&#123;filesize&#125; 是一个变量，表示文件大小，将根据实际下载的文件大小进行替换。这个命令通常用于将下载的映像文件写入MMC设备的存储区，以便在开发板上进行系统更新或固件烧录。</span><br></pre></td></tr></table></figure></div>

<h4 id="烧写单独镜像"><a href="#烧写单独镜像" class="headerlink" title="烧写单独镜像"></a><em>烧写单独镜像</em></h4><p><em>在UBoot内： 如单独烧写分区镜像part，对应文件file： 使用mmc write命令。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tftp 0xa0000000 $file</span><br><span class="line">mmc write 0xa0000000 [part addr] [part len]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p><em>part addr为目标分区起始地址，可以通过mmc part命令查询后计算（起始blk）；part len为擦写块总数，由（filesize&#x2F;0x200）得出，其中，filesize为文件大小，必须为16进制，tftp下载后会打印出来。 在Kernel内： 通过tftp下载文件。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth1 xx.xx.xx.xx</span><br><span class="line">tftp –g xx.xx.xx.xx -r $file</span><br><span class="line"></span><br><span class="line">ifconfig eth1 xx.xx.xx.xx：这个指令用于配置网络接口 eth1 的IP地址为 xx.xx.xx.xx。ifconfig 是一个用于配置网络接口的命令，通过指定接口名和IP地址来配置对应的网络接口。</span><br><span class="line"></span><br><span class="line">tftp –g xx.xx.xx.xx -r $file：这个指令使用TFTP协议从远程主机 xx.xx.xx.xx 下载文件。-g 参数表示使用&quot;get&quot;（获取）模式，-r 参数后面跟着的是要下载的文件名，而 $file 则是一个变量，表示</span><br></pre></td></tr></table></figure></div>

<p><em>将文件写入对应分区。分区定义可通过命令”fdisk -l”查看。</em></p>
<h4 id="Fastboot"><a href="#Fastboot" class="headerlink" title="Fastboot"></a><em>Fastboot</em></h4><blockquote>
<p><em>Fastboot是一种用于Android设备的开发者工具和协议，用于在设备上执行各种操作，例如刷写固件、解锁引导加载程序、刷入分区、安装系统映像等。</em></p>
<p><em>以下是Fastboot的主要特点和用途：</em></p>
<ol>
<li><em>刷写固件和分区：Fastboot允许开发人员将固件（如操作系统、引导加载程序、内核等）和分区映像刷写到Android设备的存储器中。这是一种常用的方式来更新设备的固件或进行定制开发。</em></li>
<li><em>解锁引导加载程序：Fastboot提供了一种方式来解锁设备的引导加载程序（Bootloader）。解锁引导加载程序可以允许用户在设备上安装自定义固件、根据需要更改系统设置等。但请注意，解锁引导加载程序可能会导致设备安全性降低并且失去某些保修和支持。</em></li>
<li><em>安装系统映像：Fastboot可用于将完整的Android系统映像（如ROM、GSI等）刷入设备中。这对于开发人员和ROM定制者来说是非常有用的，可以进行系统级别的修改和调试。</em></li>
<li><em>调试和故障排除：Fastboot还提供了一些调试功能，例如查看设备状态、查看分区信息、重新启动设备等。这对于开发人员在调试和故障排除过程中非常有帮助。</em></li>
</ol>
<p><em>使用Fastboot需要在计算机上安装ADB（Android Debug Bridge）工具和设备驱动程序。然后，通过连接Android设备到计算机，并在计算机上运行相应的Fastboot命令，可以与设备进行通信和执行各种操作。</em></p>
</blockquote>
<p><em><strong>fastboot切忌使用系统自带的版本，可到<a class="link"   target="_blank" rel="noopener" href="https://wiki.lineageos.org/adb_fastboot_guide.html%E4%B8%8B%E8%BD%BD%EF%BC%8C%E6%88%96%E4%BB%8E%E5%8F%91%E5%B8%83%E5%8C%85downloadtools/fastboot/%E8%B7%AF%E5%BE%84%E4%B8%8B%E8%8E%B7%E5%8F%96%E3%80%82" >https://wiki.lineageos.org/adb_fastboot_guide.html下载，或从发布包downloadtools/fastboot/路径下获取。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></em></p>
<p><em>在Kernel内：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot bootloader</span><br></pre></td></tr></table></figure></div>

<p><em>在UBoot内：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run fastboot_cmd</span><br></pre></td></tr></table></figure></div>

<p><em>使用方法： 开发板通过上述方法进入Fastboot模式，并通过ethernet连接至PC，而PC端需安装Fastboot 工具，请参考LineageOS官网配置。使用Fastboot烧写镜像。 单板端命令：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#配置单板ip</span><br><span class="line">setenv ipaddr xx.xx.xx.xx</span><br><span class="line">#进入fastboot模式</span><br><span class="line">run fastboot_cmd</span><br><span class="line">#查看mmc分区表</span><br><span class="line">mmc part</span><br><span class="line">#查看mtd分区表</span><br><span class="line">mtd list</span><br></pre></td></tr></table></figure></div>

<p><em>PC端命令：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#配置要升级的单板ip,ip需与开发板配置相同</span><br><span class="line">export ANDROID_SERIAL=udp:xx.xx.xx.xx:5554</span><br><span class="line">#进入发布包packages目录，使用脚本完整升级镜像</span><br><span class="line">./flash_all.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#flash_all.sh部分可选配置</span><br><span class="line">[--golden] [--packages &lt;~/images/packages&gt;] [--ignore_bigimage] [--bootdevice mmc] [--secure]</span><br><span class="line">#升级golden镜像</span><br><span class="line">[--golden]</span><br><span class="line">#镜像文件所在路径</span><br><span class="line">[--packages &lt;~/images/packages&gt;]</span><br><span class="line">#忽略大镜像文件升级</span><br><span class="line">[--ignore_bigimage]</span><br><span class="line">#强制选择升级镜像位置，mmc/nor/hyper</span><br><span class="line">[--bootdevice mmc/nor/hyper]</span><br><span class="line">#升级secure boot		Secure Boot是许多现代计算机上的安全功能之一。它旨在确保在计算机启动过程中仅加载由操作系统制造商签名的代码和驱动程序，从而防止恶意代码启动和攻击。</span><br><span class="line">[--secure]</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em><strong>Golden镜像是指已经被完全配置、并进行了所有必要的软件安装和更新的镜像。</strong>它可以快速部署在多个计算机上，这些计算机共享相同的软件和配置，从而确保在整个组织中获得一致且可靠的部署。Golden镜像通常用于大型企业或组织内部、IT部门或系统管理员完成镜像创建。</em></p>
<p><em>Golden镜像可以包含操作系统、预安装的软件、安全设置、系统配置文件和补丁等内容。在创建镜像时，管理员应该考虑到需要创建的计算机数量、硬件类型、操作系统版本等，以确保镜像能够在所有目标计算机上成功部署。</em></p>
<p><em>使用Golden镜像可以带来多个好处：</em></p>
<ol>
<li><em>简化部署过程：通过使用Golden镜像，可以减少部署新计算机时的工作量和时间。当需要部署新计算机时，只要将Golden镜像应用到硬件上，系统管理员便不需要一遍又一遍地手动操作，从而可以快速且一致地部署新计算机。</em></li>
<li><em>加强安全性：通过预配置的安全设置和更新，可以确保所有的计算机都需要有相同的安全性和更新。</em></li>
<li><em>提高可管理性：通过使用Golden镜像，系统管理员可以管理、更新和升级组织中的所有计算机，并确保所有计算机都位于同一更新和配置级别上，简化管理和维护流程。</em></li>
</ol>
</blockquote>
<p><em>可以单独操作某一分区：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#单独烧写分区命令</span><br><span class="line">fastboot flash [part] [file]</span><br><span class="line">#其中part为分区名，file为要烧录的文件，如下：</span><br><span class="line">fastboot flash system_a system.img</span><br><span class="line">#单独擦写分区命令</span><br><span class="line">fastboot erase [part]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fastboot flash [part] [file]：这个命令用于将一个特定的分区烧写到Android设备的指定位置。[part] 参数指定要写入的分区名称，[file] 参数指定要烧录的文件名或路径。例如，fastboot flash system_a system.img 将 system.img 文件烧录到 system_a 分区中。在执行该命令之前，需要将设备设置为Fastboot模式，并将其连接到主机。</span><br><span class="line"></span><br><span class="line">fastboot erase [part]：这个命令用于擦除Android设备上的一个特定分区。[part] 参数指定要擦除的分区名称。例如，fastboot erase system_a 将擦除 system_a 分区。在执行该命令之前，需要将设备设置为Fastboot模式，并将其连接到主机。</span><br></pre></td></tr></table></figure></div>

<p><em>升级完成后可以直接复位单板。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastboot reboot</span><br></pre></td></tr></table></figure></div>

<h3 id="SD"><a href="#SD" class="headerlink" title="SD"></a><em>SD</em></h3><h4 id="烧写完整镜像-1"><a href="#烧写完整镜像-1" class="headerlink" title="烧写完整镜像"></a><em>烧写完整镜像</em></h4><p><em>制作 SD 卡：</em></p>
<ol>
<li><em>准备一张 SD 卡</em></li>
<li><em>本机完成完整镜像编译</em></li>
<li><em>进入 build&#x2F;scripts&#x2F; 目录</em></li>
<li><em>执行 mk_disk_img.sh 脚本</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gpt config is</span><br><span class="line">*******************************************************************</span><br><span class="line">*             ./mk_disk_img.sh Version 1.0</span><br><span class="line">*             generate disk.img</span><br><span class="line">*             usage: ./mk_disk_img.sh -d mmc|nor|hyper -s -k 0|4</span><br><span class="line">*******************************************************************</span><br><span class="line">其中-d指定启动介质，-s指定为加密镜像，-k指定芯片使用key0/key4</span><br></pre></td></tr></table></figure></div>

<p><em>在 out&#x2F;target&#x2F;product&#x2F;packages&#x2F; 目录下会生成 disk_xxx.img 镜像</em></p>
<p><em>导入到 SD 卡：</em></p>
<ol>
<li><em>假设 SD 卡在本机被识别为 &#x2F;dev&#x2F;sdb，sudo dd if&#x3D;disk_mmc.img of&#x3D;&#x2F;dev&#x2F;sdb</em></li>
<li><em>sync</em></li>
<li><em>disk_mmc.img 烧写</em></li>
<li><em>将 disk_mmc.img 放到 SD 卡的 userdata 分区，使用 SD 卡方式启动</em></li>
<li><em>在 Uboot 下使用 mmc read 的方式将 disk.img 读入到内存中，地址及大小仅供参考</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mmc dev 1           //切换到SD卡</span><br><span class="line">mmc read 0xa0000000 599c10 5821  // mmc read 内存地址 分区地址（userdata区） 块大小（disk.img大小）</span><br><span class="line">mmc dev 0           //切换到eMMC</span><br><span class="line">mmc write 0xa0000000 0 5821         // mmc write 内存地址 分区地址（从eMMC开头开始写） 块大小（disk.img大小）</span><br></pre></td></tr></table></figure></div>

<p><em>断电，选择 eMMC 启动。</em></p>
<h4 id="烧写分区镜像"><a href="#烧写分区镜像" class="headerlink" title="烧写分区镜像"></a><em>烧写分区镜像</em></h4><ol>
<li><em>将各分区镜像放在 SD 卡的 userdata 分区</em></li>
<li><em>在 Uboot 下使用 mmc write 的方式将各分区镜像写入到 emmc 对应的分区上</em></li>
</ol>
<h2 id="验证检查"><a href="#验证检查" class="headerlink" title="验证检查"></a><em>验证检查</em></h2><h3 id="系统版本"><a href="#系统版本" class="headerlink" title="系统版本"></a><em>系统版本</em></h3><p><em>使用以下命令检查当前系统的版本：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb:~# cat /proc/version</span><br></pre></td></tr></table></figure></div>

<h4 id="状态检查：BPU"><a href="#状态检查：BPU" class="headerlink" title="状态检查：BPU"></a><em>状态检查：BPU</em></h4><blockquote>
<p><em>BPU指的是分支预测单元（Branch Prediction Unit），是现代CPU中一个重要的功能单元。</em></p>
<p><em><strong>在CPU中，分支指令是一个重要的控制结构，它可以判断程序执行路线，并对后续指令的执行顺序进行控制。</strong>但是分支指令的执行会导致CPU的流水线（Pipeline）暂停，从而影响CPU的性能。为了减少流水线的暂停，BPU被设计用于预测分支指令的执行结果。</em></p>
<p><em>BPU通常利用历史和上下文信息，来预测分支指令的执行路径。例如，它可能会记录之前分支指令的执行结果，以便判断某个分支指令执行的可能路径。BPU还可能会根据分支指令所处的上下文环境进行预测，例如，它可能会根据当前程序代码中循环结构的特征来预测分支指令的执行路径。</em></p>
<p><em>如果BPU预测正确，它将能够使CPU流水线保持高效的运行。但是，如果BPU预测错误，则会导致流水线中断，从而使CPU性能下降。因此，研究和优化BPU的预测算法，是提高CPU性能的一个重要方向。</em></p>
</blockquote>
<p><em>可使用 hrut_somstatus 工具查看 BPU 基本工作状态，可获取到 BPU 当前运行频率信息和占用率信息。</em></p>
<p><em>( BPU 未使能工作时，频率信息仅为软件记录信息，并非 BPU 真实工作频率)</em></p>
<p><em>Linux shell 中执行命令 hrut_somstatus，可打印基本工作状态。</em></p>
<p><em>除 hrut_somstatus 工具外，BPU 的详细工作状态还可以通过 BPU 相关的 sys 节点查看。</em></p>
<h3 id="状态检查：MCore"><a href="#状态检查：MCore" class="headerlink" title="状态检查：MCore"></a><em>状态检查：MCore</em></h3><blockquote>
<p><em>mcore可能指多核中心（multicore），是计算机中的一种处理器类型。</em></p>
<p><em><strong>多核中心（multicore）指的是将多个核心集成到同一个物理芯片中的处理器。</strong>与单核心（single-core）处理器相比，多核心处理器可以在同一时间内执行更多的任务。例如，在多核心计算机上，一个核心可以运行操作系统，另一个核心可以同时运行一个计算密集型的应用程序，从而提高计算机的总体性能。</em></p>
<p><em>多核心处理器也可以带来更好的能效比（energy efficiency ratio），因为每个核心可以更高效地使用电能和计算资源。此外，多核心设计也可以提高计算机的可靠性，因为即使其中一个核心受到故障或运行缓慢，其他核心仍然可以继续运行任务。</em></p>
<p><em>现今，多数计算机都采用多核心处理器，而不是单核心处理器，因为多核心处理器拥有更高的计算性能和更好的能效比。</em></p>
</blockquote>
<p><em>使用以下命令检查 MCore 工作状态和当前运行的 MCore firmware 的版本：</em></p>
<ol>
<li><em>使用以下命令检查Mcore工作状态</em></li>
</ol>
<p><em>在 Linux shell 中执行命令 “cat &#x2F;sys&#x2F;class&#x2F;remoteproc&#x2F;remoteproc0&#x2F;live”，如果显示 live，则表示 MCore 正常运行。</em></p>
<p><em>如果显示 dead，则表示 MCore 没有正常工作。</em></p>
<ol>
<li><em>使用以下命令检查 MCore firmware 的版本：</em></li>
</ol>
<p><em>在 Linux shell 中执行命令 “cat &#x2F;sys&#x2F;class&#x2F;remoteproc&#x2F;remoteproc0&#x2F;version”，即可查看 MCore 固件的版本号信息。</em></p>
<h2 id="常用工具"><a href="#常用工具" class="headerlink" title="常用工具"></a><em>常用工具</em></h2><h4 id="hrut-bpuprofile"><a href="#hrut-bpuprofile" class="headerlink" title="hrut_bpuprofile"></a><em>hrut_bpuprofile</em></h4><p><em>hrut_bpuprofile工具可用来调频，开关bpu电源，开关bpu clock，查看使用率，获取fc时间等。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508105126487.png"
                      class="" title="image-20230508105126487"
                ></em></p>
<p><em>参数如下：</em></p>
<ul>
<li><p><em>-b</em></p>
<p><em>指定哪个bpu，0-bpu0，1-bpu1，2-all</em></p>
</li>
<li><p><em>-p</em></p>
<p><em>电源掉电&#x2F;上电，0-off，1-on</em></p>
</li>
<li><p><em>-c</em></p>
<p><em>clock on&#x2F;off，0-off，1-on</em></p>
</li>
<li><p><em>-f</em></p>
<p><em>设置bpu频率，n-设置bpu频率为n</em></p>
</li>
<li><p><em>-r</em></p>
<p><em>查看bpu使用率，n-查看n次，0-始终查看</em></p>
</li>
<li><p><em>-e</em></p>
<p><em>使能查看fc执行时间功能(兼容参数，J5默认已开启且无法关闭)</em></p>
</li>
<li><p><em>-t</em></p>
<p><em>查看前50次每个fc的执行时间</em></p>
</li>
<li><p><em>-h</em></p>
<p><em>帮助信息</em></p>
</li>
</ul>
<p><em>查看2个bpu的使用率（always）</em></p>
<p><em>BPU Core0:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 0 -r 1</span><br></pre></td></tr></table></figure></div>

<p><em>查看BPU Core0的使用率，-r 1代表只执行一次，-r n代表执行n次，间隔1s, n&#x3D;0表示一直循环执行。</em></p>
<p><em>BPU Core1:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 1 -r 1</span><br></pre></td></tr></table></figure></div>

<p><em>查看BPU Core1的使用率，-r 1代表只执行一次，-r n代表执行n次，间隔1s，n&#x3D;0表示一直循 环执行。</em></p>
<p><em>BPU Core0&#x2F;1：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 2 -r 1</span><br></pre></td></tr></table></figure></div>

<p><em>同时查看BPU Core0和Core1的使用率，-r 1代表只执行一次，-r n代表执行n次，间隔1s, n&#x3D;0 表示一直循环执行。</em></p>
<p><em>设置2个bpu的频率</em></p>
<p><em>BPU Core0：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 0 -f 400000000 设置bpu0的频率为400M</span><br></pre></td></tr></table></figure></div>

<p><em>查看支持哪些频率：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/devices/system/bpu/bpu0/devfreq/*/available_frequencies</span><br></pre></td></tr></table></figure></div>

<p><em>查看频率有没有设置成功：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/devices/system/bpu/bpu0/devfreq/*/cur_freq</span><br></pre></td></tr></table></figure></div>

<p><em>BPU Core1:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 1 -f 400000000 设置bpu1的频率为400M</span><br></pre></td></tr></table></figure></div>

<p><em>查看支持哪些频率：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/devices/system/bpu/bpu1/devfreq/*/available_frequencies</span><br></pre></td></tr></table></figure></div>

<p><em>查看频率有没有设置成功：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/devices/system/bpu/bpu1/devfreq/*/cur_freq</span><br></pre></td></tr></table></figure></div>

<p><em>BPU Core0&#x2F;1：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 2 -f 400000000设置bpu0/bpu1的频率为400M</span><br></pre></td></tr></table></figure></div>

<p><em>BPU core支持频率的查看方法同上</em></p>
<p><em>给2个bpu上下电</em></p>
<p><em>BPU Core0:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 0 -p 0</span><br></pre></td></tr></table></figure></div>

<p><em>将BPU Core 0下电</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 0 -p 1</span><br></pre></td></tr></table></figure></div>

<p><em>将BPU Core 0上电</em></p>
<p><em>BPU Core1:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 1 -p 0</span><br></pre></td></tr></table></figure></div>

<p><em>将BPU Core 1下电</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 1 -p 1</span><br></pre></td></tr></table></figure></div>

<p><em>将BPU Core 1上电</em></p>
<p><em>BPU Core0&#x2F;1：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 2 -p 0</span><br></pre></td></tr></table></figure></div>

<p><em>同时将BPU Core 0&#x2F;1下电</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 2 -p 1</span><br></pre></td></tr></table></figure></div>

<p><em>同时将BPU Core 0&#x2F;1上电</em></p>
<p><em>查看fc执行时间</em></p>
<p><em>BPU Core0:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 0 -t 1</span><br></pre></td></tr></table></figure></div>

<p><em>显示BPU Core0最近已处理fc任务的执行时间信息</em></p>
<p><em>BPU Core1:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_bpuprofile -b 1 -t 1</span><br></pre></td></tr></table></figure></div>

<p><em>显示BPU Core1最近已处理fc任务的执行时间信息</em></p>
<p><em>输出信息如下：</em></p>
<ul>
<li><em>index：该任务位于BPU硬件FIFO中的位置</em></li>
<li><em>id：用户设置的中断id</em></li>
<li><em>hwid：底层驱动维护的中断id</em></li>
<li><em>group：用户设置的组id，用户进程号</em></li>
<li><em>prio：任务优先级</em></li>
<li><em>s_time：任务处理开始的时间戳</em></li>
<li><em>e_time：任务处理结束的时间戳</em></li>
<li><em>r_time：任务被处理的总耗时</em></li>
</ul>
<h4 id="hrut-ddr"><a href="#hrut-ddr" class="headerlink" title="hrut_ddr"></a><em>hrut_ddr</em></h4><p><em>使用 hrut_ddr 用来实时采集内存的吞吐量，方便分析程序实际的内存使用量。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508105624157.png"
                      class="" title="image-20230508105624157"
                ></em></p>
<p><em>参数如下：</em></p>
<ul>
<li><p><em>-t</em></p>
<p><em>指定需要采集的端口，默认是采集所有端口的内存吞吐量</em></p>
</li>
<li><p><em>-p</em></p>
<p><em>指定采集的周期，单位 us，建议最小设置为 10000，防止采集中断过多</em></p>
</li>
<li><p><em>-d</em></p>
<p><em>指定采集的 DDR 设备，默认会采集两个 DDR 上的内存吞吐量</em></p>
</li>
<li><p><em>-n</em></p>
<p><em>指定采样数量，默认值为 100</em></p>
</li>
<li><p><em>-r</em></p>
<p><em>采集原始寄存器里面的数据，不做任何转换</em></p>
</li>
</ul>
<p><em>输入结果如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508105637087.png"
                      class="" title="image-20230508105637087"
                ></em></p>
<h4 id="hrut-mac-utility"><a href="#hrut-mac-utility" class="headerlink" title="hrut_mac_utility"></a><em>hrut_mac_utility</em></h4><p><em>使用 hrut_mac utility 用来保存当前板子网卡 MAC 相关参数的 utility。</em></p>
<p><em>用法：</em></p>
<ol>
<li><em>写入</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_mac s [eth0/eth1] aa:bb:cc:dd:ee:ff</span><br></pre></td></tr></table></figure></div>

<p><em>配置成功后，重启生效。</em></p>
<ol>
<li><em>读出</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_mac g [eth0/eth1]</span><br></pre></td></tr></table></figure></div>

<ol>
<li><em>清除</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_mac c [eth0/eth1]</span><br></pre></td></tr></table></figure></div>

<h4 id="hrut-ipfull-utility"><a href="#hrut-ipfull-utility" class="headerlink" title="hrut_ipfull_utility"></a><em>hrut_ipfull_utility</em></h4><p><em>hrut_ipfull utility 是用来保存当前板子内核下 IP 相关参数的工具，IP 配置完成后，板子下次上电会自动配置网络参数 (IP、mask), 并添加网关 (gateway) 到路由。</em></p>
<p><em>注意：部分产品 IP 被锁死，无法通过本工具进行配置。Uboot 下的 IP 地址，在 Uboot 下使用 setenv ipaddr 192.168.1.10 来实现。</em></p>
<p><em>用法：</em></p>
<ol>
<li><em>写入</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_ipfull s [eth0/eth1] IP MASK GATEWAY</span><br></pre></td></tr></table></figure></div>

<p><em>e.g. hrut_ipfull s [eth0&#x2F;eth1] 192.168.1.10 255.255.255.0 192.168.1.1</em></p>
<p><em>配置成功后，将在下一次启动生效。GATEWAY是可选参数，eth0&#x2F;eth1也是可选参数，如果不指定网口则默认设置eth0</em></p>
<ol>
<li><em>读出</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_ipfull g [eth0/eth1]</span><br></pre></td></tr></table></figure></div>

<p><em>下面打印应当出现：</em></p>
<ul>
<li><em>ip&#x3D;192.168.1.10</em></li>
<li><em>mask&#x3D;255.255.255.0</em></li>
<li><em>gw&#x3D;192.168.1.1</em></li>
</ul>
<ol>
<li><em>清除</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_ipfull c  [eth0/eth1]</span><br></pre></td></tr></table></figure></div>

<p><em>注意：一旦配置成功，重启后在&#x2F;tmp下面会有几个文件，记录了当前的配置的值，其含义如名字</em></p>
<ul>
<li><em>&#x2F;tmp&#x2F;ip_mac_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_ip_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_mask_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_gw_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_mac_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_ip_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_mask_eth0</em></li>
<li><em>&#x2F;tmp&#x2F;ip_gw_eth0</em></li>
</ul>
<h4 id="hrut-boardid"><a href="#hrut-boardid" class="headerlink" title="hrut_boardid"></a><em>hrut_boardid</em></h4><p><em>hrut_boardid utility 是用来获取当前开发板 Board ID 的工具。</em></p>
<p><em>用法：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_boardid</span><br></pre></td></tr></table></figure></div>

<h4 id="hrut-somstatus"><a href="#hrut-somstatus" class="headerlink" title="hrut_somstatus"></a><em>hrut_somstatus</em></h4><p><em>hrut_somstatus utility 是用来获取当前开发板 SOM 状态的工具，包含温度、CPU 频率、BPU 状态。</em></p>
<p><em>用法：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hrut_somstatus</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>SOM 是 System-on-Module 的缩写，意为模块化系统。SOM 是一种嵌入式系统开发的模块化解决方案，它将各种核心组件和电路集成在一个小型的模块中，包括处理器、内存、存储、通信接口和其他周边设备。</em></p>
</blockquote>
<h1 id="地平线征程5-芯片算法工具链"><a href="#地平线征程5-芯片算法工具链" class="headerlink" title="地平线征程5 芯片算法工具链"></a><em>地平线征程5 芯片算法工具链</em></h1><p><em>地平线征程5（也称Journey5、J5）芯片算法工具链是基于地平线征程5代芯片研发的芯片算法解决方案。 它包含： <strong>模型算法处理</strong> 和 <strong>嵌入式模型预测库</strong> 两大重要组件。 模型算法处理提供PTQ训练后量化方案和QAT量化感知训练方案。 转换后得到的定点模型配合模型编译工具处理后就可以在地平线芯片上执行。 嵌入式模型预测库提供利用定点模型完成推理的系列支持接口。</em></p>
<blockquote>
<p><em><strong>模型算法处理指的是利用数学模型和算法来解决实际问题的过程</strong>。在机器学习和数据分析领域中，模型算法处理通常包括以下几个主要步骤：</em></p>
<ol>
<li><em>数据采集和预处理：获取原始数据集并进行清洗、处理、转换等预处理，以便于后续的建模和算法处理。</em></li>
<li><em>特征提取和选择：根据业务特定需要和算法要求，从原始数据中提取出特征变量，并对其进行选择和过滤，以提高模型的准确性和泛化能力。</em><u>模型的泛化能力指的是模型对未见过的数据的适应能力，也就是说，模型在训练集上训练得很好，但在测试集或实际应用中表现不佳的情况。</u> </li>
<li><em>模型选择和训练：根据问题的复杂度和数据集的大小，选择适当的模型算法，如决策树、支持向量机、神经网络等，进行模型训练和优化。</em></li>
<li><em>模型评估和验证：通过交叉验证、ROC曲线等方法对模型进行评估和验证，以确保模型的性能和泛化能力。</em></li>
<li><em>模型部署和应用：将训练好的模型部署到生产环境或应用场景中，并利用其进行数据预测、分类、回归、聚类等任务，实现对实际问题的优化和解决。</em></li>
</ol>
<p><em>总之，模型算法处理是一种复杂的数据分析和机器学习过程，需要综合运用数学、数据科学、计算机科学等知识和技能。通过模型算法处理，可以高效地解决实际问题，并提高企业和个人的决策效率和精度。</em></p>
</blockquote>
<blockquote>
<p><em><strong>嵌入式模型预测库是一种用于在嵌入式设备上进行机器学习模型推理的软件库。</strong>这些模型通常在云端或其他高性能计算机上训练，然后在较弱的嵌入式设备上部署，以完成特定的推理任务，例如图像分类、语音识别等。</em></p>
<p><em>嵌入式模型预测库旨在提供快速、轻便的模型推理功能，以适应嵌入式设备的资源限制，例如内存、处理能力、存储等。这些库通常是为具体的嵌入式处理器架构和操作系统开发的，可以优化底层硬件资源以提高性能。</em></p>
<p><em>嵌入式模型预测库通常实现了一些高效的机器学习算法和技术，例如卷积神经网络（Convolutional Neural Networks, CNNs）、循环神经网络（Recurrent Neural Networks, RNNs)等，以适应不同的应用场景。此外，它们通常还提供了简单易用的API接口，用于加载和运行模型，以及获取结果。</em></p>
<p><em>随着嵌入式设备变得越来越普及，越来越多的嵌入式模型预测库被开发出来，用于将机器学习带到嵌入式系统中，以提供更加智能的功能和应用。</em></p>
</blockquote>
<blockquote>
<p><em><strong>量化是一种将模型中参数和计算转化为低精度表示的过程</strong>，可以降低计算量和存储需求，从而使模型在嵌入式设备等资源有限的场景下具有更好的性能。PTQ是一种将经过训练的模型中的所有参数转为整数的量化方式，常用于对已训练的模型进行后处理来实现低精度计算。QAT是一种在训练过程中就考虑量化误差的方法。与 PTQ 不同的是，</em><em>QAT 以训练所得的模型的结构和权重作为基础，通过额外的量化感知损失函数模拟量化误差，以提高模型的精度和鲁棒性**。</em></p>
<p><em>因此，“模型算法处理提供PTQ训练后量化方案和QAT量化感知训练方案”意味着该处理提供两种不同的模型量化方法，可以让用户灵活地选择量化方式来满足不同的使用需求，提高了模型在有限的计算资源中的性能和效率。</em></p>
</blockquote>
<blockquote>
<p><em>定点模型（Fixed-Point Model）是一种在计算机领域常用的数值表示方式。相对于常用的浮点数表示，<strong>定点模型采用固定位数的整数来表示实数，具有节省存储空间、运算速度较快等优点</strong>，在嵌入式设备、移动设备等资源有限的场景下得到广泛应用。</em></p>
</blockquote>
<p><em>为了让开发者快速上手体验模型训练&#x2F;转换、部署、验证、推理等关键步骤，芯片工具链的各组件还提供 <strong>示例包</strong> 以及配合示例包使用的Docker镜像和模型发布物。 这些示例包将各工具核心业务逻辑和关键配置参数封装成脚本；模型发布物内置了丰富的算法模型；Docker镜像预置了使用示例包所需的开发环境。</em></p>
<h3 id="产品简介"><a href="#产品简介" class="headerlink" title="产品简介"></a><em>产品简介</em></h3><p>地平线J5芯片算法工具链（以下简称 工具链）是一套完整的<strong>边缘芯片算法</strong>落地解决方案，可以帮助您把浮点模型量化为定点模型， 并在地平线芯片上快速部署自研算法模型。</p>
<blockquote>
<p>边缘芯片算法指的是在边缘设备上运行的机器学习算法。边缘芯片算法是通过<strong>在局部执行数据处理和决策</strong>，将更多的智能移到数据生成的地方来实现智能化的方式。传统上，采集的数据通常在被传输到后台服务器或云端处理前会先被存储在边缘设备中。而局部执行的方法，可以在数据发送到后端之前或不经过后端，直接在数据源处执行数据处理和决策代码，从而降低了延迟和网络负载，避免了数据安全的隐患。</p>
</blockquote>
<h4 id="OE文档脉络"><a href="#OE文档脉络" class="headerlink" title="OE文档脉络"></a><em>OE文档脉络</em></h4><blockquote>
<p><em>产品简介</em></p>
</blockquote>
<p><em>OE是Open Explorer的缩写简称，中文名为天工开物（以下简称OE），它是基于地平线自研芯片打造的全生命周期开发平台， 主要包括模型编译优化工具集、芯片算法仓库和应用开发SDK三大功能模块。基于这三大功能模块开发的应用参考解决方案，为智能驾驶、智能物联网等行业方案提供了案例支撑。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508143642837.png"
                      class="" title="image-20230508143642837"
                ></em></p>
<ol>
<li><em>模型编译优化工具集：如上图中黄色框内的部分，聚焦于人工智能业务场景，包括完成算法模型转换与部署全流程中所涉及到的一系列软件工具集，具有模型量化、优化、编译、仿真、部署、调试等功能。</em></li>
<li><em>芯片算法仓库：包括产品级算法、基础算法和产品参考算法三类算法资源，赋能地平线芯片合作伙伴更快、更省地开发出自己的人工智能产品。</em></li>
<li><em>应用开发SDK：提供丰富的、高度可复用的算法模块、业务策略模块、应用组件和场景应用参考方案，旨在加速客户从业务模型集成到应用程序开发流程。</em></li>
</ol>
<blockquote>
<p><em>SOM开发板指的是搭载SOM（System On Module）模块的开发板。SOM是一种嵌入式计算模块，通常包含处理器、内存、存储器、通信接口、传感器等核心组件。它的特点是封装度高、易于集成和维护，可以大大降低嵌入式系统的开发难度和成本。</em></p>
<p><em><strong>SOM开发板通常是在SOM模块上提供一系列扩展接口和外围硬件，如网口、USB接口、HDMI接口、GPIO、SPI、I2C等，方便开发者进行硬件扩展和软件开发。</strong>SOM开发板具有丰富的功能和性能，并且易于使用和维护，非常适合用于物联网、智能家居、智能制造、智能医疗等嵌入式应用领域。</em></p>
<p><em>SOM开发板通常由硬件设计、嵌入式软件开发、系统集成等多个方面的工程师合作开发。因此，SOM开发板的开发周期一般较长，但是可以大大提高产品开发和生产的效率和质量。</em></p>
</blockquote>
<blockquote>
<p><em>EVM开发板是一种用于快速原型设计和研究的嵌入式系统开发板。EVM是英文Evaluation Module的缩写，<strong>意为评估模块，其主要功能是为用户提供一个低成本、高可靠性的硬件平台，用于验证和测试硬件和软件设计</strong>。EVM开发板通常搭载了处理器、存储器、通信接口、传感器等核心组件，可以通过扩展接口来实现更多的硬件扩展和功能增强，从而满足各种不同的应用需求。厂商一般提供相关的软件开发包和技术支持，为用户提供方便的使用和开发环境，使得用户能够快速地开发出适合自己应用场景的嵌入式产品。</em></p>
<p><em>EVM开发板的设计周期比较短，比SOM开发板更具有灵活性和适应性，<strong>主要用于将嵌入式系统快速投入到市场中，具有一定的临时性和应急性。</strong></em></p>
<ol>
<li>芯片评估和测试： EVM开发板常用于评估和测试新的芯片或处理器。通过使用EVM开发板，工程师可以快速了解芯片的性能和功能，提前评估其是否符合系统设计的要求。</li>
<li>原型设计： EVM开发板可以用于快速原型设计和系统原型验证。它允许开发者快速搭建一个原型系统，测试系统的各个组件和功能，并快速迭代和优化系统。</li>
<li>硬件调试： 当出现问题或故障时， EVM开发板可以作为故障排查的工具，帮助工程师快速排除硬件问题。它可以用来检查芯片、寄存器、总线等硬件组件是否正常。</li>
<li>驱动程序的开发调试： EVM开发板可以用于驱动程序的开发调试，为开发人员提供测试和调试整个系统的工具。</li>
</ol>
</blockquote>
<blockquote>
<p><em>PAC开发板是一种基于PAC（Programmable Automation Controller）技术的嵌入式控制器开发板。PAC是一种新型的工业自动化控制器，具有高效、灵活、可编程的特点。PAC结合了PLC（Programmable Logic Controller）和PC（Personal Computer）的优点，具有更高的计算能力和更强的自适应能力。</em></p>
<p><em>PAC开发板通常搭载了PAC芯片、运算器、内存、以太网接口、串口、GPIO等核心组件。用户可以通过扩展接口和编程语言来实现各种不同的控制任务，如运动控制、机器视觉、数据采集、数据处理等。</em></p>
<p><em>PAC开发板的优势主要体现在以下几个方面：</em></p>
<ol>
<li>数据采集和处理：PAC开发板具有强大的数据采集和处理功能，可与多种传感器进行连接，并能够快速处理和分析采集到的数据，提高控制系统的稳定性和效率。</li>
<li>机器控制：PAC开发板可以用于机器控制，包括机械手臂、运动控制系统等，提高系统的运动精度和控制速度。</li>
<li>工业自动化控制：PAC开发板具有高可靠性和安全性，可用于工业自动化控制系统，如自动化生产线、工业机器人等，提高工业生产的效率和质量。</li>
<li>智能建筑控制：PAC开发板可连接到建筑自动化系统中，并可通过与其他传感器和设备的协作，实现对建筑物能耗、环境、安全等方面的管理和控制。</li>
</ol>
</blockquote>
<blockquote>
<p><em>Matrix开发板是由美国企业Maker（Make with Ada）开发的一种基于ARM架构的开源嵌入式系统开发板。它提供了丰富的硬件接口和全面的配套软件支持，适用于各种不同规模和领域的嵌入式应用开发。</em></p>
<ol>
<li>实现物联网应用：Matrix开发板可以通过连接各种传感器和设备，实现数据采集和处理，从而实现智能化的物联网应用，如环境监测、智能家居等。</li>
<li>研究和开发人工智能算法：Matrix开发板采用了先进的人工智能芯片，支持深度学习、神经网络等技术，开发者可以在其中运行和测试自己的人工智能算法，如图像识别、自然语言处理等，从而开发更智能化、优化的人工智能应用。</li>
<li>高性能计算：Matrix开发板配备高性能的处理器和内存，可用于计算密集型应用，如科学计算、大数据分析等。</li>
<li>教育和学习：Matrix开发板易于使用，功能强大，因此可以作为教育和学习的工具，使学生和爱好者了解人工智能技术并开发自己的应用。</li>
</ol>
</blockquote>
<p><em>OE可以为地平线芯片合作伙伴提供丰富多样的算法资源、灵活高效的开发工具和简单易用的开发框架。 OE的特色和优势可以概括为以下四个方面：</em></p>
<p><em><a target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/_images/learn_oe_2.png"><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/J5/image-20230508144405157.png"
                      alt="image-20230508144405157"
                ></a></em></p>
<p><em>为了方便用户将各种解决方案部署到地平线一系列开发板上，我们提供了集开发板系统镜像、开发环境部署、应用参考解决方案示例代码以及用户手册等文件于一体的全量开发包，称之为OE包。 在您获取到OE包后，可以先按照以下步骤对OE进行了解。</em></p>
<ol>
<li><em>先参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/preface/learn_oe.html#post-item" >发布物内容 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 了解发布包的目录结构；</em></li>
<li><em>再参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/hardware/system_image.html" >系统镜像升级 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节进行板端系统镜像安装&#x2F;升级；</em></li>
<li><em>接着通过参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/model_conversion.html" >浮点模型转定点模型指导手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 和 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html" >嵌入式应用开发指导 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 完成模型转换与部署的全流程。</em></li>
</ol>
<p><em>更多更全的OE包使用教程，欢迎参考下方指导手册进行了解，相信地平线的OE包可以让您开发更高效，部署更简便！</em></p>
<p><em>更多关于OE适配的硬件内容，请你详见附录中的 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/hardware/dev_board_kit.html" >开发板套件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<blockquote>
<p><em>发布物内容</em></p>
</blockquote>
<ul>
<li><em><strong>bsp</strong>：bsp目录下包含 <code>resolve.sh</code> 脚本和 <code>tools</code> 文件夹。</em><em>其中：<code>resolve.sh</code> 脚本用于下载镜像包，但下载的镜像仅适用于J5 DVB开发板，若需要其他开发板镜像，需联系地平线进行获取。<code>tools</code> 文件夹下的 <code>resolve.sh</code> 脚本用于下载hbupdate板端升级工具和一些您在Windows下会使用到的USB_Driver等**。 其中，hbupdate板端升级工具我们为您提供了多平台（win&#x2F;linux）的版本，内容包括：</em><ul>
<li><em>hbupdate_linux_cli_{version}.tgz；</em></li>
<li><em>hbupdate_linux_gui_{version}.tgz；</em></li>
<li><em>hbupdate_win64_{version}.zip。</em></li>
</ul>
</li>
</ul>
<blockquote>
<p><em><strong>DVB（Digital Video Broadcasting）开发板是一种用于数字电视信号接收和解码的嵌入式系统开发板</strong>。它在硬件层面提供了各种通信接口和专业的解码器芯片以及优质的视频显示处理器，但同时也需要在软件层面上提供相应的编解码器并支持相关的标准协议。</em></p>
<p><em>DVB开发板通常能够支持数字地面电视（DVB-T）、有线电视（DVB-C）、卫星电视（DVB-S）以及高清电视（DVB-HD）等多种数字电视信号的接收和解码，同时也支持多种数字音频格式的解码以及众多的互联网视频和音频解码协议，如 RTSP, HLS, RTP, MPEG-DASH等。它还可以通过以太网或USB等接口，连接到互联网上进行网络视频和音频流媒体的接收和解码。</em></p>
<p><em>DVB开发板的应用范围非常广泛，包括数字电视接收机开发、嵌入式多媒体应用开发、安防监控、教育培训等领域。同时，DVB开发板也可以为数字电视产业链上游的常规卫星接收器、调制器、编码器等设备提供数字电视信号源。</em></p>
<p><em>需要注意的是，不同的国家或地区可能使用不同标准的数字电视，因此，在选择DVB开发板时，需要选择支持当地使用的数字电视标准。</em></p>
</blockquote>
<ul>
<li><em><strong>ddk</strong>：ddk目录为主要的开发组件目录，目录下包含了 package和samles文件夹。</em><ul>
<li><em>ddk.package</em><ul>
<li><em>ddk.package.board</em><ul>
<li><em><code>ddk.package.board</code> 文件夹下为板端可执行程序。</em></li>
<li><em><code>hrt_model_exec</code> 是一个模型执行工具 ，<strong>可直接在 开发板上 进行评测模型的推理性能、获取模型信息。</strong>工具分别提供了 <code>infer</code> 、模型性能分析 <code>perf</code> 和查看模型信息 <code>model_info</code> 三类功能。</em></li>
<li><em><code>hrt_bin_dump</code> 是ptq debug模型的layer dump工具，工具的输出文件为二进制文件。</em></li>
<li><em><code>install.sh</code> 是一键安装脚本，<strong>可以一键将hrt工具安装到指定的开发板</strong>。</em></li>
</ul>
</li>
<li>*ddk.package.host：<code>ddk.package.host</code> 文件夹下为发布物在x86开发环境下的环境依赖和工具依赖等。 <strong>通过执行该目录下的脚本 <code>install.sh</code> 即可在开发机上安装程序运行的所有环境和工具依赖</strong>。 <strong>通过执行该目录下的脚本 <code>resolve.sh</code> 即可下载交叉编译工具、torch等依赖。</strong>*</li>
</ul>
</li>
<li><em>ddk.samples：<code>ddk.samples</code> 下包含了 <strong>ai_benchmark、ai_toolchain、ai_forward_view_sample、vdsp_rpc_sample和model_zoo</strong> 。</em><ul>
<li><em>ai_benchmark 提供了常见的分类、检测和分割模型的<strong>评测示例</strong>，包括性能评测和精度评测两部分。</em></li>
<li><em>ai_toolchain 提供了一些模型算法的一系列示例。 （其中 horizon_model_train_samples 为浮点模型训练框架示例, horizon_model_convert_sample 为浮点模型转定点模型的转换示例, horizon_runtime_sample 为定点模型的上板示例。）</em></li>
<li><em><strong>ai_forward_view_sample 示例展示了如何在J5上运行一个检测模型并展示物体框。</strong></em></li>
<li><em>vdsp_rpc_sample 示例展示了如何在j5上使用dsp进行任务处理。</em></li>
<li><em>model_zoo 是一个模型库，用于放置工具链示例模型编译的源模型和runtime模型。</em></li>
</ul>
</li>
</ul>
</li>
<li><em><strong>resolve_all.sh</strong>：用于自动下载OE包内所有可下载的依赖项的脚本。</em></li>
<li><em><strong>run_docker.sh</strong>：在使用指定的数据集和OE包运行程序之前，需要确保已经下载和安装完成，然后使用run_docker.sh脚本启动docker，该脚本会自动将数据集挂载到docker中，并确保OE包的必要内容在docker环境中可用。</em></li>
</ul>
<blockquote>
<p><em>关键概念</em></p>
</blockquote>
<ul>
<li><em><strong>原始浮点模型</strong>，指您通过TensorFlow&#x2F;PyTorch等等DL框架训练得到的可用模型，这个模型的计算精度为float32。</em></li>
<li><em><strong>混合异构模型</strong>，是一种适合在地平线芯片上运行的模型格式。</em></li>
<li><em><strong>模型转换</strong>，指的是将原始浮点模型或QAT转换得到的onnx模型转换为地平线混合异构模型的过程。</em></li>
<li><em><strong>模型量化</strong>，目前工业界最有效的模型优化方法之一，量化是指定点与浮点等数据之间建立一种数据映射关系，使得以较小的精度损失代价获得了推理性能收益，可简单理解为用“低比特”数字表示FP32等数值，如FP32–&gt;INT8可以实现4倍的参数压缩，在压缩内存的同时可以实现更快速的计算。</em></li>
<li><em><strong>hbm文件</strong>，即Horizon BPU Model，HBDK编译器生成的模型文件，hbm包含BPU指令、模型参数、输入输出描述等信息。</em></li>
<li><em><strong>PTQ</strong>，即训练后量化方案，先训练浮点模型，然后使用校准图片计算量化参数，将浮点模型转为量化模型的量化方法。</em></li>
<li><em><strong>QAT</strong>，即量化感知训练方法</em></li>
</ul>
<blockquote>
<p><em>混合异构模型（Mixed Heterogeneous Model）是指使用不同的硬件实现深度神经网络推理（Inference）过程，以实现更高性能和更高能效的深度学习计算。混合异构模型将多种硬件平台进行集成，其中包括中央处理器（CPU）、图形处理器（GPU）、数字信号处理器（DSP）、神经网络处理器（NPU）等，每个硬件平台针对自己的优势进行计算，从而充分利用各硬件平台的特点。</em></p>
</blockquote>
<h4 id="工具链概览"><a href="#工具链概览" class="headerlink" title="工具链概览"></a><em>工具链概览</em></h4><p><em>地平线J5芯片算法工具链（以下简称工具链）是一套完整的边缘芯片算法落地解决方案，可以帮助您把浮点模型量化为定点模型， 并在地平线芯片上快速部署自研算法模型。</em></p>
<p><em>目前在GPU上训练的模型大部分都是浮点模型，即参数使用的是float类型存储。 地平线BPU架构的芯片使用的是int8的计算精度（业内芯片的通用精度），能运行定点量化模型。 那么从训练出的浮点精度转为定点模型的过程，我们称之为量化。 同时模型量化后能够有效减少模型大小，加速深度学习推理的速度，因此也在学术界和工业界被广泛研究和应用。</em></p>
<p><em>依据是否要对量化后的参数进行调整，我们可以将量化方法分为量化感知训练（QAT）和训练后量化（PTQ）。 这两种方法的操作区别如下图所示（图左为QAT，图右为PTQ）：</em></p>
<blockquote>
<p><em>BPU架构是百度公司研发的专门用于深度学习推理的硬件架构，全名为“Brain Processing Unit”。BPU采用定制化的硬件设计和算法优化，能够在底层实现更加高效、灵活的深度神经网络的计算。与传统的CPU、GPU相比，BPU在处理深度学习推理时具有更高的性能和更低的能耗。</em></p>
<p><em>BPU的设计架构具有三个领域：模型训练（Training）、模型评估和优化（Optimization）以及模型推理（Inference）。与传统的GPU等芯片相比，<strong>BPU架构在优化深度学习模型运算、控制设计和数据传输方面更加高效，可以实现更高的计算性能和更低的能耗。</strong></em></p>
<p><em>BPU架构主要由两个部分组成：<strong>计算芯片和计算框架</strong>。计算芯片使用定制化的算法和硬件优化，可以高效地实现深度神经网络的计算任务。计算框架包括一系列基于深度学习推理的软件开发和优化工具，旨在优化模型计算和部署。</em></p>
</blockquote>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508153214469.png"
                      class="" title="image-20230508153214469"
                ></em></p>
<p><em>量化感知训练QAT是将训练过的模型量化后又再进行重训练。<u>由于定点数值无法用于反向梯度计算，实际操作过程是在某些OP前插入伪量化节点（fake quantization nodes）， 用于在训练时获取流经该OP的数据的截断值，便于在部署量化模型时对节点进行量化时进行使用。</u>我们需要在训练中通过不断优化精度来获取最佳的量化参数。由于它需要对模型进行训练，因此对操作人员技术要求较高。 有关QAT方案的详细信息请阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/plugin/source/index.html" >量化感知训练（QAT） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容。</em></p>
<p><u>训练后量化PTQ是使用一批校准数据对训练好的模型进行校准，将训练过的FP32模型直接转换为定点计算的模型</u>，过程中无需对原始模型进行任何训练，只需要对几个超参数进行调整就可以完成量化过程， 且过程简单快速，无需训练，因此该方法已被广泛地应用于大量的端侧和云侧部署场景。我们优先推荐您尝试PTQ方法来查看是否满足您的部署精度和性能要求。 有关PTQ方案的详细信息请阅读训练后量化（PTQ）章节内容。</p>
<p><em>工具链由PTQ、QAT和嵌入式编译等部分组成，工具链组成示意图如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508153238553.png"
                      class="" title="image-20230508153238553"
                ></em></p>
<p><em>其中：</em></p>
<p><em>Runtime SDK 提供了异构模型的运行库支持，运行库包含arm和x86(暂未提供)两个部分，分别用于在地平线芯片平台和X86仿真平台执行异构模型。 有关嵌入式应用开发请阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html" >嵌入式应用开发指导 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容。</em></p>
<p><em>此外，工具链提供了丰富的开发工具、示例以及内置了大量算法模型的模型发布物帮助用户上手理解，并可以提高用户的开发效率。</em></p>
<p><em>工具链的整体使用流程如下图所示，地平线推荐您先尝试PTQ方式来查看是否满足您的部署精度和性能要求。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508153303552.png"
                      class="" title="image-20230508153303552"
                ></em></p>
<h3 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a><em>环境安装</em></h3><h4 id="环境部署"><a href="#环境部署" class="headerlink" title="环境部署"></a><em>环境部署</em></h4><blockquote>
<p><em>前言</em></p>
</blockquote>
<p><em>地平线OpenExplorer目前同时提供了2套模型量化方案：</em></p>
<ul>
<li><em>PTQ：Post-training Quantization，训练后量化。</em></li>
<li><em>QAT：Quantization aware training，量化感知训练（暂时只支持Pytorch框架）。</em></li>
</ul>
<p><em>其中：两套方案均不干涉浮点模型的训练阶段，您需要自行负责。地平线也在以下路径开源了一些分类&#x2F;检测&#x2F;分割等场景 高效模型的公版Pytorch实现以供参考，并支持在宿主机上进行训练和复现。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ddk/samples/ai_toolchain/horizon_model_train_sample</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em>对于PTQ方案，您需要在宿主机的开发环境完成模型的量化转换，再将编译生成的 <code>.bin</code> 模型拷贝至开发板环境 完成后续的部署工作。</em></li>
<li><em>对于QAT方案，您则需要在宿主机的开发环境先完成模型的QAT训练，再进行量化转换，再将编译生成的 <code>.bin</code> 模型 拷贝至开发板环境完成后续的部署工作。</em></li>
</ul>
<p><em>两种量化方案以及高效模型的开发环境，地平线都提供了本地手动安装和Docker容器两种方式。我们优先推荐使用 不污染本地环境，且使用方便的Docker容器，以下也将分别进行介绍。</em></p>
<blockquote>
<p><em>开发环境部署</em></p>
</blockquote>
<p><em><strong>开发机准备</strong></em></p>
<p><em>开发机应满足以下要求：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508160041194.png"
                      class="" title="image-20230508160041194"
                ></em></p>
<p><em>此外，嵌入式开发需要安装交叉编译工具（ <code>gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu.tar.xz</code> ），请从 <code>ddk/package/host</code> 目录下通过执行 <code>resolve.sh</code> 进行获取，并将其解压 到开发机的 <code>/opt</code> 目录下（ <strong>使用 Docker 可跳过此步骤</strong> ）。</em></p>
<p><em>解压命令为：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xvf gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu.tar.xz</span><br></pre></td></tr></table></figure></div>

<p><em>另外您需要在环境中新增一个变量 <code>LINARO_GCC_ROOT</code>，值为交叉编译器的完整路径，参考如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export LINARO_GCC_ROOT=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：环境变量 <code>LINARO_GCC_ROOT</code> 的设置路径需要与交叉编译工具解压的目录相同，否则会导致失败。</strong></em></p>
<p><em>对于host端（x86）依赖的库，比如isl,gmp,mpc,mpfr等，在lib&#x2F;x86_64-linux-gnu下，如果编译报错， 请在编译工程中通过LD_LIBRARY_PATH来指定。</em></p>
<p><em>如果编译过程中出现glibc库版本冲突的问题，例如：xxx@GLIBC_xxx的未定义符号的错误， 请在编译工程中通过-rpath-link来指定到工具链的aarch64-linux-gnu&#x2F;lib路径下, 同时在编译工程中加上-lxxx, 例如：-lpthread。</em></p>
<p><em>另外需要特别注意的是下图框起来的记录源文件的变量SRCS，最好放在${LIBS}链接库的前面，否则可能也会报未定义的符号。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508162216452.png"
                      class="" title="image-20230508162216452"
                ></em></p>
<blockquote>
<p><em><strong>LINARO_GCC_ROOT环境变量是指用于指定交叉编译器GCC的路径的环境变量。</strong>它通常用于在Linux操作系统下进行交叉编译，以便生成能够在不同的处理器体系结构下运行的二进制文件。</em></p>
</blockquote>
<blockquote>
<p><strong>LD_LIBRARY_PATH环境变量是一个用于指定动态链接库搜索路径的环境变量。</strong>在Linux系统中，动态链接库是在运行时加载的共享库，它们提供了一些可复用的函数和资源，用于被不同的程序共享。而LD_LIBRARY_PATH环境变量则用于指定动态链接库的搜索路径。</p>
<p><em>当一个程序需要加载一个共享库时，Linux系统会首先搜索默认路径（例如&#x2F;usr&#x2F;lib、&#x2F;usr&#x2F;local&#x2F;lib等），如果需要的共享库没有在默认路径中找到，就会去LD_LIBRARY_PATH环境变量所指定的路径中寻找。因此，设置LD_LIBRARY_PATH环境变量可以帮助在程序加载共享库时找到正确的路径，避免因为缺少动态库导致程序运行失败。</em></p>
</blockquote>
<blockquote>
<p><em>Docker容器部署</em></p>
</blockquote>
<p><strong>Docker基础环境</strong></p>
<p><em>地平线要求的Docker基础环境如下，请提前在您的宿主机上完成安装：</em></p>
<ul>
<li><em>Docker（&gt;&#x3D;1.12 建议安装18.03.0-ce），详见 <a class="link"   target="_blank" rel="noopener" href="https://docs.docker.com/install/" >Docker安装手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</em></li>
<li><em>NVIDIA Docker（2.0.3），详见 <a class="link"   target="_blank" rel="noopener" href="https://github.com/nvidia/nvidia-docker/wiki" >NVIDIA Docker安装手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</em></li>
</ul>
<blockquote>
<p>Nvidia Docker是一个用于在GPU加速的环境中运行Docker容器的工具，它是基于Docker的一个扩展。它的主要目的是简化在使用NVIDIA GPU的系统中运行容器的过程，并提供了针对GPU加速的容器化应用的优化和支持。<code>dpkg -l | grep nvidia-docker</code>查看nvidia-docker版本</p>
</blockquote>
<p><em>完成Docker基础环境安装后，还需要将无root权限的用户添加到Docker用户组中。参考命令如下：</em></p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo groupadd docker				<span class="comment">#添加docker用户组</span></span><br><span class="line">sudo gpasswd -a <span class="variable">$&#123;USER&#125;</span> docker		<span class="comment">#用户加入docker组</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改docker组权限为root权限在该行的下方添加一行</span></span><br><span class="line">sudo visudo				<span class="comment">#在sudoers文件中找到%sudo   ALL=(ALL:ALL) ALL，在该行的下方添加一行：%&lt;group_name&gt;   ALL=(ALL:ALL) ALL</span></span><br><span class="line"></span><br><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure></div>



<p><em><strong>Docker镜像使用</strong></em></p>
<p><em>为了帮助用户快速使用工具链，地平线提供了包含完整开发环境的Docker镜像，大大简化了开发环境的部署过程。</em></p>
<p><em>您可以在OE包的一级目录下直接运行以下脚本启动当前OE版本所对应的Docker容器（如果为首次启动，则脚本会自动拉取镜像）：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh run_docker.sh data/</span><br></pre></td></tr></table></figure></div>

<p><em><strong>其中， <code>data</code> 为评测数据集文件夹路径，请提前创建好后再运行命令，否则将导致加载问题。</strong></em></p>
<blockquote>
<p>在大多数Linux系统中，<code>bash</code>和<code>sh</code>是两个不同的Shell解释器。</p>
<p><code>bash</code>是Bourne Again Shell的缩写，它是Unix和Linux系统中最常用的Shell。它提供了更多的功能和扩展性，包括命令补全、命令历史记录、条件语句、循环结构等。**<code>bash</code>是<code>sh</code>的扩展版本**，向后兼容Bourne Shell（sh）。</p>
<p><code>echo $0</code>可以区分当前解析器是<code>bash</code>还是<code>sh</code></p>
</blockquote>
<p><em>若您想要使用 CPU 版本 Docker 镜像则需要增加 <code>cpu</code> 参数：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh run_docker.sh data/ cpu</span><br></pre></td></tr></table></figure></div>

<p><em>OE包示例所依赖的相关公开评测数据集的下载链接为：</em></p>
<table>
<thead>
<tr>
<th align="left"><em><strong>数据集</strong></em></th>
<th align="left"><em><strong>下载地址</strong></em></th>
<th align="left"><em><strong>下载结构</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>ImageNet</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://www.image-net.org/download.php" >https://www.image-net.org/download.php <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#imagenet-prepare" >ImageNet数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>COCO</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://cocodataset.org/" >https://cocodataset.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#coco-prepare" >COCO数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>VOC</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/" >http://host.robots.ox.ac.uk/pascal/VOC/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>需要下载2007和2012两个版本，下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#voc-prepare" >VOC数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>Cityscapes</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://github.com/mcordts/cityscapesScripts" >https://github.com/mcordts/cityscapesScripts <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#cityscapes-prepare" >Cityscapes数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>CIFAR-10</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar.html" >http://www.cs.toronto.edu/~kriz/cifar.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#cifar-prepare" >CIFAR-10数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>FlyingChairs</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html" >https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
<tr>
<td align="left"><em>KITTI3D</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d" >https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
<tr>
<td align="left"><em>CULane</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://xingangpan.github.io/projects/CULane.html" >https://xingangpan.github.io/projects/CULane.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
<tr>
<td align="left"><em>nuScenes</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://www.nuscenes.org/nuscenes" >https://www.nuscenes.org/nuscenes <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
</tbody></table>
<p><em>如果您希望手动启动Docker容器，也可以通过以下命令拉取对应的Docker镜像，其中{version}为您当前所用的OE版本号。</em></p>
<p><em><strong>注意：为方便使用，我们为您提供了两种CPU Docker以及GPU Docker，可按需选择。</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># CPU Docker</span><br><span class="line">docker pull openexplorer/ai_toolchain_ubuntu_20_j5_cpu:&#123;version&#125;</span><br><span class="line"># GPU Docker</span><br><span class="line">docker pull openexplorer/ai_toolchain_ubuntu_20_j5_gpu:&#123;version&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>成功进入Docker容器后， 您可以键入 <code>ddk_vcs list</code> 命令查看当前版本是否为您的预期版本。</em></p>
<blockquote>
<p><em>本地手动安装</em></p>
</blockquote>
<p><em>本节将分别介绍两种量化方案和地平线开源的高效模型训练所依赖的环境部署方法。我们推荐您在浮点模型训练完成后优先 选择简单易用的PTQ量化方案，只在精度问题确实无法解决时再切换到QAT量化方案。</em></p>
<p><em><strong>PTQ量化环境部署</strong></em></p>
<p><em>PTQ量化方案对于开发机操作环境的基础软件依赖如下：</em></p>
<ul>
<li><em>操作系统：Ubuntu20.04</em></li>
<li><em>Python3.8</em></li>
<li><em>libpython3.8</em></li>
<li><em>python3-devel</em></li>
<li><em>python3-pip</em></li>
<li><em>gcc&amp;c++: 5.4.0</em></li>
<li><em>graphviz</em></li>
</ul>
<blockquote>
<p><strong><code>libpython3.8</code> 是指 Python 3.8 版本的共享库（动态链接库）文件</strong>。共享库包含了 Python 解释器的核心功能和模块，可以被其他程序动态链接和使用。它们提供了对 Python 3.8 版本的标准库和扩展库的访问。<strong>通过使用 <code>libpython3.8</code>，其他程序可以调用和执行 Python 3.8 的代码，并与 Python 环境进行交互。</strong></p>
</blockquote>
<blockquote>
<p><strong><code>python3-devel</code> 是指针对 Python 3 的开发工具包或开发环境。</strong>它包含了编译和构建 Python 3 扩展模块所需的头文件、库文件和其他开发工具。</p>
<p>安装 <code>python3-devel</code> 包可以提供你在开发 Python 3 应用程序或扩展时所需的构建和调试工具。它包含了必要的头文件和库文件，使你能够编译和链接 Python 3 的扩展模块，以及其他开发工具，例如调试器和性能分析工具。</p>
</blockquote>
<blockquote>
<p>Graphviz是一个开源的图形可视化工具，用于绘制图形和图表。它提供了一组用于创建和排列图形元素的命令行工具和库。Graphviz支持多种图形类型，包括有向图、无向图、流程图、组织结构图等。</p>
</blockquote>
<p><em>在确认满足以上条件后，即可进行AI工具安装。因为其中包含一系列内部工具，所以OE包提供了脚本文件 来打包所有的安装过程以简化流程，可参考以下命令执行：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ddk/package/host/ai_toolchain</span><br><span class="line">bash install_ai_toolchain.sh</span><br></pre></td></tr></table></figure></div>

<p><em>安装脚本会自动检查相应的环境，缺少相应依赖或配置会中断安装过程，并给出修正建议如下图。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508163604194.png"
                      class="" title="image-20230508163604194"
                ></em></p>
<p><em>根据建议补充依赖后，重新执行install脚本即可。</em></p>
<p><em><strong>注意：如果修正建议指出是gcc&#x2F;g++版本不符合要求，在安装完指定版本之后，您需要重新建立gcc和g++软链接为gcc-5.4.0和g++-5.4.0。</strong></em></p>
<p><em>在顺利完成install脚本后，您可以键入 <code>ddk_vcs list</code> 命令验证下您所需的工具和依赖是否被正确安装。</em></p>
<blockquote>
<p><em>QAT量化环境部署</em></p>
</blockquote>
<p><em>QAT量化环境在本地环境进行安装，需要先确保已满足以下基础环境条件。 量化训练工具能够训练起来所必需的环境依赖如下表：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508163753480.png"
                      class="" title="image-20230508163753480"
                ></em></p>
<p><em>在完成QAT模型的训练后，我们可以选择以下两种路径完成后续的模型转换工作：</em></p>
<p><u><em>路径1：先导出onnx模型，再基于PTQ（Post Training Quantization，训练后量化）路线通过yaml文件完成模型转换。</em></u></p>
<p><em>路径2：在当前训练环境安装相关工具包，并直接通过接口调用的方式完成模型转换。</em></p>
<p><em>对于路径1，我们建议直接使用地平线提供的Docker。</em></p>
<p><em>对于路径2，我们可以通过运行以下脚本完成芯片算法工具链的环境配置。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ddk/package/host/ai_toolchain</span><br><span class="line">bash install_ai_toolchain.sh</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：</strong></em></p>
<ul>
<li><em>安装脚本会自动检查相应的环境，缺少相应依赖或配置会中断安装过程，可以根据提示补充依赖，并重新执行install脚本。</em></li>
<li><em>脚本执行成功后，会在 <code>~/.bashrc</code> 系统环境变量中添加Path等信息，请执行 <code>source ~/.bashrc</code> 来使当前terminal的配置生效。</em></li>
<li><em>torch 版本应满足 1.10.2，torchvision版本应满足0.11.3。</em></li>
</ul>
<p><em><strong>地平线在 <code>ddk/samples/ai_toolchain/horizon_model_train_sample</code> 路径下开源了一些高效模型源码，其浮点及QAT训练基础环境</strong></em></p>
<blockquote>
<p><em>运行环境部署</em></p>
</blockquote>
<p><em>当模型完成量化转换后，即可将编译好的模型部署在开发板环境推理运行。运行环境的部署需要您先准备好一块烧写好系统镜像的 开发板，再将相关补充文件拷贝到开发板中即可。</em></p>
<ul>
<li><strong>开发板准备：</strong>此阶段需要验证下开发板的可用性，将可用系统镜像烧写到开发板中。具体过程请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/hardware/system_image.html" >系统镜像升级 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容。</li>
<li><strong>板端工具安装：</strong>工具链的部分补充工具未包含在系统镜像中，<u>但可以在宿主机环境下执行OE包中的安装脚本 将其拷贝至开发板</u>，其参考命令如下：</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ddk/package/board</span><br><span class="line">bash install.sh $&#123;board_ip&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>其中，<code>$&#123;board_ip&#125;</code> 是您为开发板设置的IP地址，请确保在开发机上可以成功访问该IP。 补充文件成功安装后，请重新启动开发板，在开发板上执行 <code>hrt_model_exec --help</code> 即可验证安装是否成功。</em></p>
<h4 id="OE包版本管理"><a href="#OE包版本管理" class="headerlink" title="OE包版本管理"></a><em>OE包版本管理</em></h4><p><em>统一发版host package版本管理工具ddk_vcs用于对地平线OE包中的依赖库及whl包的版本进行管理</em></p>
<blockquote>
<p><em>功能概要</em></p>
</blockquote>
<p><em>工具包括以下功能：</em></p>
<ul>
<li><em>ddk_vcs list。</em></li>
<li><em>ddk_vcs install。</em></li>
<li><em>ddk_vcs uninstall。</em></li>
<li><em>ddk_vcs patch。</em></li>
<li><em>ddk_vcs show。</em></li>
</ul>
<blockquote>
<p><em>准备工作</em></p>
</blockquote>
<p><em>完成安装后，在使用ddk_vcs工具前，您需要先对环境变量进行设置，如下所示，当您输入 <code>ddk_vcs --help</code> 时，会出现提示，请先设置环境变量。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs --help</span><br><span class="line">Please set the value (xj3/j5) of environment variable DDK_VCS_MODE and run it again.</span><br></pre></td></tr></table></figure></div>

<p><em>环境变量的设置方法：在 <code>~/.bashrc</code> 中增加一行 <code>export DDK_VCS_MODE=j5</code> ，保存后，使用命令 <code>source ~/.bashrc</code> 使其生效即可。</em></p>
<p><em><strong>注意：如您使用OE包提供的 <code>install.sh</code> 进行安装或使用docker环境操作，我们已为您预先完成了设置，无需进行此项准备工作。</strong></em></p>
<blockquote>
<p><em>详细信息</em></p>
</blockquote>
<p><em><strong>ddk_vcs list</strong>：ddk_vcs list 用于列出已安装的软件包。</em></p>
<p><em>参数如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs list --help</span><br><span class="line">Usage: ddk_vcs list [OPTIONS]</span><br><span class="line"></span><br><span class="line">  List installed packages.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -l, --local  Show all existing packages(*.tar.gz) on host machine.</span><br><span class="line">  --help       Show this message and exit.</span><br></pre></td></tr></table></figure></div>

<p><em>不加参数执行此命令时，结果会展示当前已安装的各个模块的信息。使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs list</span><br><span class="line">Host package version: v2.0.3</span><br><span class="line">The following packages versions</span><br><span class="line">Platform           Package         Version MD5</span><br><span class="line">---------------    --------------- ------- -------------</span><br><span class="line">aarch_64           appsdk          032419  093e13b44e</span><br><span class="line">aarch_64           dnn             1.8.1g  aff0f6f4de</span><br><span class="line">x86_64_gcc5.4.0    dnn_x86         1.8.1g  e8e6bf9ed5</span><br><span class="line">x86_64_gcc5.4.0    horizon-nn      0.13.3  origin:0.13.3</span><br><span class="line">x86_64_gcc5.4.0    horizon-nn-gpu  0.13.3  origin:N/A</span><br><span class="line">x86_64_gcc5.4.0    horizon-tc-ui   1.6.4   origin:1.6.4</span><br><span class="line">x86_64_gcc5.4.0    hbdk            3.28.3  origin:3.28.3</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：最后几行的origin信息会在每次使用OE包内的install脚本进行安装后更新为当前环境下的版本， 后续在使用ddk_vcs进行安装时则不会改变，只会改变Version的值。</strong></em></p>
<p><em>使用 <code>-l</code> 或 <code>--local</code> 参数以后会显示当前可以安装的模块版本情况，可以通过 <code>ddk_vcs install</code> 进行安装，使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs list -l</span><br><span class="line">Host package version: 1.5.1</span><br><span class="line">The following packages versions</span><br><span class="line">Platform        Local Package                 Version MD5</span><br><span class="line">--------------- ----------------------------- ------- ----------</span><br><span class="line">aarch_64        appsdk_1.9.0.tar.gz           1.9.0   bf01140c9d</span><br><span class="line">aarch_64        bpu_predict_1.10.2.tar.gz     1.10.2  5b6e5dd6c5</span><br><span class="line">aarch_64        dnn_1.1.2a.tar.gz             1.1.2a  fdb5729f4f</span><br><span class="line">x86_64_gcc5.4.0 bpu_predict_1.10.2.tar.gz     1.10.2  4dbdd980a7</span><br><span class="line">x86_64_gcc5.4.0 dnn_x86_1.1.2a.tar.gz         1.1.2a  5bf5fcd4fe</span><br></pre></td></tr></table></figure></div>

<p><em><strong>ddk_vcs install：</strong>ddk_vcs install 用于对安装包进行安装</em></p>
<p><em>参数如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs install --help</span><br><span class="line">Usage: ddk_vcs install [OPTIONS] MODULE_FILE...</span><br><span class="line"></span><br><span class="line">  Install packages.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --platform [aarch_64|x86_64_gcc5.4.0]</span><br><span class="line">                                  Platform name</span><br><span class="line">  --help                          Show this message and exit.</span><br></pre></td></tr></table></figure></div>

<p><em>用户可以直接通过 <code>ddk_vcs install</code> 将对应的模块tar包进行安装。<strong>安装时需要指定对应的platform</strong>。使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs install bpu_predict_1.10.2.tar.gz -p aarch_64</span><br><span class="line">bpu_predict installed successfully, version: 1.10.2, platform: aarch_64</span><br><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs install hbdk-3.28.3-py3-none-linux_x86_64.whl  horizon_nn-0.13.3-py3-none-any.whl</span><br><span class="line">hbdk-3.28.3-py3-none-linux_x86_64.whl installed successfully</span><br><span class="line">horizon_nn-0.13.3-py3-none-any.whl installed successfully</span><br></pre></td></tr></table></figure></div>

<p><em>在使用 <code>ddk_vcs list -l</code> 后用户可以得到自己当前host package中各个模块包的版本信息， 然后使用 <code>ddk_vcs install</code> 可以很方便地切换各个版本，使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs install bpu_predict==1.7.2  --platform aarch_64</span><br><span class="line">bpu_predict installed successfully, version: 1.7.2, platform: aarch_64</span><br></pre></td></tr></table></figure></div>

<p><em>如果本地没有对应版本可以指定安装包位置进行安装。</em></p>
<p><em><strong>ddk_vcs uninstall：</strong>用于卸载指定模块</em></p>
<p><em>参数如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs uninstall --help</span><br><span class="line">Usage: ddk_vcs uninstall [OPTIONS] MODULE...</span><br><span class="line"></span><br><span class="line">  Uninstall packages.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --platform [aarch_64|x86_64_gcc5.4.0]</span><br><span class="line">                                  Platform name  [required]</span><br><span class="line">  --help                          Show this message and exit.</span><br></pre></td></tr></table></figure></div>

<p><em>使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs uninstall bpu_predict --platform aarch_64</span><br><span class="line">Start to uninstall modules, platform: aarch_64</span><br><span class="line">bpu_predict uninstalled successfully, version: 1.10.2, platform: aarch_64</span><br></pre></td></tr></table></figure></div>

<p><em><strong>ddk_vcs patch：</strong>使用 <code>ddk_vcs patch ddk_patch.tar.gz</code> 可以安装预先制作好的patch包。</em></p>
<p><em>使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs patch ddk_patch.tar.gz</span><br><span class="line">bpu_predict installed successfully, version: 1.7.2_patch0, platform: aarch64</span><br></pre></td></tr></table></figure></div>

<p><em><strong>ddk_vcs show：</strong>用于显示有关已安装软件包的信息。使用 <code>ddk_vcs show [模块名]</code> ，可以展示对应模块的信息。</em></p>
<p><em>参数如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev067 ai_toolchain]$ ddk_vcs show --help</span><br><span class="line">Usage: ddk_vcs show [OPTIONS] MODULE</span><br><span class="line"></span><br><span class="line">  Show information about installed packages.</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -p, --platform [aarch_64|x86_64_gcc5.4.0]</span><br><span class="line">                                  Platform name</span><br><span class="line">  --help                          Show this message and exit.</span><br></pre></td></tr></table></figure></div>

<p><em>使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs show bpu_predict</span><br><span class="line">Host package version 1.5.1</span><br><span class="line">The following packages versions</span><br><span class="line">Platform        Package     Version       MD5</span><br><span class="line">--------------- ----------- ------------- ----------</span><br><span class="line">aarch_64        bpu_predict 1.10.2        5b6e5dd6c5</span><br><span class="line">x86_64_gcc5.4.0 bpu_predict 1.10.2_patch1 d4f8e37921</span><br></pre></td></tr></table></figure></div>

<p><em>如果2个架构内有同名依赖，可以使用 <code>-p/--platform</code> 指定架构名进行过滤。使用示例如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev004]$ ddk_vcs show bpu_predict -p aarch_64</span><br><span class="line">Host package version 1.5.1</span><br><span class="line">The following packages versions</span><br><span class="line">Platform Package     Version MD5</span><br><span class="line">-------- ----------- ------- ----------</span><br><span class="line">aarch_64 bpu_predict 1.10.2  5b6e5dd6c5</span><br></pre></td></tr></table></figure></div>

<h3 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a><em>快速入门</em></h3><h4 id="QAT、PTQ简介"><a href="#QAT、PTQ简介" class="headerlink" title="QAT、PTQ简介"></a><em>QAT、PTQ简介</em></h4><p><em>依据是否要对量化后的参数进行调整，我们可以将量化方法分为量化感知训练（QAT）和训练后量化（PTQ）。 这两种方法的操作区别如下图所示（图左为QAT，图右为PTQ）：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508182313277.png"
                      class="" title="image-20230508182313277"
                ></em></p>
<p><em><strong>量化训练 QAT</strong> 是将训练过的模型量化后又再进行重训练。由于定点数值无法用于反向梯度计算，</em><em>实际操作过程是在某些op前插入伪量化节点（fake quantization nodes）， 用于在训练时获取流经该op的数据的截断值，便于在部署量化模型时对节点进行量化时使用**。我们需要在训练中通过不断优化精度来获取最佳的量化参数。由于它需要对模型进行训练, 对操作人员技术要求较高。</em></p>
<p><em><strong>训练后量化 PTQ</strong> 是使用一批校准数据对训练好的模型进行校准，将训练过的FP32模型直接转换为定点计算的模型，过程中无需对原始模型进行任何训练。只对几个超参数调整就可完成量化过程， 且过程简单快速，无需训练，因此此方法已被广泛应用于大量的端侧和云侧部署场景， <strong>我们优先推荐您尝试PTQ方法来查看是否满足您的部署精度和性能要求</strong> 。</em></p>
<blockquote>
<p><em>在量化训练中，由于定点数值无法直接用于反向梯度计算（因为梯度通常是浮点数），因此需要在某些操作（op）之前插入伪量化节点（fake quantization nodes）。这些伪量化节点在训练过程中用于获取流经该操作的数据的截断值，即将浮点数值截断为固定精度的定点数值。这样，模型可以在量化训练期间考虑量化过程的影响，并通过梯度反向传播来优化量化参数。</em></p>
<p><em>这些伪量化节点在量化训练期间起到两个作用：</em></p>
<ol>
<li><em>在训练过程中获取流经该操作的数据的截断值，以便计算梯度并进行反向传播。</em></li>
<li><em>为后续的量化模型部署提供参考，以便在推理阶段对节点进行真实的量化操作。</em></li>
</ol>
<p><em>定点数是一种表示数值的方式，它使用固定的小数位数。在量化训练中，浮点数的数值范围被量化为一个有限的整数范围。这个整数范围通常被划分为多个等间隔的整数值，每个整数值表示一个定点数。通过将浮点数映射到最接近的定点数，可以将浮点数量化为定点数。</em></p>
</blockquote>
<h4 id="芯片算法模型PTQ量化-上板-快速上手"><a href="#芯片算法模型PTQ量化-上板-快速上手" class="headerlink" title="芯片算法模型PTQ量化+上板 快速上手"></a><em>芯片算法模型PTQ量化+上板 快速上手</em></h4><p><em>本章节中，将介绍训练后量化PTQ方案的基本使用流程，便于实现快速上手。 这里我们以MobileNet-v1模型为例，进行使用演示，详细内容将在后续章节展开介绍，基本工作流程如下图所示。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508183501325.png"
                      class="" title="image-20230508183501325"
                ></em></p>
<p><em><strong>请注意，在您进行以下操作前，请确保您已经参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html" >环境部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节完成了开发机和开发板上的环境安装。</strong></em></p>
<blockquote>
<p><em>浮点模型准备</em></p>
</blockquote>
<p><em>地平线为您提供了丰富的PTQ示例模型。您可以根据需要，在对应的示例文件夹内执行其中的 <code>00_init.sh</code> 脚本来获取示例对应的校准数据集和原始模型。 示例模型的模型来源和相关说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#prepare-ptq-model" >如何准备模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p>*如您需要转换私有模型，请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/model_prepare.html" >浮点模型准备 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容 提前准备好 <strong>caffe1.0 或 opset&#x3D;10&#x2F;11 的 onnx 模型</strong>。下表为不同框架到ONNX模型格式转换的参考方案：*</p>
<table>
<thead>
<tr>
<th align="left"><em>训练框架</em></th>
<th align="left"><em>参考方案</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>Pytorch</em></td>
<td align="left"><em>使用官方API导出： <a class="link"   target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html" >https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>Tensorflow</em></td>
<td align="left"><em>使用ONNX社区的onnx&#x2F;tensorflow-onnx工具转换： <a class="link"   target="_blank" rel="noopener" href="https://github.com/onnx/tensorflow-onnx" >https://github.com/onnx/tensorflow-onnx <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>MXNet2Onnx</em></td>
<td align="left"><em>使用官方API导出： <a class="link"   target="_blank" rel="noopener" href="https://github.com/dotnet/machinelearning/blob/main/test/Microsoft.ML.Tests/OnnxConversionTest.cs" >https://github.com/dotnet/machinelearning/blob/main/test/Microsoft.ML.Tests/OnnxConversionTest.cs <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>其他框架</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://github.com/onnx/tutorials#converting-to-onnx-format" >https://github.com/onnx/tutorials#converting-to-onnx-format <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
</tbody></table>
<blockquote>
<p><em>模型验证</em></p>
</blockquote>
<p><em>在浮点模型准备好之后，我们建议先进行快速的模型验证，以确保其符合芯片的支持约束。 对于<strong>Caffe</strong>框架的MobileNet模型，我们可以在命令行中键入以下命令完成模型验证：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper checker --model-type caffe \</span><br><span class="line">                  --prototxt mobilenet_deploy.prototxt \</span><br><span class="line">                  --model mobilenet.caffemodel \</span><br><span class="line">                  --march bayes</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>Caffe 是一个基于图的深度学习框架，主要用于计算机视觉任务，如图像分类、目标检测和图像分割。它以速度、模块化和可扩展性为设计目标，提供了一个简单而高效的工具链，用于定义、训练和部署深度神经网络模型。</em></p>
</blockquote>
<p><em>对于<strong>ONNX</strong>格式的Efficientnet_lite0模型，则键入以下命令：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper checker --model-type onnx \</span><br><span class="line">                  --model efficientnet_lite0_fp32.onnx \</span><br><span class="line">                  --march bayes</span><br></pre></td></tr></table></figure></div>

<p><em>其中，两个模型文件都可从 <code>ddk/samples/model_zoo/mapper/classification</code> 路径获取。 而 <code>hb_mapper checker</code> 工具的主要参数如下，更多参数说明还请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html" >验证模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<table>
<thead>
<tr>
<th align="left"><em>参数</em></th>
<th align="left"><em>说明</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>–model-type</em></td>
<td align="left"><em>用于指定检查输入的模型类型，目前只支持设置 <strong>caffe</strong> 或者 <strong>onnx</strong> 。</em></td>
</tr>
<tr>
<td align="left"><em>–march</em></td>
<td align="left"><em>用于指定需要适配的芯片类型，J5芯片请设置为 <strong>bayes</strong> （默认值）。</em></td>
</tr>
<tr>
<td align="left"><em>–proto</em></td>
<td align="left"><em>此参数仅在model-type指定caffe时有效，取值为caffe模型的 <strong>prototxt</strong> 文件名称； <strong>onnx模型可以不配置该参数。</strong></em></td>
</tr>
<tr>
<td align="left"><em>–model</em></td>
<td align="left"><em>在model-type被指定为caffe时，取值为Caffe模型的 <strong>caffemodel</strong> 文件名称； 在model-type被指定为onnx时，取值为 <strong>ONNX模型</strong> 文件名称。</em></td>
</tr>
</tbody></table>
<p><em>以MobileNet-v1模型为例，您也可以基于我们示例中的 <code>01_checker.sh</code> 脚本进行对应修改后使用，参考命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd ddk/samples/ai_toolchain/horizon_model_convert_sample/   # PTQ示例目录</span><br><span class="line">cd 03_classification/01_mobilenet/mapper                    # mobilenet示例目录</span><br><span class="line">vim 01_checker.sh                                           # 对应修改脚本</span><br><span class="line">bash 01_checker.sh                                          # 运行脚本检查模型</span><br></pre></td></tr></table></figure></div>

<p><em>01_checker.sh脚本文件中的主要内容如下所示：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508185808895.png"
                      class="" title="image-20230508185808895"
                ></em></p>
<p><em>如果模型验证不通过，请根据终端打印或在当前路径下生成的 <code>hb_mapper_checker_&#123;date_time&#125;.log</code> 日志文件确认报错信息和修改建议， 更多说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html" >验证模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<blockquote>
<p><em>模型转换</em></p>
</blockquote>
<p><em>模型验证通过后，就可以使用 <code>hb_mapper makertbin</code> 工具进行模型转换，参考命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper makertbin --config mobilenet_config.yaml \</span><br><span class="line">                    --model-type caffe</span><br></pre></td></tr></table></figure></div>

<p>*其中， <code>mobilenet_config.yaml</code> <strong>为模型转换对应的配置文件</strong>，将在 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#yaml-config" >Yaml配置文件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中进行介绍。 <code>model-type</code> 则用于指定检查输入的模型类型， 可配置为caffe或者onnx，不同模型类型对应的配置文件参数会稍有不同。*</p>
<p><em>另外，PTQ 方案的模型量化还需要依赖一定数量预处理后的样本进行校准，将在 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#calibration-data-preprocess" >校准数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中进行介绍。</em></p>
<p><em><strong>Yaml配置文件</strong></em></p>
<p><em>Yaml配置文件共包含4个必选参数组（ <code>model_parameters</code> 、 <code>input_parameters</code> 、 <code>calibration_parameters</code> 、 <code>compiler_parameters</code> ）和 1个可选参数组（ <code>custom_op</code> ），每个参数组下也区分必选和可选参数（可选参数默认隐藏），具体要求和填写方式可以参考模型示例 及 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html" >模型量化与编译 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。以下为MobileNet-v1模型的配置文件：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型转化相关的参数</span></span><br><span class="line">model_parameters:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Caffe浮点网络数据模型文件</span></span><br><span class="line">  caffe_model: <span class="string">&#x27;mobilenet.caffemodel&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Caffe网络描述文件</span></span><br><span class="line">  prototxt: <span class="string">&#x27;mobilenet_deploy.prototxt&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 适用BPU架构</span></span><br><span class="line">  march: <span class="string">&quot;bayes&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 指定模型转换过程中是否输出各层的中间结果，如果为True，则输出所有层的中间输出结果</span></span><br><span class="line">  layer_out_dump: <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 模型转换输出的结果的存放目录</span></span><br><span class="line">  working_dir: <span class="string">&#x27;model_output&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 模型转换输出的用于上板执行的模型文件的名称前缀</span></span><br><span class="line">  output_model_file_prefix: <span class="string">&#x27;mobilenetv1_224x224_nv12&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型输入相关参数, 若输入多个节点, 则应使用&#x27;;&#x27;进行分隔, 使用默认缺省设置则写None</span></span><br><span class="line">input_parameters:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># (选填) 模型输入的节点名称, 此名称应与模型文件中的名称一致, 否则会报错, 不填则会使用模型文件中的节点名称</span></span><br><span class="line">  input_name: <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 网络实际执行时，输入给网络的数据格式，包括 nv12/rgb/bgr/yuv444/gray/featuremap</span></span><br><span class="line">  input_type_rt: <span class="string">&#x27;nv12&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 网络训练时输入的数据格式，可选的值为rgb/bgr/gray/featuremap/yuv444</span></span><br><span class="line">  input_type_train: <span class="string">&#x27;bgr&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 网络训练时输入的数据排布, 可选值为 NHWC/NCHW</span></span><br><span class="line">  input_layout_train: <span class="string">&#x27;NCHW&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># (选填) 模型网络的输入大小, 以&#x27;x&#x27;分隔, 不填则会使用模型文件中的网络输入大小，否则会覆盖模型文件中输入大小</span></span><br><span class="line">  input_shape: <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 网络实际执行时，输入给网络的batch_size, 默认值为1</span></span><br><span class="line">  <span class="comment">#input_batch: 1</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 网络输入的预处理方法，主要有以下几种：</span></span><br><span class="line">  <span class="comment"># no_preprocess 不做任何操作</span></span><br><span class="line">  <span class="comment"># data_mean 减去通道均值mean_value</span></span><br><span class="line">  <span class="comment"># data_scale 对图像像素乘以data_scale系数</span></span><br><span class="line">  <span class="comment"># data_mean_and_scale 减去通道均值后再乘以scale系数</span></span><br><span class="line">  norm_type: <span class="string">&#x27;data_mean_and_scale&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 图像减去的均值, 如果是通道均值，value之间必须用空格分隔</span></span><br><span class="line">  mean_value: <span class="number">103.94</span> <span class="number">116.78</span> <span class="number">123.68</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 图像预处理缩放比例，如果是通道缩放比例，value之间必须用空格分隔</span></span><br><span class="line">  scale_value: <span class="number">0.017</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型量化相关参数</span></span><br><span class="line">calibration_parameters:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 模型量化的参考图像的存放目录，图片格式支持Jpeg、Bmp等格式，输入的图片</span></span><br><span class="line">  <span class="comment"># 应该是使用的典型场景，一般是从测试集中选择20~100张图片，另外输入</span></span><br><span class="line">  <span class="comment"># 的图片要覆盖典型场景，不要是偏僻场景，如过曝光、饱和、模糊、纯黑、纯白等图片</span></span><br><span class="line">  <span class="comment"># 若有多个输入节点, 则应使用&#x27;;&#x27;进行分隔</span></span><br><span class="line">  cal_data_dir: <span class="string">&#x27;./calibration_data_bgr&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 校准数据二进制文件的数据存储类型，可选值为：float32, uint8. 若有多个输入节点, 则应使用&#x27;;&#x27;进行分隔</span></span><br><span class="line">  cal_data_type: <span class="string">&#x27;float32&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 模型量化的算法类型，支持default、mix、kl、max、load，通常采用default即可满足要求</span></span><br><span class="line">  <span class="comment"># 如不符合预期可先尝试修改为mix 仍不符合预期再尝试kl或max</span></span><br><span class="line">  <span class="comment"># 当使用QAT导出模型时，此参数则应设置为load</span></span><br><span class="line">  <span class="comment"># 相关参数的技术原理及说明请您参考用户手册中的PTQ原理及步骤中参数组详细介绍部分</span></span><br><span class="line">  calibration_type: <span class="string">&#x27;max&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 该参数为&#x27;max&#x27;校准方法的参数，用以调整&#x27;max&#x27;校准的截取点。此参数仅在calibration_type为&#x27;max&#x27;时有效。</span></span><br><span class="line">  <span class="comment"># 该参数取值范围：0.0 ~ 1.0。常用配置选项有：0.99999/0.99995/0.99990/0.99950/0.99900。</span></span><br><span class="line">  max_percentile: <span class="number">0.9999</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译器相关参数</span></span><br><span class="line">compiler_parameters:</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 编译策略，支持bandwidth和latency两种优化模式;</span></span><br><span class="line">  <span class="comment"># bandwidth以优化ddr的访问带宽为目标；</span></span><br><span class="line">  <span class="comment"># latency以优化推理时间为目标</span></span><br><span class="line">  compile_mode: <span class="string">&#x27;latency&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 设置debug为True将打开编译器的debug模式，能够输出性能仿真的相关信息，如帧率、DDR带宽占用等</span></span><br><span class="line">  debug: <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 优化等级可选范围为O0~O3</span></span><br><span class="line">  <span class="comment"># O0不做任何优化, 编译速度最快，优化程度最低,</span></span><br><span class="line">  <span class="comment"># O1-O3随着优化等级提高，预期编译后的模型的执行速度会更快，但是所需编译时间也会变长。</span></span><br><span class="line">  <span class="comment"># 推荐用O2做最快验证</span></span><br><span class="line">  optimize_level: <span class="string">&#x27;O3&#x27;</span></span><br></pre></td></tr></table></figure></div>

<p><em>其中，ONNX模型无需配置 <code>model_parameters</code> 参数组中的 <code>caffe_model</code> 和 <code>prototxt</code> 参数，而是替换为配置 <code>onnx_model</code> 参数。</em></p>
<p><em><code>input_parameters</code> 参数组中的 <code>input_type_rt</code> 和 <code>input_type_train</code> 参数分别用于指定模型在板端实际部署时会接收到的数据类型 （如 nv12）和本身训练时的数据类型（如 rgb）。当两种数据类型不一致时，转换工具会自动在模型前端插入一个能 BPU 加速的预处理节点，以完成对应的颜色空间转换。 同时，该参数组中的 <code>norm_type</code> 、 <code>mean_value</code> 、 <code>scale_value</code> 参数还能用于配置图片输入模型的数据归一化操作， 配置后转换工具也会将其集成进预处理节点实现BPU加速。数据归一化的计算公式为：</em></p>
<p><em><strong>data_norm&#x3D;(data - mean_value) * scale_value</strong></em></p>
<p><em><code>calibration_parameters</code> 参数组中的 <code>cal_data_dir</code> 参数需要配置预处理好的校准数据文件夹路径， 预处理方式的说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#calibration-data-preprocess" >校准数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</em></p>
<p><em><strong>校准数据预处理</strong></em></p>
<p><em><strong>注意：</strong></em></p>
<ul>
<li><em>请注意，在进行此步之前，请确保您已经通过执行对应示例目录下的 <code>00_init.sh</code> 脚本完成了校准数据集的获取。</em></li>
<li><em>如果当前只关注模型性能，那么可以将yaml文件中的 <code>calibration_type</code> 参数直接配置为 <code>skip</code> ，并跳过本小节， 工具会在模型转换时自动忽略 <code>cal_data_dir</code> 参数。</em></li>
</ul>
<p><em>PTQ方案的校准数据一般是从训练集或验证集中筛选100份左右（可适当增减）的典型数据，并应避免非常少见的异常样本， 如纯色图片、不含任何检测或分类目标的图片等。<strong>筛选出的校准数据还需进行与模型inference前一致的预处理操作， 处理后保持与原始模型一样的数据类型（ <code>input_type_train</code> ）、layout （ <code>input_layout_train</code> ）和尺寸（ <code>input_shape</code> ）。</strong></em></p>
<p><em>对于校准数据的预处理，地平线建议直接参考示例代码进行修改使用。以MobileNet-v1模型为例，preprocess.py文件中 的calibration_transformers函数的包含了其校准数据的前处理 transformers，处理完的校准数据与其 yaml 配置文件保持一致，即：</em></p>
<ul>
<li><em><strong>input_type_train</strong> ： ‘bgr’</em></li>
<li><em><strong>input_layout_train</strong> ：’NCHW’</em></li>
</ul>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calibration_transformers</span>():</span><br><span class="line">    transformers = [</span><br><span class="line">        ShortSideResizeTransformer(short_size=<span class="number">256</span>),</span><br><span class="line">        CenterCropTransformer(crop_size=<span class="number">224</span>),</span><br><span class="line">        HWC2CHWTransformer(),</span><br><span class="line">        RGB2BGRTransformer(data_format=<span class="string">&quot;CHW&quot;</span>),</span><br><span class="line">        ScaleTransformer(scale_value=<span class="number">255</span>),</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> transformers</span><br></pre></td></tr></table></figure></div>

<p><em>其中，transformers都定义在 <code>../../../01_common/python/data/transformer.py</code> 文件中，具体说明 请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_appendix/transformer.html" >图片处理transformer说明 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，您可以按需选用或者自定义修改及扩展。</em></p>
<p><em><strong>注意：需要注意的是，如果已经在yaml文件中配置了数据归一化来启用BPU加速，那么应避免在此处的transformers中重复操作。</strong></em></p>
<p><em>修改完preprocess.py文件后，即可修改02_preprocess.sh脚本并执行，以完成校准数据的预处理。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash 02_preprocess.sh</span><br></pre></td></tr></table></figure></div>

<p><em>02_preprocess.sh脚本文件的主要内容如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set -e -v</span><br><span class="line">cd $(dirname $0) || exit</span><br><span class="line"></span><br><span class="line">python3 ../../../data_preprocess.py \</span><br><span class="line">  --src_dir ../../../01_common/calibration_data/imagenet \</span><br><span class="line">  --dst_dir ./calibration_data_bgr \</span><br><span class="line">  --pic_ext .bgr \</span><br><span class="line">  --read_mode skimage \</span><br><span class="line">  --saved_data_type float32</span><br></pre></td></tr></table></figure></div>

<p><em>data_preprocess.py文件的传参说明如下：</em></p>
<ul>
<li><em>src_dir为原始校准数据路径。</em></li>
<li><em>dst_dir为处理后数据的存放路径，可自定义。</em></li>
<li><em>pic_ext为处理后数据的文件后缀，主要用于帮助记忆数据类型，可不配置。</em></li>
<li><em>read_mode为图片读取方式，可配置为skimage或opencv。需要注意的是，skimage读取的图片类型为RGB， 数据范围为0-1，而opencv读取的图片类型为BGR，数据范围为0-255。</em></li>
<li><em>saved_data_type为处理后数据的保存类型。</em></li>
</ul>
<p><em>如果您选择自行编写python代码实现校准数据预处理，那么可以使用 <code>numpy.tofile</code> 命令将其保存为float32 格式的二进制文件， 工具链校准时会基于 <code>numpy.fromfile</code> 命令进行读取。</em></p>
<p><em><strong>转换模型</strong></em></p>
<p><em>准备完校准数据和yaml配置文件后，即可一步命令完成模型解析、图优化、校准、量化、编译的全流程转换， 内部过程详解请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation" >转换内部过程解读 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。 以MobileNet-v1模型为例的模型转换参考命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper makertbin --config mobilenet_config.yaml \</span><br><span class="line">                    --model-type caffe</span><br></pre></td></tr></table></figure></div>

<p><em>转换完成后，会在yaml文件配置的 <code>working_dir</code> 路径下保存各阶段流程产出的模型文件和编译器预估的 模型BPU部分的静态性能评估文件，详细说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-output" >转换产出物解读 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">|-- MOBILENET_subgraph_0.html        # 静态性能评估文件（可读性更好）</span><br><span class="line">|-- MOBILENET_subgraph_0.json        # 静态性能评估文件</span><br><span class="line">|-- mobilenetv1_224x224_nv12.bin     # 用于在地平线AI芯片上加载运行的模型</span><br><span class="line">|-- mobilenetv1_224x224_nv12_optimized_float_model.onnx</span><br><span class="line">|-- mobilenetv1_224x224_nv12_original_float_model.onnx</span><br><span class="line">`-- mobilenetv1_224x224_nv12_quantized_model.onnx</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p><em>性能快速验证</em></p>
</blockquote>
<p><em>针对转换生成的 <code>xxx.bin</code> 模型文件，地平线既支持先在开发机端预估模型BPU部分的的静态性能， 也在板端提供给了无需任何代码开发的可执行工具快速评测动态性能，以下将分别进行介绍。 更详细的说明和性能调优建议请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html" >模型性能分析与调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>静态性能评估</strong></em></p>
<p><em>如 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#quickstart-model-conv" >转换模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 所述，模型成功转换后会在 <code>working_dir</code> 路径下生成包含模型静态性能预估的html和json文件，两者内容相同， 但html文件的可读性更好。以下为MobileNet-v1模型转换生成的html文件，其中：</em></p>
<ul>
<li><em>Summary选项卡提供了编译器预估的模型BPU部分性能（不包含CPU算子性能预估）。</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508193519478.png"
                      class="" title="image-20230508193519478"
                ></em></p>
<ul>
<li><em>Temporal Statistics选项卡内则主要提供了模型一帧推理时间内的带宽占用情况。</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508193533794.png"
                      class="" title="image-20230508193533794"
                ></em></p>
<ul>
<li><em>另外，如果我们在yaml文件 <code>compiler_parameters</code> 参数组内配置了 <code>debug</code> 参数为True，那么html文件中 还会增加Layer Details选项卡，其中包含了每一层BPU算子的计算量、计算耗时和数据搬运耗时。</em></li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508193547284.png"
                      class="" title="image-20230508193547284"
                ></em></p>
<p><em>针对 <code>xxx.bin</code> 模型，地平线在开发机环境还提供了 <code>hb_perf 工具</code> 重新生成静态性能预估文件。其使用方式如下， 详细说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html#hb-perf" >使用hb_perf工具估计性能 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_perf xxx.bin</span><br></pre></td></tr></table></figure></div>

<p><em>当模型的静态性能已经不符合预期时，请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html#model-performance-optimize" >模型性能优化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节进行性能调优。</em></p>
<p><em><strong>动态性能评估</strong></em></p>
<p><em>当模型的静态性能符合预期后，我们可以进一步上板实测模型的动态性能，其参考方式如下：</em></p>
<p><em>1.首先请确保已按照 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html" >环境部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节完成开发板环境部署。</em></p>
<p><em>2.将转换生成的 <code>xxx.bin</code> 模型拷贝至开发板 <code>/userdata</code> 文件夹下任意路径。</em></p>
<p><em>3.通过 <code>hrt_model_exec perf</code> 工具快捷评估模型的耗时和帧率。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 将模型拷贝至开发板</span><br><span class="line">scp model_output/mobilenetv1_224x224_nv12.bin root@&#123;board_ip&#125;:/userdata</span><br><span class="line"></span><br><span class="line"># 登录开发板评测性能</span><br><span class="line">ssh root@&#123;board_ip&#125;</span><br><span class="line">cd /userdata</span><br><span class="line"></span><br><span class="line"># 单BPU核单线程串行状态下评测latency</span><br><span class="line">hrt_model_exec perf --model_file mobilenetv1_224x224_nv12.bin --thread_num 1 --frame_count 1000</span><br><span class="line"></span><br><span class="line"># 双BPU核多线程并发状态下评测FPS</span><br><span class="line">hrt_model_exec perf --model_file mobilenetv1_224x224_nv12.bin --core_id 0 --thread_num 4 --frame_count 1000</span><br></pre></td></tr></table></figure></div>

<p><em><code>hrt_model_exec</code> 工具的主要参数说明如下，更多说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/tool_introduction/source/hrt_model_exec.html" >hrt_model_exec工具介绍 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<table>
<thead>
<tr>
<th align="left"><em>参数</em></th>
<th align="left"><em>类型</em></th>
<th align="left"><em>说明</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>model_file</em></td>
<td align="left"><em>string</em></td>
<td align="left"><em>[必选]模型文件路径</em></td>
</tr>
<tr>
<td align="left"><em>core_id</em></td>
<td align="left"><em>int</em></td>
<td align="left"><em>[可选]用于指定BPU运行核心，默认值为0。0：任意核，预测库会根据负载情况自动分配调度。1：core0。2：core1。</em></td>
</tr>
<tr>
<td align="left"><em>thread_num</em></td>
<td align="left"><em>int</em></td>
<td align="left"><em>[可选]程序运行线程数，可选范围[1,8]，默认值1。</em></td>
</tr>
<tr>
<td align="left"><em>frame_count</em></td>
<td align="left"><em>int</em></td>
<td align="left"><em>[可选]模型运行总帧数，默认值200。</em></td>
</tr>
<tr>
<td align="left"><em>profile_path</em></td>
<td align="left"><em>string</em></td>
<td align="left"><em>[可选]统计工具日志产生路径，运行产生profiler.log和profiler.csv，分析op耗时和调度耗时。</em></td>
</tr>
</tbody></table>
<p><em>注解</em></p>
<ul>
<li><em>如果您在板端无法找到 <code>hrt_model_exec</code> 工具，可以再执行一次OE包中 <code>ddk/package/board</code> 路径下的 <code>install.sh</code> 脚本。</em></li>
<li><em>评测Latency时一般采用单线程串行的推理方式，可以指定 <code>thread_num</code> 为 1。</em></li>
<li><em>评测FPS时一般采用多线程并发的推理方式来占满BPU资源，此时可以配置 <code>core_id</code> 为 0，并配置 <code>thread_num</code> 为多线程。</em></li>
<li><em><strong>如果您配置了 <code>profile_path</code> 参数，程序需要正常运行结束才会生成 <code>profiler.log</code> 和 <code>profiler.csv</code> 日志文件，请勿使用 <code>Ctrl+C</code> 命令中断程序。</strong></em></li>
</ul>
<p><em>当模型的动态性能不符合预期时，请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html#model-performance-optimize" >模型性能优化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节进行性能调优。</em></p>
<blockquote>
<p><em>在深度学习中，FPS（Frames Per Second）是用于衡量计算机或处理器在推理或训练神经网络模型时，<strong>每秒可以处理多少个数据样本或图像帧的指标</strong>。FPS越高，说明处理器的性能越好，处理速度越快。</em></p>
<p><em>在推理任务中，FPS通常指的是神经网络模型的前向计算速度，即输入数据样本通过神经网络模型，生成输出结果的速度。在训练任务中，FPS通常指的是神经网络模型每秒钟可以训练多少个数据样本的速度，即一次反向传播和梯度更新的速度。</em></p>
<p><em>FPS除了衡量处理器的性能外，还可以用于确定神经网络模型在不同硬件平台上的性能表现，以便选择最适合的硬件进行模型部署和优化。</em></p>
</blockquote>
<blockquote>
<p><em>在深度学习中，延迟（latency）指的是从输入数据进入模型，经过模型计算和处理，到最终输出结果可用的时间间隔。它是衡量模型推理或训练过程中的时间延迟或响应时间的指标。</em></p>
<p><em>对于模型推理，延迟是指从输入数据传入模型，通过前向传播计算，到输出结果可用的时间。对于实时应用，如视频处理、物体检测或语音识别，较低的延迟是非常重要的，以确保系统能够快速响应和处理实时数据。</em></p>
<p><em>对于模型训练，延迟是指每个训练步骤或批次的计算时间。较低的训练延迟意味着模型可以更快地完成一轮训练或处理更多的数据。减少训练延迟可以加快模型的迭代速度，加速实验和调参过程。</em></p>
<p><em>延迟的大小取决于多个因素，包括硬件设备的性能（如CPU、GPU或TPU）、模型的复杂度和大小、输入数据的大小等。对于大规模深度学习模型和复杂任务，可能需要更强大的硬件设备和优化技术来减小延迟并实现实时性能。</em></p>
</blockquote>
<blockquote>
<p><em>精度验证</em></p>
</blockquote>
<p><em>当模型的性能验证符合预期后，即可进行后续的精度验证。请首先确保您已经准备好相关的评测数据集，并挂载在Docker容器中。 示例模型使用的数据集可以从以下链接获取：</em></p>
<table>
<thead>
<tr>
<th align="left"><em><strong>数据集</strong></em></th>
<th align="left"><em><strong>下载地址</strong></em></th>
<th align="left"><em><strong>下载结构</strong></em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>ImageNet</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://www.image-net.org/download.php" >https://www.image-net.org/download.php <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#imagenet-prepare" >ImageNet数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>COCO</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://cocodataset.org/" >https://cocodataset.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#coco-prepare" >COCO数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>VOC</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/" >http://host.robots.ox.ac.uk/pascal/VOC/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>需要下载2007和2012两个版本，下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#voc-prepare" >VOC数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>Cityscapes</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://github.com/mcordts/cityscapesScripts" >https://github.com/mcordts/cityscapesScripts <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#cityscapes-prepare" >Cityscapes数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>CIFAR-10</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar.html" >http://www.cs.toronto.edu/~kriz/cifar.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html#cifar-prepare" >CIFAR-10数据集参考结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
</tr>
<tr>
<td align="left"><em>FlyingChairs</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html" >https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
<tr>
<td align="left"><em>KITTI3D</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d" >https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
<tr>
<td align="left"><em>CULane</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://xingangpan.github.io/projects/CULane.html" >https://xingangpan.github.io/projects/CULane.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
<tr>
<td align="left"><em>nuScenes</em></td>
<td align="left"><em><a class="link"   target="_blank" rel="noopener" href="https://www.nuscenes.org/nuscenes" >https://www.nuscenes.org/nuscenes <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></td>
<td align="left"><em>下载结构请您参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#qat-dataset-prepare" >QAT模型数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的相关描述</em></td>
</tr>
</tbody></table>
<p><em>如果您在数据准备过程中有遇到问题，可以前往 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/forum" >地平线开发者社区 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 发帖进行求助。</em></p>
<p><em>如 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#quickstart-model-conv" >转换模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 所述，模型转换会生成 <code>xxx_quantized_model.onnx</code> 和 <code>xxx.bin</code> 两个量化模型，两者输出是保持数值一致的。 您也可以在开发机环境使用 <code>hb_verifier</code> 工具进行一致性验证，参考命令如下， 详细说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_verifier.html" >hb_verifier 工具 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m quanti.onnx,model.bin -b *.*.*.* -s True (-i 选填)</span><br></pre></td></tr></table></figure></div>

<p><em><code>hb_verifier</code> 工具的参数说明如下：</em></p>
<table>
<thead>
<tr>
<th align="left"><em>参数</em></th>
<th align="left"><em>说明</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>–model, -m</em></td>
<td align="left"><em>[必选]定点模型名称和bin模型名称，多模型之间用”,”进行区分。</em></td>
</tr>
<tr>
<td align="left"><em>–board-ip&#x2F;-b</em></td>
<td align="left"><em>[可选]上板测试使用的arm board ip地址。</em></td>
</tr>
<tr>
<td align="left"><em>–run-sim&#x2F;-s</em></td>
<td align="left"><em>[可选]设置是否使用X86环境的libdnn做bin模型推理，默认为False。（<strong>libdnn指的是用于深度神经网络的库或软件包</strong>）</em></td>
</tr>
<tr>
<td align="left"><em>–input-img&#x2F;-i</em></td>
<td align="left"><em>[可选]指定推理测试时使用的图片。若不指定则会使用随机生成的tensor数据。 若指定图片为二进制形式的图片文件，其文件形式需要为后缀名为 <code>.bin</code> 形式。多输入模型添加图片的方式有以下两种传参方式，多张图片之间用”,”分割：input_name1:image1,input_name2:image2, …image1,image2…</em></td>
</tr>
<tr>
<td align="left"><em>–compare_digits&#x2F;-c</em></td>
<td align="left"><em>[可选]设置比较推理结果的数值精确度（即比较数值小数点后的位数）， 若不进行指定则工具会默认比较至小数点后五位。</em></td>
</tr>
<tr>
<td align="left"><em>–dump-all-nodes-results&#x2F;-r</em></td>
<td align="left"><em>[可选]设置是否保存模型中各个算子的输出结果，并对算子输出名称相同的结果进行对比，默认为False。当该参数设置为 <code>True</code> 时，工具将会获取模型中所有节点的输出，并根据节点输出的名字做匹配，从而进行对比。当该参数设置为 <code>False</code> 时，工具将会只获取模型最终输出的结果，并进行对比。<strong>请您注意，目前基于性能考虑，暂不支持您在X86环境下使用dump功能。</strong></em></td>
</tr>
</tbody></table>
<p><em>相比于 <code>xxx.bin</code> ，<strong>地平线更建议优先在开发机Python环境评测 <code>xxx_quantized_model.onnx</code> 模型的量化精度</strong>，其评测方式更加简单快捷， 具体请见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#board-python-env" >开发机Python环境验证 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。 <code>xxx.bin</code> 在板端基于C++代码的评测说明请见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#board-cpp-env" >开发板C++环境验证 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 更详细的精度验证和优化建议请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html" >模型精度分析与调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>开发机Python环境验证</strong></em></p>
<p><em>以 MobileNet-v1 模型为例，mobilenetv1_224x224_nv12_quantized_model.onnx量化模型的单张推理和验证集精度评测示例请参考 示例目录中的 <code>04_inference.sh</code> 和 <code>05_evaluate.sh</code> 脚本，参考命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 测试量化模型单张图片推理结果</span><br><span class="line">bash 04_inference.sh</span><br><span class="line"></span><br><span class="line"># 测试浮点模型单张图片推理结果（可选）</span><br><span class="line">bash 04_inference.sh origin</span><br><span class="line"></span><br><span class="line"># 测试量化模型精度，请确保您的评测数据集已正确挂载在Docker容器中</span><br><span class="line">bash 05_evaluate.sh</span><br><span class="line"></span><br><span class="line"># 测试浮点模型精度（可选）</span><br><span class="line">bash 05_evaluate.sh origin</span><br></pre></td></tr></table></figure></div>

<p><em>两个脚本会分别调用 <code>../../cls_inference.py</code> 和 <code>../../cls_evaluate.py</code> 文件进行推理， 以 <code>cls_inference.py</code> 文件为例，代码中的主要接口使用逻辑如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from horizon_tc_ui import HB_ONNXRuntime</span><br><span class="line">from preprocess import infer_image_preprocess</span><br><span class="line">from postprocess import postprocess</span><br><span class="line"></span><br><span class="line">def inference(sess, image_name, input_layout, input_offset):</span><br><span class="line">  if input_layout is None:</span><br><span class="line">        input_layout = sess.layout[0]</span><br><span class="line">    # 前处理</span><br><span class="line">    image_data = infer_image_preprocess(image_name, input_layout)</span><br><span class="line">    input_name = sess.input_names[0]</span><br><span class="line">    output_name = sess.output_names</span><br><span class="line">    # 模型推理</span><br><span class="line">    output = sess.run(output_name, &#123;input_name: image_data&#125;,</span><br><span class="line">                      input_offset=input_offset)</span><br><span class="line">    # 后处理</span><br><span class="line">    top_five_label_probs = postprocess(output)</span><br><span class="line"></span><br><span class="line">def main(model, image, input_layout, input_offset):</span><br><span class="line">    sess = HB_ONNXRuntime(model_file=model)</span><br><span class="line">    sess.set_dim_param(0, 0, &#x27;?&#x27;)</span><br><span class="line">    inference(sess, image, input_layout, input_offset)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></div>

<p><em>其中，infer_image_preprocess函数的前处理操作来源于 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#calibration-data-preprocess" >校准数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节 所述preprocess.py文件，相比于calibration_transformers函数会额外增加 <code>input_type_train</code> 到 <code>input_type_rt</code> （参数说明请见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#yaml-config" >Yaml配置文件 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节）颜色空间的转换来对齐模型实际部署时的输入数据类型，具体代码如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def infer_transformers(input_layout=&quot;NHWC&quot;):</span><br><span class="line">    transformers = [</span><br><span class="line">        ShortSideResizeTransformer(short_size=256),</span><br><span class="line">        CenterCropTransformer(crop_size=224),</span><br><span class="line">        RGB2BGRTransformer(data_format=&quot;HWC&quot;),</span><br><span class="line">        ScaleTransformer(scale_value=255),</span><br><span class="line">        BGR2NV12Transformer(data_format=&quot;HWC&quot;),</span><br><span class="line">        NV12ToYUV444Transformer((224, 224),</span><br><span class="line">                                yuv444_output_layout=input_layout[1:]),</span><br><span class="line">    ]</span><br><span class="line">    return transformers</span><br><span class="line"></span><br><span class="line">def infer_image_preprocess(image_file, input_layout):</span><br><span class="line">    transformers = infer_transformers(input_layout)</span><br><span class="line">    image = SingleImageDataLoader(transformers,</span><br><span class="line">                                  image_file,</span><br><span class="line">                                  imread_mode=&#x27;skimage&#x27;)</span><br><span class="line">    return image</span><br></pre></td></tr></table></figure></div>

<p><em>需要注意的是， <code>xxx.bin</code> 模型对于 <code>input_type_train</code> 到 <code>input_type_rt</code> 颜色空间的转换会配合芯片硬件完成。 而模型转换生成的几个ONNX模型前端插入的预处理节点不包含硬件转换逻辑，所以其实际输入只是一种中间类型，对应硬件 对 <code>input_type_rt</code> 类型的处理结果。下表为每种 <code>input_type_rt</code> 数据类型对应的中间类型。 以MobileNet-v1模型为例，其 <code>input_type_rt</code> 配置为nv12，此处transformers中就会从BGR处理成NV12， 再处理成YUV444，-128（对应uint8转int8）的操作则会在sess.run推理接口中由 <code>input_offset</code> 参数传入。</em></p>
<table>
<thead>
<tr>
<th align="left"><em>input_type_rt</em></th>
<th align="left"><em>nv12</em></th>
<th align="left"><em>yuv444</em></th>
<th align="left"><em>rgb</em></th>
<th align="left"><em>bgr</em></th>
<th align="left"><em>gray</em></th>
<th align="left"><em>featuremap</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>中间类型</em></td>
<td align="left"><em>yuv444_128</em></td>
<td align="left"><em>yuv444_128</em></td>
<td align="left"><em>RGB_128</em></td>
<td align="left"><em>BGR_128</em></td>
<td align="left"><em>GRAY_128</em></td>
<td align="left"><em>featuremap</em></td>
</tr>
</tbody></table>
<p><em>注解</em></p>
<p><em>_128表示数据会减去128，由uint8类型转换为int8类型。</em></p>
<p><em><strong>开发板C++环境验证</strong></em></p>
<p><em>在开发板端，地平线也提供了一套适配所有硬件平台的嵌入式端预测库LibDNN，来帮助用户快速完成模型的部署工作， 并提供了相关示例。您可以首先参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#quickstart-model-deploy" >模型部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节学习模型部署和BPU SDK API接口的基础使用， 再参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#quickstart-ai-benchmark" >AI-Benchmark <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节学习示例模型精度评测的完整代码框架。</em></p>
<ul>
<li><em>模型部署</em></li>
</ul>
<p><em>OE包提供了模型部署的基础示例，以便于用户学习LibDNN预测库API接口的使用方式， 示例的详细说明可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/basic_sample/source/index.html" >基础示例包使用说明 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em>注意：在进行模型部署前，需要先获取上板使用的模型：</em></p>
<ul>
<li><em>在 <code>ddk/samples/ai_toolchain/model_zoo/runtime/ai_benchmark</code> 目录下， 执行 <code>resolve_ai_benchmark_ptq.sh</code> 、 <code>resolve_ai_benchmark_qat.sh</code> 。</em></li>
<li><em>在 <code>ddk/samples/ai_toolchain/model_zoo/runtime/horizon_runtime_sample</code> 目录下， 执行 <code>resolve_runtime_sample.sh</code> 。</em></li>
</ul>
<p><em>其中，示例目录下的 <code>code/00_quick_start/src/run_mobileNetV1_224x224.cc</code> 文件提供了MobileNet-v1模型 从DDR读取数据，到模型推理，再执行后处理出分类结果的完整流程代码。从摄像头输入的全链路示例可以 参考 <code>ddk/samples/ai_forward_view_sample</code> 。</em></p>
<p><em>run_mobileNetV1_224x224.cc中的主要代码逻辑包括以下6个步骤，代码中所涉及的API接口的具体说明 可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/index.html" >BPU SDK API手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em>1.加载模型，获取模型句柄。</em></p>
<p><em>2.准备模型输入输出tensor，申请对应的BPU内存空间。</em></p>
<p><em>3.读取模型输入数据，并放入申请好的输入tensor中。</em></p>
<p><em>4.推理模型，获取模型输出。</em></p>
<p><em>5.基于输出tensor中的数据实现模型后处理。</em></p>
<p><em>6.释放相关资源。</em></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step1: get model handle</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">hbDNNInitializeFromFiles</span>(&amp;packed_dnn_handle, &amp;modelFileName, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">hbDNNGetModelNameList</span>(&amp;model_name_list, &amp;model_count, packed_dnn_handle);</span><br><span class="line">    <span class="built_in">hbDNNGetModelHandle</span>(&amp;dnn_handle, packed_dnn_handle, model_name_list[<span class="number">0</span>]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step2: prepare input and output tensor</span></span><br><span class="line">  std::vector&lt;hbDNNTensor&gt; input_tensors;</span><br><span class="line">  std::vector&lt;hbDNNTensor&gt; output_tensors;</span><br><span class="line">  <span class="type">int</span> input_count = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int</span> output_count = <span class="number">0</span>;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">hbDNNGetInputCount</span>(&amp;input_count, dnn_handle);</span><br><span class="line">    <span class="built_in">hbDNNGetOutputCount</span>(&amp;output_count, dnn_handle);</span><br><span class="line">    input_tensors.<span class="built_in">resize</span>(input_count);</span><br><span class="line">    output_tensors.<span class="built_in">resize</span>(output_count);</span><br><span class="line">    <span class="built_in">prepare_tensor</span>(input_tensors.<span class="built_in">data</span>(), output_tensors.<span class="built_in">data</span>(), dnn_handle);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step3: set input data to input tensor</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// read a single picture for input_tensor[0], for multi_input model, you</span></span><br><span class="line">    <span class="comment">// should set other input data according to model input properties.</span></span><br><span class="line">    <span class="built_in">read_image_2_tensor_as_nv12</span>(FLAGS_image_file, input_tensors.<span class="built_in">data</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step4: run inference</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// make sure memory data is flushed to DDR before inference</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; input_count; i++) &#123;</span><br><span class="line">      <span class="built_in">hbSysFlushMem</span>(&amp;input_tensors[i].sysMem[<span class="number">0</span>], HB_SYS_MEM_CACHE_CLEAN);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    hbDNNInferCtrlParam infer_ctrl_param;</span><br><span class="line">    <span class="built_in">HB_DNN_INITIALIZE_INFER_CTRL_PARAM</span>(&amp;infer_ctrl_param);</span><br><span class="line">    <span class="built_in">hbDNNInfer</span>(&amp;task_handle,</span><br><span class="line">               &amp;output,</span><br><span class="line">               input_tensors.<span class="built_in">data</span>(),</span><br><span class="line">               dnn_handle,</span><br><span class="line">               &amp;infer_ctrl_param);</span><br><span class="line">    <span class="comment">// wait task done</span></span><br><span class="line">    <span class="built_in">hbDNNWaitTaskDone</span>(task_handle, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step5: do postprocess with output data</span></span><br><span class="line">  std::vector&lt;Classification&gt; top_k_cls;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// make sure CPU read data from DDR before using output tensor data</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; output_count; i++) &#123;</span><br><span class="line">      <span class="built_in">hbSysFlushMem</span>(&amp;output_tensors[i].sysMem[<span class="number">0</span>], HB_SYS_MEM_CACHE_INVALIDATE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">get_topk_result</span>(output, top_k_cls, FLAGS_top_k);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; FLAGS_top_k; i++) &#123;</span><br><span class="line">      <span class="built_in">VLOG</span>(EXAMPLE_REPORT) &lt;&lt; <span class="string">&quot;TOP &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; result id: &quot;</span> &lt;&lt; top_k_cls[i].id;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Step6: release resources</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// release task handle</span></span><br><span class="line">    <span class="built_in">hbDNNReleaseTask</span>(task_handle);</span><br><span class="line">    <span class="comment">// free input mem</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; input_count; i++) &#123;</span><br><span class="line">      <span class="built_in">hbSysFreeMem</span>(&amp;(input_tensors[i].sysMem[<span class="number">0</span>]));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// free output mem</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; output_count; i++) &#123;</span><br><span class="line">      <span class="built_in">hbSysFreeMem</span>(&amp;(output_tensors[i].sysMem[<span class="number">0</span>]));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// release model</span></span><br><span class="line">    <span class="built_in">hbDNNRelease</span>(packed_dnn_handle);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>该示例运行的参考方式如下：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开发机环境执行交叉编译，生成可执行程序</span></span><br><span class="line">cd /open_explorer/ddk/samples/ai_toolchain/horizon_runtime_sample/code</span><br><span class="line">bash build_j5.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝j5目录至板端</span></span><br><span class="line">mkdir ../j5/runtime</span><br><span class="line">scp -r ../j5/ root@&#123;board_ip&#125;:/userdata</span><br><span class="line"><span class="comment"># 拷贝模型文件至板端</span></span><br><span class="line">scp -r ../../model_zoo/runtime/mobilenetv1/ root@&#123;board_ip&#125;:/userdata/j5/model/runtime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 登录开发板环境</span></span><br><span class="line">ssh root@&#123;board_ip&#125;</span><br><span class="line"><span class="comment"># 进入j5/script/目录下，执行相应运行脚本即可</span></span><br><span class="line">cd /userdata/j5/script/00_quick_start/</span><br><span class="line">bash run_mobilenetV1.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em><strong>AI-Benchmark</strong></em></li>
</ul>
<p><em>OE包在以下路径提供了典型分类、检测、分割、光流示例模型板端性能和精度评测的示例包，其中预置了源码、可执行程序和评测脚本， 您可以基于这些示例进行进一步的应用开发。 以下 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#quickstart-sample" >示例使用 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节将介绍示例的使用方式， <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/faststart/quickstart.html#quickstart-code-structure" >代码结构 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节将简单介绍示例的代码结构。</em></p>
<blockquote>
<p><em>示例使用</em></p>
</blockquote>
<p><em>示例包的使用流程主要包括4个步骤，以下将依次展开介绍，更多说明请见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/index.html" >AI-Benchmark使用说明 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>步骤一：环境部署</strong></em></p>
<p><em>AI-Benchmark示例使用请首先确保已按照 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html" >环境部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节完成开发机和开发板的环境部署。</em></p>
<p><em><strong>步骤二：工程示例编译</strong></em></p>
<p><em>工程示例的编译需要在开发机环境完成，参考命令如下：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开发机环境完成交叉编译</span></span><br><span class="line">cd /open_explorer/ddk/samples/ai_benchmark/code</span><br><span class="line">bash build_ptq_j5.sh</span><br></pre></td></tr></table></figure></div>

<p><em>编译完成后，可执行程序和对应依赖会自动拷贝至 <code>../j5/ptq/script/aarch64</code> 目录下，请将相关示例拷贝至板端，参考命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r ../j5/ptq root@&#123;board_ip&#125;:/userdata</span><br></pre></td></tr></table></figure></div>

<p><em><strong>步骤三：评测数据集准备</strong></em></p>
<blockquote>
<p><em>评测数据集准备在机器学习和人工智能领域的模型评估中起着至关重要的作用。数据集准备工作的目标是准备一个符合要求、有效且可重复使用的数据集，以便用于机器学习模型训练和评估。</em></p>
</blockquote>
<p><em>模型的精度评测需要先在开发机端完成评测数据的预处理， <strong>如果仅执行性能评测可以跳过此步骤</strong> 。 以MobileNet-v1模型为例，ImageNet数据集的预处理命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_eval_preprocess -m mobilenetv1 -i imagenet/val -o ./pre_mobilenetv1</span><br></pre></td></tr></table></figure></div>

<p><em>其中， <code>hb_evel_preprocess</code> 工具封装了地平线示例模型对应的前处理操作，工具常用参数如下， 更多说明请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_eval_preprocess.html" >hb_eval_preprocess 工具 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<table>
<thead>
<tr>
<th align="left"><em>参数</em></th>
<th align="left"><em>说明</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>-m</em></td>
<td align="left"><em>[必选]模型名称，如mobilenetv1，可以通过hb_eval_preprocess -h查看可选项。</em></td>
</tr>
<tr>
<td align="left"><em>-i</em></td>
<td align="left"><em>[必选]原始数据集路径。</em></td>
</tr>
<tr>
<td align="left"><em>-o</em></td>
<td align="left"><em>[可选]预处理后数据集的保存路径。</em></td>
</tr>
<tr>
<td align="left"><em>-h, –help</em></td>
<td align="left"><em>[可选]显示帮助信息。</em></td>
</tr>
</tbody></table>
<p><em>预处理后生成的pre_mobilenetv1文件夹建议以以下目录结构存放：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">|-- nfs</span><br><span class="line">|   |-- data</span><br><span class="line">|   |   |-- imagenet</span><br><span class="line">|   |   |   |-- pre_mobilenetv1</span><br><span class="line">|   |   |   |   |-- xxxx.bin         # 预处理好的二进制文件</span><br></pre></td></tr></table></figure></div>

<p><em>因为评测数据集一般较大，不适合直接存放在开发板上，所以更推荐采用挂载的方式（开发机端需要具备root权限） 提供给开发板读取，参考方式如下：</em></p>
<ul>
<li><p><em><strong>开发机端：</strong></em></p>
<p><em>1.编辑 <code>/etc/exports</code> ，增加一行:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/nfs *(insecure,rw,sync,all_squash,anonuid=1000,anongid=1000,no_subtree_check)</span><br></pre></td></tr></table></figure></div>

<p><em>其中 <code>/nfs</code> 为本机挂载路径，可替换为用户指定目录。</em></p>
<p><em>2.执行命令 <code>exportfs -a -r</code> ，使 <code>/etc/exports</code> 生效。</em></p>
</li>
</ul>
<blockquote>
<ol>
<li><em><code>/nfs</code> 表示将 NFS 共享目录挂载到本地目录 <code>/nfs</code> 下。</em></li>
<li><em><code>*</code> 表示任何机器都可以访问该共享。</em></li>
<li><em><code>insecure</code> 选项用于允许不受信任的客户端挂载共享，这在一些测试或开发场景中非常有用。但在生产环境中，建议不使用该选项。</em></li>
<li><em><code>rw</code> 表示文件系统具有读写权限。</em></li>
<li><em><code>sync</code> 表示文件系统在写入数据时采用同步模式，即每次写入操作都会等待写入完成后再返回成功。</em></li>
<li><em><code>all_squash</code> 表示将所有的 UID 和 GID 映射为匿名用户，这通常用于保护 NFS 服务中的安全性。</em></li>
<li><em><code>anonuid=1000</code> 和 <code>anongid=1000</code> 表示匿名用户的 UID 和 GID 均为 1000。</em></li>
<li><em><code>no_subtree_check</code> 表示该选项禁用自动检查共享的父目录以保证安全性。</em></li>
</ol>
</blockquote>
<ul>
<li><em><strong>开发板端：</strong></em></li>
</ul>
<p><em>1.创建需要挂载的目录，例如： <code>mkdir -p /mnt</code> 。</em></p>
<p><em>2.输入指令完成挂载： <code>mount -t nfs &#123;PC端ip&#125;:/nfs /mnt -o nolock</code> 。其中 <code>/nfs</code> 为本机挂载路径， <code>/mnt</code> 为板端被挂载路径，均可替换为用户指定目录。执行成功后需要再将挂载的预处理数据目录的软连接替换至 <code>/userdata/ptq/data</code> 路径下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 进入到开发板ptq文件夹下</span><br><span class="line">cd /userdata/ptq</span><br><span class="line">rm -rf ./data</span><br><span class="line">ln -s /mnt/data ./data</span><br></pre></td></tr></table></figure></div>

<p><em>最后还需要在板端执行以下命令完成lst文件的生成，lst文件包含了每一个预处理文件的路径。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find /userdata/ptq/data/imagenet/pre_mobilenetv1 -name &quot;*bin&quot; &gt; /userdata/ptq/data/imagenet/pre_mobilenetv1.lst</span><br></pre></td></tr></table></figure></div>

<p><em>以上准备工作完成后的板端目录结构应该如下所示：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230508210604846.png"
                      class="" title="image-20230508210604846"
                ></em></p>
<blockquote>
<p><em>mkdir -p file</em></p>
<p><em><strong>上述命令的<code>-p</code> 参数用于创建指定目录的所有父目录，即使这些目录不存在。</strong></em></p>
<p><em>例如，如果要在 <code>/home/chatgpt/test/folder</code> 目录下创建一个新目录 <code>new_folder</code>，可以使用以下命令：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/chatgpt/test/folder/new_folder</span><br></pre></td></tr></table></figure></div>

<p><em>在这个例子中，如果 <code>/home/chatgpt</code> 目录下的 <code>test</code> 和 <code>folder</code> 目录不存在，<code>mkdir -p</code> 命令将会同时创建这两个目录。如果 <code>-p</code> 选项没有使用，那么如果 <code>test</code> 和 <code>folder</code> 目录没有一个存在，将会创建 <code>folder</code> 目录的失败，因为缺少其父目录。</em></p>
</blockquote>
<blockquote>
<p><em><strong>NFSv3 的锁定机制是一种用于确保共享文件系统同步的机制，它主要用于防止多个使用者同时对同一文件进行更改。</strong></em></p>
<p><em>NFSv3 锁定机制的优点是可以确保共享文件系统的同步性和一致性。无论是在局域网内还是在广域网上，多个客户端访问同一共享的文件系统时，都可以使用该锁定机制来避免冲突和数据破坏。</em></p>
<p><em>然而，NFSv3 锁定机制也存在一些缺点，例如性能下降、死锁和容错性的问题。因此，最好在使用 NFSv3 锁定机制时，谨慎配置选项，以确保实现最佳性能和可靠性。</em></p>
<p><em><strong><code>-o nolock</code> 表示在挂载共享目录时不使用 NFSv3 的锁定机制。这个选项可能对性能有积极的影响，但也可能会使共享目录容易出现文件冲突等问题。如果不是必需的，建议不使用该选项。</strong></em></p>
</blockquote>
<blockquote>
<p><em><code>rm -rf ./data</code> 删除当前目录下的 <code>data</code> 目录，其中 <code>-rf</code> 选项表示强制删除目录及其子目录，如果有必要的话，还将忽略所有提示和警告。</em></p>
<p><em><code>ln -s /mnt/data ./data</code> 创建了一个名为 <code>data</code> 的软链接，将其链接到 <code>/mnt/data</code> 目录。这意味着任何使用 <code>data</code> 目录的操作实际上都将在 <code>/mnt/data</code> 中执行。</em></p>
</blockquote>
<blockquote>
<ol>
<li><em><code>find /userdata/ptq/data/imagenet/pre_mobilenetv1</code>：用于搜索 <code>/userdata/ptq/data/imagenet/pre_mobilenetv1</code> 目录下的文件和子目录。<code>find</code> 命令是在 Linux 中用于搜索文件和目录的命令，它可以使用各种选项和条件，过滤文件和目录。</em></li>
<li><em><code>-name &quot;*bin&quot;</code>：表示查找文件名以 <code>.bin</code> 结尾的所有文件。</em><em><code>-name</code> 是 <code>find</code> 命令的一个选项，用于根据文件名模式匹配搜索结果。</em>**</li>
<li><em><code>&gt; /userdata/ptq/data/imagenet/pre_mobilenetv1.lst</code>：将前面找到的<strong>所有文件的路径和名称</strong>输出到 <code>userdata/ptq/data/imagenet/pre_mobilenetv1.lst</code> 文件中。*</em><code>&gt;</code> 是输出重定向操作符*<em>，用于将输出写入到指定的文件中。如果指定的文件不存在，则会自动创建该文件，如果该文件已经存在，则会覆盖原有内容。</em></li>
</ol>
<p><em>通过上述命令，可以将指定目录下所有以 <code>.bin</code> 结尾的文件的路径名称存储到 <code>pre_mobilenetv1.lst</code> 文件中。这个操作通常用于管理大量的图片数据，便于使用其他数据处理工具对这些文件进行处理。</em></p>
</blockquote>
<p><em><strong>步骤四：性能&#x2F;精度评测</strong></em></p>
<p><em>以MobileNet-v1模型为例，其性能评测的执行命令参考如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /userdata/ptq/script/classification/mobilenetv1</span><br><span class="line">bash fps.sh        # 评测帧率</span><br><span class="line">bash latency.sh    # 评测耗时</span><br></pre></td></tr></table></figure></div>

<p><em>精度评测的执行命令参考如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash accuracy.sh</span><br></pre></td></tr></table></figure></div>

<p><em>脚本执行完成后，会在当前路径生成模型预测结果文件 <code>eval.log</code> 。请将该日志文件拷贝回开发机端OE包任意位置， 并执行以下脚本，即可得到MobileNet-v1模型的量化精度：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python3 /open_explorer/ddk/samples/ai_benchmark/j5/ptq/tools/python_tools/accuracy_tools/cls_eval.py \</span><br><span class="line">  --log_file ./eval.log \</span><br><span class="line">  --gt_file /data/horizon_j5/data/imagenet/val.txt</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>代码结构</em></p>
</blockquote>
<p><em>以精度评测脚本为例，其可执行程序源码的main函数定义在 <code>code/src/simple_example.cc</code> ，并由 <code>workflow_accuracy.json</code> 文件传入相关参数。</em></p>
<p><em>simple_example.cc的主要代码如下：</em></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;plugin/input_plugin.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;plugin/output_plugin.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;plugin/workflow_plugin.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;rapidjson/document.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;rapidjson/istreamwrapper.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;rapidjson/writer.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EMPTY <span class="string">&quot;&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Parsing command line arguments; Init logging</span></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Parsing config</span></span><br><span class="line">  <span class="function">std::ifstream <span class="title">ifs</span><span class="params">(FLAGS_config_file)</span></span>;</span><br><span class="line">  <span class="function">rapidjson::IStreamWrapper <span class="title">isw</span><span class="params">(ifs)</span></span>;</span><br><span class="line">  rapidjson::Document document;</span><br><span class="line">  document.<span class="built_in">ParseStream</span>(isw);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Input plugin</span></span><br><span class="line">  <span class="keyword">auto</span> input_plg = InputProducerPlugin::<span class="built_in">GetInstance</span>();</span><br><span class="line">  <span class="type">int</span> ret_code =</span><br><span class="line">      input_plg-&gt;<span class="built_in">Init</span>(EMPTY, <span class="built_in">json_to_string</span>(document[<span class="string">&quot;input_config&quot;</span>]));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Workflow plugin</span></span><br><span class="line">  <span class="keyword">auto</span> workflow_plg = WorkflowPlugin::<span class="built_in">GetInstance</span>();</span><br><span class="line">  ret_code = workflow_plg-&gt;<span class="built_in">Init</span>(EMPTY, <span class="built_in">json_to_string</span>(document));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Output plugin</span></span><br><span class="line">  <span class="keyword">auto</span> output_plg = OutputConsumerPlugin::<span class="built_in">GetInstance</span>();</span><br><span class="line">  ret_code = output_plg-&gt;<span class="built_in">Init</span>(EMPTY,</span><br><span class="line">                              <span class="built_in">json_to_string</span>(document[<span class="string">&quot;output_config&quot;</span>]));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Start</span></span><br><span class="line">  ret_code = input_plg-&gt;<span class="built_in">Start</span>();</span><br><span class="line">  ret_code = workflow_plg-&gt;<span class="built_in">Start</span>();</span><br><span class="line">  ret_code = output_plg-&gt;<span class="built_in">Start</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!input_plg-&gt;<span class="built_in">IsRunning</span>()) &#123;    <span class="comment">// finish</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Stop</span></span><br><span class="line">  input_plg-&gt;<span class="built_in">Stop</span>();</span><br><span class="line">  workflow_plg-&gt;<span class="built_in">Stop</span>();</span><br><span class="line">  output_plg-&gt;<span class="built_in">Stop</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>其中， <code>ai_benchmark/code/src/plugin</code> 路径下包含了input_plg、workflow_plg、output_plg三个线程实例的类定义， 其主要作用分别是：</em></p>
<ul>
<li><em><strong>input_plg</strong>：用于迭代模型的输入数据。</em></li>
<li><em><strong>workflow_plg</strong>：用于实现模型的前向推理和后处理。各个模型的后处理实现和统一的模型前向实现都定义在 <code>code/src/method</code> 路径下。</em></li>
<li><em><strong>output_plg</strong>：用于模型推理时的性能指标统计和打印，帧id的顺序保持，精度评测时的 <code>eval.log</code> 日志生成等。</em></li>
</ul>
<blockquote>
<p><em>应用开发</em></p>
</blockquote>
<p><em>当模型的性能和精度验证都符合预期后，即可参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html" >嵌入式应用开发指导 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节实现上层应用的具体开发。</em> </p>
<h3 id="浮点模型转定点模型手册"><a href="#浮点模型转定点模型手册" class="headerlink" title="浮点模型转定点模型手册"></a><em>浮点模型转定点模型手册</em></h3><p><em>地平线提供了两种浮点模型转定点模型的方法，分别为PTQ模型量化手段和QAT模型量化手段， 本章内容包括 <strong>训练后量化（PTQ）</strong> 和 <strong>量化感知训练（QAT）</strong></em></p>
<h4 id="训练后量化（PTQ）"><a href="#训练后量化（PTQ）" class="headerlink" title="训练后量化（PTQ）"></a><em>训练后量化（PTQ）</em></h4><h5 id="PTQ原理及步骤"><a href="#PTQ原理及步骤" class="headerlink" title="PTQ原理及步骤"></a><em>PTQ原理及步骤</em></h5><p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509081114868.png"
                      class="" title="image-20230509081114868"
                ></em></p>
<p><em><strong>环境部署：</strong>用于构建模型转换和应用开发的依赖环境，这个动作只需要在您第一次工具链时做一遍即可。 具体部署方式请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html" >环境部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>模型训练：</strong>，指使用TensorFlow、PyTorch、Caffe等公开深度学习框架得到可用模型的过程，通过训练得到的可用模型将作为模型转换阶段的输入。 工具链本身不会提供训练相关的库或工具，具体支持的公开学习框架可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/model_prepare.html" >浮点模型准备 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中的说明。</em></p>
<p><em><strong>模型转换：</strong>本阶段以模型训练得到的浮点模型为输入，通过模型结构优化、模型校准量化等重要步骤， 将浮点模型转换为可以在地平线芯片平台高效运行的混合异构模型。 为了验证异构模型的可用性，工具链还提供了性能分析、精度分析和丰富的异常调试工具与建议。 具体使用请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html" >模型量化和编译 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 、 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html" >模型性能分析与调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 、 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html" >模型精度分析与调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中的说明。</em></p>
<p><em><strong>算子开发：</strong>本阶段是一个可选阶段，主要是解决模型存在工具链不支持算子的情况，如果您没有此种情况，可以直接忽略本阶段的处理。 具体使用方式请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/custom_op.html" >自定义算子开发 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中的说明。</em></p>
<blockquote>
<p><em>“模型存在工具链不支持算子的情况” 意味着在使用某个特定的模型工具链（例如深度学习框架或推理引擎）时，可能会遇到无法支持模型中的某些算子（操作）的情况。</em></p>
<p><em>在深度学习中，模型通常由多个算子组成，每个算子执行特定的操作，如卷积、池化、激活函数等。这些算子在不同的模型工具链中可能具有不同的实现方式和支持情况。</em></p>
<p><em>当模型中包含一些特定的算子，而所选的模型工具链不支持这些算子时，就会出现工具链不支持算子的情况。这可能是由于工具链版本过低、算子在该工具链中尚未实现或优化，或者工具链本身不支持特定类型的算子。</em></p>
<p><em>在这种情况下，通常会有几种处理方式：</em></p>
<ol>
<li><em>升级工具链：尝试升级所使用的模型工具链到更高版本，以获得对更多算子的支持。新版本的工具链通常会引入新的功能和算子支持。</em></li>
<li><em>算子替换：尝试使用工具链中提供的其他算子或算子的替代方式来重新设计模型，以避免使用不受支持的算子。</em></li>
<li><em>自定义实现：在工具链中添加自定义的算子实现，以使其能够支持模型中的特定算子。这通常需要深入了解工具链的扩展机制和编程接口。</em></li>
<li><em>切换工具链：如果当前工具链无法满足模型的需求，可以考虑使用其他支持所需算子的模型工具链或推理引擎。</em></li>
</ol>
<p><em>总之，当模型中的某些算子无法在特定的模型工具链中得到支持时，需要考虑升级工具链、替换算子、自定义实现或切换工具链等方式来解决这个问题。</em></p>
</blockquote>
<p><em><strong>嵌入式应用开发：</strong>工具链支持了在X86仿真环境和真实嵌入式环境的应用开发能力，在不方便使用开发板的情况下， 您在仿真环境完成程序的调试和计算结果的验证。 为了降低仿真验证的代价，工具链提供的仿真库接口与嵌入式接口完全一致，只是采用了不同的编译配置。 具体使用方式请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html" >嵌入式应用开发指导 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中的说明。</em></p>
<blockquote>
<p><em><strong>PTQ转换的流程与步骤</strong></em></p>
</blockquote>
<p><em>模型转换是指将原始浮点模型转换为地平线混合异构模型的过程。</em></p>
<p><em>原始浮点模型（文中部分地方也称为浮点模型）是指您通过TensorFlow&#x2F;PyTorch等等DL框架训练得到的可用模型，这个模型的计算精度为float32；混合异构模型是一种适合在地平线芯片上运行的模型格式。</em></p>
<p><em>本章节将反复使用到这两种模型名词，为避免理解歧义，请先理解这个概念再阅读下文。</em></p>
<p><em>配合地平线工具链的模型完整开发过程，需要经过 <strong>浮点模型准备</strong> 、 <strong>模型检查</strong> 、 <strong>模型转换</strong> 、 <strong>性能评估</strong> 和 <strong>精度评估</strong> 共五个重要阶段，如下图所示。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509082134522.png"
                      class="" title="image-20230509082134522"
                ></em></p>
<p><em><strong>浮点模型准备</strong> 阶段的产出是输入到模型转换工具的浮点模型， 这些模型一般都是基于公开DL训练框架得到的， 需要您注意的是将模型导出为地平线工具支持的格式。 具体要求与建议请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/model_prepare.html" >浮点模型准备 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>模型检查</strong> 阶段用来确保算法模型是符合芯片要求的。 地平线提供了指定工具完成此阶段检查，对于不符合要求的情况， 检查工具会明确给出不符合要求的具体算子信息，方便您结合算子约束的说明将模型调整过来。 具体使用请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html" >验证模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>模型转换</strong> 阶段将完成浮点模型到地平线混合异构模型的转换。 为了模型能在地平线芯片上高效运行，地平线转换工具内部会完成模型优化、量化和编译等关键步骤， 地平线的量化方法经过了长期的技术与生产验证，在大部分典型模型上可以保证精度损失小于1%。 具体使用请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/prepare_calibration_data.html" >校准数据准备 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 及 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html" >模型量化与编译 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>性能评估</strong> 阶段提供了系列评估模型性能的工具。 在应用部署前，您可以使用这些工具验证模型性能是否达到应用要求。 对于部分性能不及预期的情况，也可以参考地平线提供的性能优化建议进行调优。 具体评估请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html" >模型性能分析与调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em><strong>精度评估</strong> 阶段提供了系列评估模型精度的工具。 大部分情况下，地平线转换后模型可以保持与原始浮点模型基本一致的精度效果， 在应用部署前，您可以使用地平线工具验证模型的精度是否符合预期。 对于部分精度不及预期的情况，也可以参考地平线提供的性能优化建议进行调优。 具体评估请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html" >模型精度分析与调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em>注意：</em></p>
<ul>
<li><em>通常在模型转换后就已经得到了可以上板的模型， 但是为了确保您得到的模型性能和精度都是符合应用要求的， 地平线强烈建议每次转换后都完成后续的性能评估与精度评估步骤。</em></li>
<li><em>模型转换过程会生成onnx模型，该模型均为中间产物，只是便于用户验证模型精度情况， 因此不保证其在版本间的兼容性。若使用示例中的评测脚本对onnx模型单张或在测试集上进行评测时， 请使用当前版本工具生成的onnx模型进行操作。</em></li>
</ul>
<blockquote>
<p><em>算子约束</em></p>
</blockquote>
<p><em>为了确保模型能顺利在地平线平台高效运行，模型中所使用的算子需要符合平台的算子约束。 因此，为方便您了解当前版本支持的算子信息及对应约束条件，您可以在进行浮点模型准备前， 先参照 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/supported_op_list.html" >模型转换工具链算子支持约束列表 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中内容进行查询。</em></p>
<blockquote>
<p><em>浮点模型准备</em></p>
</blockquote>
<p><em>在您阅读本节内容前，我们建议您先阅读我们的算子支持列表，对地平线支持的算子及约束条件进行了解， 或在您导出ONNX模型后，可以先参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html" >验证模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节的内容， 验证模型是否能被地平线支持完成正常转换部署。</em></p>
<p><em>基于公开DL框架训练得到的浮点模型是转换工具的输入，目前转换工具支持的DL框架如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509082954384.png"
                      class="" title="image-20230509082954384"
                ></em></p>
<p><em>以上框架中，Caffe导出的caffemodel是直接支持的； PyTorch、TensorFlow和MXNet是通过转到ONNX实现间接支持， ONNX目前主要支持的opset版本是opset10和opset11。</em></p>
<p><em>对于不同框架到ONNX的转换，目前都有对应的标准化方案，参考如下：</em></p>
<ul>
<li><p><em>🔗 Pytorch2Onnx：PytTorch官方API支持直接将模型导出为ONNX模型，参考链接：</em></p>
<p><em><a class="link"   target="_blank" rel="noopener" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html%E3%80%82" >https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></p>
</li>
<li><p><em>🔗 Tensorflow2Onnx：基于ONNX社区的onnx&#x2F;tensorflow-onnx 进行转换，参考链接：</em></p>
<p><em><a class="link"   target="_blank" rel="noopener" href="https://github.com/onnx/tensorflow-onnx%E3%80%82" >https://github.com/onnx/tensorflow-onnx。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></p>
</li>
<li><p><em>🔗 MXNet2Onnx：MXNet官方API支持直接将模型导出为ONNX模型，参考链接：</em></p>
<p><em><a class="link"   target="_blank" rel="noopener" href="https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxConversionTest.cs%E3%80%82" >https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Tests/OnnxConversionTest.cs。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></p>
</li>
<li><p><em>🔗 更多框架的ONNX转换支持，参考链接：</em></p>
<p><em><a class="link"   target="_blank" rel="noopener" href="https://github.com/onnx/tutorials#converting-to-onnx-format%E3%80%82" >https://github.com/onnx/tutorials#converting-to-onnx-format。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></p>
</li>
</ul>
<p><em><strong>注意：原始模型限制：ir_version≤7, opset&#x3D;10或11，ir_version与onnx版本的对应关系请参考 <a class="link"   target="_blank" rel="noopener" href="https://github.com/onnx/onnx/blob/main/docs/Versioning.md" >onnx官方文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</strong></em></p>
<blockquote>
<p><em>“Opset” 是指操作集版本（Operation Set Version），在深度学习框架中用于描述和标识支持的操作集合和对应版本。</em></p>
<p><em>深度学习框架通常支持一系列操作（算子），例如卷积、池化、激活函数等。这些操作可以按照不同的版本进行组织和定义。每个操作集版本都定义了一组操作及其规范，以确保在该版本下的模型可以正确执行和运行。</em></p>
<p><em><strong>Opset 的版本号通常与深度学习框架的版本号相关联。每个框架版本会引入新的操作或对已有操作进行修改、优化或修复，因此对应的操作集版本也会相应更新。</strong></em></p>
<p><em>在使用深度学习模型时，需要确保所选框架版本支持模型中使用的操作。这就需要检查模型的操作集版本和所选框架的操作集版本是否兼容。如果模型中使用了不受所选框架支持的操作，就可能会遇到不兼容或无法正确运行的问题。</em></p>
<p><em>因此，在导入或加载模型时，需要确保所选框架的操作集版本与模型中使用的操作集版本匹配。这通常涉及到对模型进行转换或更新以适应所选框架的操作集版本。</em></p>
</blockquote>
<blockquote>
<p><em>验证模型</em></p>
</blockquote>
<p><em>为了确保模型能顺利在地平线平台高效运行，模型中所使用的算子需要符合平台的算子约束。 算子约束部分给出了我们支持的具体算子，每个算子都给出了具体的参数限制， 具体详细信息请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/supported_op_list.html" >模型转换工具链算子支持约束列表 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节的内容。 考虑到地平线支持的算子较多，为了避免人工逐条校对的麻烦， 我们提供了 <code>hb_mapper checker</code> 工具用于验证模型所使用算子的支持情况。</em></p>
<p><em><strong>使用hb_mapperchecker工具验证模型</strong></em></p>
<p><em>hb_mapper checker 工具的使用方式如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper checker --model-type $&#123;model_type&#125; \</span><br><span class="line">                  --march $&#123;march&#125; \</span><br><span class="line">                  --proto $&#123;proto&#125; \</span><br><span class="line">                  --model $&#123;caffe_model/onnx_model&#125; \</span><br><span class="line">                  --input-shape $&#123;input_node&#125; $&#123;input_shape&#125; \</span><br><span class="line">                  --output $&#123;output&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>hb_mapper checker 参数解释：</em></p>
<ul>
<li><p><em>–model-type</em></p>
<p><em>用于指定检查输入的模型类型，目前只支持设置 <code>caffe</code> 或者 <code>onnx</code>。</em></p>
</li>
<li><p><em>–march</em></p>
<p><em>用于指定需要适配的芯片类型，可设置值为 <code>bernoulli2</code> 和 <code>bayes</code>， 分别对应X3&amp;J3和J5芯片，根据您需要适配的平台选择即可。</em></p>
</li>
<li><p><em>–proto</em></p>
<p><em>此参数仅在 <code>model-type</code> 指定 <code>caffe</code> 时有效，取值为Caffe模型的prototxt文件名称。</em></p>
</li>
<li><p><em>–model</em></p>
<p><em>在 <code>model-type</code> 被指定为 <code>caffe</code> 时，取值为Caffe模型的caffemodel文件名称。 在 <code>model-type</code> 被指定为 <code>onnx</code> 时，取值为ONNX模型文件名称。</em></p>
</li>
<li><p><em>–input-shape</em></p>
<p><em>可选参数，明确指定模型的输入shape。 取值为 <code>&#123;input_name&#125; &#123;NxHxWxC/NxCxHxW&#125;</code> ，<code>input_name</code> 与shape之间以空格分隔。 例如模型输入名称为 <code>data1</code>，输入shape为 <code>[1,224,224,3]</code>， 则配置应该为 <code>--input-shape data1 1x224x224x3</code>。 如果此处配置shape与模型内shape信息不一致，以此处配置为准。</em></p>
</li>
</ul>
<p><em><strong>注意：</strong></em></p>
<ul>
<li><em><strong>一个 <code>--input-shape</code> 只接受一个name和shape组合，如果您的模型有多个输入节点， 在命令中多次配置 <code>--input-shape</code> 参数即可。</strong></em></li>
<li><em><strong>–output参数已经废弃，log信息默认存储于 <code>hb_mapper_checker.log</code> 中。</strong></em></li>
</ul>
<p><em><strong>检查异常处理</strong></em></p>
<p><em>如果模型检查不通过， <code>hb_mapper checker</code> 工具会报出ERROR。 在当前工作目录下会生成 <code>hb_mapper_checker_&#123;date_time&#125;.log</code> 文件，从文件中可以查看到具体的报错。 例如以下配置中含不可识别算子类型 <code>Accuracy</code>：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;data&quot;</span><br><span class="line">  type: &quot;Input&quot;</span><br><span class="line">  top: &quot;data&quot;</span><br><span class="line">  input_param &#123; shape: &#123; dim: 1 dim: 3 dim: 224 dim: 224 &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;Convolution1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;Convolution1&quot;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 128</span><br><span class="line">    bias_term: false</span><br><span class="line">    pad: 0</span><br><span class="line">    kernel_size: 1</span><br><span class="line">    group: 1</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;msra&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: &quot;accuracy&quot;</span><br><span class="line">  type: &quot;Accuracy&quot;</span><br><span class="line">  bottom: &quot;Convolution3&quot;</span><br><span class="line">  top: &quot;accuracy&quot;</span><br><span class="line">  include &#123;</span><br><span class="line">    phase: TEST</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>使用 <code>hb_mapper checker</code> 检查这个模型，您会在 <code>hb_mapper_checker_&#123;date_time&#125;.log</code> 中得到如下信息：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ValueError: Not support layer name=accuracy type=Accuracy</span><br></pre></td></tr></table></figure></div>

<p><em><strong>检查结果解读</strong></em></p>
<p><em>如果不存在ERROR，则顺利通过校验。 <code>hb_mapper checker</code> 工具将直接输出如下信息：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">==============================================</span><br><span class="line">Node         ON   Subgraph  Type</span><br><span class="line">----------------------------------------------</span><br><span class="line">conv1        BPU  id(0)     HzSQuantizedConv</span><br><span class="line">conv2_1/dw   BPU  id(0)     HzSQuantizedConv</span><br><span class="line">conv2_1/sep  BPU  id(0)     HzSQuantizedConv</span><br><span class="line">conv2_2/dw   BPU  id(0)     HzSQuantizedConv</span><br><span class="line">conv2_2/sep  BPU  id(0)     HzSQuantizedConv</span><br><span class="line">conv3_1/dw   BPU  id(0)     HzSQuantizedConv</span><br><span class="line">conv3_1/sep  BPU  id(0)     HzSQuantizedConv</span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>

<p><em>结果中每行都代表一个模型节点的check情况，每行含Node、ON、Subgraph和Type四列， 分别为节点名称、执行节点计算的硬件、节点所属子图和节点映射到的地平线内部实现名称。 <strong>如果模型在非输入和输出部分出现了CPU计算的算子，工具将把这个算子前后连续在BPU计算的部分拆分为两个Subgraph（子图）。</strong></em></p>
<p><em><strong>检查结果的调优指导</strong></em></p>
<p><em>在最理想的情况下，非输入和输出部分都应该在BPU上运行，也就是只有一个子图。 如果出现了CPU算子导致拆分多个子图， <code>hb_mapper checker</code> 工具会给出导致CPU算子出现的具体原因。 例如以下ONNX模型的出现了Mul + Add + Mul的结构，从算子约束列表中我们可以看到，Mul和Add算子在五维上支持BPU运行有约束条件。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509085125392.png"
                      class="" title="image-20230509085125392"
                ></em></p>
<p><em>因此模型最终检查结果也会出现分段情况，如下:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">====================================================================================</span><br><span class="line">Node                                    ON   Subgraph  Type</span><br><span class="line">-------------------------------------------------------------------------------------</span><br><span class="line">Reshape_199                             BPU  id(0)     Reshape</span><br><span class="line">Transpose_200                           BPU  id(0)     Transpose</span><br><span class="line">Sigmoid_201                             BPU  id(0)     HzLut</span><br><span class="line">Split_202                               BPU  id(0)     Split</span><br><span class="line">Mul_204                                 CPU  --        Mul</span><br><span class="line">Add_206                                 CPU  --        Add</span><br><span class="line">Mul_208                                 CPU  --        Mul</span><br><span class="line">Mul_210                                 CPU  --        Mul</span><br><span class="line">Pow_211                                 BPU  id(1)     HzLut</span><br><span class="line">Mul_213                                 CPU  --        Mul</span><br><span class="line">Concat_214                              CPU  --        Concat</span><br><span class="line">Reshape_215                             CPU  --        Reshape</span><br><span class="line">Conv_216                                BPU  id(0)     HzSQuantizedConv</span><br><span class="line">Reshape_217                             BPU  id(0)     Reshape</span><br><span class="line">Transpose_218                           BPU  id(0)     Transpose</span><br><span class="line">Sigmoid_219                             BPU  id(0)     HzLut</span><br><span class="line">Split_220                               BPU  id(0)     Split</span><br><span class="line">Mul_222                                 CPU  --        Mul</span><br><span class="line">Add_224                                 CPU  --        Add</span><br><span class="line">Mul_226                                 CPU  --        Mul</span><br><span class="line">Mul_228                                 CPU  --        Mul</span><br><span class="line">Pow_229                                 BPU  id(2)     HzLut</span><br><span class="line">Mul_231                                 CPU  --        Mul</span><br><span class="line">Concat_232                              CPU  --        Concat</span><br><span class="line">Reshape_233                             CPU  --        Reshape</span><br><span class="line">Conv_234                                BPU  id(0)     HzSQuantizedConv</span><br><span class="line">Reshape_235                             BPU  id(0)     Reshape</span><br><span class="line">Transpose_236                           BPU  id(0)     Transpose</span><br><span class="line">Sigmoid_237                             BPU  id(0)     HzLut</span><br><span class="line">Split_238                               BPU  id(0)     Split</span><br><span class="line">Mul_240                                 CPU  --        Mul</span><br><span class="line">Add_242                                 CPU  --        Add</span><br><span class="line">Mul_244                                 CPU  --        Mul</span><br><span class="line">Mul_246                                 CPU  --        Mul</span><br><span class="line">Pow_247                                 BPU  id(3)     HzLut</span><br><span class="line">Mul_249                                 CPU  --        Mul</span><br><span class="line">Concat_250                              CPU  --        Concat</span><br><span class="line">Reshape_251                             CPU  --        Reshape</span><br><span class="line">Concat_252                              CPU  --        Concat</span><br></pre></td></tr></table></figure></div>

<p><em>根据 hb_mapper checker 给出的提示，一般来说算子运行在BPU上会有更好的性能表现。 <strong>当然，多个子图也不会影响整个转换流程，但会较大程度地影响模型性能，建议尽量调整至全BPU执行。</strong></em></p>
<blockquote>
<p><em>一个模型可以由多个子图组成，每个子图代表了一组相关操作的计算图。而在这种情况下，工具将根据连续的CPU计算算子将原本应该在BPU（边缘处理单元）进行计算的部分拆分为两个子图。</em></p>
<p><em>这样做的目的可能是为了在模型部署和执行过程中进行优化。边缘处理单元（BPU）通常是专门用于执行深度学习计算的硬件加速器，而CPU则是通用的处理单元。通过将连续的CPU计算部分拆分为两个子图，可以将这些部分分别交给适当的处理单元来执行，以获得更好的性能和效率。</em></p>
</blockquote>
<blockquote>
<p><em>这意味着在理想情况下，整个模型应该在BPU上进行计算，以充分利用硬件加速器的性能。然而，如果模型中存在CPU算子，这可能导致无法将整个计算过程放在BPU上执行，而需要将部分计算拆分为多个子图。</em></p>
<p><em>hb_mapper checker 工具可以帮助分析模型中CPU算子出现的原因。它可以提供有关CPU算子限制和约束的信息，以帮助理解为什么需要将计算拆分为多个子图。</em></p>
<p><em>举例来说，如果模型中存在 Mul + Add + Mul 的结构，而在算子约束列表中我们可以看到 Mul 和 Add 算子在五维上支持BPU运行有约束条件，那么这可能是导致拆分子图的原因。这意味着在这个特定的模型结构中，<strong>Mul 和 Add 算子在某些维度上无法在BPU上运行，从而导致了多个子图的出现。</strong></em></p>
<p><em>通过分析 hb_mapper checker 工具提供的信息，可以了解CPU算子出现的具体原因，并尝试优化模型或调整算子的使用方式，以达到在BPU上最大化运行模型的目标。</em></p>
</blockquote>
<blockquote>
<p><em>校准数据准备</em></p>
</blockquote>
<p><em><strong>注意：如果本过程，您需在示例文件夹内进行，那么您需要先执行文件夹中的 <code>00_init.sh</code> 脚本以获取对应的原始模型和数据集。</strong></em></p>
<p><em>在进行模型转换时，校准阶段会需要20~100份的标定样本输入，每一份样本都是一个独立的数据文件。 为了确保转换后模型的精度效果，我们希望这些校准样本来自于您训练模型使用的训练集或验证集， 不要使用非常少见的异常样本，例如纯色图片、不含任何检测或分类目标的图片等。</em></p>
<p><em>转换配置文件中的 <code>preprocess_on</code> 参数，该参数启用和关闭状态下分别对应了两种不同的预处理样本要求。 (有关参数的详细配置可参考后文校准参数组中相关说明)</em></p>
<p><em><strong><code>preprocess_on</code> 关闭状态下，您需要把取自训练集&#x2F;验证集的样本做与inference前一样的前处理</strong>， 处理完后的校准样本会与原始模型具备一样的数据类型( <code>input_type_train</code> )、尺寸( <code>input_shape</code> )和 layout( <code>input_layout_train</code> )，对于featuremap输入的模型，您可以通过 <code>numpy.tofile</code> 命令将数据保存为float32格式的二进制文件， 工具链校准时会基于 <code>numpy.fromfile</code> 命令进行读取。 例如，有一个使用ImageNet训练的用于分类的原始浮点模型，它只有一个输入节点，输入信息描述如下：</em></p>
<ul>
<li><em>输入类型：<code>BGR</code>。</em></li>
<li><em>输入layout：<code>NCHW</code>。</em></li>
<li><em>输入尺寸：<code>1x3x224x224</code>。</em></li>
</ul>
<p><em>使用验证集做Inference时的数据预处理步骤如下：</em></p>
<ol>
<li><em>图像长宽等比scale，短边缩放到256。</em></li>
<li><em><code>center_crop</code> 方法获取224x224大小图像。</em></li>
<li><em>按通道减mean。</em></li>
<li><em>数据乘以scale系数。</em></li>
</ol>
<blockquote>
<p><em>特征图是指在卷积神经网络（CNN）中经过卷积层或其他层处理后得到的输出。它是一个三维的张量，具有高度、宽度和通道数三个维度。每个通道代表了一种特定的特征在图像中的表示。</em></p>
<p><em>这种设计方式的优点是可以利用先前层次的特征提取和处理结果，使得模型能够更加高效地学习和表示图像中的特征。通过使用特征图作为输入，模型可以更好地捕捉到图像的局部信息和抽象特征，从而提高模型的性能和泛化能力。</em></p>
</blockquote>
<p><em>依照 <code>preprocess_on</code> 关闭状态下的样本文件制作原则，针对上述举例模型的样本处理代码如下 (为避免过长代码篇幅，各种简单transformer实现代码未贴出，transformer使用方法可参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_appendix/transformer.html" >图片处理transformer说明 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本示例使用skimage，如果是opencv会有所区别</span></span><br><span class="line"><span class="comment"># 需要您特别注意的是，transformers中并没有体现减mean和乘scale的处理</span></span><br><span class="line"><span class="comment"># mean和scale操作已经融合到了模型中，参考前文norm_type/mean_values/scale_values配置</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_transformer</span>():</span><br><span class="line">  transformers = [</span><br><span class="line">  <span class="comment"># 长宽等比scale，短边缩放至256</span></span><br><span class="line">  ShortSideResizeTransformer(short_size=<span class="number">256</span>),</span><br><span class="line">  <span class="comment"># CenterCrop获取224x224图像</span></span><br><span class="line">  CenterCropTransformer(crop_size=<span class="number">224</span>),</span><br><span class="line">  <span class="comment"># skimage读取结果为NHWC排布，转换为模型需要的NCHW</span></span><br><span class="line">  HWC2CHWTransformer(),</span><br><span class="line">  <span class="comment"># skimage读取结果通道顺序为RGB，转换为模型需要的BGR</span></span><br><span class="line">  RGB2BGRTransformer(),</span><br><span class="line">  <span class="comment"># skimage读取数值范围为[0.0,1.0]，调整为模型需要的数值范围</span></span><br><span class="line">  ScaleTransformer(scale_value=<span class="number">255</span>)</span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> transformers</span><br><span class="line"></span><br><span class="line"><span class="comment"># src_image 标定集中的原图片</span></span><br><span class="line"><span class="comment"># dst_file 存放最终标定样本数据的文件名称</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_image</span>(<span class="params">src_image, dst_file, transformers</span>):</span><br><span class="line">  image = skimage.img_as_float(skimage.io.imread(src_file))</span><br><span class="line">  <span class="keyword">for</span> trans <span class="keyword">in</span> transformers:</span><br><span class="line">      image = trans(image)</span><br><span class="line">  <span class="comment"># 模型指定的input_type_train BGR数值类型是UINT8</span></span><br><span class="line">  image = image.astype(np.uint8)</span><br><span class="line">  <span class="comment"># 二进制存储标定样本到数据文件</span></span><br><span class="line">  image.tofile(dst_file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  <span class="comment"># 此处表示原始标定图片集合，伪代码</span></span><br><span class="line">  src_images = [<span class="string">&#x27;ILSVRC2012_val_00000001.JPEG&#x27;</span>, ...]</span><br><span class="line">  <span class="comment"># 此处表示最终标定文件名称（后缀名不限制），伪代码</span></span><br><span class="line">  <span class="comment"># calibration_data_bgr_f32是您在配置文件中指定的cal_data_dir</span></span><br><span class="line">  dst_files = [<span class="string">&#x27;./calibration_data_bgr_f32/ILSVRC2012_val_00000001.bgr&#x27;</span>, ...]</span><br><span class="line"></span><br><span class="line">  transformers = data_transformer()</span><br><span class="line">  <span class="keyword">for</span> src_image, dst_file <span class="keyword">in</span> <span class="built_in">zip</span>(src_images, dst_files):</span><br><span class="line">      convert_image(src_image, dst_file, transformers)</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：</strong></em></p>
<ul>
<li><p><em><strong><code>preprocess_on</code> 启用状态下，标定样本使用skimage支持读取图片格式的文件即可。 转换工具读取这些图片后，会将其缩放到模型输入节点要求的尺寸大小，以此结果作为校准的输入。 这样的操作会简单，但是对于量化的精度没有保障，因此我们强烈建议您使用关闭 <code>preprocess_on</code> 的方式。</strong></em></p>
</li>
<li><p><em>请注意，yaml文件中input_shape参数作用为指定原始浮点模型的输入数据尺寸。若为动态输入模型则可通过这个参数设置转换后的输入大小，而校准数据的shape大小应与input_shape保持一致。</em></p>
<p><em>例如：若原始浮点模型输入节点shape为?x3x224x224（“?”号代表占位符，即该模型第一维为动态输入）, 转换配置文件中设置input_shape: 8x3x224x224，则用户需要准备的每份校准数据大小为 8x3x224x224。 （<strong>请知悉，此类输入shape第一维不等于1的模型，不支持通过input_batch参数修改模型batch信息</strong>。）</em></p>
</li>
</ul>
<blockquote>
<p><em>模型量化与编译</em></p>
</blockquote>
<p><em>转换模型阶段会完成浮点模型到地平线混合异构模型的转换，经过这个阶段，您将得到一个可以在地平线芯片上运行的模型。 在进行转换之前，请确保已经顺利通过了 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html" >验证模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 小节的过程。</em></p>
<p><em>模型转换使用 <code>hb_mapper makertbin</code> 工具完成，转换期间会完成模型优化和校准量化等重要过程，校准需要依照模型预处理要求准备校准数据， 您可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/prepare_calibration_data.html" >校准数据准备 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容对校准数据进行预先准备。 为了方便您全面了解模型转换，本节将依次介绍转换工具使用、转换内部过程解读、转换结果解读和转换产出物解读。</em></p>
<p><em><strong>使用 <code>hb_mapper makertbin</code> 工具转换模型</strong></em></p>
<p><em>hb_mapper makertbin命令使用方式如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper makertbin --config $&#123;config_file&#125;  \</span><br><span class="line">                    --model-type  $&#123;model_type&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>hb_mapper makertbin参数解释：</em></p>
<ul>
<li><p><em>–model-type</em></p>
<p><em>用于指定转换输入的模型类型，目前支持设置 <code>caffe</code> 或者 <code>onnx</code>。</em></p>
</li>
<li><p><em>–config</em></p>
<p><em>模型编译的配置文件，内容采用yaml格式，文件名使用.yaml后缀。一份完整的配置文件模板如下：</em></p>
</li>
</ul>
<p><em><strong>注意：</strong>此处配置文件仅作展示，在实际模型配置文件中 <code>caffe_model</code> 与 <code>onnx_model</code> 两种只存在其中之一。</em></p>
<p><em>即，要么是Caffe模型，要么是ONNX模型。即 <code>caffe_model</code> + <code>prototxt</code> 或者 <code>onnx_model</code> 二选一。</em></p>
<ul>
<li><pre><code class="python"># 模型参数组
model_parameters:
  # 原始Caffe浮点模型描述文件
  prototxt: &#39;***.prototxt&#39;

  # 原始Caffe浮点模型数据模型文件
  caffe_model: &#39;****.caffemodel&#39;

  # 原始Onnx浮点模型文件
  onnx_model: &#39;****.onnx&#39;

  # 转换的目标芯片架构
  march: &#39;bayes&#39;

  # 模型转换输出的用于上板执行的模型文件的名称前缀
  output_model_file_prefix: &#39;mobilenetv1&#39;

  # 模型转换输出的结果的存放目录
  working_dir: &#39;./model_output_dir&#39;

  # 指定转换后混合异构模型是否保留输出各层的中间结果的能力
  layer_out_dump: False

  # 指定模型的输出节点
  output_nodes: &#123;OP_name&#125;

  # 批量删除某一类型的节点
  remove_node_type: Dequantize

  # 删除指定名称的节点
  remove_node_name: &#123;OP_name&#125;

# 输入信息参数组
input_parameters:
  # 原始浮点模型的输入节点名称
  input_name: &quot;data&quot;

  # 原始浮点模型的输入数据格式（数量/顺序与input_name一致）
  input_type_train: &#39;bgr&#39;

  # 原始浮点模型的输入数据排布（数量/顺序与input_name一致）
  input_layout_train: &#39;NCHW&#39;

  # 原始浮点模型的输入数据尺寸
  input_shape: &#39;1x3x224x224&#39;

  # 网络实际执行时，输入给网络的batch_size, 默认值为1
  input_batch: 1

  # 在模型中添加的输入数据预处理方法
  norm_type: &#39;data_mean_and_scale&#39;

  # 预处理方法的图像减去的均值, 如果是通道均值，value之间必须用空格分隔
  mean_value: &#39;103.94 116.78 123.68&#39;

  # 预处理方法的图像缩放比例，如果是通道缩放比例，value之间必须用空格分隔
  scale_value: &#39;0.017&#39;

  # 转换后混合异构模型需要适配的输入数据格式（数量/顺序与input_name一致）
  input_type_rt: &#39;yuv444&#39;

  # 输入数据格式的特殊制式
  input_space_and_range: &#39;regular&#39;

  # 转换后混合异构模型需要适配的输入数据排布（数量/顺序与input_name一致），若input_type_rt配置为nv12，则此处参数不需要配置
  input_layout_rt: &#39;NHWC&#39;

# 校准参数组
calibration_parameters:
  # 模型校准使用的标定样本的存放目录
  cal_data_dir: &#39;./calibration_data&#39;

  # 指定校准数据二进制文件的数据存储类型。
  cal_data_type: &#39;float32&#39;

  # 开启图片校准样本自动处理（skimage read; resize到输入节点尺寸）
  #preprocess_on: False

  # 校准使用的算法类型
  calibration_type: &#39;kl&#39;

  # max 校准方式的参数
  max_percentile: 1.0

  # 强制指定OP在CPU上运行
  run_on_cpu:  &#123;OP_name&#125;

  # 强制指定OP在BPU上运行
  run_on_bpu:  &#123;OP_name&#125;

  # 指定是否针对每个channel进行校准
  per_channel: False

  # 指定输出节点的数据精度
  optimization: set_model_output_int16

# 编译参数组
compiler_parameters:
  # 编译策略选择
  compile_mode: &#39;latency&#39;

  # 是否打开编译的debug信息
  debug: False

  # 模型运行核心数
  core_num: 1

  # 模型编译的优化等级选择
  optimize_level: &#39;O2&#39;

  # 指定名称为data的输入数据来源
  input_source: &#123;&quot;data&quot;: &quot;pyramid&quot;&#125;

  # 指定模型的每个function call的最大可连续执行时间
  max_time_per_fc: 1000

  # 指定编译模型时的进程数
  jobs: 8

custom_op:
  # 自定义op的校准方式
  custom_op_method: register

  # 自定义OP的实现文件, 该文件可由模板生成, 详情见自定义OP相关文档
  op_register_files: sample_custom.py

  # 自定义OP实现文件所在的文件夹, 请使用相对路径
  custom_op_dir: ./custom_op
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*配置文件主要包含模型参数组、输入信息参数组、校准参数组和编译参数组。 在您的配置文件中，四个参数组位置都需要存在，具体参数分为可选和必选，可选参数可以不配置。*</span><br><span class="line"></span><br><span class="line">***param_value配置***</span><br><span class="line"></span><br><span class="line">*具体参数的设置形式为：`param_name: &#x27;param_value&#x27;` ，参数存在多个值时使用 `&#x27;;&#x27;` 符号分隔： `param_name: &#x27;param_value1; param_value2; param_value3&#x27;` 。*</span><br><span class="line"></span><br><span class="line">***注意：***</span><br><span class="line"></span><br><span class="line">- *当模型为多输入模型时，强烈建议您将 `input_shape` 等参数们显式的写出，以免造成参数对应顺序上的错误。*</span><br><span class="line">- *如果设置 `input_type_rt` 为 `nv12` 或 `yuv444` ，则模型的输入尺寸中不能出现奇数。*</span><br><span class="line"></span><br><span class="line">&gt; *当模型的输入为 nv12 或 yuv444 格式时，通常要求输入尺寸中的宽度和高度都是偶数，而不允许出现奇数。*</span><br><span class="line">&gt;</span><br><span class="line">&gt; *这要求的原因主要与视频编码和图像处理相关。在 nv12 或 yuv444 格式中，图像的亮度和色度信息被分离存储。nv12 是一种广泛用于视频编码和图像处理的格式，其中亮度信息（Y）与色度信息（UV）交错存储。yuv444 则是一种不交错存储的格式，它将亮度和色度信息分别存储。*</span><br><span class="line">&gt;</span><br><span class="line">&gt; *在这些格式中，**亮度和色度信息的采样是以4:2:0或4:4:4的比例进行的，其中 &quot;4&quot; 表示每 4 个亮度像素对应一个色度像素**。由于采样比例的限制，要保证正确的采样和处理，输入图像的宽度和高度通常需要是偶数。*</span><br><span class="line">&gt;</span><br><span class="line">&gt; *如果输入图像的宽度或高度是奇数，那么在进行色度信息的采样和处理时会出现对齐问题，可能导致图像质量下降或处理错误。为了避免这种情况，通常要求输入图像的宽度和高度都是偶数，以确保正确的采样和处理。*</span><br><span class="line"></span><br><span class="line">***int16配置说明***</span><br><span class="line"></span><br><span class="line">*在模型转换的过程中，模型中的大部分算子都会被量化到int8进行计算，而通过配置 `set_node_data_type` 参数， 可以详细指定某个op（当前版本只支持conv，后续地平线会释放更多op）的输出为int16计算，基本原理如下：*</span><br><span class="line"></span><br><span class="line">***在用户配置了某个op输出为int16后，模型转换内部会自动进行op输入输出上下文（context）int16配置的更新和检查**。 例如，当配置conv_1为int16计算输出时，实际上潜在同时指定了conv_1的下一个op需要支持以int16输入计算。 对于不支持的场景，模型转换工具会打印log提示该int16配置组合暂时不被支持并回退到int8计算。*</span><br><span class="line"></span><br><span class="line">*以下是具体参数信息，参数会比较多，我们依照上述的参数组次序介绍。*</span><br><span class="line"></span><br><span class="line">*🛠️ **模型参数组***</span><br><span class="line"></span><br><span class="line">| *编 号* | *参数名称*                   | *参数配置说明*                                               | *可选/必选* |</span><br><span class="line">| :------ | :--------------------------- | :----------------------------------------------------------- | :---------- |</span><br><span class="line">| *1*     | *`prototxt`*                 | ***参数作用**：指定Caffe浮点模型的prototxt文件名称。**取值范围**：无。**默认配置**：无。**参数说明**：在 `hb_mapper makertbin` 的 `model-type` 为 `caffe` 时必须配置。* | *可选*      |</span><br><span class="line">| *2*     | *`caffe_model`*              | ***参数作用**：指定Caffe浮点模型的caffemodel文件名称。**取值范围**：无。**默认配置**：无。**参数说明**：在 `hb_mapper makertbin` 的 `model-type` 为 `caffe` 时必须配置。* | *可选*      |</span><br><span class="line">| *3*     | *`onnx_model`*               | ***参数作用**：指定ONNX浮点模型的onnx文件名称。**取值范围**：无。**默认配置**：无。**参数说明**：在 `hb_mapper makertbin` 的 `model-type` 为 `onnx` 时必须配置。* | *可选*      |</span><br><span class="line">| *4*     | *`march`*                    | ***参数作用**：指定产出混合异构模型需要支持的平台架构。**取值范围**： `bayes` 或 `bernoulli2` 。**默认配置**： 无。**参数说明**： 两个可选配置值依次对应J5和X3&amp;J3芯片， 根据您使用的平台选择。* | *必选*      |</span><br><span class="line">| *5*     | *`output_model_file_prefix`* | ***参数作用**：指定转换产出混合异构模型的名称前缀。**取值范围**：无。**默认配置**：`model`。**参数说明**：输出的定点模型文件的名称前缀。* | *可选*      |</span><br><span class="line">| *6*     | *`working_dir`*              | ***参数作用**：指定模型转换输出的结果的存放目录。**取值范围**：无。**默认配置**：`model_output`。**参数说明**：若该目录不存在，则工具会自动创建目录。* | *可选*      |</span><br><span class="line">| *7*     | *`layer_out_dump`*           | ***参数作用**：指定混合异构模型是否保留输出中间层值的能力。**取值范围**：`True` 、 `False`。**默认配置**：`False`。**参数说明**：输出中间层的值是调试需要用到的手段， 常规状态下请不要开启。* | *可选*      |</span><br><span class="line">| *8*     | *`output_nodes`*             | ***参数作用**：指定模型的输出节点。**取值范围**：无。**默认配置**：无。**参数说明**：一般情况下，转换工具会自动识别模型的输出节点。此参数用于支持您指定一些中间层次作为输出。设置值为模型中的具体节点名称， 多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。需要您注意的是，**一旦设置此参数后，工具将不再自动识别输出节点， 您通过此参数指定的节点就是全部的输出。*** | ***可选***  |</span><br><span class="line">| *9*     | *`remove_node_type`*         | ***参数作用**：设置删除节点的类型。**取值范围**：”Quantize”, “Transpose”, “Dequantize”, “Cast”, “Reshape”, “Softmax”。不同类型用”;”分割。**默认配置**：无。**参数说明**：该参数为隐藏参数， 不设置或设置为空不影响模型转换过程。 此参数用于支持您设置待删除节点的类型信息。被删除的节点必须在模型的开头或者末尾, 与模型的输入或输出连接。**注意：待删除节点会按顺序依次删除，并动态更新模型结构； 同时在节点删除前还会判断该节点是否位于模型的输入输出处。 因此节点的删除顺序很重要。*** | *可选*      |</span><br><span class="line">| *10*    | *`remove_node_name`*         | ***参数作用**：设置删除节点的名称。**取值范围**：无。不同名称用”;”分割。**默认配置**：无。**参数说明**：该参数为隐藏参数， 不设置或设置为空不影响模型转换过程。 此参数用于支持您设置待删除节点的名称。被删除的节点必须在模型的开头或者末尾, 与模型的输入或输出连接。注意：待删除节点会按顺序依次删除，并动态更新模型结构； 同时在节点删除前还会判断该节点是否位于模型的输入输出处。 因此节点的删除顺序很重要。* | *可选*      |</span><br><span class="line">| *11*    | *`set_node_data_type`*       | ***参数作用**：配置指定op的输出数据类型为int16。**取值范围**：当前只支持配置conv节点。**默认配置**：无。**参数说明**：在模型转换过程中，大多数op的默认输入输出数据类型为int8， 通过该参数可以指定特定op的输出数据类型为int16（在满足一定的约束条件下）。 int16相关说明详见 [int16配置说明](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#int16-config) 部分的描述。 具体算子int16支持情况详见 [模型转换工具链算子支持约束列表](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/supported_op_list.html) 。* | *可选*      |</span><br><span class="line">| *12*    | *`debug_mode`*               | ***参数作用**：保存用于精度debug分析的校准数据。**取值范围**：`&quot;dump_calibration_data&quot;`**默认配置**：无。**参数说明**：该参数作用为保存用于精度debug分析的校准数据，数据格式为.npy。 该数据通过np.load()可直接送入模型进行推理。 若不设置此参数，您也可自行保存数据并使用精度debug工具进行精度分析。* | *可选*      |</span><br><span class="line"></span><br><span class="line">&gt;*输出的定点模型文件的名称前缀指的是文件名的一部分。文件名前缀是指文件名的开头部分，它通常用于标识文件的类型、用途或其他相关信息。*</span><br><span class="line">&gt;</span><br><span class="line">&gt;*在生成定点模型文件时，为了与原始的浮点模型文件区分开来，并且便于标识该文件是定点模型，可以在文件名前添加一个特定的前缀。这个前缀可以是任意字符或字符串，通常选择与模型类型、转换工具、精度等相关的标识符。例如，可以使用&quot;quantized&quot;、&quot;fixed&quot;、&quot;int_&quot;等前缀来表示定点模型。*</span><br><span class="line"></span><br><span class="line">*🛠️ **输入信息参数组***</span><br><span class="line"></span><br><span class="line">| *编 号* | *参数名称*                | *参数配置说明*                                               | *可选/必选* |</span><br><span class="line">| :------ | :------------------------ | :----------------------------------------------------------- | :---------- |</span><br><span class="line">| *1*     | *`input_name`*            | ***参数作用**：指定原始浮点模型的输入节点名称。**取值范围**：无。**默认配置**：无。**参数说明**：浮点模型只有一个输入节点情况时不需要配置， 多于一个输入节点时必须配置以保证后续类型及校准数据输入顺序的准确性。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* | *可选*      |</span><br><span class="line">| *2*     | *`input_type_train`*      | ***参数作用**：指定原始浮点模型的输入数据类型。**取值范围**： `rgb` 、 `bgr` 、 `yuv444` 、 `gray` 、 `featuremap`。**默认配置**：无。**参数说明**：每一个输入节点都需要配置一个确定的输入数据类型， 存在多个输入节点时，设置的节点顺序需要与 `input_name` 里的顺序严格保持一致。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。数据类型的选择请参考： [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 部分的介绍。* | *必选*      |</span><br><span class="line">| *3*     | *`input_layout_train`*    | ***参数作用**：指定原始浮点模型的输入数据排布。**取值范围**：`NHWC` 、 `NCHW`。**默认配置**：无。**参数说明**：每一个输入节点都需要配置一个确定的输入数据排布， 这个排布必须与原始浮点模型所采用的数据排布相同。存在多个输入节点时， 设置的节点顺序需要与 `input_name` 里的顺序严格保持一致。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。什么是数据排布请参考： [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 部分的介绍。* | *必选*      |</span><br><span class="line">| *4*     | *`input_type_rt`*         | ***参数作用**：转换后混合异构模型需要适配的输入数据格式。**取值范围**：`rgb` 、 `bgr` 、 `yuv444` 、`nv12` 、 `gray` 、 `featuremap`。**默认配置**：无。**参数说明**：这里是指明您需要使用的数据格式。**不要求与原始模型的数据格式一致。但是需要注意在边缘平台喂给模型的数据是使用这个格式**。每一个输入节点都需要配置一个确定的输入数据类型，存在多个输入节点时， 设置的节点顺序需要与 `input_name` 里的顺序严格保持一致。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。数据类型的选择请参考： [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 部分的介绍。* | *必选*      |</span><br><span class="line">| *5*     | *`input_layout_rt`*       | ***参数作用**：转换后混合异构模型需要适配的输入数据排布。**取值范围**： `NCHW` 、 `NHWC`。**默认配置**：无。**参数说明**：每一个输入节点都需要配置一个确定的输入数据排布。 这个输入是您希望给混合异构模型指定的排布。不合适的输入数据的排布设置将会影响性能， 存在多个输入节点时，设置的节点顺序需要与 `input_name` 里的顺序严格保持一致。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。什么是数据排布请参考： [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 部分的介绍。* | *可选*      |</span><br><span class="line">| *6*     | *`input_space_and_range`* | ***参数作用**：指定输入数据格式的特殊制式。**取值范围**： `regular` , `bt601_video`。**默认配置**： `regular`。**参数说明**：**这个参数是为了适配不同ISP输出的yuv420格式， 在相应 `input_type_rt` 为 `nv12` 时，该配置才有效。**`regular` 就是常见的yuv420格式，数值范围为 `[0,255]`；`bt601_video` 是另一种视频制式yuv420，数值范围为 `[16,235]`。更多信息可以通过网络资料了解bt601。在没有明确需要的情况下，您不要配置此参数。* | *可选*      |</span><br><span class="line">| *7*     | *`input_shape`*           | ***参数作用**：指定原始浮点模型的输入数据尺寸。**取值范围**：无。**默认配置**：无。**参数说明**：shape的几个维度以 `x` 连接，例如 `1x3x224x224`。原始浮点模型只有一个输入节点情况时可以不配置， 工具会自动读取模型文件中的尺寸信息。配置多个输入节点时，设置的节点顺序需要与 `input_name` 里的顺序严格保持一致。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* | *可选*      |</span><br><span class="line">| *8*     | *`input_batch`*           | ***参数作用**：指定转换后混合异构模型需要适配的输入batch数量。**取值范围**：`1-4096`。**默认配置**：`1`。**参数说明**：这里input_batch为转换后混合异构bin模型输入batch数量， 但不影响转换后onnx的模型的输入batch数量。此参数不配置时默认为1。此参数仅在单输入且 `input_shape` 第一维为1的时候可以使用。* | *可选*      |</span><br><span class="line">| *9*     | *`norm_type`*             | ***参数作用**：在模型中添加的输入数据预处理方法。**取值范围**： `data_mean_and_scale` 、 `data_mean` 、`data_scale` 、 `no_preprocess`。**默认配置**：`no_preprocess`。**参数说明**： `no_preprocess` 表示不添加任何数据预处理；`data_mean` 表示提供减均值预处理；`data_scale` 表示提供乘scale系数预处理；`data_mean_and_scale` 表示提供先减均值再乘scale系数前处理。输入节点时多于一个时，设置的节点顺序需要与 `input_name` 里的顺序严格保持一致， 多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。配置该参数的影响请参考： [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 部分的介绍。* | *可选*      |</span><br><span class="line">| *10*    | *`mean_value`*            | ***参数作用**：指定预处理方法的图像减去的均值。**取值范围**：无。**默认配置**：无。**参数说明**：当 `norm_type` 存在 `data_mean_and_scale`或 `data_mean` 时需要配置该参数。对于每一个输入节点而言，存在两种配置方式。第一种是仅配置一个数值，表示所有通道都减去这个均值；第二种是提供与通道数量一致的数值（这些数值以空格分隔开）， 表示每个通道都会减去不同的均值。配置的输入节点数量必须与 `norm_type` 配置的节点数量一致。如果存在某个节点不需要 `mean` 处理，则为该节点配置 `&#x27;None&#x27;`。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* | *可选*      |</span><br><span class="line">| *11*    | *`scale_value`*           | ***参数作用**：指定预处理方法的数值scale系数。**取值范围**：无。**默认配置**：无。**参数说明**：当 `norm_type` 存在 `data_mean_and_scale` 或`data_scale` 时需要配置该参数。对于每一个输入节点而言，存在两种配置方式。第一种是仅配置一个数值，表示所有通道都乘以这个系数；第二种是提供与通道数量一致的数值（这些数值以空格分隔开）， 表示每个通道都会乘以不同的系数。配置的输入节点数量必须与 `norm_type` 配置的节点数量一致。如果存在某个节点不需要 `scale` 处理，则为该节点配置 `&#x27;None&#x27;`。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* |             |</span><br><span class="line"></span><br><span class="line">*🛠️ **校准参数组***</span><br><span class="line"></span><br><span class="line">| *编 号* | *参数名称*           | *参数配置说明*                                               | *可选/必选* |</span><br><span class="line">| :------ | :------------------- | :----------------------------------------------------------- | :---------- |</span><br><span class="line">| *1*     | *`cal_data_dir`*     | ***参数作用**：指定模型校准使用的标定样本的存放目录。**取值范围**：无。**默认配置**：无。**参数说明**：目录内校准数据需要符合输入配置的要求。具体请参考 [校准数据准备](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/prepare_calibration_data.html) 部分的介绍。配置多个输入节点时， 设置的节点顺序需要与 `input_name` 里的顺序严格保持一致。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。**当calibration_type为 `load`, `skip` 时，cal_data_dir不用填**。注意： 为了方便您的使用，如果未发现cal_data_type的配置，我们将根据文件夹 后缀对数据类型进行配置。如果文件夹后缀以 `_f32` 结尾，则认为数据 类型是float32，否则认为数据类型是uint8。 当然，我们强烈建议您通过cal_data_type参数对数据类型进行约束。* | *可选*      |</span><br><span class="line">| *2*     | *`cal_data_type`*    | ***参数作用**：指定校准数据二进制文件的数据存储类型。**取值范围**：`float32`、`uint8`。**默认配置**：无。**参数说明**：指定模型校准时使用的二进制文件的数据存储类型。没有指定值的情况下将会使用文件夹名字后缀来做判断。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* | *可选*      |</span><br><span class="line">| *3*     | *`preprocess_on`*    | ***参数作用**：开启图片校准样本自动处理。**取值范围**： `True` 、 `False`。**默认配置**： `False`。**参数说明**：**该选项仅适用于4维图像输入的模型， 非4维模型不要打开该选项。**在启动该功能时，cal_data_dir 目录下存放的都是jpg/bmp/png 等图片数据，工具会使用skimage读取图片， 并resize到输入节点需要的尺寸。为了保证校准的效果，建议您保持该参数关闭。使用的影响请参考 [校准数据准备](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/prepare_calibration_data.html) 部分的介绍。* | *可选*      |</span><br><span class="line">| *4*     | *`calibration_type`* | ***参数作用**：校准使用的算法类型。**取值范围**：`default`、`mix`、`kl`、`max` 、 `load` 和 `skip`。**默认配置**：`default`。**参数说明**： `kl` 和 `max` 都是公开的校准量化算法， 其基本原理可以通过网络资料查阅。使用 `load` 方式校准时, qat模型必须是通过plugin 导出的模型。详情参见 [使用QAT量化感知训练方案进一步提升模型精度](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#qat-accuracy) 。`default` 是一个自动搜索的策略， 会尝试从系列校准量化参数中获得一个相对效果较好的组合。`mix` 是一个集成多种校准方法的搜索策略， 能够自动确定量化敏感节点，并在节点粒度上从不同的校准方法 中挑选出最佳方法，最终构建一个融合了多种校准方法优势的组合校准方式。如果您使用的是QAT导出的模型，则应选择 `load`。建议您先尝试 `default`， 如果最终的精度结果不满足预期， 再根据 [精度调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#accuracy-optimization) 部分的建议配置不同的校准参数。若您只想尝试对模型性能进行验证，但对精度没有要求， 则可以尝试 “skip” 方式进行校准。该方式会使用随机数进行校准， 不需要您准备校准数据，比较适合初次尝试对模型结构进行验证。注意： 使用skip方式时，因使用随机数校准, 得到的模型不可用于精度验证。* | *可选*      |</span><br><span class="line">| *5*     | *`max_percentile`*   | ***参数作用**：该参数为 `max` 校准方法的参数，用以调整 `max` 校准的截取点。**取值范围**： `0.0` ~ `1.0`。**默认配置**： `1.0`。**参数说明**：此参数仅在 `calibration_type` 为 `max` 时有效，常用配置选项有：0.99999/0.99995/0.99990/0.99950/0.99900。建议您先尝试 `calibration_type` 配置 `default`， 如果最终的精度结果不满足预期， 再根据 [精度调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#accuracy-optimization) 部分建议调整该参数。* | *可选*      |</span><br><span class="line">| *6*     | *`per_channel`*      | ***参数作用**：控制是否针对featuremap的每个channel进行校准。**取值范围**： `True` 、 `False`。**默认配置**： `False`。**参数说明**： **`calibration_type` 设置非default、非mix时有效**。建议您先尝试 `default`， 如果最终的精度结果不满足预期， 再根据 [精度调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#accuracy-optimization) 部分建议调整该参数。* | *可选*      |</span><br><span class="line">| *7*     | *`run_on_cpu`*       | ***参数作用**：强制指定算子在CPU上运行。**取值范围**：无。**默认配置**：无。**参数说明**：CPU上虽然性能不及BPU，但是提供的是float精度计算。如果您确定某些算子需要在CPU上计算， 可以通过该参数指定。设置值为模型中的具体节点名称。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* | *可选*      |</span><br><span class="line">| *8*     | *`run_on_bpu`*       | ***参数作用**：强制指定OP在BPU上运行。**取值范围**：无。**默认配置**：无。**参数说明**：为了保证最终量化模型的精度，少部分情况下， 转换工具会将一些具备BPU计算条件的算子放在CPU上运行。如果您对性能有较高的要求，愿意以更多一些量化损失为代价， 则可以通过该参数明确指定算子运行在BPU上。设置值为模型中的具体节点名称。多个值的配置方法请参考 [param_value配置](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#param-value)。* | *可选*      |</span><br><span class="line">| *9*     | *`optimization`*     | ***参数作用**：使模型以 int8/int16 格式输出。**取值范围**：`set_model_output_int8` 或者 `set_model_output_int16` 。**默认配置**：无。**参数说明**：指定值为set_model_output_int8时，设置模型为 int8 格式低精度输出；指定值为set_model_output_int16时，设置模型为 int16 格式低精度输出。* |             |</span><br><span class="line"></span><br><span class="line">&gt; 1. *Default（默认）：默认校准算法通常是指一种基本的校准方法，用于对模型进行校准。它可能是一种简单的统计方法或规则，适用于大多数情况下。*</span><br><span class="line">&gt; 2. *Mix（混合）：混合校准算法是指将多种校准方法结合使用的算法。它可以将不同的校准技术或策略组合在一起，以实现更好的校准效果。通过使用不同的方法来校准模型，可以更好地适应不同的数据分布和特性。*</span><br><span class="line">&gt; 3. *KL（Kullback-Leibler）：KL校准算法基于Kullback-Leibler散度，用于**度量两个概率分布之间的差异**。KL校准算法的目标是通过调整模型输出的分布，使其与期望的标签分布更接近。它通常用于解决分类问题中的校准挑战，使得模型的置信度能够更好地反映真实概率。*</span><br><span class="line">&gt; 4. *Max（最大化）：最大化校准算法是一种通过**最大化模型输出的对数似然**来进行校准的方法。它基于统计方法和优化技术，通过调整模型的参数或预测分数，使得模型在训练集上的对数似然最大化。最大化校准算法通常用于概率模型或生成模型的校准，以提高模型的准确性和鲁棒性。*</span><br><span class="line">&gt; 5. *Load（加载）：加载校准算法是指从外部文件或数据源加载校准参数或配置的方法。校准参数可以是预先训练好的权重、偏置、标定数据等信息，用于调整模型的输出或预测结果。加载校准算法可以帮助快速应用已经训练好的校准参数，以便在新的数据上进行校准和预测。*</span><br><span class="line">&gt; 6. *Skip（跳过）：跳过校准算法指的是在校准过程中跳过特定的数据或步骤。这种算法通常用于根据特定条件或需求选择性地跳过校准过程中的一些操作或样本。通过跳过校准算法，可以加快校准过程或避免不必要的计算开销。*</span><br><span class="line"></span><br><span class="line">&gt; *最大化模型输出的对数似然是一种校准方法，用于调整模型的预测分数或概率分布，使其在训练集上的对数似然最大化。*</span><br><span class="line">&gt;</span><br><span class="line">&gt; *在分类问题中，模型通常会输出一个分数或概率分布来表示每个类别的预测置信度。**对数似然是一种衡量模型预测结果与真实标签之间的匹配程度的指标**。**对数似然越大，表示模型的预测结果与真实标签越匹配。***</span><br><span class="line">&gt;</span><br><span class="line">&gt; *最大化模型输出的对数似然的过程可以通过优化算法来实现。具体步骤如下：*</span><br><span class="line">&gt;</span><br><span class="line">&gt; 1. *定义对数似然函数：将模型输出的概率分布或分数转化为对数概率或对数分数。这可以通过对预测分数或概率取对数来实现。*</span><br><span class="line">&gt; 2. *计算对数似然：使用训练集的标签和模型的对数概率分布（或对数分数）来计算对数似然。对数似然可以通过比较模型预测结果与真实标签的差异来衡量。*</span><br><span class="line">&gt; 3. *优化过程：使用优化算法，例如梯度下降，迭代地调整模型的参数或预测分数，以最大化对数似然。优化过程的目标是找到最优的模型参数，使得模型在训练集上的对数似然达到最大值。*</span><br><span class="line"></span><br><span class="line">*🛠️ **编译参数组***</span><br><span class="line"></span><br><span class="line">| *编 号* | *参数名称*          | *参数配置说明*                                               | *可选/必选* |</span><br><span class="line">| :------ | :------------------ | :----------------------------------------------------------- | :---------- |</span><br><span class="line">| *1*     | *`compile_mode`*    | ***参数作用**：编译策略选择。**取值范围**： `latency`、 `bandwidth`。**默认配置**： `latency`。**参数说明**： `latency` 以优化推理时间为目标；`bandwidth` 以优化ddr的访问带宽为目标。如果模型没有严重超过预期的带宽占用，建议您使用 `latency` 策略。* | *可选*      |</span><br><span class="line">| *2*     | *`debug`*           | ***参数作用**：是否打开编译的debug信息。**取值范围**： `True` 、 `False`。**默认配置**： `False`。**参数说明**：开启该参数情况下， 编译后模型将附带一些调试信息， 用于支持后续的调优分析过程。默认情况下，建议您保持该参数关闭。* | *可选*      |</span><br><span class="line">| *3*     | *`core_num`*        | ***参数作用**：模型运行核心数。**取值范围**： `1`、 `2`。**默认配置**： `1`。**参数说明**：地平线平台支持利用多个AI加速器核心同时完成一个推理任务，多核心适用于输入尺寸较大的情况， 理想状态下的双核速度可以达到单核的1.5倍左右。如果您的模型输入尺寸较大，对于模型速度有极致追求， 可以配置 `core_num=2`。**该选项在J5上尚不支持, 请勿配置!*** | *可选*      |</span><br><span class="line">| *4*     | *`optimize_level`*  | ***参数作用**：模型编译的优化等级选择。**取值范围**： `O0` 、 `O1` 、 `O2` 、 `O3`。**默认配置**：`O0`。**参数说明**：优化等级可选范围为 `O0` ~ `O3`。`O0` 不做任何优化, 编译速度最快，优化程度最低。`O1` - `O3` 随着优化等级提高， 预期编译后的模型的执行速度会更快， 但是所需编译时间也会变长。正常用于生产和验证性能的模型， 必须使用 `O3` 级别优化才能保证得到最优性能。某些流程验证或精度调试过程中， 可以尝试使用更低级别优化加快过程速度。* | *可选*      |</span><br><span class="line">| *5*     | *`input_source`*    | ***参数作用**：设置上板bin模型的输入数据来源。**取值范围**： `ddr`, `pyramid`, `resizer`。**默认配置**： 无，默认会根据input_type_rt的值从可选范围中自动选择。**参数说明**：这个参数是适配工程环境的选项， 建议您已经全部完成模型检查后再配置。`ddr` 表示数据来自内存，`pyramid` 和 `resizer` 表示来自芯片上的固定硬件。具体在工程环境中如何适配 `pyramid` 和 `resizer` 数据源， 请您参考 [BPU SDK API 手册](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/index.html)。此参数配置有些特殊，例如模型输入名称为 data, 数据源为内存(ddr), 则此处应该配置值为 `&#123;&quot;data&quot;: &quot;ddr&quot;&#125;`。* | *可选*      |</span><br><span class="line">| *6*     | *`max_time_per_fc`* | ***参数作用**：指定模型的每个function call的最大可连续执行时间(单位μs)。**取值范围**：`0或1000-4294967295`。**默认配置**：`0`。**参数说明**：编译后的数据指令模型在BPU上进行推理计算时， 它将表现为1个或者多个function-call（BPU的执行粒度）的调用。 取值为0代表不做限制。**该参数用来限制每个function-call最大的执行时间, 模型只有在单个function-call执行完时才有机会被抢占。**详情参见 [模型优先级控制](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html#preemption) 部分的介绍。注意：此参数仅用于实现模型抢占功能，如无需实现该功能则可以忽略。**模型抢占功能仅支持在板端实现，不支持模拟器实现。*** | *可选*      |</span><br><span class="line">| *7*     | *`jobs`*            | ***参数作用**：设置编译bin模型时的进程数。**取值范围**：`机器支持的最大核心数范围内`。**默认配置**：无。**参数说明**：在编译bin模型时，用于设置进程数。 一定程度上可提高编译速度。* | *可选*      |</span><br><span class="line"></span><br><span class="line">&gt; *模型抢占功能指的是在深度学习推理过程中，当新的任务或请求到达时，系统可以中断当前正在进行的推理任务，并立即切换到处理新任务。这种功能可以在具备并发处理能力的系统中实现，以提高系统的资源利用率和实时性能。*</span><br><span class="line"></span><br><span class="line">*🛠️ **自定义算子参数组***</span><br><span class="line"></span><br><span class="line">| *编 号* | *参数名称*            | *参数配置说明*                                               | *可选/必选* |</span><br><span class="line">| :------ | :-------------------- | :----------------------------------------------------------- | :---------- |</span><br><span class="line">| *1*     | *`custom_op_method`*  | ***参数作用**：自定义算子策略选择。**取值范围**：`register`。**默认配置**：无。**参数说明**：目前仅支持register策略，具体使用请参考 [自定义算子开发](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/custom_op.html)。* | *可选*      |</span><br><span class="line">| *2*     | *`op_register_files`* | ***参数作用**：自定义算子的Python实现文件名称。**取值范围**：无。**默认配置**：无。**参数说明**：多个文件可用 `;` 分隔，算子如何实现请参考 [自定义算子开发](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/custom_op.html)。* | *可选*      |</span><br><span class="line">| *3*     | *`custom_op_dir`*     | ***参数作用**：自定义算子的Python实现文件存放路径。**取值范围**：无。**默认配置**：无。**参数说明**：设置路径时，请使用相对路径。* | *可选*      |</span><br><span class="line"></span><br><span class="line">***转换内部过程解读***</span><br><span class="line"></span><br><span class="line">*模型转换完成浮点模型到地平线混合异构模型的转换。 为了使得这个异构模型能快速高效地在嵌入式端运行， 模型转换重点在解决 **输入数据处理** 和 **模型优化编译** 两个问题，本节会依次围绕这两个重点问题展开。*</span><br><span class="line"></span><br><span class="line">***输入数据处理** 方面地平线的边缘AI计算平台会为某些特定类型的输入通路提供硬件级的支撑方案， 但是这些方案的输出不一定符合模型输入的要求。 例如视频通路方面就有视频处理子系统，为采集提供图像裁剪、缩放和其他图像质量优化功能，这些子系统的输出往往是yuv420格式图像， 而我们的算法模型往往是基于bgr/rgb等一般常用图像格式训练得到的。 地平线针对此种情况提供的固定解决方案是，每个转换模型都提供两份输入信息描述， 一份用于描述原始浮点模型输入（ `input_type_train` 和 `input_layout_train`）， 另一份则用于描述我们需要对接的边缘平台输入数据（ `input_type_rt` 和 `input_layout_rt`）。*</span><br><span class="line"></span><br><span class="line">*图像数据的mean/scale也是比较常见的操作，显然yuv420等边缘平台数据格式不再适合做这样的操作， 因此，我们也将这些常见图像前处理固化到了模型中。 经过以上两种处理后，转换产出的异构模型的输入部分将变成如下图状态。*</span><br><span class="line"></span><br><span class="line">*![image-20230509104049706](J5/image-20230509104049706.png)*</span><br><span class="line"></span><br><span class="line">*上图中的数据排布就只有NCHW和NHWC两种数据排布格式，N代表数量、C代表channel、H代表高度、W代表宽度， 两种不同的排布体现的是不同的内存访问特性。在TensorFlow模型NHWC较常用，Caffe中就都使用NCHW， 地平线平台不会限制使用的数据排布，但是有两条要求：第一是 `input_layout_train` 必须与原始模型的数据排布一致； 第二是在边缘AI平台准备好与 `input_layout_rt` 一致排布的数据，正确的数据排布指定是顺利解析数据的基础。*</span><br><span class="line"></span><br><span class="line">*工具会根据 `input_type_rt` 和 `input_type_train` 指定的数据格式自动添加数据转换节点，根据地平线的实际生产经验， 并不是任意type组合都是需要的，为了避免您误用，我们只开放了一些固定的type组合如下表。*</span><br><span class="line"></span><br><span class="line">| *`input_type_train` \ `input_type_rt`* | *nv12* | *yuv444* | *rgb* | *bgr* | *gray* | *featuremap* |</span><br><span class="line">| -------------------------------------- | ------ | -------- | ----- | ----- | ------ | ------------ |</span><br><span class="line">| *yuv444*                               | *Y*    | *Y*      | *N*   | *N*   | *N*    | *N*          |</span><br><span class="line">| *rgb*                                  | *Y*    | *Y*      | *Y*   | *Y*   | *N*    | *N*          |</span><br><span class="line">| *bgr*                                  | *Y*    | *Y*      | *Y*   | *Y*   | *N*    | *N*          |</span><br><span class="line">| *gray*                                 | *N*    | *N*      | *N*   | *N*   | *Y*    | *N*          |</span><br><span class="line">| *featuremap*                           | *N*    | *N*      | *N*   | *N*   | *N*    | *Y*          |</span><br><span class="line"></span><br><span class="line">*表格中第一行是 `input_type_rt` 中支持的类型，第一列是 `input_type_train` 支持的类型， 其中的 **Y/N** 表示是否支持相应的 `input_type_rt` 到 `input_type_train` 的转换。 **在转换得到的最终产出bin模型中， `input_type_rt` 到 `input_type_train` 是一个内部的过程， 您只需要关注 `input_type_rt` 的数据格式即可**。 **正确理解每种** `input_type_rt` **的要求，对于嵌入式应用准备推理数据很重要，以下是对** `input_type_rt` **每种格式的说明：***</span><br><span class="line"></span><br><span class="line">- *rgb、bgr和gray都是比较常见的图像数据，注意每个数值都采用UINT8表示。*</span><br><span class="line">- *yuv444是一种常见的图像格式，注意每个数值都采用UINT8表示。*</span><br><span class="line">- *nv12是常见的yuv420图像数据，每个数值都采用UINT8表示。*</span><br><span class="line">- *nv12有个比较特别的情况是 `input_space_and_range` 设置 `bt601_video` （参考前文对 `input_space_and_range` 参数的介绍），较于常规nv12情况，它的数值范围由[0,255]变成了[16,235]， 每个数值仍然采用UINT8表示。*</span><br><span class="line">- *featuremap适用于以上列举格式不满足您需求的情况，此type每个数值采用float32表示。 例如雷达和语音等模型处理就常用这个格式。*</span><br><span class="line"></span><br><span class="line">***注意：***</span><br><span class="line"></span><br><span class="line">- *以上 `input_type_rt` 与 `input_type_train` 是固化在工具链的处理流程中，如果您非常确定不需要转换， 将两个 `input_type` 设置成一样就可以了，一样的 `input_type` 会做直通处理，不会影响模型的实际执行性能。*</span><br><span class="line"></span><br><span class="line">- *同样的，数据前处理也是固化在流程中，如果您不需要做任何前处理，通过 `norm_type` 配置关闭这个功能即可，不会影响模型的实际执行性能。*</span><br><span class="line"></span><br><span class="line">***模型优化编译** 方面完成了模型解析、模型优化、模型校准与量化、模型编译几个重要阶段，其内部工作过程如下图所示。*</span><br><span class="line"></span><br><span class="line">*![image-20230509105524772](J5/image-20230509105524772.png)*</span><br><span class="line"></span><br><span class="line">***模型解析阶段** 对于Caffe浮点模型会完成到ONNX浮点模型的转换。 在原始浮点模型上会根据转换配置中的配置参数决定是否加入数据预处理节点，此阶段产出一个original_float_model.onnx。 这个ONNX模型计算精度仍然是float32，在输入部分加入了一个数据预处理节点。*</span><br><span class="line"></span><br><span class="line">*理想状态下，这个预处理节点应该完成 `input_type_rt` 到 `input_type_train` 的完整转换， 实际情况是整个type转换过程会配合地平线芯片硬件完成，**ONNX模型里面并没有包含硬件转换的部分**。 **因此ONNX的真实输入类型会使用一种中间类型，这种中间类型就是硬件对 `input_type_rt` 的处理结果类型**， 数据layout(NCHW/NHWC)会保持原始浮点模型的输入layout一致。 每种 `input_type_rt` 都有特定的对应中间类型，如下表：*</span><br><span class="line"></span><br><span class="line">| ***nv12***   | ***yuv444*** | ***rgb*** | ***bgr*** | ***gray*** | *featuremap* |</span><br><span class="line">| ------------ | ------------ | --------- | --------- | ---------- | ------------ |</span><br><span class="line">| *yuv444_128* | *yuv444_128* | *RGB_128* | *BGR_128* | *GRAY_128* | *featuremap* |</span><br><span class="line"></span><br><span class="line">*注解*</span><br><span class="line"></span><br><span class="line">*表格中第一行加粗部分是 `input_type_rt` 指定的数据类型，第二行是特定 `input_type_rt` 对应的中间类型， 这个中间类型就是original_float_model.onnx的输入类型。每个类型解释如下：*</span><br><span class="line"></span><br><span class="line">- *yuv444_128 是yuv444数据减去128结果，每个数值采用int8表示。*</span><br><span class="line">- *RGB_128 是RGB数据减去128的结果，每个数值采用int8表示。*</span><br><span class="line">- *BGR_128 是BGR数据减去128的结果，每个数值采用int8表示。*</span><br><span class="line">- *GRAY_128 是gray数据减去128的结果，每个数值采用int8表示。*</span><br><span class="line">- *featuremap 是一个四维张量数据，每个数值采用float32表示。*</span><br><span class="line"></span><br><span class="line">***模型优化阶段** 实现模型的一些适用于地平线平台的算子优化策略，例如BN融合到Conv等。 此阶段的产出是一个optimized_float_model.onnx，这个ONNX模型的计算精度仍然是float32，经过优化后不会影响模型的计算结果。 模型的输入数据要求还是与前面的original_float_model一致。*</span><br><span class="line"></span><br><span class="line">***模型校准阶段** 会使用您提供的校准数据来计算必要的量化参数，通过校准数据计算得到的每个节点对应的量化参数并将其保存在校准节点中，此阶段的产出是calibrated_model.onnx。*</span><br><span class="line"></span><br><span class="line">***模型量化阶段** 使用校准得到的参数完成模型量化，此阶段的产出是一个quantized_model.onnx。 这个模型的计算精度已经是int8，使用这个模型可以评估到模型量化带来的精度损失情况。 这个模型要求输入的基本数据格式和layout仍然与 `original_float_model` 一样，不过取值范围已经发生了变化， 整体较于 `original_float_model` 输入的变化情况描述如下：*</span><br><span class="line"></span><br><span class="line">- *当 `input_type_rt` 的取值为非 `featuremap` 时，则输入的数据类型均使用INT8， 反之， 当 `input_type_rt` 取值为 `featuremap` 时，则输入的数据类型则为float32。*</span><br><span class="line"></span><br><span class="line">*数据排布layout关系对应如下例：*</span><br><span class="line"></span><br><span class="line">- *原模型输入layout：NCHW。*</span><br><span class="line">- *input_layout_train： NCHW。*</span><br><span class="line">- *origin.onnx输入layout：NCHW。*</span><br><span class="line">- *calibrated_model.onnx输入layout：NCHW。*</span><br><span class="line">- *quanti.onnx输入layout：NCHW。*</span><br><span class="line"></span><br><span class="line">*即：input_layout_train、origin.onnx、calibrated_model.onnx、quanti.onnx输入的layout与原模型输入的layout一致。*</span><br><span class="line"></span><br><span class="line">***注意：如果input_type_rt为nv12时，对应quanti.onnx的输入layout都是NHWC。***</span><br><span class="line"></span><br><span class="line">***模型编译阶段** 会使用地平线模型编译器，将量化模型转换为地平线平台支持的计算指令和数据， 这个阶段的产出一个***.bin模型，这个bin模型是后续将在地平线边缘嵌入式平台运行的模型，也就是模型转换的最终产出结果。*</span><br><span class="line"></span><br><span class="line">***转换结果解读***</span><br><span class="line"></span><br><span class="line">*本节将依次介绍模型转换成功状态的解读、转换不成功的分析方式。 确认模型转换成功，需要您从 `makertbin` 状态信息、相似度信息和 `working_dir` 产出三个方面确认。 `makertbin` 状态信息方面，转换成功将在控制台输出信息尾部给出明确的提示信息如下：*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
</code></pre>
</li>
</ul>
<h1 id="2021-04-21-11-13-08-337-INFO-Convert-to-runtime-bin-file-successfully-2021-04-21-11-13-08-337-INFO-End-Model-Convert"><a href="#2021-04-21-11-13-08-337-INFO-Convert-to-runtime-bin-file-successfully-2021-04-21-11-13-08-337-INFO-End-Model-Convert" class="headerlink" title="2021-04-21 11:13:08,337 INFO Convert to runtime bin file successfully!2021-04-21 11:13:08,337 INFO End Model Convert"></a>2021-04-21 11:13:08,337 INFO Convert to runtime bin file successfully!<br>2021-04-21 11:13:08,337 INFO End Model Convert<br><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*相似度信息也存在于 `makertbin` 的控制台输出内容中，在 `makertbin` 状态信息之前，其内容形式如下：*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></h1><h2 id="Node-ON-Subgraph-Type-Cosine-Similarity-Threshold"><a href="#Node-ON-Subgraph-Type-Cosine-Similarity-Threshold" class="headerlink" title="Node    ON   Subgraph  Type     Cosine Similarity  Threshold"></a>Node    ON   Subgraph  Type     Cosine Similarity  Threshold</h2><p>…    …     …     …       0.999936           127.000000<br>…    …     …     …       0.999868           2.557209<br>…    …     …     …       0.999268           2.133924<br>…    …     …     …       0.996023           3.251645<br>…    …     …     …       0.996656           4.495638</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*上面列举的输出内容中，Node、ON、Subgraph、Type与 `hb_mapper checker` 工具的解读是一致的， 请参考前文 [检查结果解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html#check-result) ； Threshold是每个层次的校准阈值，用于异常状态下向地平线技术支持反馈信息，正常状况下不需要关注； **Cosine Similarity反映的Node指示的节点中，原始浮点模型与量化模型输出结果的余弦相似度。***</span><br><span class="line"></span><br><span class="line">***注意：**需要您特别注意的是，Cosine Similarity只是指明量化后数据稳定性的一种参考方式，对于模型精度的影响不存在明显的直接关联关系。 一般情况下，输出节点的相似度低于0.8就有了较明显的精度损失，当然由于与精度不存在绝对的直接关联， 完全准确的精度情况还需要您参考 [模型精度分析与调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html) 的介绍。*</span><br><span class="line"></span><br><span class="line">*转换产出存放在转换配置参数 `working_dir` 指定的路径中，成功完成模型转换后， 您可以在该目录下得到以下文件(***部分是您通过转换配置参数 `output_model_file_prefix` 指定的内容)：*</span><br><span class="line"></span><br><span class="line">- ****_original_float_model.onnx*</span><br><span class="line">- ****_optimized_float_model.onnx*</span><br><span class="line">- ****_calibrated_model.onnx*</span><br><span class="line">- ****_quantized_model.onnx*</span><br><span class="line">- ****.bin*</span><br><span class="line"></span><br><span class="line">*[转换产出物解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-output) 介绍了每个产出物的用途。 不过在上板运行前，我们强烈建议您完成 [验证模型](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html) 和 [模型性能分析与调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html) 介绍的性能&amp;精度评测过程，避免将模型转换问题延伸到后续嵌入式端。*</span><br><span class="line"></span><br><span class="line">*如果以上验证模型转换成功的三个方面中，有任一个出现缺失都说明模型转换出现了错误。 一般情况下，`makertbin` 工具会在出现错误时将错误信息输出至控制台， 例如我们在Caffe模型转换时不配置 `prototxt` 和 `caffe_model` 参数，工具给出如下提示。*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>2021-04-21 14:45:34,085 ERROR Key ‘model_parameters’ error:<br>Missing keys: ‘caffe_model’, ‘prototxt’<br>2021-04-21 14:45:34,085 ERROR yaml file parse failed. Please double check your input<br>2021-04-21 14:45:34,085 ERROR exception in command: makertbin</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*如果以上步骤不能帮助您发现问题，欢迎在地平线唯一官方技术社区（https://developer.horizon.ai/）提出您的问题， 我们将在24小时内给您提供支持。*</span><br><span class="line"></span><br><span class="line">***转换产出物解读***</span><br><span class="line"></span><br><span class="line">*上文提到模型成功转换的产出物包括以下四个部分，本节将介绍每个产出物的用途：*</span><br><span class="line"></span><br><span class="line">- ****_original_float_model.onnx*</span><br><span class="line">- ****_optimized_float_model.onnx*</span><br><span class="line">- ****_calibrated_model.onnx*</span><br><span class="line">- ****_quantized_model.onnx*</span><br><span class="line">- ****.bin*</span><br><span class="line"></span><br><span class="line">****_original_float_model.onnx的产出过程可以参考 [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 的介绍， 这个模型计算精度与转换输入的原始浮点模型是一模一样的，有个重要的变化就是为了适配地平线平台添加了一些数据预处理计算。 一般情况下，您不需要使用这个模型，在转换结果出现异常时，如果能把这个模型提供给地平线的技术支持，将有助于帮助您快速解决问题。*</span><br><span class="line"></span><br><span class="line">****_optimized_float_model.onnx的产出过程可以参考 [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 的介绍， 这个模型经过一些算子级别的优化操作，常见的就是算子融合。 通过与original_float模型的可视化对比，您可以明显看到一些算子结构级别的变化，不过这些都不影响模型的计算精度。 一般情况下，您不需要使用这个模型，在转换结果出现异常时，如果能把这个模型提供给地平线的技术支持，将有助于帮助您快速解决问题。*</span><br><span class="line"></span><br><span class="line">****_calibrated_model.onnx的产出过程可以参考 [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 的介绍， 这个模型是模型转换工具链将浮点模型经过结构优化后，通过校准数据计算得到的每个节点对应的量化参数并将其保存在校准节点中得到的中间产物。*</span><br><span class="line"></span><br><span class="line">**** _quantized_model.onnx的产出过程可以参考 [转换内部过程解读](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation) 的介绍， 这个模型已经完成了校准和量化过程，量化后的精度损失情况可以从这里查看。 这个模型是精度验证过程中必须要使用的模型，具体使用方式请参考 [模型精度分析与调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html) 部分的介绍。*</span><br><span class="line"></span><br><span class="line">***.bin就是可以用于在地平线芯片上加载运行的模型， 配合 [嵌入式应用开发指导](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html) 部分介绍的内容， 您就可以将模型快速在芯片部署运行。不过为了确保模型的性能与精度效果是符合您的预期的， 我们强烈建议完成 [模型性能分析与调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html) 和 [模型精度分析与调优](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html) 介绍的性能和精度分析过程后再进入到应用开发和部署。***</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; *模型性能分析与调优*</span><br><span class="line"></span><br><span class="line">*本节介绍了如何使用地平线提供的工具评估模型性能。 如果此阶段发现评估结果不符合预期，强烈建议您尽量在此阶段根据地平线的优化建议解决性能问题， 不建议将模型的问题延伸到应用开发阶段。*</span><br><span class="line"></span><br><span class="line">***使用 `hb_perf` 工具估计性能***</span><br><span class="line"></span><br><span class="line">*地平线提供的 `hb_perf` 以模型转换得到的 ***.bin为输入，可以直接得到模型预期上板性能（不含CPU部分的计算评估），工具使用方式如下：*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>hb_perf  ***.bin</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">***注意：如果分析的是 `pack` 后模型，需要加上一个 `-p` 参数，命令为 `hb_perf -p ***.bin`。 关于模型 `pack`，请查看 [其他模型工具（可选）](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/other_tools.html) 部分的介绍。***</span><br><span class="line"></span><br><span class="line">*命令中的 ***.bin就是模型转换产出的bin模型，命令执行完成后， 在当前工作目录下会得到一个 `hb_perf_result` 目录，分析结果以html形式提供。 以下是我们分析一个MobileNet的示例结果，其中mobilenetv1_224x224_nv12.html就是查看分析结果的主页面。*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>hb_perf_result&#x2F;<br>└── mobilenetv1_224x224_nv12<br>    ├── MOBILENET_subgraph_0.html<br>    ├── MOBILENET_subgraph_0.json<br>    ├── mobilenetv1_224x224_nv12<br>    ├── mobilenetv1_224x224_nv12.html<br>    ├── mobilenetv1_224x224_nv12.png<br>    └── temp.hbm</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*通过浏览器打开结果主页面，其内容如下图：*</span><br><span class="line"></span><br><span class="line">*![image-20230509134200321](J5/image-20230509134200321.png)*</span><br><span class="line"></span><br><span class="line">*分析结果主要由Model Performance Summary、Details和BIN Model Structure三个部分组成。 Model Performance Summary是整个bin模型的整体性能评估结果，其中各项指标为:*</span><br><span class="line"></span><br><span class="line">- *Model Name——模型名称。*</span><br><span class="line">- *BPU Model Latency(ms)——模型整体单帧计算耗时(单位为ms)。*</span><br><span class="line">- *Total DDR (loaded+stored) bytes per frame(MB per frame)——模型整体BPU部分数据加载和存储所占用的DDR总量（单位为MB/frame）。*</span><br><span class="line">- *Loaded Bytes per Frame——模型运行每帧读取数据量。*</span><br><span class="line">- *Stored Bytes per Frame——模型运行每帧存储数据量。*</span><br><span class="line"></span><br><span class="line">*在了解Details和BIN Model Structure前，您需要了解子图（subgraph）的概念。 如果模型在非输入和输出部分出现了CPU计算的算子，模型转换工具将把这个算子前后连续在BPU计算的部分拆分为两个独立的子图（subgraph）。 具体可以参考 [验证模型](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html) 部分的介绍。*</span><br><span class="line"></span><br><span class="line">*Details是每份模型BPU子图的具体信息，在主页面中，每个子图提供的指标解读如下：*</span><br><span class="line"></span><br><span class="line">- *Model Subgraph Name——子图名称。*</span><br><span class="line">- *Model Subgraph Calculation Load (OPpf)——子图的单帧计算量。*</span><br><span class="line">- *Model Subgraph DDR Occupation(Mbpf)——子图的单帧读写数据量（单位为MB）。*</span><br><span class="line">- *Model Subgraph Latency(ms)——子图的单帧计算耗时（单位为ms）。*</span><br><span class="line"></span><br><span class="line">*每份子图结果提供了一个明细入口，以上指标都是明细页面提取到的，进入到明细页面可以给您更加细致的参考信息。*</span><br><span class="line"></span><br><span class="line">***注意：需要特别注意的是，明细页面会根据您是否启用调试参数（ `debug` ）而有所区别， 下图中的Layer Details仅当在配置文件中设置 `debug` 参数为 `True` 时才可以拿到， 这个 `debug` 参数配置方法请参考 [使用 hb_mapper makertbin 工具转换模型](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#makertbin) 部分的介绍。***</span><br><span class="line"></span><br><span class="line">*Layer Details提供到了具体算子级别的分析，在调试分析阶段也是比较不错的参考， 如果是某些BPU算子导致性能低，可以帮助您定位到这个具体算子。*</span><br><span class="line"></span><br><span class="line">*![image-20230509134410094](J5/image-20230509134410094.png)*</span><br><span class="line"></span><br><span class="line">*BIN Model Structure部分提供的是bin模型的子图级可视化结果，图中深色节点表示运行在BPU上的节点，灰色节点表示在CPU上计算的节点。*</span><br><span class="line"></span><br><span class="line">*使用 `hb_perf` 的意义在于了解bin模型子图结构，对于BPU上计算部分，该工具也能提供较全面的静态分析指标。 **不过 `hb_perf` 不含CPU部分的计算评估**，**如果CPU计算仅限于模型输入或输出部分的常规性处理，不含计算密集型计算节点，这个影响不大。 否则，您就一定需要利用开发板工具实测性能。***</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">***开发板实测性能***</span><br><span class="line"></span><br><span class="line">*发板上实测模型性能使用的是开发板上 `hrt_model_exec perf` 工具， `hrt _model_exec` 是一个模型执行工具，可直接在开发板上评测模型的推理性能、获取模型信息。 一方面可以让用户拿到模型时实际了解模型真实性能； 另一方面也可以帮助用户了解模型可以做到的速度极限，对于应用调优的目标极限具有指导意义。*</span><br><span class="line"></span><br><span class="line">*使用 `hrt_model_exec perf` 工具前，有两个准备工作。*</span><br><span class="line"></span><br><span class="line">1. *确保您已经参考 [环境部署](https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html) 介绍完成了开发板上工具安装。*</span><br><span class="line">2. *第二是需要将Ubuntu开发机上得到的bin模型拷贝到开发板上（建议放在/userdata目录）， 开发板上是一个Linux系统，可以通过 `scp` 等Linux系统常用方式完成这个拷贝过程。*</span><br><span class="line"></span><br><span class="line">***注意：此时使用的模型不需要打开debug，debug打开会影响模型在开发板的测试结果。***</span><br><span class="line"></span><br><span class="line">*使用 `hrt_model_exec perf` 实测性能的参考命令如下（**注意是在开发板上执行**）：*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>.&#x2F;hrt_model_exec perf –model_file mobilenetv1_224x224_nv12.bin <br>                      –model_name&#x3D;”” <br>                      –core_id&#x3D;0 <br>                      –frame_count&#x3D;200 <br>                      –perf_time&#x3D;0 <br>                      –thread_num&#x3D;1 <br>                      –profile_path&#x3D;”.”</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*其中，各参数含义如下：*</span><br><span class="line"></span><br><span class="line">*`model_file`： 需要分析性能的bin模型名称。*</span><br><span class="line"></span><br><span class="line">*`model_name`： 需要分析性能的bin模型名字。若 `model_file` 只含一个模型，则可以省略。*</span><br><span class="line"></span><br><span class="line">*`core_id`： 默认值 `0`，运行模型使用的核心id，`0` 代表任意核心，`1` 代表核心0，`2` 代表核心1。若要分析双核极限帧率，请将此处设为 `0`。*</span><br><span class="line"></span><br><span class="line">*`frame_count`： 默认值 `200`，设置推理帧数，工具会执行指定次数后再分析平均耗时。 当 `perf_time` 为 `0` 时生效。*</span><br><span class="line"></span><br><span class="line">*`perf_time`： 默认值 `0`，单位分钟。设置推理时间，工具会执行指定时间后再分析平均耗时。*</span><br><span class="line"></span><br><span class="line">*`thread_num`： 默认值 `1`，设置运行的线程数，取值范围 `[1,8]`。若要分析极限帧率，请将线程数改大。*</span><br><span class="line"></span><br><span class="line">*`profile_path`： 默认关闭，统计工具日志产生路径。该参数引入的分析结果会存放在指定目录下的profiler.log和profiler.csv文件中。*</span><br><span class="line"></span><br><span class="line">*命令执行完成后，您将在控制台得到如下结果。 最终的评估结果就是 `Average latency` 和 `Frame rate`，分别表示平均单帧推理延时和模型极限帧率。 如果想获得模型在板子上运行的极限帧率，需将 `thread_num` 设置得足够大。*</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<p>Running condition:<br>  Thread number is: 4<br>  Frame count   is: 1000<br>  Program run time: 279.004000 ms<br>Perf result:<br>  Frame totally latency is: 1084.040527 ms<br>  Average    latency    is: 1.084041 ms<br>  Frame      rate       is: 3584.178005 FPS</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*控制台得到的信息只有整体情况，通过 `profile_path` 控制产生的 `profiler.log` 和 `profiler.csv` 文件记录了更加丰富的信息如下：*</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">&#123;</span><br><span class="line">  &quot;perf_result&quot;: &#123;</span><br><span class="line">    &quot;FPS&quot;: 3718.384436330103,</span><br><span class="line">    &quot;average_latency&quot;: 1.0366870164871216</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;running_condition&quot;: &#123;</span><br><span class="line">    &quot;core_id&quot;: 0,</span><br><span class="line">    &quot;frame_count&quot;: 1000,</span><br><span class="line">    &quot;model_name&quot;: &quot;mobilenetv1_224x224_nv12&quot;,</span><br><span class="line">    &quot;run_time&quot;: 268.934,</span><br><span class="line">    &quot;thread_num&quot;: 4</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">***</span><br><span class="line">&#123;</span><br><span class="line">  &quot;chip_latency&quot;: &#123;</span><br><span class="line">    &quot;BPU_inference_time_cost&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.8493590000000001,</span><br><span class="line">      &quot;max_time&quot;: 1.328,</span><br><span class="line">      &quot;min_time&quot;: 0.766</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;CPU_inference_time_cost&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.074976,</span><br><span class="line">      &quot;max_time&quot;: 0.382,</span><br><span class="line">      &quot;min_time&quot;: 0.066</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;model_latency&quot;: &#123;</span><br><span class="line">    &quot;BPU_MOBILENET_subgraph_0&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.8493590000000001,</span><br><span class="line">      &quot;max_time&quot;: 1.328,</span><br><span class="line">      &quot;min_time&quot;: 0.766</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;Dequantize_fc7_1_HzDequantize&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.029727,</span><br><span class="line">      &quot;max_time&quot;: 0.124,</span><br><span class="line">      &quot;min_time&quot;: 0.028</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;MOBILENET_subgraph_0_output_layout_convert&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.011379,</span><br><span class="line">      &quot;max_time&quot;: 0.077,</span><br><span class="line">      &quot;min_time&quot;: 0.008</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;Preprocess&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.005363000000000001,</span><br><span class="line">      &quot;max_time&quot;: 0.039,</span><br><span class="line">      &quot;min_time&quot;: 0.003</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;Softmax_prob&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.028507,</span><br><span class="line">      &quot;max_time&quot;: 0.142,</span><br><span class="line">      &quot;min_time&quot;: 0.027</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;task_latency&quot;: &#123;</span><br><span class="line">    &quot;TaskPendingTime&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.021235,</span><br><span class="line">      &quot;max_time&quot;: 0.336,</span><br><span class="line">      &quot;min_time&quot;: 0.002</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;TaskRunningTime&quot;: &#123;</span><br><span class="line">      &quot;avg_time&quot;: 0.983558,</span><br><span class="line">      &quot;max_time&quot;: 2.208,</span><br><span class="line">      &quot;min_time&quot;: 0.904</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>这里的内容会对应到 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html#hb-perf" >使用hb_perf工具估计性能 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的BIN Model Structure部分介绍的bin可视化图中， 图中每个节点都有一个对应节点在profiler.log文件中，可以通过 <code>name</code> 对应 起来。 <code>profiler.log</code> 文件中记录了每个节点的执行时间，对优化节点有重要的参考意义。 由于模型中的BPU节点对输入输出有特殊要求，如特殊的layout和padding对齐要求，因此需要对BPU节点的输入、输出数据进行处理。</em></p>
<ul>
<li><em><code>Preprocess</code>：表示对模型输入数据进行padding和layout转换操作，其耗时统计在Preprocess中。</em></li>
<li><em><code>xxxx_input_layout_convert</code>： 表示对BPU节点的输入数据进行padding和layout转换的操作，其耗时统计在xxxx_input_layout_convert中。</em></li>
<li><em><code>xxxx_output_layout_convert</code>： 表示对BPU节点输出数据进行去掉padding和layout转换的操作，其耗时统计在xxxx_output_layout_convert中。</em></li>
</ul>
<p><em><code>profiler</code> 分析是经常使用的操作，前文 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html#check-result" >检查结果解读 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分提到检查阶段不用过于 关注CPU算子， 此阶段就能看到CPU算子的具体耗时情况了，如果根据这里的评估认为CPU耗时太长，那就值得优化了。</em></p>
<p><em><strong>模型性能优化</strong></em></p>
<p>*根据以上性能分析结果，您可能发现性能结果不及预期，本章节内容介绍了地平线对提升模型性能的建议与措施，包括： <strong>检查yaml配置参数</strong>、 <strong>处理CPU算子</strong>、 <strong>高性能模型设计建议</strong>、 <strong>使用地平线平台友好结构&amp;模型</strong> 共四个方面。*</p>
<p><em>部分修改可能会影响原始浮点模型的参数空间，意味着需要您重训模型，为了避免性能调优过程中反复调整并训练的代价， <strong>在得到满意性能效果前，建议您使用随机参数导出模型来验证性能即可。</strong></em></p>
<p><em><strong>检查影响模型性能的yaml参数</strong></em></p>
<p><em>在模型转换的yaml配置文件中，部分参数会实际影响模型的最终性能，可以先检查下是否已正确按照预期配置， 各参数的具体含义和作用请参考 <code>hb_mapper 工具介绍</code> 章节中的 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_mapper.html#hb-mapper-config" >配置文件详细介绍 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 小节的内容。</em></p>
<ul>
<li><em><code>layer_out_dump</code>：指定模型转换过程中是否输出模型的中间结果，一般仅用于调试功能。 如果将其配置为 <code>True</code>，则会为每个卷积算子增加一个反量化输出节点，它会显著的降低模型上板后的性能。 所以在性能评测时，务必要将该参数配置为 <code>False</code>。</em></li>
<li><em><code>compile_mode</code>：该参数用于选择模型编译时的优化方向为带宽还是时延，关注性能时请配置为 <code>latency</code>。</em></li>
<li><em><code>optimize_level</code>：该参数用于选择编译器的优化等级，实际生产中应配置为 <code>O3</code> 获取最佳性能。</em></li>
<li><em><code>debug</code>：配置为 <code>True</code> 将打开编译器的debug模式，能够输出性能仿真的相关信息，如帧率、DDR 带宽占用等。 一般用于性能评估阶段，在产品化交付时候，可关闭该参数减小模型大小，提高模型执行效率。</em></li>
<li><em><code>max_time_per_fc</code>：该参数用于控制编译后的模型数据指令的function-call的执行时长，从而实现模型优先级抢占功能。 设置此参数更改被抢占模型的function-call执行时长会影响该模型的上板性能。</em></li>
</ul>
<p><em><strong>处理CPU算子</strong></em></p>
<p><em>根据 <code>hrt_model_exec perf</code> 的评估，已经确认突出的性能瓶颈是CPU算子导致的。 此种情况下，我们建议您先查看 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/supported_op_list.html" >模型转换工具链算子支持约束列表 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节，确认当前运行在CPU上的算子是否具备BPU支持的能力。</em></p>
<p><em>如果算子不具备BPU支持能力，那么就是您的算子参数超过了BPU支持的参数约束范围， 将相应原始浮点模型计算参数调整到约束范围内即可。 为了方便您快速知晓超出约束的具体参数，建议您再使用 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/check_model.html" >验证模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分介绍的方法做一遍检查， 工具将会直接给出超出BPU支持范围的参数提示。</em></p>
<p><em><strong>注意：修改原始浮点模型参数对模型计算精度的影响需要您自己把控， 例如Convolution的 <code>input_channel</code> 或 <code>output_channel</code> 超出范围就是一种较典型的情况， 减少channel快速使得该算子被BPU支持，单单只做这一处修改也预计会对模型精度产生影响。</strong></em></p>
<p><em>如果算子并不具备BPU支持能力，就需要您根据以下情况做出对应优化操作：</em></p>
<ul>
<li><p><em>CPU 算子处于模型中部</em></p>
<p><em>对于CPU 算子处于模型中部的情况，建议您优先尝试参数调整、算子替换或修改模型。</em></p>
</li>
<li><p><em>CPU算子处于模型首尾部</em></p>
<p><em>对于CPU算子处于模型首尾部的情况，请参考以下示例，下面以量化&#x2F;反量化节点为例：</em></p>
<ul>
<li><p><em>对于与模型输入输出相连的节点，可以在yaml文件model_parameters配置组（模型参数组）中增加 <code>remove_node_type</code> 参数，并重新编译模型。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">remove_node_type: &quot;Quantize; Dequantize&quot;</span><br></pre></td></tr></table></figure></div>

<p><em>或使用hb_model_modifier 工具对bin模型进行修改：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier x.bin -a Quantize -a Dequantize</span><br></pre></td></tr></table></figure></div>
</li>
<li><p><em>对于下图这种没有与输入输出节点相连的模型，则需要使用hb_model_modifier工具判断相连节点是否支持删除后按照顺序逐个进行删除。</em></p>
</li>
</ul>
</li>
</ul>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509142108471.png"
                      class="" title="image-20230509142108471"
                ></em></p>
<p><em>先使用hb_perf工具获取模型结构图片，然后使用以下两条命令可以自上而下移除Quantize节点， 对于Dequantize节点自下而上逐个删除即可，每一步可删除节点的名称可以通过 <code>hb_model_modifier x.bin</code> 进行查看。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier x.bin -r res2a_branch1_NCHW2NHWC_LayoutConvert_Input0</span><br><span class="line">hb_model_modifier x_modified.bin -r data_res2a_branch1_HzQuantize</span><br></pre></td></tr></table></figure></div>

<p><em><strong>性能模型设计建议</strong></em></p>
<p>*根据性能评估结果，CPU上耗时占比可能很小，主要的性能瓶颈还是BPU推理时间过长。 这种情况下，我们已经把计算器件都用上了，发力的空间就在于提升计算资源的利用率。 <strong>每种芯片都有自己的硬件特性，算法模型的计算参数是否很好地符合了硬件特性， 直接决定了计算资源的利用率，符合度越高则利用率越高，反之则低</strong>。 本部分介绍重点在于阐明地平线的硬件特性。 首先，地平线的芯片是一款旨在加速CNN（卷积神经网络）的芯片，主要的计算资源都集中在处理各种卷积计算。 所以，我们希望您的模型是以卷积计算为主的模型，卷积之外的算子都会导致计算资源的利用率降低，不同OP的影响程度会有所不同。*</p>
<p><em><strong>其他建议</strong></em></p>
<p><em>地平线芯片上的depthwise convolution的计算效率接近100%，所以对于MobileNet类的模型，BPU芯片具有效率优势。</em></p>
<p><em>另外，在模型设计时，我们应尽量让模型BPU段的输入输出维度降低，以减少量化、反量化节点的耗时和硬件的带宽压力。 以典型的分割模型为例，我们可以将Argmax算子直接合入模型本身。 但需注意，只有满足以下条件，Argmax才支持BPU加速：</em></p>
<ol>
<li><em>Caffe中的Softmax层默认axis&#x3D;1，而ArgMax层则默认axis&#x3D;0，算子替换时要保持axis的一致。</em></li>
<li><em>Argmax的Channel需小于等于64，否则只能在CPU上计算。</em></li>
</ol>
<blockquote>
<p><em>Depthwise convolution是卷积神经网络中的一种特殊类型的卷积操作，它在卷积层中被广泛使用。</em></p>
<p><em>传统的卷积操作是在输入数据的每个通道上应用一个卷积核，并通过对所有通道的输出进行求和来生成最终的输出。而<strong>depthwise convolution将每个输入通道与一个独立的卷积核进行卷积操作，生成相应的输出通道</strong>。换句话说，depthwise convolution在每个输入通道上都有一个单独的卷积核进行滑动窗口计算，而不是在整个输入张量上进行卷积。</em></p>
<p><em>Depthwise convolution的主要特点是它具有较少的参数量和计算量。由于每个输入通道都有一个独立的卷积核，因此参数的数量较小。这使得depthwise convolution在资源受限的设备上（如移动设备、嵌入式设备）具有更低的计算复杂度和更小的模型尺寸，从而节省了存储空间和计算资源。</em></p>
<p><em>然而，depthwise convolution的输出通道仍然是输入通道的线性组合，通常需要使用pointwise convolution（1x1卷积）来增加输出通道的数量和模型的表达能力。通过depthwise convolution和pointwise convolution的组合，可以构建轻量级的卷积神经网络模型，如MobileNet系列，以在资源有限的设备上实现高效的图像分类、目标检测和语义分割等任务。</em></p>
</blockquote>
<blockquote>
<p><em>MobileNet是一种轻量级的卷积神经网络架构，旨在在移动设备和嵌入式设备上实现高效的图像分类和目标检测任务。它是由Google团队提出的，旨在解决在资源受限的设备上部署深度学习模型的挑战。</em></p>
<p><em>MobileNet的设计目标是在保持较高的准确性的同时，大幅减少模型的参数量和计算复杂度。它采用了两个主要的技术：深度可分离卷积和宽度可调节（通道数可变）。</em></p>
<ol>
<li><em>深度可分离卷积（Depthwise Separable Convolution）：MobileNet使用了一种深度可分离卷积的操作，将标准的卷积操作分解为两个步骤：<strong>深度卷积和逐点卷积</strong>。深度卷积首先在输入通道上应用卷积核，然后逐点卷积将输出通道与输入通道进行线性组合。这种分解减少了模型的参数量和计算量，同时保持了一定的特征提取能力。</em></li>
<li><em><strong>宽度可调节</strong>（Width Multiplier）：MobileNet通过控制每个卷积层的通道数来调节模型的宽度。通道数决定了模型的复杂度和计算量，通过减少通道数，可以进一步减小模型的尺寸和计算复杂度。宽度可调节使得MobileNet可以在不同的资源限制条件下进行灵活的模型大小和性能权衡。</em></li>
</ol>
<p><em>MobileNet的设计使得它非常适合在移动设备和嵌入式设备上部署。它在保持较低的模型尺寸和计算复杂度的同时，仍然能够提供相对较高的图像分类和目标检测准确性</em></p>
</blockquote>
<blockquote>
<p><em><strong>在深度学习中，axis（轴）是指数据张量中的一个特定维度。</strong>张量是多维数组，每个维度可以看作是一个轴。通过指定轴，我们可以在张量中选择特定的维度进行操作，如求和、平均、最大值等。</em></p>
<p><em>轴(axis)通常用整数表示，从0开始计数。对于二维张量，第一个轴是行轴，第二个轴是列轴。对于三维张量，第一个轴是深度轴，第二个轴是行轴，第三个轴是列轴。对于更高维度的张量，可以类似地通过轴的索引来访问和操作不同的维度。</em></p>
<p><em>在深度学习中，轴(axis)常用于进行各种张量操作，例如：</em></p>
<ol>
<li><em>求和（Summation）：通过指定轴，可以沿着该轴将张量的元素相加，得到一个维度更低的张量。</em></li>
<li><em>平均（Average）：类似于求和，通过指定轴，可以计算沿着该轴的元素的平均值。</em></li>
<li><em>最大值（Maximum）：通过指定轴，可以找到沿着该轴的元素的最大值。</em></li>
<li><em>拼接（Concatenation）：通过指定轴，可以将多个张量沿着该轴进行拼接，生成一个更大的张量。</em></li>
</ol>
<p><em>轴(axis)的选择取决于所需操作的维度和上下文。</em></p>
</blockquote>
<blockquote>
<p><em><strong>ArgMax是一种数学运算，常用于机器学习和深度学习中。它表示在一组值中找到最大值所对应的索引或位置。</strong></em></p>
<p><em>具体而言，给定一组数值，ArgMax操作会返回其中最大值所对应的索引或位置。这可以理解为找到数组中取得最大值的元素的下标。如果有多个最大值，ArgMax通常只返回其中一个。</em></p>
<p><em>ArgMax操作在机器学习和深度学习中广泛应用于各种任务，如分类、目标检测和语义分割等。在分类任务中，通常使用ArgMax操作来确定模型对于输入样本的预测类别。在目标检测和语义分割任务中，ArgMax操作可以用于确定像素的类别或物体的边界框。</em></p>
<p><em>举个例子，假设有一个数组 [5, 2, 9, 1, 7]，使用ArgMax操作后会返回索引2，因为值9在数组中的位置是2，并且是最大值。</em></p>
<p><em>需要注意的是，ArgMax操作仅返回最大值的索引或位置，而不是最大值本身。如果需要获取最大值本身，可以通过使用索引来获取数组中的元素。</em></p>
</blockquote>
<p><em><strong>BPU面向高效率模型优化</strong></em></p>
<p><em>学术界在持续优化算法模型的计算效率（同样算法精度下所需的理论计算量越小越高效）、参数效率（同样算法精度下所用参数量越小越高效）。 这方面的代表工作有EfficientNet和ResNeXt，二者分别使用了Depthwise Convolution和Group Convolution。 面对这样的高效率模型，GPU&#x2F;TPU支持效率很低，不能充分发挥算法效果，学术界被迫针对GPU&#x2F;TPU分别优化了EfficientNet V2&#x2F;X和NFNet， 优化过程主要是通过减少Depthwise Convolution的使用以及大幅扩大Group Convolution中的Group大小， 这些调整都降低了原本模型的计算效率和参数效率。</em></p>
<p><em>在J5芯片上，BPU 针对 GroupConv，甚至 DepthwiseConv 做了针对性的优化，所以我们更推荐采用*<em>Depthwise+Pointwise</em></em> 结构的 <strong>MobileNetv2、EfficientNet_lite</strong>， 以及地平线基于 GroupConv 手工设计自研的 <strong>VarGNet</strong> 作为模型的 Backbone，以便获得更高的性能收益。*</p>
<p><em>更多的模型结构和业务模型都在持续探索中，我们将提供更加丰富的模型给您作为直接的参考， 这些产出将不定期更新至 <a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master%E3%80%82" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master。 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></em></p>
<blockquote>
<p><em><strong>Group Convolution（分组卷积）是一种卷积神经网络中的操作，它将输入特征图分成多个组，并对每个组分别进行卷积操作。</strong>在每个组内部，输入特征图的通道被分割成较小的子集，每个子集与一组卷积核进行卷积计算，然后将每个组的输出特征图进行拼接。</em></p>
<p><em>Group Convolution的主要目的是减少卷积操作的计算量和参数量。通过将输入特征图分成多个组，每个组只需要与一部分卷积核进行卷积操作，从而减少了计算的复杂度。此外，由于每个组内的通道数较少，因此参数量也相应减少。</em></p>
<p><em>具体而言，假设输入特征图的通道数为C，将其分为G个组，每个组有C&#x2F;G个通道。对于每个组，使用C&#x2F;G个卷积核进行卷积操作，输出特征图的通道数也为C&#x2F;G。最后，将每个组的输出特征图按顺序进行拼接，得到最终的输出特征图。</em></p>
<p><em>Group Convolution在一些深度学习模型中被广泛应用，特别是在一些轻量级模型中，如MobileNet和ShuffleNet。通过适当选择组的数量和通道数，可以在减少计算量和参数量的同时，仍然保持一定的模型性能。</em></p>
</blockquote>
<blockquote>
<p><em>Depthwise Convolution（深度卷积）是卷积神经网络中的一种卷积操作，它与传统的卷积操作（也称为Pointwise Convolution，即点卷积）相比具有更轻量级的特点。</em></p>
<p><em><strong>在传统的卷积操作中，卷积核同时操作输入张量的所有通道，并生成与卷积核数量相等的输出通道。</strong>这样的操作需要大量的计算资源和参数。而Depthwise Convolution则将卷积操作分解为两个步骤：Depthwise Convolution和Pointwise Convolution。</em></p>
<ol>
<li><em>Depthwise Convolution（深度卷积）：<strong>Depthwise Convolution只在输入张量的每个通道(B,G,R三个通道)上应用一个独立的卷积核</strong>，生成与输入通道数相等的输出通道数（<strong>没有后续卷积操作</strong>）。它通过在通道维度上进行卷积操作，捕捉输入张量的空间特征。</em></li>
<li><em>Pointwise Convolution（点卷积）：Pointwise Convolution是传统的卷积操作，它在深度卷积的输出上应用1x1的卷积核，用于将不同通道之间的特征进行组合和混合。它通过在通道维度上进行卷积操作，实现通道之间的特征交互。</em></li>
</ol>
<p><em>通过将深度卷积和点卷积结合起来，Depthwise Convolution能够有效地减少参数量和计算量。因为深度卷积只在每个通道上进行卷积操作，所以参数数量大大减少；而点卷积则用于对通道进行线性组合，增加了模型的表达能力。</em></p>
<p><em>Depthwise Convolution广泛应用于轻量级的神经网络架构，如MobileNet系列。它在保持相对较高的准确性的同时，大幅减小了模型的大小和计算复杂度，适合于在资源受限的设备上进行推理和部署。</em></p>
</blockquote>
<blockquote>
<p><em>模型精度分析与调优</em></p>
</blockquote>
<p><em>基于几十或上百张校准数据实现浮点模型到定点模型转换的后量化方式，不可避免地会存在一定的精度损失。 但经过大量实际生产经验验证，如果能筛选出最优的量化参数组合，地平线的转换工具在大部分情况下，都可以将精度损失保持在1%以内。</em></p>
<p><em>本节先介绍了如何正确地进行模型精度分析，如果通过评估发现不及预期，则可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#accuracy-optimization" >精度调优 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 小节的内容尝试调优， 实在无法解决可寻求地平线的技术支持。</em></p>
<p><em><strong>模型精度分析</strong></em></p>
<p><em>在进入到此部分介绍前，我们希望您已经了解如何对一个模型进行精度评测。本节介绍的内容是如何使用模型转换的产出物进行推理。</em></p>
<p><em>前文提到模型成功转换的产出物包括以下四个部分：</em></p>
<ul>
<li>****_original_float_model.onnx*</li>
<li>****_optimized_float_model.onnx*</li>
<li>****_quantized_model.onnx*</li>
<li>****.bin*</li>
</ul>
<p><em>虽然最后的bin模型才是将部署到芯片的模型，考虑到方便在Ubuntu开发机上完成精度评测， 我们提供了</em>**_quantized_model.onnx完成这个精度评测的过程。 quantized模型已经完成了量化，与最后的bin模型具有一致的精度效果。 使用地平线开发库加载ONNX模型推理的基本流程如下所示，这份示意代码不仅适用于quantized模型， 对original和optimized模型同样适用，根据不同模型的输入类型和layout要求准备数据即可。*</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载地平线依赖库</span></span><br><span class="line"><span class="keyword">from</span> horizon_tc_ui <span class="keyword">import</span> HB_ONNXRuntime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备模型运行的feed_dict</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_input_dict</span>(<span class="params">input_names</span>):</span><br><span class="line">  feed_dict = <span class="built_in">dict</span>()</span><br><span class="line">  <span class="keyword">for</span> input_name <span class="keyword">in</span> input_names:</span><br><span class="line">      <span class="comment"># your_custom_data_prepare代表您的自定义数据</span></span><br><span class="line">      <span class="comment"># 根据输入节点的类型和layout要求准备数据即可</span></span><br><span class="line">      feed_dict[input_name] = your_custom_data_prepare(input_name)</span><br><span class="line">  <span class="keyword">return</span> feed_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  <span class="comment"># 创建推理Session</span></span><br><span class="line">  sess = HB_ONNXRuntime(model_file=<span class="string">&#x27;***_quantized_model.onnx&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 获取输入节点名称</span></span><br><span class="line">  input_names = [<span class="built_in">input</span>.name <span class="keyword">for</span> <span class="built_in">input</span> <span class="keyword">in</span> sess.get_inputs()]</span><br><span class="line">  <span class="comment"># 或</span></span><br><span class="line">  input_names = sess.input_names</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 获取输出节点名称</span></span><br><span class="line">  output_names = [output.name <span class="keyword">for</span> output <span class="keyword">in</span> sess.get_outputs()]</span><br><span class="line">  <span class="comment"># 或</span></span><br><span class="line">  output_names = sess.output_names</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 准备模型输入数据</span></span><br><span class="line">  feed_dict = prepare_input_dict(input_names)</span><br><span class="line">  <span class="comment"># 开始模型推理，推理的返回值是一个list，依次与output_names指定名称一一对应</span></span><br><span class="line">  <span class="comment"># 输入图像的类型范围为（RGB/BGR/NV12/YUV444/GRAY）</span></span><br><span class="line">  outputs = sess.run(output_names, feed_dict, input_offset=<span class="number">128</span>)</span><br><span class="line">  <span class="comment"># 输入数据的类型范围为（FEATURE）</span></span><br><span class="line">  outputs = sess.run_feature(output_names, feed_dict, input_offset=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  Modification  history:</span></span><br><span class="line"><span class="string">    OE 1.3 ~ 1.6</span></span><br><span class="line"><span class="string">        outputs = sess.run(output_names, feed_dict, input_type_rt=None, float_offset=0)</span></span><br><span class="line"><span class="string">        outputs = sess.run_feature(output_names, feed_dict, &#123;input_name: &quot;featuremap&quot;&#125;, float_offset=0)</span></span><br><span class="line"><span class="string">    OE 1.7</span></span><br><span class="line"><span class="string">        outputs = sess.run(output_names, feed_dict, input_type_rt=None, float_offset=None, input_offset=128)</span></span><br><span class="line"><span class="string">        outputs = sess.run_feature(output_names, feed_dict, &#123;input_name: &quot;featuremap&quot;&#125;, float_offset=0)</span></span><br><span class="line"><span class="string">    OE 1.8 ~ 1.9</span></span><br><span class="line"><span class="string">        outputs = sess.run(output_names, feed_dict, input_offset=128)</span></span><br><span class="line"><span class="string">        outputs = sess.run_feature(output_names, feed_dict, input_offset=128)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    note: OE 1.5 后架构上的调整，如果更新 OE 需要重新编译模型</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></div>

<p><em>上述代码中， <code>input_offset</code> 参数可以不提供，其默认值为128。对于有前处理节点的模型，这里都需要做-128的操作。如果模型输入前并未添加前处理节点，则需要将 <code>input_offset</code> 设置为0。</em></p>
<p><em><strong>注意：</strong>对于多输入模型：</em></p>
<ul>
<li><em>如果输入input_type均属于（RGB&#x2F;BGR&#x2F;NV12&#x2F;YUV444&#x2F;GRAY），可以采用 <code>sess.run</code> 方法做推理。</em></li>
<li><em>如果输入input_type均属于（FEATURE），可以采用 <code>sess.run_feature</code> 方法做推理。</em></li>
<li><em>请注意，目前暂不支持输入 input_type 为混合类型。</em></li>
</ul>
<p><em>此外， <code>your_custom_data_prepare</code> 所代表的输入数据准备过程是最容易出现误操作的部分。 较于您设计&amp;训练原始浮点模型的精度验证过程，我们需要您在数据预处理后将推理输入数据进一步调整， 这些调整主要是数据格式（RGB、NV12等）、数据精度（int8、float32等）和数据排布（NCHW或NHWC）。 至于具体怎么调整，这个是由您在模型转换时设置的 <code>input_type_train</code> 、 <code>input_layout_train</code> 、 <code>input_type_rt</code> 和 <code>input_layout_rt</code> 四个参数共同决定的，其详细规则请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation" >转换内部过程解读 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分的介绍。</em></p>
<p><em>举个例子，有一个使用ImageNet训练的用于分类的原始浮点模型，它只有一个输入节点。 这个节点接受BGR顺序的三通道图片，输入数据排布为NCHW。原始浮点模型设计&amp;训练阶段，验证集推理前做的数据预处理如下：</em></p>
<ol>
<li><em>图像长宽等比scale,短边缩放到256。</em></li>
<li><em><code>center_crop</code> 方法获取224x224大小图像。</em></li>
<li><em>按通道减mean。</em></li>
<li><em>数据乘以scale系数。</em></li>
</ol>
<p><em>使用地平线转换这个原始浮点模型时， <code>input_type_train</code> 设置 <code>bgr</code> 、 <code>input_layout_train</code> 设置 <code>NCHW</code> 、 <code>input_type_rt</code> 设置 <code>bgr</code> 、 <code>input_layout_rt</code> 设置 <code>NHWC</code> 。</em></p>
<p>*根据 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation" >转换内部过程解读 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分介绍的规则， ***_quantized_model.onnx接受的输入应该为bgr_128、NCHW排布。 对应到前文的示例代码， <code>your_custom_data_prepare</code> 部分提供的数据处理应该一个这样的过程：*</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本示例使用skimage，如果是opencv会有所区别</span></span><br><span class="line"><span class="comment"># 需要您特别注意的是，transformers中并没有体现减mean和乘scale的处理</span></span><br><span class="line"><span class="comment"># mean和scale操作已经融合到了模型中，参考前文norm_type/mean_values/scale_values配置</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">your_custom_data_prepare_sample</span>(<span class="params">image_file</span>):</span><br><span class="line">  <span class="comment"># skimage读取图片，已经是NHWC排布</span></span><br><span class="line">  image = skimage.img_as_float(skimage.io.imread(image_file))</span><br><span class="line">  <span class="comment"># 长宽等比scale，短边缩放至256</span></span><br><span class="line">  image = ShortSideResize(image, short_size=<span class="number">256</span>)</span><br><span class="line">  <span class="comment"># CenterCrop获取224x224图像</span></span><br><span class="line">  image = CenterCrop(image, crop_size=<span class="number">224</span>)</span><br><span class="line">  <span class="comment"># skimage读取结果通道顺序为RGB，转换为bgr_128需要的BGR顺序</span></span><br><span class="line">  image = RGB2BGR(image)</span><br><span class="line">  <span class="comment"># 如果原模型是 NCHW 输入（input_type_rt为nv12除外）</span></span><br><span class="line">  <span class="keyword">if</span> layout == <span class="string">&quot;NCHW&quot;</span>:</span><br><span class="line">    image = HWC2CHW(image)</span><br><span class="line">  <span class="comment"># skimage读取数值范围为[0.0,1.0]，调整为bgr需要的数值范围</span></span><br><span class="line">  image = image * <span class="number">255</span></span><br><span class="line">  <span class="comment"># bgr_128是bgr减去128</span></span><br><span class="line">  image = image - <span class="number">128</span></span><br><span class="line">  <span class="comment">#bgr_128使用int8</span></span><br><span class="line">  image = image.astype(np.int8)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure></div>



<p><em><strong>精度调优</strong></em></p>
<p><em>基于前文的精度分析工作，如果确定模型的量化精度不符合预期，则主要可分为以下两种情况进行解决：</em></p>
<p><em>1.精度有较明显损失（损失大于4%）。</em></p>
<p><em>这种问题往往是由于yaml配置不当，校验数据集不均衡等导致的，可以根据我们接下来提供的建议逐一排查。</em></p>
<p><em>2.精度损失较小（1.5%~3%）。</em></p>
<p><em>排除1导致的精度问题后，如果仍然出现精度有小幅度损失，往往是由于模型自身的敏感性导致，可以使用我们提供的精度调优工具进行调优。</em></p>
<p><em>3.在尝试1和2后，如果精度仍无法满足预期，可以尝试使用我们提供的精度debug工具进行进一步尝试。</em></p>
<p><em>整体精度问题解决流程示意如下图：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509154920761.png"
                      class="" title="image-20230509154920761"
                ></em></p>
<p><em>一、 <strong>精度有明显损失（4%以上）</strong></em></p>
<p><em>通常情况下，明显的精度损失往往是由于各种配置不当引起的，我们建议您依次从pipeline、模型转换配置和一致性三个方面检查。</em></p>
<p><em><strong>pipeline检查</strong>：</em></p>
<p><em>pipeline是指您完成数据准备、模型推理、后处理、精度评测Metric的全过程。 在以往的实际问题跟进经验中，我们发现这些部分在原始浮点模型训练阶段中有变动，却没有及时更新到模型转换的精度验证过程来是比较常见的情况。</em></p>
<p><em><strong>模型转换配置检查</strong>：</em></p>
<ul>
<li><em><code>input_type_rt</code> 和 <code>input_type_train</code> 该参数用来区分转后混合异构模型与原始浮点模型需要的数据格式，需要认真检查是否符合预期，尤其是BGR和RGB通道顺序是否正确。</em></li>
<li><em><code>norm_type</code>、 <code>mean_values</code>、 <code>scale_values</code> 等参数是否配置正确。通过转换配置可以直接在模型中插入mean和scale操作节点， 需要确认是否对校验&#x2F;测试图片进行了重复的mean和scale操作。<strong>重复预处理是错误的易发区。</strong></em></li>
</ul>
<p><em><strong>数据处理一致性检查</strong>：</em></p>
<ul>
<li><em><code>skimage.read</code> 和 <code>opencv.imread</code> 是两种常用图片读取方法，这两种方法在输出的范围和格式上都有所区别。 使用 <code>skimage</code> 的图片读取，得到的是RGB通道顺序，取值范围为0<del>1，数值类型为float；而使用 <code>opencv</code>，得到的是BGR通道顺序，取值范围为0</del>255，数据类型为uint8。</em></li>
<li><em>在校准数据准备阶段、给应用程序准备应用样本时，我们常使用numpy的tofile序列化数据。这种方式不会保存shape和类型信息， 在加载时都需要手动指定，需要您确保这些文件的序列化和反序列化过程的数据类型、数据尺寸和数据排布等信息都是一致的。</em></li>
<li><em>推荐您在地平线工具链使用过程中，依然使用原始浮点模型训练验证阶段依赖的数据处理库。 对于鲁棒性较差的模型，不同库实现的功能resize、crop等典型功能都可能引起扰动，进而影响模型精度。</em></li>
<li><em>校验图片集是否合理设置。校准图片集数量应该在百张左右，同时最好可以覆盖到数据分布的各种场合，例如在多任务或多分类时，校验图片集可以覆盖到各个预测分支或者各个类别。 同时避免偏离数据分布的异常图片（过曝光等）。</em></li>
<li>*使用 ***_original_float_model.onnx再验证一遍精度，正常情况下，这个模型的精度应该是与原始浮点模型精度保持小数点后三到五位对齐。 如果验证发现不满足这种对齐程度，则表明您的数据处理需要再仔细检查。*</li>
</ul>
<p><em>二、 <strong>较小精度损失提升</strong></em></p>
<p><em>一般情况下，为降低模型精度调优的难度，我们建议您在转换配置中使用的是自动参数搜索功能。 如果发现自动搜索的精度结果仍与预期有一定的差距，较于原始浮点模型的精度损失在1.5%到3%范围左右。 可以分别尝试使用以下建议提高精度：</em></p>
<ul>
<li><em>尝试在配置转换中手动指定 <code>calibration_type</code> ，可以先选择 <code>mix</code> ，如果最终精度仍不符合预期，再尝试 <code>kl</code> &#x2F; <code>max</code> 。</em></li>
<li><em>尝试在配置转换中启用 <code>per_channel</code> 。</em></li>
<li><em>在 <code>calibration_type</code> 设定为 <code>max</code> 时， 同时配置 <code>max_percentile</code> 参数分别为 <code>0.99999</code> 、 <code>0.99995</code> 、 <code>0.9999</code> 、 <code>0.9995</code> 、 <code>0.999</code> 进行尝试。</em></li>
</ul>
<p><em>三、 <strong>精度debug工具</strong></em></p>
<p><em>在尝试了一和二中提供的方法后，如果您的精度仍无法满足预期，为了方便您定位问题，我们提供了精度debug工具用于协助您定位问题。 该工具能够协助您对校准模型进行节点粒度的量化误差分析，快速定位出现精度异常的节点。 工具的详细介绍及使用方法您可参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/accuracy_debug.html" >精度debug工具 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><em>根据以往的实际生产经验，以上策略已经可以应对各种实际问题。 如果经过以上尝试仍然未能解决您的问题，欢迎在地平线唯一官方技术社区（<a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/" >https://developer.horizon.ai <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>）发帖与我们取得联系， 我们将根据您的具体问题提供更具针对性的指导建议。</em></p>
<p><em><strong>注意：</strong>可以通过配置部分op以int16计算来进行尝试精度调优：</em></p>
<ul>
<li><em>在模型转换过程中，大部分op默认会以int8的数据计算，在一些场景下部分op使用int8计算会导致精度损失明显。 新版本模型转换工具链已经提供了指定特定op以int16 bit计算的能力， 详情可参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#model-parameter-group" >模型参数组 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中关于 <code>set_node_data_type</code> 参数配置的说明。 通过配置量化精度损失敏感op（可以以余弦相似度为参考）以int16 bit计算，一些场景下可以解决精度损失问题。</em></li>
</ul>
<p><em><strong>使用QAT量化感知训练方案进一步提升模型精度</strong></em></p>
<p><em>如果通过上述分析，并没有发现任何配置上的问题，但是精度仍不能满足要求，则可能是PTQ本身的限制。 这时候我们可以改用QAT的方式来对模型进行量化。</em></p>
<p><em>本小节内容对QAT方案进行详细介绍：</em></p>
<ul>
<li><em>首先，<a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#about-quantization" >关于量化 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 介绍量化的概念和两种量化方法；</em></li>
<li><em>其次，<a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#about-conversion" >关于模型转换 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 介绍地平线模型转换、原始浮点模型和混合异构模型的概念；</em></li>
<li><em>接着，在理解了以上一些概念后，<a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#about-quantization-compile" >关于模型量化编译流程 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一小节内容，让您理解地平线PTQ和QAT方案的关系，便于您可以在不同情况下选择更合适的模型处理方案；</em></li>
<li><em>最后，<a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/accuracy_evaluation.html#qat-quantzation-compile" >QAT模型量化编译 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 则是为您引入通过QAT方案完成量化模型编译的介绍。</em></li>
</ul>
<p><em>目前在GPU上训练的模型大部分都是浮点模型，即参数使用的是float类型存储。 地平线BPU架构的AI芯片使用的是int8的计算精度（业内AI芯片的通用精度），能运行定点量化模型。 那么 <strong>从训练出的浮点精度转为定点模型的过程，我们叫做量化。</strong></em></p>
<p><em><strong>量化方法有两种，分别为</strong>：</em></p>
<ul>
<li><p><em><strong>后量化（post training quantization，PTQ）</strong>：</em></p>
<p><em>先训练浮点模型，然后使用校准图片计算量化参数，将浮点模型转为量化模型。 该方法简单、快捷，但将浮点模型直接转为量化模型难免会有一些量化损失。</em></p>
<p><em><strong>注意</strong>：关于PTQ模型的量化和编译流程， <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html" >模型量化与编译 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 已为您做出了详细介绍。</em></p>
</li>
<li><p><em><strong>量化感知训练（quantization aware training，QAT）</strong>：</em></p>
<p><em>在浮点训练的时候，就先对浮点模型结构进行干预，增加量化误差，使得模型能够感知到量化带来的损失。 该方法需要用户在全量训练集上重新训练，能有效地降低量化部署的量化误差。 一些社区框架都提供QAT方案，例如pytorch的eager mode方案、pytorch的fx graph方案、tf-lite量化方案等。</em></p>
<p><em><strong>QAT训练与浮点训练的关系</strong></em></p>
<p><em>QAT训练是一种finetune方法，最好是在浮点结果已经拟合的情况下，再用QAT方法提升量化精度。 即用户的训练分为了两个步骤，先训练浮点模型，将模型精度提升到满意的指标；再通过QAT训练，提升量化精度。</em></p>
<p><em>为了让模型更好的感知到量化误差，QAT训练需要使用全量的训练数据集。 训练轮数和模型难度相关，大约是原来的浮点训练的1&#x2F;10。 因为是在浮点模型上finetune，所以QAT训练的学习率尽量和浮点模型的最后几个epoch一致。</em></p>
</li>
</ul>
<p><em><strong>关于模型转换</strong></em></p>
<p><em>模型转换是指将原始浮点模型转换为地平线混合异构模型的过程。 其中会包括模型前处理节点修改、原始模型图优化、模型量化和上板模型编译等过程。</em></p>
<p><em><strong>原始浮点模型</strong> （文中部分地方也称为浮点模型）是指您通过TensorFlow&#x2F;PyTorch等等DL框架训练得到的可用模型，这个模型的计算精度为float32； 目前我们的QAT方案中，训练工具基于Pytorch开发，因此只支持Pytorch格式的模型。 PTQ方案只支持Caffe&amp;ONNX模型格式，因此对于TensorFlow&#x2F;PyTorch等格式的模型，需要先通过转换到ONNX模型后，才能够被地平线的工具进行量化&amp;编译。</em></p>
<p><em><strong>混合异构模型</strong> 是一种适合在地平线芯片上运行的模型格式，之所以被称为异构模型是因为它能够支持模型同时在ARM CPU和BPU上执行。 由于在BPU上的运算速度会远大于CPU上的速度，因此会尽可能的将算子放在BPU上运算。 对于BPU上暂时不支持的算子，则会放在CPU上进行运算。</em></p>
<p><em><strong>关于模型量化编译流程</strong></em></p>
<p><em>正常的模型量化编译流程如下图所示：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509161118772.png"
                      class="" title="image-20230509161118772"
                ></em></p>
<p><em><strong>注意：由于PTQ方式的使用代价小，因此推荐用户首先尝试该方法进行模型量化编译。 若尝试并调优后的模型精度依然无法满足要求，则可以再改为尝试QAT方案。</strong></em></p>
<p><em><strong>QAT模型量化编译介绍</strong></em></p>
<p><em>Horizon Plugin Pytorch参考了PyTorch官方的量化接口和思路，Plugin采用的是Quantization Aware Training(QAT)方案， 因此建议用户先阅读 <a class="link"   target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/quantization.html#quantization" >PyTorch官方文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中和QAT相关部分。</em></p>
<p><em>更详细的关于Horizon Plugin Pytorch的介绍，您可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/plugin/source/index.html" >量化感知训练（QAT） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<blockquote>
<p><em>其他模型工具</em></p>
</blockquote>
<p><em>本节将对上述常规流程中不涉及的工具做统一介绍，这些工具是为某些特定需要提供，如果有类似的需求，可以酌情选用。</em></p>
<p><em><strong>模型打包</strong></em></p>
<p><em>模型打包提供了将多个转换后bin模型整合成一个文件的功能， 应用开发阶段，我们也为打包后模型提供了相关的接口，在您业务场景中模型比较多的时候可以使用。 打包工具 <code>hb_pack</code> 使用命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_pack -o dst_name.bin  to_pack_1.bin to_pack_2.bin</span><br></pre></td></tr></table></figure></div>

<p><em>工具使用 <code>-o</code> 参数指定打包后文件名称。</em></p>
<p><em>需要打包的bin模型依次在命令尾部添加，使用空格分隔即可。</em></p>
<p><em><strong>模型信息查看</strong></em></p>
<p><em>模型信息查看工具可以提供模型转换时使用的配置参数信息，其使用命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_info model_name.bin</span><br></pre></td></tr></table></figure></div>

<p><em><code>hb_model_info</code> 后加上模型名称即可，如果您使用的是打包后模型，需要带上一个在 <code>hb_model_info</code> 后先加上一个 <code>-p</code> 参数。 命令执行后会输出一些转换环境信息和转换配置中使用的配置参数信息，转换配置参数解读请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#makertbin" >使用 hb_mapper makertbin 工具转换模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分介绍。</em></p>
<p><em><strong>bin模型节点修改</strong></em></p>
<p><em>出于某些极大尺寸输入场景下的极致性能需求，部分输入的量化和转置操作可以融合在数据前处理中一并完成。 此时您可以选择使用 <code>hb_model_modifier</code> 工具移除这些节点（目前工具支持移除的节点包括： 指定的runtime模型中输入端的Transpose、Quantize、Cast、Reshape节点和输出端的Transpose、Dequantize、Cast、Reshape、Softmax节点）， 使用命令如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier  bin_file  -r &#123;node_name&#125;</span><br></pre></td></tr></table></figure></div>

<p><em><code>-r</code> 参数指定需要删除的节点名称。</em></p>
<p><em><code>-o</code> 指定删除节点后产生的新模型文件名称。</em></p>
<p><em><code>-a/--all</code> 指定节点类型，支持一键删除所有对应类型的功能。若有多个类型节点需要删除, 需要指定多次。</em></p>
<p><em>需要删除的节点名称必须与bin模型中的名称完全一致，且每次调用工具只能删除一个节点。 在 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/performance_evaluation.html#hb-perf" >使用hb_perf工具估计性能 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分介绍的 <strong>BIN Model Structure</strong> 中可以查看节点名称。</em></p>
<p><em><strong>注意：删除节点的操作可能会改变模型输入输出信息，可以通过 <code>hb_model_info</code> 工具查看被删除节点信息，输出信息末尾会打印被删除节点的名称， 同时会生成 <code>deleted_nodes_info.txt</code> 文件， 文件中每一行记录了对应被删除节点的初始信息，可据此自行实现量化&#x2F;反量化等处理逻辑。</strong></em></p>
<blockquote>
<p><em>训练后量化（PTQ）常见问题</em></p>
</blockquote>
<p> <em><strong>如何理解算子约束中提及的BPU加速和CPU计算两种形式</strong></em></p>
<ul>
<li><em>BPU加速：是指模型在板端推理时，该算子可以通过BPU硬件进行量化加速。其中，大部分算子（如conv等）是硬件直接支持的； 有些会被替换成其他算子实现加速（如gemm会被替换成conv）；还有一些则依赖特定的上下文（如Reshape、Transpose需要前后均为BPU算子）才能被动量化。</em></li>
<li><em>CPU计算：对于模型中BPU硬件无法直接或间接加速的算子，工具链会将其放在CPU上计算，runtime预测库也会在模型推理时自动完成执行硬件的异构调度。</em></li>
</ul>
<p> <em><strong>如何理解模型分段的性能影响</strong></em></p>
<p><em>当模型在BPU算子中间存在不能加速的CPU算子时，就会被切分成不同的Subgraph（模型转换日志中会通过不同的id号进行区分），从而引入一定的性能损耗，具体包括两方面：</em></p>
<ul>
<li><em>CPU算子性能远低于BPU算子；</em></li>
<li><em><strong>CPU和BPU之间的异构调度还会引入量化、反量化算子（运行在CPU上）</strong>，且因为内部计算需要遍历数据，所以其耗时会与shape大小成正比。</em></li>
</ul>
<p><em>以上CPU算子和量化、反量化算子均可通过板端工具hrt_model_exec传入 <code>profile_path</code> 参数实测得到。地平线建议您尽量选择BPU算子搭建模型，以获取更好的性能表现。</em></p>
<blockquote>
<p><em>在这个异构调度过程中，可能涉及到量化和反量化算子。量化是指将浮点型数据转换为定点型或低精度的表示形式，以降低计算和存储开销。反量化则是将定点型或低精度的数据重新转换为浮点型数据。这些量化和反量化的操作通常需要在CPU上进行，因为CPU在处理复杂的算法和数据类型时具有更灵活的能力。</em></p>
</blockquote>
<p><em><strong>如何理解模型尾部部分BPU可加速算子运行在CPU上</strong></em></p>
<p><em>首先，我们需要理解以下两个概念：</em></p>
<ul>
<li><em>J5芯片算法工具链目前只在模型尾部支持Conv算子以int32高精度输出，其他算子都只能以int8低精度输出；</em></li>
<li><em>通常情况下，模型转换会在optimization阶段将Conv与其后的BN和ReLU&#x2F;ReLU6融合在一起进行计算。 但由于BPU硬件本身限制，在模型尾部以int32高精度输出的Conv却并不支持算子融合。</em></li>
</ul>
<p><em>所以如果模型以Conv+ReLU&#x2F;ReLU6结尾，那么为了保证量化模型的整体精度，Conv会默认以int32高精度输出，ReLU&#x2F;ReLU6则会跑在CPU上。 同理，其他尾部可加速算子运行在CPU上也都是默认精度优先的选择。不过，地平线支持在yaml文件将这些算子配置 <code>run_on_bpu</code> ，从而获取更好的性能表现，但会引入一定的精度损失。</em></p>
<p><em><strong>是否支持非对称量化</strong></em></p>
<p><em>目前地平线的J5芯片算法工具链默认为对称量化，非对称量化仅会在少数情况下会被default校准方式搜索到，暂不支持用户主动开启。</em></p>
<p><em><strong>如何理解地平线的default校准方式</strong></em></p>
<p><em>为了减轻用户调试校准方案的工作量，地平线提供了default自动搜索策略，当前其内部逻辑如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509163550937.png"
                      class="" title="image-20230509163550937"
                ></em></p>
<ul>
<li><em>Step1：尝试Max、Max-Percentile 0.99995和KL三种校准方法，计算得到分别的余弦相似度。 如果三种方法中的最高余弦相似度小于0.995，进入Step2；反之，返回最高相似度对应的阈值组合。</em></li>
<li><em>Step2：尝试Max-Percentile 0.99995和perchannel量化的组合方法，如果四种方法中的最高余弦相似度小于0.995，进入Step3； 反之，返回最高相似度对应的阈值组合。</em></li>
<li><em>Step3：选取Step2中最高余弦相似度对应的方法，应用非对称量化作为第5种方法，根据余弦相似度选取5种方案中的最佳方案， 返回对应的阈值组合。</em></li>
</ul>
<p><em><strong>如何理解地平线的mix校准方式</strong></em></p>
<p><em>为了集成不同校准方法的优势，地平线提供了mix搜索策略，当前其内部逻辑如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509163811644.png"
                      class="" title="image-20230509163811644"
                ></em></p>
<ul>
<li><em>Step1：采用KL校准方法，计算当前模型中节点的量化敏感度（使用余弦相似度来衡量），将值小于特定阈值的节点定义为 量化敏感节点（对模型量化精度影响较大的节点）。</em></li>
<li><em>Step2：遍历所有量化敏感节点，在每一个节点上尝试Max、Max-Percentile 0.99995和KL三种校准方法， 并为该节点选出最佳的校准方法，最终得到Mix校准模型。</em></li>
<li><em>Step3：评估Mix、Max、Max-Percentile 0.99995和KL校准模型的累积误差情况，输出最优模型。</em></li>
</ul>
<p> <em><strong>如何理解yaml文件中的编译器优化等级参数</strong></em></p>
<p><em>在模型转换的yaml配置文件中，编译参数组提供了optimize_level参数来选择模型编译的优化等级，可选范围为 O0~O3。其中：</em></p>
<ul>
<li><em>O0 不做任何优化，<strong>编译速度最快，适合在模型转换功能验证、调试不同校准方式时使用。</strong></em></li>
<li><em>O3 优化等级最高，可以获得模型最佳性能，但编译时间也相对较长。</em></li>
<li><em>在 O1～O3 范围内，优化等级越高，编译优化时的搜索空间就会越大。同时，一些比较耗时的优化策略也仅会在 O2&#x2F;O3 等级才会启用。</em></li>
<li><em>编译器的优化策略并不是算子粒度层面的，而是针对整个模型的全局优化。</em></li>
</ul>
<p><em><strong>为何nv12 模型 hb_perf 得出的输入大小和预测库不一致？</strong></em></p>
<p><em>NV12图像格式属于YUV颜色空间中的YUV420SP格式，是摄像头可直接输出的视频格式。由于一般在实际训练时不会使用这种格式， 因此底层硬件拿到摄像头输出的数据后，会先将其转换为yuv444的格式再进行后续推理（该转换过程用户不感知，板端推理时只需依据模型转换时配置的input_type_rt准备对应类型的数据即可）。 hb_perf工具显示的是nv12数据的大小（即NxHxWx3&#x2F;2），而板端hrt_model_exec model_info获取到的数据大小则是模型真实输入的数据大小（即NxHxWx3）。 <strong>且由于nv12数据已经不具有channel的概念了，板端部署时用户只需依据输入节点的H和W信息，准备对应大小的nv12数据即可。</strong></em></p>
<p><em><strong>量化模型和上板bin模型的输入的数据排布是否一定一致</strong></em></p>
<p><em>onnx模型和上板bin模型的输入数据排布 <strong>不一定完全一致</strong> 。.bin的输入数据排布与yaml配置文件中的input_layout_rt对齐，但quanti.onnx的数据排布则会因为多种因素发生改变，例如：</em></p>
<ul>
<li><em>当模型的input type rt设置为 <strong>nv12</strong> 时，input_source默认为 <strong>pyramid</strong> ， 当输入为pyramid时，量化模型quanti.onnx 的输入均为NHWC。</em></li>
<li><em>当input type rt为 <strong>yuv444&#x2F;rgb&#x2F;bgr</strong> 等类型时，input_source 默认为 <strong>ddr</strong> ， 此时量化模型quanti.onnx 的输入与原始浮点模型一致。</em></li>
</ul>
<p><em>此外其他场景也有可能会出现</em><em>.onnx与</em><em>.bin输入数据排布不一致的情况。</em></p>
<p><em>因此，当您在PC端推理</em>**.onnx时，建议使用可视化工具查看一下onnx模型的输入shape，并准备对应的数据。 当在板端推理.bin模型时，则依据转换时配置的input_layout_rt或使用工具hrt_model_exec model_info以及BPU SDK相关API（hbDNNGetInputTensorProperties()）获取.bin模型的输入shape。 当您使用同一张图片推理quanti.onnx以及.bin发现输出结果差异很大时，建议您先排查输入数据排布是否正确。*</p>
<blockquote>
<p><em>在深度学习中，金字塔（pyramid）是指一种多尺度的技术，其可以使用不同尺度的特征图来改进模型的性能。</em></p>
<p><em>金字塔技术最初用于计算机视觉领域，用于解决图像尺度的问题。当使用一个固定的尺度进行计算时，无法提取出各种尺度的特征信息，因此需要对图像进行金字塔处理，从而在多个不同的尺度上进行分析。在深度学习中，金字塔技术同样适用于解决特征提取的尺度问题。</em></p>
<p><em>在深度学习中的金字塔主要有两种类型：</em></p>
<ol>
<li><em><strong>图像金字塔</strong>：这种金字塔方法从原始图像开始，按照不同的尺度对图像进行缩放，随后将每个尺度的图像输入到模型中进行特征提取，从而得到不同尺度的特征。图像金字塔一般在卷积神经网络（CNN）和图像分割中使用。</em></li>
<li><em><strong>特征金字塔</strong>：这种金字塔方法在模型的中间层收集多尺度的特征图，通过上采样、插值等方式将不同尺度的特征图进行对齐，从而允许特征图在多个尺度上进行分类或者分割。特征金字塔一般在实现目标检测等任务时使用。</em></li>
</ol>
<p><em>在深度学习中，金字塔技术可以增强模型对不同尺度的输入的敏感性。通过使用多尺度的特征图，模型能够在不同的层次上对输入进行分析，从而提高分类、检测、分割等任务的精度和鲁棒性。</em></p>
</blockquote>
<p><em><strong>如何编译得到多 batch 模型</strong></em></p>
<p><em>根据原模型种类，我们将分为动态输入模型和非动态输入模型来讨论这个问题。</em></p>
<p><em><strong>注意：</strong></em></p>
<ul>
<li><em><code>input_batch</code> 参数仅在单输入且 <code>input_shape</code> 第一维为1的时候可以使用。</em></li>
<li><em>每份校准数据shape大小，应和 <code>input_shape</code> 的大小保持一致。</em></li>
</ul>
<p><em>动态输入模型：如果原模型为动态输入模型时，比如，? x3x224x224（动态输入模型必须使用input_shape参数指定模型输入信息）。</em></p>
<p><em>1.当配置input_shape为1x3x224x224时， 如果您想编译得到多batch的模型，可以使用 <code>input_batch</code> 参数，此时每份校准数据shape大小为1x3x224x224。</em></p>
<p><em>2.当配置input_shape的第一维为大于1的整数时，原模型本身将会认定为多batch模型，将无法使用 <code>input_batch</code> 参数，且需要注意每份校准数据shape大小。例如配置input_shape为4x3x224x224时， 此时每份校准数据shape大小为4x3x224x224。</em></p>
<p><em>非动态输入模型：</em></p>
<p><em>1.当输入的input shape[0]为1 ，且是单输入模型时，可以使用 <code>input_batch</code> 参数。每份校准数据shape大小与原模型shape保持一致。</em></p>
<p><em>2.当输入的input shape[0]不为1，不支持使用 <code>input_batch</code> 参数。</em></p>
<p><em><strong>多输入模型在转换过程中，模型输入顺序发生变化，此种情况正常么</strong></em></p>
<p><em>此种情况是正常现象，多输入模型在转换过程中，模型输入顺序是有可能发生变化的。 可能发生的情况如下例所示：</em></p>
<ul>
<li><em>原始浮点模型输入顺序：input1、input2、input3。</em></li>
<li><em>original.onnx模型输入顺序：input1、input2、input3。</em></li>
<li><em>quanti.onnx模型输入顺序：input2、input1、input3。</em></li>
<li><em>bin模型输入顺序：input3、input2、input1。</em></li>
</ul>
<p><em><strong>注意：</strong></em></p>
<ul>
<li><em>当您做精度一致性对齐时，请确保输入顺序是正确的，不然有可能会影响精度结果。</em></li>
<li><em>如果您想查看bin模型输入的顺序，可以使用 <code>hb_model_info</code> 指令来查看，input_parameters info分组中列出的输入顺序，即为bin模型的输入顺序。</em></li>
</ul>
<blockquote>
<p><em>在多输入模型的转化过程中，输入顺序发生变化的原因是由于在不同框架之间传递模型时，<strong>输入的顺序可能被解释器重新安排</strong>。</em></p>
<p><em>具体来说，在深度学习模型的转化过程中，通常会通过各种解释器或转换器将模型从一个框架转换到另一个框架。在这一过程中，解释器通常要求模型的输入顺序以及各个输入的名称与框架的要求相匹配。因此，如果源框架和目标框架之间存在差异，例如输入顺序或输入名称不同，那么在转换过程中就会发生重新排列。</em></p>
<p><em>此外，由于多输入模型的神经网络架构通常比较复杂，有多个层级，不同的层级可能对于不同的输入输入数据进行处理和计算，因此在不同的框架之间传递多输入模型时，需要确保输入数据和计算结果的顺序正确。如果在模型转换过程中发生输入顺序的错误或混淆，可能会产生错误的计算结果，从而影响模型的准确性和性能。</em></p>
</blockquote>
<p><em><strong>如何理解PTQ模型转换过程中的主动量化和被动量化</strong></em></p>
<p><em>在模型成功转换成bin模型后，可能会出现发现仍然有个别op运行在CPU上的情况，但回头仔细对照工具链算子约束列表，明明该op是符合算子约束条件的，也就是理论上该算子应该成功运行在BPU上，为什么仍然是CPU计算呢？</em></p>
<blockquote>
<p><em>自定义算子开发</em></p>
</blockquote>
<p><em><strong>简介</strong></em></p>
<p><em>地平线工具链中已经支持了丰富的算子，在大多数情况下，您的模型应该可以通过前文所述模型转换顺利部署到地平线芯片上。 已支持的算子情况可以参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/supported_op_list.html" >模型转换工具链算子支持约束列表 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。 少部分算子不支持情况下，我们强烈建议您先尝试下替换算子的可能性，这样有利于将地平线芯片能力充分发挥出来，且开发成本会更低。</em></p>
<p><em>自定义算子只提供CPU上算子开发能力，一个完整的自定义算子应用过程包括创建模板、算子实现、算子编译、 含自定义算子模型转换和运行含自定义op模型几个阶段。具体流程如下图所示:</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230509180655936.png"
                      class="" title="image-20230509180655936"
                ></em></p>
<p><em>如图所示，定义自定义OP需要有两部分的任务：在模型转换阶段，需要提供自定义OP的python代码；在模拟器&#x2F;上板运行推理阶段，需要提供自定义OP的C++代码。 要确保这两部分的代码运算的一致性。</em></p>
<p><em><strong>含自定义算子的模型转换</strong></em></p>
<p><em><strong>模型文件修改</strong></em></p>
<p><em>在准备好自定义算子实现后，为了将算子应用起来，您需要从原始模型文件和模型转换配置两个方面做出相应调整 (下面分别以 <code>Caffe</code> 模型和 <code>ONNX</code> 模型为例)。</em></p>
<p><em><strong>caffe模型</strong></em></p>
<p><em>原始模型文件中，将自定义算子对应的算子类型标记为 <code>Custom</code>，并提供一组 <code>custom_param</code>，示例如下。</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;hr_op&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Custom&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;res3d_in&quot;</span></span><br><span class="line">  top: <span class="string">&quot;res3d&quot;</span></span><br><span class="line">  custom_param &#123;</span><br><span class="line">    kind: <span class="string">&quot;CustomIdentity&quot;</span></span><br><span class="line">    shape &#123;</span><br><span class="line">      dim: <span class="number">1</span></span><br><span class="line">      dim: <span class="number">512</span></span><br><span class="line">      dim: <span class="number">28</span></span><br><span class="line">      dim: <span class="number">28</span></span><br><span class="line">    &#125;</span><br><span class="line">    params: <span class="string">&quot;&#x27;kernel_size&#x27;: 10 \n&#x27;threshold&#x27;: 0.5&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>以上完整 <code>custom_param</code> 示例中。 <code>kind</code> 是自定义算子的内部实现名称，该自定义OP为恒等OP，因此命名为 <code>CustomIdentity</code>，该名称在后续Python及C++代码中均会体现； <code>shape</code> 是算子的输出尺寸，需要完整指定；<code>params</code> 是算子的传入参数指定形式为 <code>&#39;param_name&#39;: param_value</code>， 多个参数之间使用 <code>\n</code> 分隔。</em></p>
<blockquote>
<p> <em>“kind” 是指自定义算子（Custom Operator）的内部实现名称。自定义算子是在深度学习框架中用户自定义的操作，可以根据具体需求实现一些特定功能的操作。在这个例子中，自定义算子的功能是恒等操作，即输入和输出完全相等，不做任何变换。</em></p>
<p> <em>为了在代码中标识和引用这个自定义算子，需要给它一个名称，这个名称在代码中被称为 “kind”。在这个例子中，这个自定义算子的名称被命名为 “CustomIdentity”，表示它是一个自定义的恒等操作。</em></p>
<p> <em>通过给自定义算子命名，可以在代码中使用这个名称来调用和使用该算子。这样，当需要使用恒等操作时，可以直接引用该自定义算子的名称，而不需要每次都重新编写相同的代码。这样能够提高代码的可读性和可维护性。</em></p>
</blockquote>
<p><em>在模型转换配置中，使用自定义算子需要在配置文件中加入一个新的自定义op参数组如下：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#...</span></span><br><span class="line"></span><br><span class="line">custom_op:</span><br><span class="line">  <span class="comment"># 自定义op的校准方式</span></span><br><span class="line">  custom_op_method: register</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 自定义OP的实现文件</span></span><br><span class="line">  op_register_files: sample_custom.py</span><br></pre></td></tr></table></figure></div>

<p><em>对于 <code>Caffe</code> 模型，以上参数组中，三个参数都是必须配置的。 <code>custom_op_method</code> 固定使用 <code>register</code>； <code>op_register_files</code> 是自定义算子计算的实现文件，请使用相对路径。</em></p>
<p><em>完成这些配置后，模型转换的后续步骤与其他一般模型转换过程一致。</em></p>
<p><em><strong>ONNX模型</strong></em></p>
<ol>
<li><em>含有自定义算子的Onnx模型的获取:</em></li>
</ol>
<ul>
<li><em>从pytorch等其他框架转换而来</em></li>
</ul>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> horizon_nn.horizon_onnx.onnx_pb <span class="keyword">import</span> TensorProto</span><br><span class="line"><span class="keyword">from</span> torch.onnx.symbolic_helper <span class="keyword">import</span> parse_args</span><br><span class="line"><span class="keyword">from</span> torch.onnx.utils <span class="keyword">import</span> register_custom_op_symbolic</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> Tensor</span><br><span class="line"></span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;pytorch/vision:v0.10.0&#x27;</span>, <span class="string">&#x27;googlenet&#x27;</span>, pretrained=<span class="literal">True</span>)	<span class="comment">#使用torch.hub加载语寻李娜的GoogleNet模型，通过torch.hub可以方便地从PyTorch官方提供的预训练模型中加载指定的模型。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_transform_input</span>(<span class="params">x: Tensor</span>) -&gt; Tensor:	<span class="comment">#这是一个辅助函数，用于对输入进行转换。</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model._transform_input = _transform_input</span><br><span class="line"></span><br><span class="line"><span class="meta">@parse_args(<span class="params"><span class="string">&quot;v&quot;</span>, <span class="string">&quot;v&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">horizon_pool</span>(<span class="params">g, <span class="built_in">input</span>, output_size</span>):		<span class="comment">#这段代码定义了一个名为horizon_pool的自定义操作。它接受一个输入张量(input)和输出尺寸(output_size)作为参数，并使用g.op函数创建了一个自定义操作节点。</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> g.op(</span><br><span class="line">        <span class="string">&#x27;horizon.custom::PyOp&#x27;</span>, <span class="comment">#required, ! must be &#x27;horizon.custom&#x27; domain ! 这是操作节点的类型，指定了自定义操作的类型。在这个例子中，&#x27;horizon.custom::PyOp&#x27; 表示使用自定义操作 &#x27;PyOp&#x27;。</span></span><br><span class="line">        <span class="built_in">input</span>,</span><br><span class="line">        class_name_s=<span class="string">&quot;GlobalAveragePool&quot;</span>,  <span class="comment">#required ! must match the class def name in sample_custom python file !</span></span><br><span class="line">        compute_s=<span class="string">&quot;compute&quot;</span>,  <span class="comment">#optional, &#x27;compute&#x27; by default</span></span><br><span class="line">        module_s=<span class="string">&quot;sample_custom&quot;</span>,  <span class="comment">#required ! must match the file name of the &quot;op_register_files&quot; !</span></span><br><span class="line">        input_types_i=[TensorProto.FLOAT],  <span class="comment">#required  这是输入张量的类型列表，指定了输入张量的类型。在这个例子中，输入张量的类型为 FLOAT。</span></span><br><span class="line">        output_types_i=[TensorProto.FLOAT],  <span class="comment">#required</span></span><br><span class="line">        output_shape_s=[<span class="string">&quot;1, 1024, 1, 1&quot;</span>]) <span class="comment">#required  这是输出张量的形状，指定了输出张量的形状。在这个例子中，输出张量的形状为 [1, 1024, 1, 1]。</span></span><br><span class="line"></span><br><span class="line">d_input = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)		<span class="comment">#这里创建了一个形状为(1, 3, 224, 224)的随机张量作为输入。</span></span><br><span class="line">register_custom_op_symbolic(<span class="string">&#x27;::adaptive_avg_pool2d&#x27;</span>,</span><br><span class="line">                            horizon_pool,</span><br><span class="line">                            opset_version=<span class="number">11</span>)		<span class="comment">#这里注册了一个自定义操作符号化函数，用于将自定义操作转换为ONNX图中的节点。</span></span><br><span class="line">torch.onnx.export(model, d_input, <span class="string">&quot;googlenet_cop.onnx&quot;</span>, opset_version=<span class="number">11</span>)		<span class="comment">#通过torch.onnx.export函数将模型导出为ONNX格式，并保存为&quot;googlenet_cop.onnx&quot;文件。opset_version参数指定了使用的ONNX版本。</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>提供输入张量是为了确定模型的输入形状，以便在导出的ONNX模型中正确定义输入节点。</em></p>
</blockquote>
<blockquote>
<p><em>在<code>register_custom_op_symbolic</code>函数中，第一个参数<code>&#39;::adaptive_avg_pool2d&#39;</code>是要注册的自定义操作的名称。这里的名称是指定的字符串 <code>&#39;::adaptive_avg_pool2d&#39;</code>，它用于标识要注册的自定义操作的符号化函数。这个名称可以是任意的，但是需要与模型定义中使用的相应操作名称保持一致。</em></p>
</blockquote>
<blockquote>
<p><em>在代码中使用自定义 domain 前，需要先注册该 domain。这可以通过调用 <code>torch.onnx.register_custom_op_symbolic()</code> 函数来实现。</em></p>
<p><em>在注册过程中，需要提供自定义算子的名称和对应的符号函数。符号函数负责定义算子在 ONNX 图中的行为和操作。它将接收符号图 (<code>g</code>) 和输入参数，然后返回用于表示算子行为的 ONNX 图节点。</em></p>
<p><em>在注册自定义算子时，需要确保为其指定正确的 domain 名称。这样，ONNX 解析器在解析模型时能够识别并处理该自定义算子。</em></p>
<p><em>当没有指定 <code>domain</code> 属性时，<code>register_custom_op_symbolic</code> 函数会将自定义算子默认注册到 ONNX 标准的 <code>onnx</code> domain 下。这意味着自定义算子会被默认视为标准的 ONNX 算子。</em></p>
<p><em>如果希望将自定义算子注册到不同的 <code>domain</code> 下，可以在 <code>register_custom_op_symbolic</code> 函数中指定 <code>domain</code> 参数的值，例如：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pythonCopy code</span><br><span class="line">register_custom_op_symbolic(&#x27;::my_custom_op&#x27;, my_custom_op, domain=&#x27;my_domain&#x27;)</span><br></pre></td></tr></table></figure></div>

<p><em>这样就将自定义算子注册到名为 <code>&#39;my_domain&#39;</code> 的自定义 <code>domain</code> 下。这在处理具有多个自定义算子或将自定义算子与特定的实现关联时可能会有用。</em></p>
</blockquote>
<blockquote>
<p><em>在深度学习框架中，<code>g.op</code> 是一个用于创建操作节点（Operator Node）的函数。在上述代码中，<code>g.op</code> 函数用于创建一个操作节点，具体的参数解析如下：</em></p>
<ul>
<li><em>第一个参数：操作节点的名称，这里是 <code>&#39;horizon.custom::PyOp&#39;</code>，它指定了自定义算子的名称和所属的 <code>domain</code>。</em></li>
<li><em>后续参数：操作节点的输入和属性信息，以关键字参数的形式传递。</em></li>
</ul>
</blockquote>
<ul>
<li><em>直接生成onnx模型</em></li>
</ul>
<p><em>参考代码：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> onnx <span class="keyword">import</span> helper, checker, shape_inference, numpy_helper, TensorProto</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_normal_data</span>(<span class="params">shape</span>):</span><br><span class="line">    <span class="keyword">return</span> np.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">1.0</span>, size=shape).astype(np.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># conv</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_simple_model</span>():</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create nodes</span></span><br><span class="line">    conv_input_shape = (<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    conv_output_shape = (<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"></span><br><span class="line">    add_param_shape = (<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    add_1_param_data = np.zeros(add_param_shape).astype(np.float32)</span><br><span class="line">    add_2_param_data = np.ones(add_param_shape).astype(np.float32)</span><br><span class="line"></span><br><span class="line">    conv_weight_shape = (<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    conv_output_shape = (<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    conv_weight_data = make_normal_data(conv_weight_shape)</span><br><span class="line"></span><br><span class="line">    add_1_node = helper.make_node(</span><br><span class="line">        <span class="string">&quot;PyOp&quot;</span>,  <span class="comment"># required, 类型必须是&#x27;PyOp&#x27;</span></span><br><span class="line">        name=<span class="string">&quot;add_1&quot;</span>,  <span class="comment"># required, 不同的op名称不能相同</span></span><br><span class="line">        inputs=[<span class="string">&quot;input0&quot;</span>, <span class="string">&quot;add_1_param&quot;</span>],  <span class="comment"># required, 需要是一个list, 且需要与实现文件中的输入数量保持一致</span></span><br><span class="line">        outputs=[<span class="string">&quot;add_1_out&quot;</span>],  <span class="comment"># required, 需要是一个list, 且需要与实现文件中的输出数量保持一致</span></span><br><span class="line">        </span><br><span class="line">        domain=<span class="string">&quot;horizon.cop1&quot;</span>,  <span class="comment"># required, 不同实现逻辑的自定义算子实现需要通过不同的domain名称来实现</span></span><br><span class="line">        </span><br><span class="line">        class_name=<span class="string">&quot;Cop1&quot;</span>,  <span class="comment"># required, 需要与自定义算子的实现文件中的class名称一致</span></span><br><span class="line">        module=<span class="string">&quot;custom_op.horizon_ops&quot;</span>,  <span class="comment"># required, 需要与包含自定义算子的实现文件的路径一致</span></span><br><span class="line">        compute=<span class="string">&quot;compute&quot;</span>,  <span class="comment"># required, 需要与自定义算子实现class中的计算逻辑函数一致</span></span><br><span class="line">        input_types=[</span><br><span class="line">            TensorProto.FLOAT,</span><br><span class="line">            TensorProto.FLOAT,</span><br><span class="line">        ],  <span class="comment"># required, 需要是一个list, 其长度需要与该算子的inputs属性数量一致, 且与实现文件中的输入数量保持一致</span></span><br><span class="line">        output_types=[</span><br><span class="line">            TensorProto.FLOAT</span><br><span class="line">        ],  <span class="comment"># required, 需要是一个list, 其长度需要与该算子的outputs属性数量一致, 且与实现文件中的输出数量保持一致</span></span><br><span class="line">        output_shape=[<span class="string">&quot;1, 3, 224, 224&quot;</span>],  <span class="comment"># optional, 在模型中未添加pyop的输出 value_info时, 必须填写</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    add_2_node = helper.make_node(</span><br><span class="line">        <span class="string">&quot;PyOp&quot;</span>,</span><br><span class="line">        name=<span class="string">&quot;add_2&quot;</span>,</span><br><span class="line">        inputs=[<span class="string">&quot;input1&quot;</span>, <span class="string">&quot;add_1_out&quot;</span>, <span class="string">&quot;add_2_param&quot;</span>],</span><br><span class="line">        outputs=[<span class="string">&quot;add_2_out&quot;</span>, <span class="string">&quot;output0&quot;</span>],</span><br><span class="line">        domain=<span class="string">&quot;horizon.cop2&quot;</span>,</span><br><span class="line">        class_name=<span class="string">&quot;Cop2&quot;</span>,</span><br><span class="line">        module=<span class="string">&quot;custom_op.horizon_ops&quot;</span>,</span><br><span class="line">        compute=<span class="string">&#x27;compute&#x27;</span>,</span><br><span class="line">        input_types=[TensorProto.FLOAT, TensorProto.FLOAT,</span><br><span class="line">                     TensorProto.FLOAT],  <span class="comment">#required</span></span><br><span class="line">        output_types=[TensorProto.FLOAT, TensorProto.FLOAT],  <span class="comment">#required</span></span><br><span class="line">        output_shape=[<span class="string">&quot;1, 3, 224, 224&quot;</span>, <span class="string">&quot;1, 3, 224, 224&quot;</span>])</span><br><span class="line"></span><br><span class="line">    conv_1_node = helper.make_node(<span class="string">&quot;Conv&quot;</span>,</span><br><span class="line">                                   inputs=[<span class="string">&quot;add_2_out&quot;</span>, <span class="string">&quot;W0&quot;</span>],</span><br><span class="line">                                   outputs=[<span class="string">&quot;output1&quot;</span>],</span><br><span class="line">                                   dilations=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   group=<span class="number">1</span>,</span><br><span class="line">                                   kernel_shape=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   pads=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   name=<span class="string">&quot;conv_1&quot;</span>)</span><br><span class="line">    <span class="comment"># nodes</span></span><br><span class="line">    nodes = [add_1_node, add_2_node, conv_1_node]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># inputs</span></span><br><span class="line">    model_input_1 = helper.make_tensor_value_info(<span class="string">&quot;input0&quot;</span>, TensorProto.FLOAT,</span><br><span class="line">                                                  conv_input_shape)</span><br><span class="line">    model_input_2 = helper.make_tensor_value_info(<span class="string">&quot;input1&quot;</span>, TensorProto.FLOAT,</span><br><span class="line">                                                  conv_input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Outputs</span></span><br><span class="line">    model_output_1 = helper.make_tensor_value_info(<span class="string">&quot;output0&quot;</span>,</span><br><span class="line">                                                   TensorProto.FLOAT,</span><br><span class="line">                                                   conv_output_shape)</span><br><span class="line">    model_output_2 = helper.make_tensor_value_info(<span class="string">&quot;output1&quot;</span>,</span><br><span class="line">                                                   TensorProto.FLOAT,</span><br><span class="line">                                                   conv_output_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Intermediate tensors</span></span><br><span class="line">    add_1_out = helper.make_tensor_value_info(<span class="string">&quot;add_1_out&quot;</span>, TensorProto.FLOAT,</span><br><span class="line">                                              conv_output_shape)</span><br><span class="line">    add_2_out = helper.make_tensor_value_info(<span class="string">&quot;add_2_out&quot;</span>, TensorProto.FLOAT,</span><br><span class="line">                                              conv_output_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create constant tensor</span></span><br><span class="line">    W0_tensor = helper.make_tensor(<span class="string">&quot;W0&quot;</span>, TensorProto.FLOAT, conv_weight_shape,</span><br><span class="line">                                   conv_weight_data.flatten())</span><br><span class="line"></span><br><span class="line">    add_1_param = helper.make_tensor(<span class="string">&quot;add_1_param&quot;</span>,</span><br><span class="line">                                     TensorProto.FLOAT, add_param_shape,</span><br><span class="line">                                     add_1_param_data.flatten())</span><br><span class="line">    add_2_param = helper.make_tensor(<span class="string">&quot;add_2_param&quot;</span>,</span><br><span class="line">                                     TensorProto.FLOAT, add_param_shape,</span><br><span class="line">                                     add_2_param_data.flatten())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make graph</span></span><br><span class="line">    graph = helper.make_graph(</span><br><span class="line">        nodes,</span><br><span class="line">        <span class="string">&quot;simple_conv_model&quot;</span>,</span><br><span class="line">        inputs=[model_input_1, model_input_2],  <span class="comment"># input</span></span><br><span class="line">        outputs=[model_output_1, model_output_2],  <span class="comment"># output</span></span><br><span class="line">        initializer=[W0_tensor, add_1_param, add_2_param],  <span class="comment"># initializer</span></span><br><span class="line">        value_info=[add_1_out, add_2_out],  <span class="comment"># value_info</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># make model</span></span><br><span class="line">    onnx_model = helper.make_model(graph,</span><br><span class="line">                                   opset_imports=[</span><br><span class="line">                                       helper.make_opsetid(<span class="string">&quot;&quot;</span>, <span class="number">11</span>),</span><br><span class="line">                                       helper.make_opsetid(<span class="string">&quot;horizon.cop1&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                                       helper.make_opsetid(<span class="string">&quot;horizon.cop2&quot;</span>, <span class="number">1</span>)</span><br><span class="line">                                   ],</span><br><span class="line">                                   producer_name=<span class="string">&quot;onnx-test&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shape inference</span></span><br><span class="line">    onnx_model = shape_inference.infer_shapes(onnx_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># # model check</span></span><br><span class="line">    checker.check_model(onnx_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># save model</span></span><br><span class="line">    onnx.save(onnx_model, <span class="string">&quot;custom_op.onnx&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><em>在深度学习中，”PyOp” 是指基于 Python 实现的自定义操作（Custom Operator）。<strong>PyOp 是一种扩展机制，允许用户根据自己的需求定义和实现自己的操作，从而扩展深度学习框架的功能。</strong></em></p>
<p><em>PyOp 提供了一个接口，使用户能够编写自定义的操作逻辑，包括前向传播和反向传播的计算。通过定义自己的 PyOp，用户可以在深度学习框架中使用自定义的算子，从而实现更复杂、更灵活的计算。</em></p>
<p><em>PyOp 通常需要提供输入和输出的描述信息，包括输入数据类型、输出数据类型以及输入输出的形状等。这些信息用于在模型导出或推理过程中进行类型和形状的匹配和检查。</em></p>
</blockquote>
<blockquote>
<p><em>在 ONNX（Open Neural Network Exchange）中，domain（领域）用于标识特定的算子集合或自定义算子的来源。它是一个用于区分不同算子组的命名空间，以避免冲突和命名重复。</em></p>
<p><em>ONNX 标准提供了一些内置的 domain，如 “ai.onnx”、”ai.onnx.ml” 等，用于存放标准算子。这些 domain 是 ONNX 规范的一部分。</em></p>
<p><em>对于自定义算子，为了避免与标准算子冲突，需要将它们定义在不同的 domain 下。<strong>通过将自定义算子放置在特定的 domain 中，可以确保算子的唯一性，并且在模型导出或运行时能够正确识别和加载。</strong></em></p>
<p><em>在给定的代码中，’horizon.custom::PyOp’ 中的 ‘horizon.custom’ 就是自定义算子所属的 domain。通过指定特定的 domain，可以确保自定义算子被正确地识别和解析，避免与 ONNX 标准算子发生冲突和混淆。如果不提供 domain，那么默认情况下会将算子视为标准算子，并尝试在标准的 ONNX domain 中查找对应的实现，这可能导致错误。因此，为了正确处理自定义算子，需要明确指定它们所属的 domain。</em></p>
<p><em><strong>需要注意的是，定义 domain 仅适用于自定义算子或扩展，对于标准的 ONNX 算子，不需要定义 domain，因为它们已经被分配到 ONNX 的标准 domain 中。</strong></em></p>
</blockquote>
<p><em><strong>注意：</strong>Onnx模型中PyOp属性的注意点:</em></p>
<ol>
<li><em><strong>domain属性一定要设置, 不然的话会被默认成onnx标准domain从而报错。不同实现的自定义算子需要设置在不同的domain下</strong>。</em></li>
<li><em>module需要与注册时使用的注册文件同名。若注册文件在当前目录的子文件夹中，则需要修改module内容。例如: 若 <code>sample_custom.py</code> 在当前路径的custom_op 文件夹中，则该module应设置为 <code>custom_op.sample_custom</code> 。</em></li>
<li><em>目前仅onnx模型支持多种类型的自定义算子，如您需要在其他框架中支持多种类型的自定义算子请联系地平线。</em></li>
</ol>
<p><em><strong>算子实现</strong></em></p>
<p><em>在模型转换阶段，需要提供自定义算子的Python实现，工具会利用该实现函数完成模型校准必需的推理阶段。</em></p>
<p><em>Python模板文件(sample_custom.py)如下:</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> horizon_nn.custom.op_registration <span class="keyword">import</span> op_implement_register, op_shape_infer_register</span><br><span class="line"></span><br><span class="line"><span class="meta">@op_implement_register(<span class="params"><span class="string">&quot;CustomIdentity&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomIdentity</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel_size, threshold</span>):</span><br><span class="line">        self._kernel_size = kernel_size</span><br><span class="line">        self._default_threshold = threshold</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="meta">@op_shape_infer_register(<span class="params"><span class="string">&quot;CustomIdentity&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">infer_shape</span>(<span class="params">inputs_shape</span>):</span><br><span class="line">    outputs_shape = inputs_shape</span><br><span class="line">    <span class="keyword">return</span> outputs_shape</span><br></pre></td></tr></table></figure></div>

<p><em>custom_op示例中的配置文件(horizon_ops.py)如下:</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> horizon_nn.custom.op_registration <span class="keyword">import</span> op_implement_register</span><br><span class="line"></span><br><span class="line"><span class="meta">@op_implement_register(<span class="params"><span class="string">&quot;Cop1&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cop1</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">        out = x1 + x2 + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@op_implement_register(<span class="params"><span class="string">&quot;Cop2&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cop2</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self, x1, x2, x3</span>):</span><br><span class="line">        out = x1 + x2 + x3 + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> out, out</span><br></pre></td></tr></table></figure></div>

<p><em>该文件的名字(sample_custom.py)需要填入模型转换的yaml配置文件中 <code>op_register_files</code> ，否则工具无法正常import自定义算子定义， 并且修饰器 <code>op_implement_register</code> 注册的custom op类的名称 <code>CustomIdentity</code> 需要与Caffe自定义OP的属性 <code>kind</code> 或者Onnx自定义OP的属性 <code>class_name</code> 一致。</em></p>
<p><em><strong>对于 <code>Caffe</code> 模型， <code>init</code> 函数中的参数(<code>kernel_size, threshold</code>)都是通过prototxt文件中的 <code>params</code> 传入的， 用于自定义op模块的初始化。 <code>op_shape_infer_register</code> 用于Caffe模型的算子shape注册。</strong></em></p>
<p><em>对于 <code>Onnx</code> 模型，*<em>自定义op的shape解析有两种方式，可以通过在创建onnx模型时，将pyop输出的value_info添加到onnx模型中， 或者在对应的pyop中创建output_shape属性。</em></em> 还需要注意自定义算子中的 <code>module</code> 必须与存放自定义算子实现的文件保持一致， 如果属性设置为 <code>custom_op.horizon_ops</code> ， 则自定义算子实现的文件名称为 <code>horizon_ops</code> ，且要放在 custom_op文件夹中， 保持与onnx模型的层级关系。 由于同一个domain中的同名算子实现必须相同， 因此不同的自定义算子的 <code>domain</code> 属性需要不同。*</p>
<p><em>上述操作完成后即可进行浮点转定点的操作，得到相应的bin文件（即 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_mapper.html#hb-mapper-makertbin" >模型编译命令（hb_mapper makertbin） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ）。</em></p>
<blockquote>
<p><em>含自定义算子的上板运行</em></p>
</blockquote>
<p><em>在拿到bin文件后，还不能直接在开发板上运行。在运行之前需要先提供自定义算子的C++代码实现。 <strong>可以使用下文提供的模板进行修改并添加到示例代码中进行使用。</strong></em></p>
<p><em>如果您只是希望测试自定义算子的功能，也可以直接使用我们提供的模版文件，模版文件中将输入直接赋值为输出使用， 所以这个自定义算子并不会对结果造成任何影响。</em></p>
<p><em>Runtime模板文件如下:</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">// custom_identity_add1.h		ADVANCED_SAMPLES_CUSTOM_IDENTITY_ADD1_H_ 条件编译指令，用于避免头文件的重复包含</span><br><span class="line"><span class="comment">#ifndef ADVANCED_SAMPLES_CUSTOM_IDENTITY_ADD1_H_     </span></span><br><span class="line"><span class="comment">#define ADVANCED_SAMPLES_CUSTOM_IDENTITY_ADD1_H_</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &lt;string&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &quot;dnn/hb_dnn.h&quot;</span></span><br><span class="line"><span class="comment">#include &quot;dnn/plugin/hb_dnn_layer.h&quot;</span></span><br><span class="line"><span class="comment">#include &quot;dnn/plugin/hb_dnn_ndarray.h&quot;</span></span><br><span class="line"></span><br><span class="line">namespace hobot &#123;</span><br><span class="line">namespace dnn &#123;				//嵌套的命名空间声明，将后续的代码都放在 hobot::dnn 命名空间中。</span><br><span class="line"></span><br><span class="line">Layer *Cop1_layer_creator();</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cop1</span> : public Layer &#123;</span><br><span class="line">public:</span><br><span class="line">  Cop1() = default;				//在代码中的 Cop1() = default; 中，Cop1 类的默认构造函数被定义为编译器生成的默认实现。也就是说，没有显式指定构造函数的具体实现，而是使用编译器提供的默认实现。</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">  int32_t Init(const Attribute &amp;attributes) override;	//在代码中的 override 关键字用于声明派生类中的 Init 函数覆盖了基类的同名虚函数。通过使用 override 关键字，可以提高代码的可读性，清晰地表达出派生类中的函数是重写基类中的虚函数的意图，并且在编译阶段进行静态检查，以确保正确的函数覆盖。如果派生类中的函数并没有成功覆盖基类中的虚函数，编译器将会发出错误提示。</span><br><span class="line"></span><br><span class="line">  int32_t Forward(const std::vector&lt;NDArray *&gt; &amp;bottomBlobs,</span><br><span class="line">                  std::vector&lt;NDArray *&gt; &amp;topBlobs,</span><br><span class="line">                  const hbDNNInferCtrlParam *inferCtrlParam) override;</span><br><span class="line"></span><br><span class="line">  std::string GetType() const override &#123; <span class="keyword">return</span> <span class="string">&quot;Cop1&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line">  uint32_t GetInputCount() const override &#123; <span class="keyword">return</span> num_args_; &#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">  std::string custom_op_name_;</span><br><span class="line">  int32_t num_args_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace dnn</span><br><span class="line">&#125;  // namespace hobot</span><br><span class="line"><span class="comment">#endif</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">// custom_identity_add1.cpp</span><br><span class="line"><span class="comment">#include &quot;custom_identity_add1.h&quot;</span></span><br><span class="line"></span><br><span class="line">namespace hobot &#123;</span><br><span class="line">namespace dnn &#123;</span><br><span class="line"></span><br><span class="line">Layer *Cop1_layer_creator() &#123; <span class="keyword">return</span> new Cop1; &#125;</span><br><span class="line"></span><br><span class="line">int32_t Cop1::Init(const Attribute &amp;attributes) &#123;</span><br><span class="line">  // unused attribute, just demonstrating</span><br><span class="line">  attributes.GetAttributeValue(&amp;custom_op_name_, <span class="string">&quot;custom_op_name&quot;</span>);</span><br><span class="line">  // node<span class="string">&#x27;s input count</span></span><br><span class="line"><span class="string">  attributes.GetAttributeValue(&amp;num_args_, &quot;num_args&quot;);</span></span><br><span class="line"><span class="string">  return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">int32_t Cop1::Forward(const std::vector&lt;NDArray *&gt; &amp;bottomBlobs,</span></span><br><span class="line"><span class="string">                      std::vector&lt;NDArray *&gt; &amp;topBlobs,</span></span><br><span class="line"><span class="string">                      const hbDNNInferCtrlParam *inferCtrlParam) &#123;</span></span><br><span class="line"><span class="string">  const NDArray *input0 = bottomBlobs[0];</span></span><br><span class="line"><span class="string">  const NDArray *input1 = bottomBlobs[1];</span></span><br><span class="line"><span class="string">  NDArray *out = topBlobs[0];</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  const auto *input0_data = input0-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string">  const auto *input1_data = input1-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  auto *out_data = out-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string">  uint32_t size = out-&gt;Size();</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  for (uint32_t i = 0U; i &lt; size; i++) &#123;</span></span><br><span class="line"><span class="string">    out_data[i] = input0_data[i] + input1_data[i] + 1;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">  return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;  // namespace dnn</span></span><br><span class="line"><span class="string">&#125;  // namespace hobot</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">// custom_identity_add2.h</span><br><span class="line"><span class="comment">#ifndef ADVANCED_SAMPLES_CUSTOM_IDENTITY_ADD2_H_</span></span><br><span class="line"><span class="comment">#define ADVANCED_SAMPLES_CUSTOM_IDENTITY_ADD2_H_</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &lt;string&gt;</span></span><br><span class="line"><span class="comment">#include &lt;vector&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &quot;dnn/hb_dnn.h&quot;</span></span><br><span class="line"><span class="comment">#include &quot;dnn/plugin/hb_dnn_layer.h&quot;</span></span><br><span class="line"><span class="comment">#include &quot;dnn/plugin/hb_dnn_ndarray.h&quot;</span></span><br><span class="line"></span><br><span class="line">namespace hobot &#123;</span><br><span class="line">namespace dnn &#123;</span><br><span class="line"></span><br><span class="line">Layer *Cop2_layer_creator();</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Cop2</span> : public Layer &#123;</span><br><span class="line">public:</span><br><span class="line">  Cop2() = default;</span><br><span class="line">  ~Cop2() override = default;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">  int32_t Init(const Attribute &amp;attributes) override;</span><br><span class="line"></span><br><span class="line">  int32_t Forward(const std::vector&lt;NDArray *&gt; &amp;bottomBlobs,</span><br><span class="line">                  std::vector&lt;NDArray *&gt; &amp;topBlobs,</span><br><span class="line">                  const hbDNNInferCtrlParam *inferCtrlParam) override;</span><br><span class="line"></span><br><span class="line">  std::string GetType() const override &#123; <span class="keyword">return</span> <span class="string">&quot;Cop2&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line">  uint32_t GetInputCount() const override &#123; <span class="keyword">return</span> num_args_; &#125;</span><br><span class="line"></span><br><span class="line">  uint32_t GetOutputCount() const override &#123; <span class="keyword">return</span> 2U; &#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">  std::string custom_op_name_;</span><br><span class="line">  int32_t num_args_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  // namespace dnn</span><br><span class="line">&#125;  // namespace hobot</span><br><span class="line"></span><br><span class="line"><span class="comment">#endif</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">// custom_identity_add2.cpp</span><br><span class="line"><span class="comment">#include &quot;custom_identity_add2.h&quot;</span></span><br><span class="line"></span><br><span class="line">namespace hobot &#123;</span><br><span class="line">namespace dnn &#123;</span><br><span class="line"></span><br><span class="line">Layer *Cop2_layer_creator() &#123; <span class="keyword">return</span> new Cop2; &#125;</span><br><span class="line"></span><br><span class="line">int32_t Cop2::Init(const Attribute &amp;attributes) &#123;</span><br><span class="line">  // unused attribute, just demonstrating</span><br><span class="line">  attributes.GetAttributeValue(&amp;custom_op_name_, <span class="string">&quot;custom_op_name&quot;</span>);</span><br><span class="line">  // node<span class="string">&#x27;s input count</span></span><br><span class="line"><span class="string">  attributes.GetAttributeValue(&amp;num_args_, &quot;num_args&quot;);</span></span><br><span class="line"><span class="string">  return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">int32_t Cop2::Forward(const std::vector&lt;NDArray *&gt; &amp;bottomBlobs,</span></span><br><span class="line"><span class="string">                      std::vector&lt;NDArray *&gt; &amp;topBlobs,</span></span><br><span class="line"><span class="string">                      const hbDNNInferCtrlParam *inferCtrlParam) &#123;</span></span><br><span class="line"><span class="string">  const NDArray *input0 = bottomBlobs[0];</span></span><br><span class="line"><span class="string">  const NDArray *input1 = bottomBlobs[1];</span></span><br><span class="line"><span class="string">  const NDArray *input2 = bottomBlobs[2];</span></span><br><span class="line"><span class="string">  NDArray *out0 = topBlobs[0];</span></span><br><span class="line"><span class="string">  NDArray *out1 = topBlobs[1];</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  const auto *input0_data = input0-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string">  const auto *input1_data = input1-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string">  const auto *input2_data = input2-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  auto *out0_data = out0-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string">  auto *out1_data = out1-&gt;Dptr&lt;float&gt;();</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  uint32_t size = out0-&gt;Size();</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  for (uint32_t i = 0U; i &lt; size; i++) &#123;</span></span><br><span class="line"><span class="string">    out0_data[i] = input0_data[i] + input1_data[i] + input2_data[i] + 1;</span></span><br><span class="line"><span class="string">    out1_data[i] = out0_data[i];</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">  return 0;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;  // namespace dnn</span></span><br><span class="line"><span class="string">&#125;  // namespace hobot</span></span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：</strong></em></p>
<p><em>该函数名称的前缀(即 <code>Cop1</code> 和 <code>Cop2</code>) 需要与自定义OP的类型（<code>Kind</code>）一致, 其传入的参数为:</em></p>
<ul>
<li><em><code>bottom_blobs</code> ：自定义OP节点输入数据。</em></li>
<li><em><code>top_blobs</code> ：自定义OP节点输出数据。</em></li>
<li><em><code>inferCtrlParam</code> ：自定义算子初始化阶段的输入参数。</em></li>
<li><em><strong>模板中的运算规则均为输出等于所有输入数据累加后再加上数值1, 因此后续用户若要定义其他行为, 则需相应的更改运算规则即可。</strong></em></li>
</ul>
<p><em><strong>自定义算子注册</strong></em></p>
<p><em>当您完成C++版本模版的修改后，仅需要在示例的CMakeLists.txt中添加对模版文件的包含， 并在应用程序中增加对算子的注册即可，注册请参考以下代码：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;custom_identity_add1.h&quot;</span><br><span class="line">#include &quot;custom_identity_add2.h&quot;</span><br><span class="line"></span><br><span class="line">hbDNNRegisterLayerCreator(&quot;Cop1&quot;, hobot::dnn::Cop1_layer_creator);</span><br><span class="line">hbDNNRegisterLayerCreator(&quot;Cop2&quot;, hobot::dnn::Cop2_layer_creator);</span><br><span class="line">....</span><br></pre></td></tr></table></figure></div>

<p><em>当您完成对模版文件的依赖及算子注册后，即可对含有自定义算子的模型进行执行等操作。</em></p>
<p><em><strong>注意：在使用前，请您确认模型的自定义算子名称与注册的算子名称是相同的。</strong></em></p>
<h5 id="PTQ工具文档"><a href="#PTQ工具文档" class="headerlink" title="PTQ工具文档"></a><em>PTQ工具文档</em></h5><p><em>本章节旨在说明地平线J5芯片算法工具链所提供的PTQ模型转换方案的工具包的介绍及使用方法。</em></p>
<p><em>建议在阅读本章内容之前先完成以下准备工作：</em></p>
<ol>
<li><em>阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/preface/toolchain_overview.html" >工具链概览 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中PTQ方案的相关内容和 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/ptq_usage.html" >PTQ原理及步骤 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节的内容， 以了解对PTQ方案和模型转换步骤。</em></li>
<li><em>根据 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html#model-docker-env" >Docker容器部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节的内容完成了Docker环境安装配置和镜像拉取。</em></li>
<li><em>运行 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/ptq_sample.html" >PTQ模型转换示例手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节中的模型转换相关示例。</em></li>
</ol>
<p><em>本章内容主要介绍地平线PTQ方案的模型转换工具包。 该工具包可在开发机或Docker环境下运行。 如果您选择在开发机中运行该工具包，则需要在J5天工开物发布物（即：horizon_j5_open_explorer）的 <code>ddk/package/host</code> 路径下运行 <code>install.sh</code> 脚本进行安装。安装完成后，运行 <code>hb_mapper --help</code> 命令验证工具安装是否成功。 如果您选择在Docker容器中运行该工具，则无需以上安装步骤，根据 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html#model-docker-env" >Docker容器部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容， 进入Docker容器后，然后运行 <code>hb_mapper --help</code> 命令验证工具安装是否成功。</em></p>
<blockquote>
<p><em>模型转换过程详解</em></p>
</blockquote>
<p><em>模型的转换通常可分为以下几个步骤：</em></p>
<ol>
<li><em>检查待转换的模型中是否包含不支持的OP类型。</em></li>
<li><em>准备好20-100张校准使用的图片，用于转换阶段的校准操作。</em></li>
<li><em>使用浮点模型转换工具将原始浮点模型转换为定点模型。</em></li>
<li><em>对转换后的模型进行性能和精度的评估，确保转换后的定点模型精度与之前相差不大。</em></li>
<li><em>在模拟器&#x2F;开发板上运行模型，对模型的性能和精度进行验证。</em></li>
</ol>
<p><em>模型转换步骤的流程图如下:</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230510101919593.png"
                      class="" title="image-20230510101919593"
                ></em></p>
<p><em>对应到工具使用方面，各步骤说明如下：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230510102108014.png"
                      class="" title="image-20230510102108014"
                ></em></p>
<p><em><strong>模型检查（hb_mapper checker）</strong></em></p>
<p><em><strong>注意：如果本过程，您需在示例文件夹内进行，那么您需要先执行文件夹中的 <code>00_init.sh</code> 脚本以获取对应的原始模型和数据集。</strong></em></p>
<p><em>模型在从浮点转换为定点模型之前，我们首先需要通过工具 <code>hb_mapper checker</code> 子命令检查一下，看看该模型是否包含不能在地平线硬件上运行的OP。 如果存在，则会在该阶段提示不认识该OP，<code>hb_mapper checker</code> 子命令使用方式可参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_mapper.html#hb-mapper-checker" >模型检查命令 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节内容。</em></p>
<p><em>若过程中存在不支持OP，则会出现如下提示:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR HorizonRT not support these cpu operators: &#123;不支持的OP名称&#125;</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意</strong></em></p>
<ul>
<li><em>有关地平线硬件可支持的OP信息，请参见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/supported_op_list.html" >模型转换工具链算子支持约束列表 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节内容。</em></li>
<li><em>若无不支持OP，则会输出模型转换后的各OP的列表，以及各OP被划分在CPU还是BPU上执行。 若验证结束且无报错，即可继续进行后续步骤。参见如下：</em></li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hb_mapper checker --model-type caffe --proto mobilenet_deploy.prototxt \</span><br><span class="line">--model mobilenet.caffemodel --march bayes</span><br><span class="line">2021-01-08 17:33:53,117 INFO Start hb_mapper....</span><br><span class="line">2021-01-08 17:33:53,118 INFO hb_mapper version 1.1.42</span><br><span class="line">...</span><br><span class="line">fc7          BPU  id(0)     HzSQuantizedConv</span><br><span class="line">prob         CPU  --        Softmax</span><br><span class="line">2021-01-08 17:33:53,329 INFO [Fri Jan  8 17:33:53 2021] End to Horizon NN Model Convert.</span><br><span class="line">2021-01-08 17:33:53,332 INFO model deps info empty</span><br><span class="line">2021-01-08 17:33:53,351 INFO End model checking....</span><br></pre></td></tr></table></figure></div>

<p><em>若存在不支持OP，可咨询地平线技术人员相关OP开发计划，或者通过 <strong>自定义算子（Custom OP）</strong> 功能添加该OP。</em></p>
<p><em><strong>准备校准图片</strong></em></p>
<p><em>如果本过程，您需在示例文件夹内进行，那么您需要先执行文件夹中的 <code>00_init.sh</code> 脚本以获取对应的原始模型和数据集。</em></p>
<p><em>在进行模型转换时，校准阶段需要20-100张图片输入进行校准操作。 由于模型的输入类型及layout的不同，输入的图片格式可以多种多样。 该阶段既可以输入原始图片（</em>.jpg等)， 也可以输入处理过的，满足模型输入要求的图片。 用户可以直接从模型训练时的数据集中获取相应的校准图片，也可以自行处理图片生成校准数据集。*</p>
<p><em>推荐用户自行对校准图片进行前处理，将图片的通道(BGR&#x2F;RGB)，数据排布(NHWC&#x2F;NCHW)，图像大小及填充(Resize&amp;Padding)等操作调整好后， 设置yaml文件(mobilenet_config.yaml) 中的 <code>preprocess_on</code> 参数为 <code>False</code>，那么工具则会通过二进制文件的方式将图片读入后送入校准阶段。</em></p>
<p><em>以MobileNet为例，则需要进行如下transformer的操作：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">transformers = [</span><br><span class="line">      ShortSideResizeTransformer(short_size=256),   # 短边Pad到256, 保持长宽比</span><br><span class="line">      CenterCropTransformer(crop_size=224),         # 图像中心抠224*224的图像</span><br><span class="line">      HWC2CHWTransformer(),                         # 数据排布从NHWC转换到NCHW</span><br><span class="line">      RGB2BGRTransformer(data_format=&quot;CHW&quot;),        # 颜色通道从RGB转换为BGR</span><br><span class="line">      ScaleTransformer(scale_value=255),            # 数据范围从 0-1 转为 0-255</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure></div>

<p><em>注意：</em></p>
<ul>
<li><p><em>若模型训练时是bgr&#x2F;rgb色彩空间的，则校准阶段传入工具的图片数据需要是bgr&#x2F;rgb色彩空间的， 工具内部会自动完成从bgr&#x2F;rgb到yuv444&#x2F;gray等的色彩转换。</em></p>
<p><em>例如：示例中的MobileNet模型实际输入设置为nv12，而02_preprocess.sh脚本转换结束后是bgr颜色空间的， 剩余的从bgr到nv12的转换是由工具内部自动补全的。</em></p>
</li>
</ul>
<p><em><strong>模型转换（hb_mapper makertbin）</strong></em></p>
<p><em>当用户通过上述 <code>hb_mapper checker</code> 子命令，确定了模型能够被转换成功， 接下来可以使用 <code>hb_mapper makertbin</code> 子命令来将浮点模型转换为一个可以在地平线硬件上运行的定点模型。</em></p>
<p><em>该命令需要用户传入待转换模型的模型类型(<code>caffe</code> &#x2F; <code>onnx</code> )以及一个包含转换要求的配置文件(</em>.yaml)。 具体的配置文件设置，请参阅 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_mapper.html#hb-mapper-config" >配置文件详细介绍 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。*</p>
<p><em>模型转换过程结束后，还会将原始模型与转换后的定点模型的相似程度打印在log中， 用户可根据 <code>Cosine Similarity</code> 字段来判断模型转换前后的相似度。 如下方所示，模<strong>型转换后的 <code>Cosine Similarity</code> 非常接近1， 因此模型转换后的模型表现会与转换前的浮点模型非常相近。</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">config_file=&quot;./mobilenet_config.yaml&quot;</span><br><span class="line">model_type=&quot;caffe&quot;</span><br><span class="line"># build model</span><br><span class="line">hb_mapper makertbin --config $&#123;config_file&#125;  \</span><br><span class="line">                    --model-type  $&#123;model_type&#125;</span><br><span class="line">2023-03-01 20:26:50,149 INFO Start hb_mapper....</span><br><span class="line">......</span><br><span class="line">2023-03-01 20:27:21,427 INFO [Wed Mar  1 20:27:21 2023] End to compile the model with march bayes.</span><br><span class="line">2023-03-01 20:27:21,429 INFO The converted model node information:</span><br><span class="line">======================================================================================================================</span><br><span class="line">Node                    ON   Subgraph  Type                           Cosine Similarity  Threshold   In/Out DataType</span><br><span class="line">----------------------------------------------------------------------------------------------------------------------</span><br><span class="line">HZ_PREPROCESS_FOR_data  BPU  id(0)     HzSQuantizedPreprocess         0.999988           127.000000  int8/int8</span><br><span class="line">conv1                   BPU  id(0)     HzSQuantizedConv               0.999922           2.937425    int8/int8</span><br><span class="line">conv2_1/dw              BPU  id(0)     HzSQuantizedConv               0.999378           2.040827    int8/int8</span><br><span class="line">conv2_1/sep             BPU  id(0)     HzSQuantizedConv               0.996680           4.486579    int8/int8</span><br><span class="line">conv2_2/dw              BPU  id(0)     HzSQuantizedConv               0.997340           3.545496    int8/int8</span><br><span class="line">conv2_2/sep             BPU  id(0)     HzSQuantizedConv               0.996384           2.791299    int8/int8</span><br><span class="line">conv3_1/dw              BPU  id(0)     HzSQuantizedConv               0.994165           1.417208    int8/int8</span><br><span class="line">conv3_1/sep             BPU  id(0)     HzSQuantizedConv               0.985451           2.188753    int8/int8</span><br><span class="line">conv3_2/dw              BPU  id(0)     HzSQuantizedConv               0.994921           1.822225    int8/int8</span><br><span class="line">conv3_2/sep             BPU  id(0)     HzSQuantizedConv               0.994251           1.841765    int8/int8</span><br><span class="line">conv4_1/dw              BPU  id(0)     HzSQuantizedConv               0.988263           1.043535    int8/int8</span><br><span class="line">conv4_1/sep             BPU  id(0)     HzSQuantizedConv               0.990294           1.736999    int8/int8</span><br><span class="line">conv4_2/dw              BPU  id(0)     HzSQuantizedConv               0.992460           0.990603    int8/int8</span><br><span class="line">conv4_2/sep             BPU  id(0)     HzSQuantizedConv               0.993468           1.574677    int8/int8</span><br><span class="line">conv5_1/dw              BPU  id(0)     HzSQuantizedConv               0.988949           0.823123    int8/int8</span><br><span class="line">conv5_1/sep             BPU  id(0)     HzSQuantizedConv               0.990803           1.265912    int8/int8</span><br><span class="line">conv5_2/dw              BPU  id(0)     HzSQuantizedConv               0.990202           0.772344    int8/int8</span><br><span class="line">conv5_2/sep             BPU  id(0)     HzSQuantizedConv               0.983443           1.530479    int8/int8</span><br><span class="line">conv5_3/dw              BPU  id(0)     HzSQuantizedConv               0.986502           0.783812    int8/int8</span><br><span class="line">conv5_3/sep             BPU  id(0)     HzSQuantizedConv               0.977642           1.927324    int8/int8</span><br><span class="line">conv5_4/dw              BPU  id(0)     HzSQuantizedConv               0.982337           0.996043    int8/int8</span><br><span class="line">conv5_4/sep             BPU  id(0)     HzSQuantizedConv               0.962062           2.167391    int8/int8</span><br><span class="line">conv5_5/dw              BPU  id(0)     HzSQuantizedConv               0.978872           1.923361    int8/int8</span><br><span class="line">conv5_5/sep             BPU  id(0)     HzSQuantizedConv               0.960184           3.578415    int8/int8</span><br><span class="line">conv5_6/dw              BPU  id(0)     HzSQuantizedConv               0.980317           2.463874    int8/int8</span><br><span class="line">conv5_6/sep             BPU  id(0)     HzSQuantizedConv               0.981055           4.124151    int8/int8</span><br><span class="line">conv6/dw                BPU  id(0)     HzSQuantizedConv               0.998241           0.667692    int8/int8</span><br><span class="line">conv6/sep               BPU  id(0)     HzSQuantizedConv               0.985220           0.983833    int8/int8</span><br><span class="line">pool6                   BPU  id(0)     HzSQuantizedGlobalAveragePool  0.993602           11.415899   int8/int8</span><br><span class="line">fc7                     BPU  id(0)     HzSQuantizedConv               0.995105           5.843800    int8/int32</span><br><span class="line">prob                    CPU  --        Softmax                        0.985517           --          float/float</span><br><span class="line">2023-03-01 20:27:21,430 INFO The quantify model output:</span><br><span class="line">=======================================================================</span><br><span class="line">Node  Cosine Similarity  L1 Distance  L2 Distance  Chebyshev Distance</span><br><span class="line">-----------------------------------------------------------------------</span><br><span class="line">prob  0.985517           0.000385     0.000203     0.185123</span><br><span class="line">2023-03-01 20:27:21,432 INFO [Wed Mar  1 20:27:21 2023] End to Horizon NN Model Convert.</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：该相似度为校准图片中的第一张的相似度情况，并不完全代表模型转换前后的精度。</strong></em></p>
<p><em>在模型转换成功后，会在生成的文件夹 (默认为 model_output) 中生成如下文件：</em></p>
<ul>
<li>*静态性能评估文件（可读性更好）： ***_subgraph_0.html。*</li>
<li>*静态性能评估文件： ***_subgraph_0.json。*</li>
<li>*原始浮点模型： ***_original_float_model.onnx。*</li>
<li>*优化后的浮点模型： ***_optimized_float_model.onnx。*</li>
<li>*校准模型：： ***_calibrated_model.onnx。*</li>
<li>*定点模型： ***_quantized_model.onnx。*</li>
<li>*上板使用的混合模型： ***.bin。*</li>
</ul>
<p><em>这几个模型文件是模型转换的几个关键阶段产出的文件，并会在后续阶段使用到。</em></p>
<p><em><strong>注意：用户可调用03_classification&#x2F;01_mobilenet&#x2F;mapper&#x2F;03_build.sh脚本， 来体验 <code>hb_mapper makertbin</code> 子命令的使用效果。</strong></em></p>
<p><em><strong>单张图片的模型推理</strong></em></p>
<p><em>在运行浮点模型转换之后，得到了定点模型，还需对其自身的正确性进行验证。</em></p>
<p><em>用户需要对模型的输入&#x2F;输出结构比较了解，并能够正确地对模型输入图片做前处理以及模型输出的后处理解析，并自行编写模型运行脚本。 在此过程中可参照交付包中对应模型的示例代码。 代码逻辑如下:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from horizon_tc_ui import HB_ONNXRuntime</span><br><span class="line">sess = HB_ONNXRuntime(model_file=FLAGS.model)</span><br><span class="line">output = sess.run([output_name], &#123;input_name: image_data&#125;, input_offset=input_offset)</span><br></pre></td></tr></table></figure></div>

<p><em>使用该脚本后，便可通过输入单张图片验证其自身的正确性。该脚本的输入为一张斑马的图片， 在经过前处理将图片数据从rgb处理到input_type_rt的中间类型（无需-128）后 （由于示例mobilenet的 <code>input_type_rt</code> 是nv12，对应的中间类型为yuv444_128， 因此infer_transformers过程需要完成rgb–&gt;nv12–&gt;yuv444，关于中间类型的介绍可参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#conversion-interpretation" >转换过程内部解读 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ），通过 <code>HB_ONNXRuntime</code> 命令传入模型进行推理， 并通过设置 <code>input_offset</code> 参数完成-128的操作，最后打印出其最可能的5个种类。</em></p>
<p><em>运行后的输出如下所示，最可能的类别是 <code>label: 340</code>。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">I0108 18:11:47.398328 140427646048000 cls_inference.py:89] The input picture is classified to be:</span><br><span class="line">label 340: prob 0.97</span><br><span class="line">label 292: prob 0.02</span><br><span class="line">label 282: prob 0.00</span><br><span class="line">label 83: prob 0.00</span><br></pre></td></tr></table></figure></div>

<p><em><code>label</code> 的类别使用的是ImageNet的类别，也可以在 01_common&#x2F;test_data&#x2F;classes.txt 中查到， <code>340</code> 正是对应着斑马，因此该图片推理正确。</em></p>
<p><em><strong>模型精度验证</strong></em></p>
<p><em>光对单张图片进行验证还不足以说明模型的精度，因此还有脚本对模型转换后的精度进行评测。</em></p>
<p><em>用户需要编写代码使模型能够循环推理图片，并将结果与标准结果进行比较，得到精度结果。</em></p>
<p>*因为精度评测时，需要对图片进行 <strong>前处理</strong>，对模型数据进行 <strong>后处理</strong>，所以我们提供了一个示例Python脚本。 其原理与单张推理一致，但需要在整个数据集上面运行。 使用该脚本后，便可通过读取数据集，对模型的输出结果进行评判，并输出评测结果。 运行该脚本耗费时间较长，但可以通过设置 <code>PARALLEL_PROCESS_NUM</code> 环境变量来设置运行评测的线程数量。*</p>
<p><em>在执行结束后得到的输出如下所示：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">===REPORT-START&#123;MAPPER-EVAL&#125;===</span><br><span class="line">0.7011</span><br><span class="line">===REPORT-END&#123;MAPPER-EVAL&#125;===</span><br></pre></td></tr></table></figure></div>

<p><em>可以看到转换后的定点模型精度为 <code>0.7011</code>。</em></p>
<p><em>注意：</em></p>
<ul>
<li><em>在不同的系统下，由于依赖库版本不同，转换得到的模型精度可能会略有差别。</em></li>
<li><em>同时由于版本更迭，得到的定点模型精度可能也会略有差别。</em></li>
<li><em>如果用户在使用模型转换工具后得到的定点模型有精度损失的话， 请与地平线技术团队联系并获取文档《浮点转定点精度损失定位Checklist》来进行问题查究。</em></li>
</ul>
<p><em><strong>模型性能验证</strong></em></p>
<p><em>模型在开发板上的运行帧率也是一个很重要的性能指标，为免去开发者架设开发板环境的麻烦， 我们可以直接使用 <code>hb_perf</code> 子命令对转换出来的模型进行性能分析。</em></p>
<p><em>在MobileNetv1示例中，运行命令 <code>hb_perf mobilenetv1_224x224_nv12.bin</code> 后， 即可在 hb_perf_result&#x2F;mobilenetv1_224x224_nv12&#x2F; 目录下找到模型分析文件 mobilenetv1_224x224_nv12.html 。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[horizon@gpu-dev model_output]$ hb_perf mobilenetv1_224x224_nv12.bin</span><br><span class="line">2022-05-19 14:42:42,303 INFO Start hb_perf....</span><br><span class="line">2022-05-19 14:42:42,304 INFO hb_perf version 1.7.7</span><br><span class="line">2022-05-19 14:42:42,348 INFO ********* mobilenetv1_224x224_nv12 perf **********</span><br><span class="line">2022-05-19 14:42:42,457 INFO draw graph png finished.</span><br><span class="line">2022-05-19 14:42:42,476 INFO get bpu model succeeded.</span><br><span class="line">2022-05-19 14:42:42,787 INFO get perf info succeeded.</span><br><span class="line">2022-05-19 14:42:42,787 WARNING bpu model don&#x27;t have per-layer perf info.</span><br><span class="line">2022-05-19 14:42:42,787 WARNING if you need per-layer perf info please enable[compiler_parameters.debug:True] when use makertbin.</span><br><span class="line">2022-05-19 14:42:42,794 INFO generating html...</span><br><span class="line">2022-05-19 14:42:42,795 INFO html generation finished.</span><br><span class="line">2022-05-19 14:42:42,795 INFO file stored at : /home/users/horizon/codeWKS/tc_sys/j5_toolchain/samples/03_classification/01_mobilenet/mapper/model_output/hb_perf_result/mobilenetv1_224x224_nv12/mobilenetv1_224x224_nv12.html</span><br></pre></td></tr></table></figure></div>

<p><em>从 mobilenetv1_224x224_nv12.html 文件中，我们可以看到模型整体的各项性能数据。 当模型分为多段时，还会对每一段在BPU上运行的部分单独有性能分析报告。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230510110605591.png"
                      class="" title="image-20230510110605591"
                ></em></p>
<p><em>上图中各项性能分别为:</em></p>
<ul>
<li><em><code>Model Name</code>： 模型名称。</em></li>
<li><em><code>BPU Model Latency(ms)</code>：模型整体耗时(单位为ms)。</em></li>
<li><em><code>Total DDR (loaded+stored) bytes per frame(MB per frame)</code>：模型整体BPU部分数据加载和存储所占用的DDR总量（单位为MB&#x2F;frame）。</em></li>
<li><em><code>Loaded Bytes per Frame</code>：模型运行每帧读取数据量。</em></li>
<li><em><code>Stored Bytes per Frame</code>：模型运行每帧存储数据量。</em></li>
</ul>
<p><em><strong>注意：上述 <code>BPU Model Latency(ms)</code> 是指模型中在BPU上执行部分的耗时，如果模型中有CPU上执行的部分，则该部分耗时未被计算在内。</strong></em></p>
<p><em><strong>校准方法</strong></em></p>
<p><em>目前我们支持了以下的校准方法：</em></p>
<p><em>1.default</em></p>
<p><em><code>default</code> 是一个自动搜索的策略，会尝试从系列校准量化参数中获得一个相对效果较好的组合。</em></p>
<p><em>2.mix</em></p>
<p><em><code>mix</code> 是一个集成多种校准方法的搜索策略，能够自动确定量化敏感节点，并在节点粒度上从不同的校准方法中挑选出最佳方法， 最终构建一个融合了多种校准方法优势的组合校准方式。</em></p>
<p><em>3.KL</em></p>
<p><em>KL校准方法是借鉴了 <a class="link"   target="_blank" rel="noopener" href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf" >TensorRT提出的解决方案 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 使用KL熵值来遍历每个量化层的数据分布，通过寻找最低的KL熵值，来确定阈值。 这种方法会导致较多的数据饱和和更小的数据量化粒度，<strong>在一些数据分布比较集中的模型中拥有着比max校准方法更好的效果。</strong></em></p>
<p><em>4.max</em></p>
<p><em>max校准方法是在校准过程中，自动选择量化层中的最大值作为阈值。 这种方法会导致数据量化粒度较大，但也会带来比KL方法更少的饱和点数量，<strong>适用于那些数据分布比较离散的神经网络模型。</strong></em></p>
<p><em>5.load</em></p>
<p><em>使用 <code>QAT</code> 导出的模型时，需使用此参数。</em></p>
<p><em>6.skip</em></p>
<p><em>若您只想尝试对模型性能进行验证，但对精度没有要求，则可以尝试 <code>skip</code> 方式进行校准。 该方式会使用随机数进行校准，不需要您准备校准数据，比较适合初次尝试对模型结构进行验证。</em></p>
<p><em><strong>注意：需要您注意的是，使用skip方式时，因该方式使用随机数校准，故得到的模型不可用于精度验证。</strong></em></p>
<blockquote>
<p><em>hb _mapper工具</em></p>
</blockquote>
<p><em><code>hb_mapper</code> 工具是一个将浮点模型映射为量化模型，并附带验证功能的工具。 <code>hb_mapper</code> 包括三个子命令 <code>checker</code>、 <code>makertbin</code> 和 <code>infer</code>。 它们分别提供了的模型检查、模型转换，以及各阶段卷积层向量输出的功能。 接下来的内容逐一介绍上述子命令。</em></p>
<p><em><strong>模型检查命令（hb_mapper checker）</strong></em></p>
<p><em>在实际工程中，由于并非所有浮点模型均能够转为量化模型，因此在转换之前需要进行一次检查， 这个check过程，会走一遍模型转换的过程，但是对于比较耗时的步骤，进行了简化处理。 该命令在完成模型的检查后，会输出检查结果和OP在设备上的部署情况。</em></p>
<ul>
<li><p><em>hb_mapper checker的使用方法：</em></p>
<p><em><code>hb_mapper checker --model-type $&#123;model_type&#125; \                  --march $&#123;march&#125; \                  --proto $&#123;proto&#125; \                  --model $&#123;caffe_model/onnx_model&#125; \                  --input-shape $&#123;input_node&#125; $&#123;input_shape&#125; \                  --output $&#123;output&#125; </code></em></p>
</li>
<li><p><em>hb_mapper checker的命令行参数：</em></p>
<p><em>–model-type转换的模型类型，目前支持 <code>caffe</code> 或者 <code>onnx</code>。</em></p>
<p><em>–marchBPU的微架构。若使用x&#x2F;j3系列芯片则设置为 <code>bernoulli2</code>，若使用j5芯片则设置为 <code>bayes</code>。</em></p>
<p><em>–proto    Caffe模型的prototxt文件。</em></p>
<p><em>–model     Caffe或ONNX浮点模型文件。</em></p>
<p><em>–input-shape可选参数，输入模型的输入节点以及该节点的输入的shape，其shape以 <code>x</code> 分隔，e.g. <code>data 1x3x224x224</code>。</em></p>
<p><em>–output该参数已经废弃，log信息存储于 <code>hb_mapper_checker_&#123;date_time&#125;.log</code> 中。</em></p>
<p><em>–help显示帮助信息并退出。</em></p>
</li>
</ul>
<p><em><strong>模型编译命令（hb_mapper makertbin）</strong></em></p>
<p><em>该命令根据配置文件和模型的种类，会生成ONNX量化模型以及仿真上板情况的runtime模型。 配置文件的具体设置将会在 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_mapper.html#hb-mapper-config" >配置文件详细介绍 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分具体讲解。</em></p>
<ul>
<li><p><em>hb_mapper makertbin的使用方式：</em></p>
<p><em><code>hb_mapper makertbin --config $&#123;config_file&#125;  \                 </code></em></p>
<p> <em><code>  --model-type  $&#123;model_type&#125;</code></em></p>
</li>
<li><p><em>hb_mapper makertbin的命令行参数：</em></p>
<p><em>-c, –config模型编译的配置文件，为yaml格式。-</em></p>
<p><em>-model-type<code>caffe</code> 或者 <code>onnx</code>。</em></p>
<p><em>–help显示帮助信息并退出。</em></p>
</li>
</ul>
<p><em>编译产生的log文件会储存在命令执行路径下面，名称为 <code>hb_mapper_makertbin_&#123;date_time&#125;.log</code>。</em></p>
<p><em><strong>模型推理命令（hb_mapper infer）</strong></em></p>
<p><em><strong>注意：</strong></em></p>
<ul>
<li><em><strong>hb_mapper infer 受 onnxruntime 限制，不支持动态的shape infer，因此要求输入的模型shape信息明确。</strong></em></li>
<li><em>该工具不支持 infer 含有 shape信息为 ? 的模型。</em></li>
</ul>
<p><em>该命令利用浮点和量化模型进行推理，并保存推理结果到 <code>--output-dir</code> 指定的目录里面。</em></p>
<p><em>为了验证分析模型编译是否正确，可将配置文件中 <code>layer_out_dump</code> 设置为 <code>True</code>，它将会输出conv和输出节点的推理结果， 之后可以借助向量比较工具来分析模型编译的正确与否。</em></p>
<p><em>hb_mapper infer的使用方式：</em></p>
<p><em><code>hb_mapper infer --config $&#123;config_file&#125; \              </code></em></p>
<p> <em><code> --model-file $&#123;quantized_model_file&#125;  \     </code></em>  </p>
<p> <em><code>         --model-type $&#123;caffe/onnx&#125; \           </code></em>          </p>
<p> <em><code>   --image-file $&#123;input_node&#125; $&#123;image_file&#125; \     </code></em>    </p>
<p> <em><code>         --input-layout $&#123;input_layout&#125; \       </code></em>          </p>
<p> <em><code>--output-dir $&#123;quantized_output_dir&#125;</code></em></p>
<p><em>在使用 <code>hb_mapper infer</code> 命令时，请输入与 <code>hb_mapper makertbin</code> 命令相同的配置文件，以保证输入数据处理的部分的设置是相同的。 简单地说，您在 <code>hb_mapper makertbin</code> 时使用的校准数据是什么样的图片或数据，那么在 <code>hb_mapper infer</code> 时也需要使用相同格式的图片或数据。</em></p>
<p><em><strong>注意：</strong></em></p>
<p><em>您使用 <code>hb_mapper infer</code> 命令时输入数据的选择与配置文件中以下输入数据配置部分有关：</em></p>
<ul>
<li><em><code>preprocess_on: True</code>，则工具可以接收JPEG图片，自动进行resize等预处理，并转化成 <code>input_type_rt</code> 的格式。</em></li>
<li><em><code>preprocess_on: False</code>，则只能接收已经处理好，储存为二进制格式的图片文件，因此预处理需要用户自己完成， 并把图片转化成相应的二进制文件。(请参考脚本02_preprocess.sh)。</em></li>
</ul>
<p><em>hb_mapper infer的命令行参数：</em></p>
<p><em>-c, –config模型编译时的配置文件。</em></p>
<p><em>–model-file进行推理的模型文件，可以是浮点和量化ONNX模型。</em></p>
<p><em>–model-type指定推理的原始浮点模型类型，可指定为 <code>caffe</code> 或 <code>onnx</code>。</em></p>
<p><em>–image-file输入节点名称和其对应的用于推理的图像文件。–input-layout模型输入的layout（此为可选参数）。</em></p>
<p><em>–output-dir推理结果的保存路径，如果是量化模型，推理结果为反量化的浮点数据。</em></p>
<p><em>–help显示帮助信息并退出。</em></p>
<p><em>输出内容在 output_dir 目录里，输出文件命名规则： <code>$&#123;layername&#125;_float.bin</code>。</em></p>
<p><em><strong>关键配置参数 calibration_parameters.preprocess_on 介绍</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">calibration_parameters:</span><br><span class="line">    # 模型量化的参考图像的存放目录，图片格式支持JPEG、BMP等格式，输入的图片</span><br><span class="line">    # 应该是使用的典型场景，一般是从测试集中选择20~100张图片，另外输入</span><br><span class="line">    # 的图片要覆盖典型场景，不要是偏僻场景，如过曝光、饱和、模糊、</span><br><span class="line">    # 纯黑、纯白等图片</span><br><span class="line">    # 若有多个输入，则应使用&#x27;;&#x27;进行分隔</span><br><span class="line">    cal_data_dir: &#x27;./calibration_data_bgr_f32&#x27;</span><br><span class="line">    # 当输入的图片文件尺寸和模型训练的尺寸不一致，并且preprocess_on为True时，则将采用默认预处理方法(skimage resize)，</span><br><span class="line">    # 将输入图片缩放或者裁减到指定尺寸，否则，需要用户提前把图片处理为训练时的尺寸</span><br><span class="line">    # preprocess_on: False</span><br></pre></td></tr></table></figure></div>

<p><em><strong>如果用户指定配置参数</strong> <code>preprocess_on=True</code>：</em></p>
<p><em>工具可通过该设置 <code>preprocess_on</code> 为 <code>True</code> 来自动完成的校准图片的前处理。 该模式下用户需在 <code>cal_data_dir</code> 中指定校准JPEG图片的存放路径。 则在模型校准时，工具内部会通过skimage方式读入的JPEG图片，通过skimage resize的方式缩放图片到配置文件指定的 <code>input_shape</code>， 并把图像格式调整为 <code>input_type_rt</code> 指定的格式。</em></p>
<p><em>举一个例子，假如输入的JPEG图像的尺寸为608x608，则通过默认的预处理后，图像被缩放为224x224， 图像的内存格式调整为bgr(NCHW)的格式，像素值调整为0-255范围。</em></p>
<p><em>默认的预处理，请参考如下代码：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_transformer</span>(<span class="params">norm_type, input_dim, input_type_train</span>):</span><br><span class="line">    image_width = input_dim[<span class="number">2</span>]</span><br><span class="line">    image_height = input_dim[<span class="number">1</span>]</span><br><span class="line">    transformers = [</span><br><span class="line">        ResizeTransformer((image_height, image_width)),</span><br><span class="line">        HWC2CHWTransformer(),  <span class="comment"># to CXHXW</span></span><br><span class="line">        RGB2BGRTransformer(),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    transformers.append(ScaleTransformer(<span class="number">255</span>))</span><br></pre></td></tr></table></figure></div>

<p><em><strong>如果用户指定配置参数</strong> <code>preprocess_on=False</code>：</em></p>
<p><em>需要用户自己来处理图片，将图片处理为 <code>input_type_train</code> 指定的格式，并且将数据以二进制形式保存为文件. 工具内部会自动增加从 <code>input_type_train</code> 到 <code>input_type_rt</code> 的格式转换。</em></p>
<p><em><strong>注意：文件格式为： <a class="link"   target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Row-_and_column-major_order" >Row-major order <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 的uint8&#x2F;float32数据存储。</strong></em></p>
<blockquote>
<p><em>当数据以行优先的方式存储时，对于一个二维数组，内存中的连续存储顺序是先存储第一行的所有元素，接着存储第二行的所有元素，以此类推。</em></p>
<p><em>在文件格式中，”uint8”表示无符号8位整数数据类型，而”float32”表示32位浮点数数据类型。这是常见的表示图像像素或浮点数数据的数据类型。</em></p>
</blockquote>
<p><em><strong>配置文件详细介绍</strong></em></p>
<ul>
<li><em><strong>参考配置文件以及说明</strong></em></li>
</ul>
<p><em>配置文件采用yaml格式进行配置，详细信息请参考各个参数的注释：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型转化相关的参数</span></span><br><span class="line">model_parameters:</span><br><span class="line">    <span class="comment"># Caffe浮点网络数据模型文件</span></span><br><span class="line">    caffe_model: <span class="string">&#x27;../../../01_common/model_zoo/mapper/classification/mobilenet/mobilenet.caffemodel&#x27;</span></span><br><span class="line">    <span class="comment"># Caffe网络描述文件</span></span><br><span class="line">    prototxt: <span class="string">&#x27;../../../01_common/model_zoo/mapper/classification/mobilenet/mobilenet_deploy.prototxt&#x27;</span></span><br><span class="line">    <span class="comment"># 适用BPU架构</span></span><br><span class="line">    march: <span class="string">&quot;bayes&quot;</span></span><br><span class="line">    <span class="comment"># 指定模型转换过程中是否输出各层的中间结果，如果为True，则输出所有层的中间输出结果，</span></span><br><span class="line">    layer_out_dump: <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 日志文件的输出控制参数，</span></span><br><span class="line">    <span class="comment"># debug输出模型转换的详细信息</span></span><br><span class="line">    <span class="comment"># info只输出关键信息</span></span><br><span class="line">    <span class="comment"># warn输出警告和错误级别以上的信息</span></span><br><span class="line">    working_dir: <span class="string">&#x27;model_output&#x27;</span></span><br><span class="line">    <span class="comment"># 模型转换输出的用于上板执行的模型文件的名称前缀</span></span><br><span class="line">    output_model_file_prefix: <span class="string">&#x27;mobilenetv1_224x224_nv12&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型输入相关参数, 若输入多个节点, 则应使用&#x27;;&#x27;进行分隔, 使用默认缺省设置则写None</span></span><br><span class="line">input_parameters:</span><br><span class="line">    <span class="comment"># (可不填) 模型输入的节点名称, 此名称应与模型文件中的名称一致, 否则会报错, 不填则会使用模型文件中的节点名称</span></span><br><span class="line">    input_name: <span class="string">&quot;data&quot;</span></span><br><span class="line">    <span class="comment"># 网络实际执行时，输入给网络的数据格式，包括 nv12/rgb/bgr/yuv444/gray/featuremap,</span></span><br><span class="line">    <span class="comment"># 如果输入的数据为yuv444, 模型训练用的是bgr(NCHW)，则hb_mapper将自动插入YUV到BGR(NCHW)转化操作</span></span><br><span class="line">    input_type_rt: <span class="string">&#x27;nv12&#x27;</span></span><br><span class="line">    <span class="comment"># 转换后混合异构模型需要适配的输入数据排布，可设置为：NHWC/NCHW</span></span><br><span class="line">    <span class="comment"># 若input_type_rt配置为nv12，则此处参数不需要配置</span></span><br><span class="line">    <span class="comment">#input_layout_rt: &#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 网络训练时输入的数据格式，可选的值为rgb/bgr/gray/featuremap/yuv444</span></span><br><span class="line">    input_type_train: <span class="string">&#x27;bgr&#x27;</span></span><br><span class="line">    <span class="comment"># 网络训练时输入的数据排布, 可选值为 NHWC/NCHW</span></span><br><span class="line">    input_layout_train: <span class="string">&#x27;NCHW&#x27;</span></span><br><span class="line">    <span class="comment"># 模型网络的输入大小, 以&#x27;x&#x27;分隔, 不填则会使用模型文件中的网络输入大小，否则会覆盖模型文件中输入大小</span></span><br><span class="line">    <span class="comment"># input_shape: &#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 网络输入的预处理方法，主要有以下几种：</span></span><br><span class="line">    <span class="comment"># no_preprocess 不做任何操作</span></span><br><span class="line">    <span class="comment"># data_mean 减去通道均值mean_value</span></span><br><span class="line">    <span class="comment"># data_scale 对图像像素乘以data_scale系数</span></span><br><span class="line">    <span class="comment"># data_mean_and_scale 减去通道均值后再乘以scale系数</span></span><br><span class="line">    norm_type: <span class="string">&#x27;data_mean_and_scale&#x27;</span></span><br><span class="line">    <span class="comment"># 图像减去的均值, 如果是通道均值，value之间必须用空格分隔</span></span><br><span class="line">    mean_value: <span class="number">103.94</span> <span class="number">116.78</span> <span class="number">123.68</span></span><br><span class="line">    <span class="comment"># 图像预处理缩放比例，如果是通道缩放比例，value之间必须用空格分隔</span></span><br><span class="line">    scale_value: <span class="number">0.017</span></span><br><span class="line"></span><br><span class="line">calibration_parameters:</span><br><span class="line">    <span class="comment"># 模型量化的参考图像的存放目录，图片格式支持JPEG、BMP等格式，输入的图片</span></span><br><span class="line">    <span class="comment"># 应该是使用的典型场景，一般是从测试集中选择20~100张图片，另外输入</span></span><br><span class="line">    <span class="comment"># 的图片要覆盖典型场景，不要是偏僻场景，如过曝光、饱和、模糊、纯黑、纯白等图片</span></span><br><span class="line">    <span class="comment"># 若有多个输入节点, 则应使用&#x27;;&#x27;进行分隔</span></span><br><span class="line">    cal_data_dir: <span class="string">&#x27;./calibration_data_bgr_f32&#x27;</span></span><br><span class="line">    <span class="comment"># 校准数据二进制文件的数据存储类型，可选值为：float32, uint8. 若有多个输入节点, 则应使用&#x27;;&#x27;进行分隔</span></span><br><span class="line">    cal_data_type: <span class="string">&#x27;float32&#x27;</span></span><br><span class="line">    <span class="comment"># 如果输入的图片文件尺寸和模型训练的尺寸不一致时，并且preprocess_on为true，</span></span><br><span class="line">    <span class="comment"># 则将采用默认预处理方法(skimage resize)，</span></span><br><span class="line">    <span class="comment"># 将输入图片缩放或者裁减到指定尺寸，否则，需要用户提前把图片处理为训练时的尺寸</span></span><br><span class="line">    <span class="comment"># preprocess_on: False</span></span><br><span class="line">    <span class="comment"># 模型量化的算法类型，支持default、mix、kl、max、load，通常采用default即可满足要求,</span></span><br><span class="line">    <span class="comment"># default 是一个自动搜索的策略，会尝试从系列校准量化参数中获得一个相对效果较好的组合。</span></span><br><span class="line">    <span class="comment"># 建议您先尝试 default，如果最终的精度结果不满足预期可进一步尝试mix,</span></span><br><span class="line">    <span class="comment"># mix是一个集成多种校准方法的搜索策略，能够自动确定量化敏感节点，并在节点粒度上从不同的校准方法中挑选出最佳方法。</span></span><br><span class="line">    <span class="comment"># 如果default和mix的精度结果均不满足预期再尝试用kl或max并详细调整量化参数进行精度调优，</span></span><br><span class="line">    <span class="comment"># kl和max是模型量化的算法类型，通常采用KL即可满足要求。</span></span><br><span class="line">    <span class="comment"># 当使用QAT导出模型时，此参数则应设置为load。</span></span><br><span class="line">    calibration_type: <span class="string">&#x27;default&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译器相关参数</span></span><br><span class="line">compiler_parameters:</span><br><span class="line">    <span class="comment"># 编译策略，支持bandwidth和latency两种优化模式;</span></span><br><span class="line">    <span class="comment"># bandwidth以优化ddr的访问带宽为目标；</span></span><br><span class="line">    <span class="comment"># latency以优化推理时间为目标</span></span><br><span class="line">    compile_mode: <span class="string">&#x27;latency&#x27;</span></span><br><span class="line">    <span class="comment"># 设置debug为True将打开编译器的debug模式，能够输出性能仿真的相关信息，如帧率、DDR带宽占用等</span></span><br><span class="line">    debug: <span class="literal">False</span></span><br><span class="line">    <span class="comment"># 编译模型指定核数，不指定默认编译单核模型, 若编译双核模型，将下边注释打开即可</span></span><br><span class="line">    <span class="comment"># core_num: 2</span></span><br><span class="line">    <span class="comment"># 优化等级可选范围为O0~O3</span></span><br><span class="line">    <span class="comment"># O0不做任何优化, 编译速度最快，优化程度最低,</span></span><br><span class="line">    <span class="comment"># O1-O3随着优化等级提高，预期编译后的模型的执行速度会更快，但是所需编译时间也会变长。</span></span><br><span class="line">    <span class="comment"># 推荐用O2做最快验证</span></span><br><span class="line">    optimize_level: <span class="string">&#x27;O3&#x27;</span></span><br></pre></td></tr></table></figure></div>



<ul>
<li><em><strong>关于 input_type_rt&#x2F; input_type_train</strong></em></li>
</ul>
<p><em>地平线的芯片架构，在设计时为了提升性能，做了两点假设：</em></p>
<ol>
<li><em>假设输入的数据都是int8的量化数据。</em></li>
<li><em>摄像头获取到的数据是nv12。</em></li>
</ol>
<p><em>因此，如果用户在模型训练时使用rgb(NCHW)输入格式，但是想使这个模型能够高效处理nv12数据，只需要在模型转换时做如下配置：</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input_parameters:</span><br><span class="line">    input_type_rt: <span class="string">&#x27;nv12&#x27;</span></span><br><span class="line">    input_type_train: <span class="string">&#x27;rgb&#x27;</span></span><br><span class="line">    input_layout_train: <span class="string">&#x27;NCHW&#x27;</span></span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：若用户训练模型时使用gray格式，而实际使用中输入的数据格式为nv12格式， 则用户可以将模型转换时的 <code>input_type_rt</code> 及 <code>input_type_train</code> 均配置为 <code>gray</code>， 在嵌入式应用开发时仅使用nv12的y通道地址作为输入即可。</strong></em></p>
<p><em>除了将输入数据转换为nv12，我们还支持用户在训练和runtime infer时使用不同的rgb-order。 具体的 <code>input_type_rt</code> &#x2F; <code>input_type_train</code> 的支持类型，可以参考(Y为已支持类型，N为暂不支持类型)：</em></p>
<table>
<thead>
<tr>
<th><em><code>input_type_train</code> \ <code>input_type_rt</code></em></th>
<th><em>nv12</em></th>
<th><em>yuv444</em></th>
<th><em>rgb</em></th>
<th><em>bgr</em></th>
<th><em>gray</em></th>
<th><em>featuremap</em></th>
</tr>
</thead>
<tbody><tr>
<td><em>yuv444</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
</tr>
<tr>
<td><em>rgb</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
</tr>
<tr>
<td><em>bgr</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>Y</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
</tr>
<tr>
<td><em>gray</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>Y</em></td>
<td><em>N</em></td>
</tr>
<tr>
<td><em>featuremap</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>N</em></td>
<td><em>Y</em></td>
</tr>
</tbody></table>
<p><em>注意：为了配合芯片对于输入数据类型的要求（int8），减小推理开销， 对于 <code>input_type_rt</code> 类型为 rgb(NHWC&#x2F;NCHW)&#x2F;bgr(NHWC&#x2F;NCHW) 的配置， 转换工具转换出的模型，其输入数据类型均为 <code>int8</code>。 <strong>也就是说，对于常规的图像数据，需要-128使用（该操作在API中已自动进行，用户无需再进行该操作）。</strong></em></p>
<blockquote>
<p><em>hb_perf工具</em></p>
</blockquote>
<p><em><code>hb_perf</code> 是用于分析地平线量化混合模型性能的分析工具。</em></p>
<p><em><strong>使用方法</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_perf [OPTIONS] BIN_FILE</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em><strong>命令行参数</strong></em></li>
</ul>
<p><em>–version</em><br><em>显示版本并退出。</em></p>
<p><em>-m</em><br><em>后接模型名称。当指定BIN_FILE为pack模型时，仅输出指定模型的模型编译信息。</em></p>
<p><em>–help</em><br><em>显示帮助信息。</em></p>
<ul>
<li><em>输出内容说明</em></li>
</ul>
<p><em>模型的信息会输出在当前目录的 <code>hb_perf_result</code> 文件夹中。 其中会有以该模型为名的文件夹，该模型信息将会展示在以其模型名称命名的 <code>html</code> 文件中。目录结构如下示例所示:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hb_perf_result/</span><br><span class="line">└── mobilenetv1</span><br><span class="line">    ├── mobilenetv1</span><br><span class="line">    ├── mobilenetv1.html</span><br><span class="line">    ├── mobilenetv1.png</span><br><span class="line">    ├── MOBILENET_subgraph_0.html</span><br><span class="line">    ├── MOBILENET_subgraph_0.json</span><br><span class="line">    └── temp.hbm</span><br></pre></td></tr></table></figure></div>

<p><em>若该模型在编译时未设置为debug模式(<code>compiler_parameters.debug:True</code>) 则 <code>hb_perf</code> 工具会产生如下提示， 该提示仅表明子图信息中不包括逐层信息，对模型整体信息的生成没有影响。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2021-01-12 10:41:40,000 WARNING bpu model don&#x27;t have per-layer perf info.</span><br><span class="line">2021-01-12 10:41:40,000 WARNING if you need per-layer perf info please enable[compiler_parameters.debug:True] when use makertbin.</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p><em>vec_diff工具</em></p>
</blockquote>
<p><em><code>vec_diff</code> 工具旨在帮助用户定位精度异常问题。当出现精度异常时，可能有几种原因：</em></p>
<ol>
<li><em>校准或者量化导致某一layer的输出存在误差，经过可能的误差放大，导致最终结果差异较大。</em></li>
<li><em>模型转换工具的某一步存在未知问题，浮点模型到定点模型转换过程中，经过了几次优化和变换，这些变换可能会存在问题，导致异常。</em></li>
<li><em>软件bug：在应该保证数值一致的地方，因为软件bug，导致误差。</em></li>
</ol>
<p><em>为了定位这些问题，我们开发了向量比较工具。使用向量比较工具，用户可以比较不同阶段模型的卷积层输出差异。</em></p>
<p><em><strong>使用方式</strong></em></p>
<p><em><code>vec_diff</code> 工具，可以比较不同阶段模型的输出feature的差异，所以，第一步，用户需要得到模型的 <code>infer</code> 输出结果。</em></p>
<p><em>对于模型转换工具（<code>hb_mapper</code>）输出的模型，用户可以使用 <code>infer</code> 命令得到模型的输出向量文件。 具体使用，请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_mapper.html#hb-mapper-infer" >模型推理命令（hb_mapper infer） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</em></p>
<p><em>对于</em>.bin模型，用户可以上板运行，得到中间向量输出。此过程请参考runtime工具 文档： <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/tool_introduction/source/hrt_bin_dump.html" >《hrt_bin_dump工具介绍》 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。*</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vec_diff [OPTIONS] left_file/folder right_file/folder</span><br></pre></td></tr></table></figure></div>



<p><em><strong>命令行参数</strong></em></p>
<p><em>vec_diff的命令行参数：</em></p>
<p><em>–version显示版本并退出。</em></p>
<p><em>left_file&#x2F;folder文件名，或者文件夹名。</em></p>
<p><em>right_file&#x2F;folder文件名，或者文件夹名。</em></p>
<p><em>-o, –output-file FILENAME输出结果文件的文件名。</em></p>
<p><em>–help打印帮助信息。</em></p>
<p><em><strong>输出结果说明</strong></em></p>
<p><em>由 <code>vec_diff -o</code> 指定的CSV文件，列表（表项为：左侧文件名，右侧文件名，余弦相似度、相对欧拉距、最大绝对误差、方差），参考如下：</em></p>
<table>
<thead>
<tr>
<th align="left"><em>Left Files</em></th>
<th align="left"><em>Right Files</em></th>
<th align="left"><em>Cosine Similarity</em></th>
<th align="left"><em>Relative Euclidean Distance</em></th>
<th align="left"><em>Max Absolute Error</em></th>
<th align="left"><em>Mean Square Error</em></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><em>Layerxxx-quanti-input.txt</em></td>
<td align="left"><em>Layerxxx-float-input.txt</em></td>
<td align="left"><em>xxx</em></td>
<td align="left"><em>xxx</em></td>
<td align="left"><em>xxx</em></td>
<td align="left"><em>xxx</em></td>
</tr>
<tr>
<td align="left"><em>Layerxxx-quanti-param.txt</em></td>
<td align="left"><em>Layerxxx-float-param.txt</em></td>
<td align="left"><em>xxx</em></td>
<td align="left"><em>xxx</em></td>
<td align="left"><em>xxx</em></td>
<td align="left"><em>xxx</em></td>
</tr>
</tbody></table>
<blockquote>
<p><em>hb_model_info 工具</em></p>
</blockquote>
<p><em><code>hb_model_info</code> 是用于解析混合模型(</em>.bin)编译时的依赖及参数信息的工具。*</p>
<p><em><strong>使用方法</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_info $&#123;model_file&#125;</span><br></pre></td></tr></table></figure></div>



<p><em><strong>命令行参数</strong></em></p>
<p><em>hb_model_info的命令行参数：</em></p>
<p><em>–version显示版本并退出。</em></p>
<p><em>-m后接模型名称。当指定BIN_FILE为pack模型时，仅输出指定模型的模型编译信息。</em></p>
<p><em>–help显示帮助信息。</em></p>
<p><em><strong>输出内容说明</strong></em></p>
<p><em>输出部分将会是模型编译时的一些输入信息，如下所示：<strong>以下代码块中的版本号信息将随发布包版本变化，此处仅为示例。</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Start hb_model_info....</span><br><span class="line">hb_model_info version 1.3.35</span><br><span class="line">******** efficient_det_512x512_nv12 info *********</span><br><span class="line">############# model deps info #############</span><br><span class="line">hb_mapper version   : 1.3.35</span><br><span class="line">hbdk version        : 3.23.3</span><br><span class="line">hbdk runtime version: 3.13.7</span><br><span class="line">horizon_nn version  : 0.10.10</span><br><span class="line">############# model_parameters info #############</span><br><span class="line">onnx_model          : /release/01_common/model_zoo/mapper/detection/efficient_det/efficientdet_nhwc.onnx</span><br><span class="line">BPU march           : bayes</span><br><span class="line">layer_out_dump      : False</span><br><span class="line">working dir         : /release/04_detection/05_efficient_det/mapper/model_output</span><br><span class="line">output_model_file_prefix: efficient_det_512x512_nv12</span><br><span class="line">############# input_parameters info #############</span><br><span class="line">------------------------------------------</span><br><span class="line">---------input info : data ---------</span><br><span class="line">input_name          : data</span><br><span class="line">input_type_rt       : nv12</span><br><span class="line">input_space&amp;range   : regular</span><br><span class="line">input_layout_rt     : None</span><br><span class="line">input_type_train    : rgb</span><br><span class="line">input_layout_train  : NCHW</span><br><span class="line">norm_type           : data_mean_and_scale</span><br><span class="line">input_shape         : 1x3x512x512</span><br><span class="line">mean_value          : 123.68,116.779,103.939,</span><br><span class="line">scale_value         : 0.017,</span><br><span class="line">cal_data_dir        : /release/04_detection/05_efficient_det/mapper/calibration_data_rgb_f32</span><br><span class="line">---------input info : data end -------</span><br><span class="line">------------------------------------------</span><br><span class="line">############# calibration_parameters info #############</span><br><span class="line">preprocess_on       : False</span><br><span class="line">calibration_type    : max</span><br><span class="line">############# compiler_parameters info #############</span><br><span class="line">hbdk_pass_through_params: --fast --O3</span><br><span class="line">input-source        : &#123;&#x27;data&#x27;: &#x27;pyramid&#x27;, &#x27;_default_value&#x27;: &#x27;ddr&#x27;&#125;</span><br><span class="line">--------- input/output types -------------------</span><br><span class="line">model input types   : [&lt;InputDataType.NV12: 7&gt;]</span><br><span class="line">model output types  : [&lt;InputDataType.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InputDataTye.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InputDataType.F32: 5&gt;, &lt;InpuDataType.F32: 5&gt;]</span><br></pre></td></tr></table></figure></div>



<p><em>当模型中存在被删除节点时，模型信息输出末尾会打印被删除节点的名称，同时会生成 <code>deleted_nodes_info.txt</code> 文件，文件中每一行记录了对应被删除节点的初始信息。打印被删除节点的名称如下所示：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--------- deleted nodes -------------------</span><br><span class="line">deleted nodes: spconvretinanethead0_conv91_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv95_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv99_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv103_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv107_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv93_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv97_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv101_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv105_fwd_chw_HzDequantize</span><br><span class="line">deleted nodes: spconvretinanethead0_conv109_fwd_chw_HzDequantize</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p><em>hb_pack 工具</em></p>
</blockquote>
<p><em><code>hb_pack</code> 是用于将多个混合模型(</em>.bin)文件打包为一个模型文件的工具。*</p>
<p><em><strong>使用方法</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_pack [OPTIONS] BIN_FILE1 BIN_FILE2 BIN_FILE3 -o comb.bin</span><br></pre></td></tr></table></figure></div>



<p> <em><strong>命令行参数</strong></em></p>
<p><em>hb_pack的命令行参数：</em></p>
<ul>
<li><p><em>–version</em></p>
<p><em>显示版本并退出。</em></p>
</li>
<li><p><em>-o, –output_name</em></p>
<p><em>pack模型的输出名称</em></p>
</li>
<li><p><em>–help</em></p>
<p><em>显示帮助信息。</em></p>
</li>
</ul>
<p><em><strong>输出内容说明</strong></em></p>
<p><em>打包的模型会输出在当前目录文件夹中，该模型会被命名为 <code>output_name</code> 指定名称。 该打包模型中所有子模型的编译信息及性能信息均可通过 <code>hb_model_info</code> 及 <code>hb_perf</code> 获取得到。</em></p>
<p><em><strong>注意：<code>hb_pack</code> 不支持对已经打包的模型再次进行打包，否则工作台将会产生以下提示：</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ERROR exception in command: pack</span><br><span class="line">ERROR model: xxx.bin is a packed model, it can not be packed again!</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p><em>hb_verifier 工具</em></p>
</blockquote>
<p><em><code>hb_verifier</code> 工具是用于对指定的定点模型和runtime模型进行结果验证的工具。</em></p>
<p><em>若您使用工具前指定了图片，则 <code>hb_verifier</code> 工具会使用指定图片进行定点模型推理、runtime模型板端和X86端模拟器上的推理，并对结果进行两两比较， 给出是否通过的结论（此过程支持自选，您可以根据需要选择进行对比的内容）。</em></p>
<p><em>若您在使用工具前未指定图片，则 <code>hb_verifier</code> 工具会默认使用随机生成的tensor数据进行推理。</em></p>
<p><em><strong>注意：</strong></em></p>
<ul>
<li><em>在进行runtime模型在板端的推理时，需要确认给定ip可以ping通且板端已经安装 <code>hrt_tools</code> ，若无则可以使用OE包中 <code>ddk/package/board</code> 下的 <code>install.sh</code> 脚本进行安装。</em></li>
<li><em>在进行runtime模型在x86端的推理时，需要确保host端已经安装 <code>hrt_tools</code>，若无则可以使用OE包中 <code>ddk/package/host/host_package/</code> 下的 <code>install_host_package.sh</code> 脚本进行安装。</em></li>
</ul>
<p><em>在使用本工具前，以下内容需要请您注意：</em></p>
<p><em>hb_verifier工具不支持除Dequantize节点外，有其他节点变化的bin模型与quanti.onnx进行对比。</em></p>
<p><em>如果在使用本工具前，您使用hb_model_modifier工具删除了bin模型的输出前的最后一个节点且该节点为非Dequantize节点，或者yaml文件中配置了 <code>remove_node_type</code> 参数， 从而删除了bin模型的输出前的最后一个节点且该节点为非Dequantize节点，那么hb_verifier工具将不再支持quanti.onnx和删除节点后的bin模型做对比。</em></p>
<p><em>如您想解决上述问题，<strong>需要避免出现上述删除bin模型的输出前的最后一个节点且该节点为非Dequantize节点的情况。</strong></em></p>
<p><em><strong>使用方式</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m   $&#123;quanti_model&#125;,$&#123;bin_model&#125; \</span><br><span class="line">            -b   $&#123;board_ip&#125; \</span><br><span class="line">            -s   True / False \</span><br><span class="line">            -i   $&#123;input_img&#125; \</span><br><span class="line">            -c   $&#123;digits&#125;  \</span><br><span class="line">            -r   True / False</span><br></pre></td></tr></table></figure></div>



<p><em><strong>命令行参数</strong></em></p>
<p><em>hb_verifier的命令行参数：</em></p>
<ul>
<li><p><em>–model, -m</em></p>
<p><em>定点模型名称和bin模型名称，多模型之间用”,”进行区分。</em></p>
</li>
<li><p><em>–board-ip, -b</em></p>
<p><em>上板测试使用的arm board ip地址。</em></p>
</li>
<li><p><em>–run-sim, -s</em></p>
<p><em>设置是否使用X86环境的libdnn做bin模型推理，默认为False。当该参数设置为 <code>True</code> 时，工具将会使用x86环境的libdnn做bin模型推理。当该参数设置为 <code>False</code> 时，工具不会使用x86环境的libdnn做bin模型推理。</em></p>
</li>
<li><p><em>–input-img, -i</em></p>
<p><em>指定推理测试时使用的图片。若不指定则会使用随机生成的tensor数据。若指定图片为二进制形式的图片文件，其文件形式需要为后缀名为 <code>.bin</code> 形式。多输入模型添加图片的方式有以下两种传参方式，多张图片之间用”,”分割：input_name1:image1,input_name2:image2, …image1,image2…</em></p>
</li>
<li><p><em>–compare_digits, -c</em></p>
<p><em>设置比较推理结果的数值精确度（即比较数值小数点后的位数），若不进行指定则工具会默认比较至小数点后五位。</em></p>
</li>
<li><p><em>–dump-all-nodes-results, -r</em></p>
<p><em>设置是否保存模型中各个算子的输出结果，并对算子输出名称相同的结果进行对比，默认为False。当该参数设置为 <code>True</code> 时，工具将会获取模型中所有节点的输出，并根据节点输出的名字做匹配，从而进行对比。当该参数设置为 <code>False</code> 时，工具将会只获取模型最终输出的结果，并进行对比。</em></p>
</li>
</ul>
<p><em>注意：目前基于性能考虑，暂不支持您在X86环境下使用dump功能。</em></p>
<p><em><strong>参考使用场景样例</strong></em></p>
<p><em>1.quanti.onnx模型推理、bin模型在板端推理，bin模型在X86环境下进行推理，并对三方推理结果做对比：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m quanti.onnx,model.bin -b *.*.*.* -s True (-i 选填)</span><br></pre></td></tr></table></figure></div>

<p><em>2.quanti.onnx模型推理、bin模型在板端推理，并对两方推理结果做对比：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m quanti.onnx,model.bin -b *.*.*.* (-i 选填)</span><br></pre></td></tr></table></figure></div>

<p><em>3.quanti.onnx模型推理、bin模型在板端推理，过程中会保存两方模型中各个算子的输出，并对算子输出名称相同的结果进行对比：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m quanti.onnx,model.bin -b *.*.*.* -r True (-i 选填)</span><br></pre></td></tr></table></figure></div>

<p><em>4.quanti.onnx模型推理、bin模型在X86环境下进行推理，并对两方推理结果做对比：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m quanti.onnx,model.bin -s True (-i 选填)</span><br></pre></td></tr></table></figure></div>

<p><em>5.bin模型在板端、X86环境下进行推理，并对两方推理结果做对比：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_verifier -m model.bin -b *.*.*.* -s True (-i 选填)</span><br></pre></td></tr></table></figure></div>



<p><em><strong>输出内容说明</strong></em></p>
<p><em>结果对比最终会在终端展示，工具会对比多个模型在不同场景下的运行结果，若无问题应显示如下:</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Comparison results of original output is model_infer_output_0</span><br><span class="line">raw output 0 and raw output 0 result Strict check PASSED</span><br><span class="line">Quanti.onnx and Arm result Strict check PASSED</span><br></pre></td></tr></table></figure></div>

<p><em>在定点模型和runtime模型精度不一致时会输出不一致结果的具体信息，如下方log所示：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">INFO ================== Sim infer log end ==========================</span><br><span class="line">INFO ***************************************************************</span><br><span class="line">INFO compare source: Quanti.onnx VS Arm</span><br><span class="line">INFO compare model name: clr_320x800_bgr_quantized_model VS clr_320x800_bgr</span><br><span class="line">Compare progress: 100%|###################################| 1/1 [00:00&lt;00:00, 17.53it/s]</span><br><span class="line">INFO =============== Original output comparison results =================</span><br><span class="line">INFO Comparison results of original output is model_infer_output_0</span><br><span class="line">INFO mismatch result num: 13824</span><br><span class="line">INFO total result num: 14976</span><br><span class="line">INFO mismatch rate: 0.923</span><br><span class="line">INFO relative mismatch ratio: 1.0</span><br><span class="line">WARNING raw output 0 and raw output 0 result Strict check FAILED</span><br><span class="line">WARNING Quanti.onnx and Arm result Strict check FAILED</span><br><span class="line">INFO ***************************************************************</span><br><span class="line">INFO ***************************************************************</span><br><span class="line">INFO compare source: Quanti.onnx VS Sim</span><br><span class="line">INFO compare model name: clr_320x800_bgr_quantized_model VS clr_320x800_bgr</span><br><span class="line">Compare progress: 100%|###################################| 1/1 [00:00&lt;00:00, 18.51it/s]</span><br><span class="line">INFO =============== Original output comparison results =================</span><br><span class="line">INFO Comparison results of original output is model_infer_output_0</span><br><span class="line">INFO mismatch result num: 13824</span><br><span class="line">INFO total result num: 14976</span><br><span class="line">INFO mismatch rate: 0.923</span><br><span class="line">INFO relative mismatch ratio: 1.0</span><br><span class="line">WARNING raw output 0 and raw output 0 result Strict check FAILED</span><br><span class="line">WARNING Quanti.onnx and Sim result Strict check FAILED</span><br><span class="line">INFO ***************************************************************</span><br><span class="line">INFO ***************************************************************</span><br><span class="line">INFO compare source: Arm VS Sim</span><br><span class="line">INFO compare model name: clr_320x800_bgr VS clr_320x800_bgr</span><br><span class="line">Compare progress: 100%|###################################| 1/1 [00:00&lt;00:00, 48.73it/s]</span><br><span class="line">INFO =============== Original output comparison results =================</span><br><span class="line">INFO Comparison results of original output is model_infer_output_0</span><br><span class="line">INFO raw output 0 and raw output 0 result Strict check PASSED</span><br><span class="line">INFO Arm and Sim result Strict check PASSED</span><br><span class="line">INFO ***************************************************************</span><br></pre></td></tr></table></figure></div>

<p><em>其中：</em></p>
<ul>
<li><em><code>mismatch result num</code> 为两种模型精度不一致结果的个数，包括三种不一致情况：</em><ul>
<li><em><code>mismatch.line_miss num</code> 为输出结果数量不一致的个数；</em></li>
<li><em><code>mismatch.line_diff num</code> 为输出结果差距过大的个数；</em></li>
<li><em><code>mismatch.line_nan num</code> 为输出为nan的个数。</em></li>
</ul>
</li>
<li><em><code>total result num</code> 为输出数据的总个数。</em></li>
<li><em><code>mismatch rate</code> 为不一致数据个数占输出数据总个数的比例。</em></li>
<li><em><code>relative mismatch ratio</code> 为相对误差比例，取误差比例最大的值进行展示。</em></li>
</ul>
<blockquote>
<p><em>hb_model_modifier</em></p>
</blockquote>
<p><em><code>hb_model_modifier</code> 工具用于对指定的runtime模型中输入端的Transpose、Quantize、Cast、Reshape节点和输出端的Transpose、Dequantize、Cast、Reshape、Softmax节点进行删除操作， 并将删除节点的信息存放在BIN模型中，可以通过 <code>hb_model_info</code> 进行查看。</em></p>
<p><em><strong>注意：</strong></em></p>
<ol>
<li><em>hb_model_modifier工具只能删除紧挨着模型输入或输出的节点。如果待删除节点后面如果接的是其他节点，则不能进行删除操作。</em></li>
<li><em>模型节点名称需要注意不要包括 “;” “,” 等特殊符号，否则可能会影响工具的使用。</em></li>
<li><em>工具不支持对打包的模型进行处理，否则将提示： <code>ERROR pack model is not supported</code>。</em></li>
<li><em>待删除节点会按顺序依次删除，并且会动态更新模型结构; 同时在节点删除前还会判断该节点是否位于模型的输入输出处，因此节点的删除顺序很重要。</em></li>
</ol>
<p><em>由于删除特定节点后会对模型的输入情况有影响，<strong>因此工具只对模型输入后只有一条通路的情况适用</strong>，若如下图中所示，同一输入对应了多个节点的情况尚不支持。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511144012726.png"
                      class="" title="image-20230511144012726"
                ></em></p>
<p><em><strong>使用方式</strong></em></p>
<ol>
<li><em>查看可删除的节点：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier model.bin</span><br></pre></td></tr></table></figure></div>

<ol start="2">
<li><em>删除单个指定节点（以node1为例）：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier model.bin -r node1</span><br></pre></td></tr></table></figure></div>

<ol start="3">
<li><em>删除多个指定节点（以node1、node2、node3为例）：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier model.bin -r node1 -r node2 -r node3</span><br></pre></td></tr></table></figure></div>

<ol start="4">
<li><em>删除某类节点（以Dequantize为例）：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier model.bin --all Dequantize</span><br></pre></td></tr></table></figure></div>

<ol start="5">
<li><em>删除多种类型节点（以Reshape、Cast、Dequantize为例）：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier model.bin -a Reshape -a Cast -a Dequantize</span><br></pre></td></tr></table></figure></div>

<ol start="6">
<li><em>组合使用：</em></li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier model.bin -a Reshape -a Cast -a Dequantize -r node1 -r node2 -r node3</span><br></pre></td></tr></table></figure></div>



<p><em><strong>命令行参数</strong></em></p>
<p><em>hb_model_modifier的命令行参数：</em></p>
<p><em>model_file   runtime 模型文件名称。</em></p>
<p><em>-r后接指定删除节点的名称。若有多个节点需要删除，需要指定多次。</em></p>
<p><em>-o后接修改后的模型输出名称(仅在有 <code>-r</code> 参数时生效)。</em></p>
<p><em>-a, –all后接节点类型。支持一键删除所有对应类型的功能。若有多个类型节点需要删除，需要指定多次。</em></p>
<p><em><strong>输出内容说明</strong></em></p>
<p><em>若工具后不接任何参数，则工具会打印出可供候选的可删除节点（即模型中的位于输入输出位置的所有Transpose、Quantize、Dequantize、Cast、Reshape、Softmax节点）。</em></p>
<p><em>其中Quantize节点用于将模型float类型的输入数据量化至int8类型，其计算公式如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`qx = clamp(round(x / scale) + zero_point, -128, 127)`</span><br></pre></td></tr></table></figure></div>

<ul>
<li><em><code>round(x)</code> 实现浮点数的四舍五入。</em></li>
<li><em><code>clamp(x)</code> 函数实现将数据钳位在-128~127之间的整数数值。</em></li>
<li><em><code>scale</code> 为量化比例因子。</em></li>
<li><em><code>zero_point</code> 为非对称量化零点偏移值，对称量化时 zero_point &#x3D; 0 。</em></li>
</ul>
<p><em>C++的参考实现如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">static inline int8_t quantize(float32_t value, float32_t const scale, float32_t const zero_point, float32_t const min, float32_t const max)</span><br><span class="line">&#123;</span><br><span class="line">  value = std::round(value / scale + zero_point);</span><br><span class="line">  value = std::min(std::max(value, min), max);</span><br><span class="line">  return static_cast&lt;int8_t&gt;(value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>Dequantize节点则用于将模型 int8 或 int32 类型的输出数据反量化回 float 或 double 类型，其计算公式如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`deqx = (x - zero_point) * scale`</span><br></pre></td></tr></table></figure></div>

<p><em>C++的参考实现如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static_cast&lt;float&gt;(value) * scale</span><br></pre></td></tr></table></figure></div>

<p><em><strong>注意：</strong></em></p>
<p><em>目前工具支持删除：</em></p>
<ol>
<li><em>输入部位的节点为Quantize、Transpose、Cast、Reshape节点；</em></li>
<li><em>输出部位的节点为Transpose、Dequantize、Cast、Reshape、Softmax节点。</em></li>
</ol>
<p><em>工具打印信息如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier resnet50_64x56x56_featuremap.bin</span><br><span class="line">2022-04-21 18:22:30,207 INFO Nodes that can be deleted: [&#x27;data_res2a_branch1_HzQuantize_TransposeInput0&#x27;, &#x27;fc1000_reshape_0&#x27;]</span><br></pre></td></tr></table></figure></div>

<p><em>在指定 <code>-r</code> 选项后，工具会打印模型中该节点的类型，储存在bin文件中的节点信息以及告知指定节点已被删除：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier resnet50_64x56x56_featuremap.bin -r data_res2a_branch1_HzQuantize_TransposeInput0</span><br><span class="line">Node &#x27;data_res2a_branch1_HzQuantize_TransposeInput0&#x27; found, its OP type is &#x27;Transpose&#x27;</span><br><span class="line">Node &#x27;data_res2a_branch1_HzQuantize_TransposeInput0&#x27; is removed</span><br><span class="line">modified model saved as resnet50_64x56x56_featuremap_modified.bin</span><br></pre></td></tr></table></figure></div>

<p><em>之后可以通过 <code>hb_model_info</code> 工具查看被删除节点信息，输出信息末尾会打印被删除节点的名称，同时会生成 <code>deleted_nodes_info.txt</code> 文件， 文件中每一行记录了对应被删除节点的初始信息(此处仅会记录 Quantize、Dequantize和Transpose类型的节点信息)。</em></p>
<p><em>打印被删除节点的名称步骤如下所示：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hb_model_info resnet50_64x56x56_featuremap_modified.bin</span><br><span class="line">Start hb_model_info....</span><br><span class="line">hb_model_info version 1.7.0</span><br><span class="line">********* resnet50_64x56x56_featuremap info *********</span><br><span class="line">...</span><br><span class="line">--------- deleted nodes -------------------</span><br><span class="line">deleted nodes: data_res2a_branch1_HzQuantize_TransposeInput0</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p><em>hb_custom_op工具</em></p>
</blockquote>
<p><em>工具打印信息如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier resnet50_64x56x56_featuremap.bin</span><br><span class="line">2022-04-21 18:22:30,207 INFO Nodes that can be deleted: [&#x27;data_res2a_branch1_HzQuantize_TransposeInput0&#x27;, &#x27;fc1000_reshape_0&#x27;]</span><br></pre></td></tr></table></figure></div>

<p><em>在指定 <code>-r</code> 选项后，工具会打印模型中该节点的类型，储存在bin文件中的节点信息以及告知指定节点已被删除：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hb_model_modifier resnet50_64x56x56_featuremap.bin -r data_res2a_branch1_HzQuantize_TransposeInput0</span><br><span class="line">Node &#x27;data_res2a_branch1_HzQuantize_TransposeInput0&#x27; found, its OP type is &#x27;Transpose&#x27;</span><br><span class="line">Node &#x27;data_res2a_branch1_HzQuantize_TransposeInput0&#x27; is removed</span><br><span class="line">modified model saved as resnet50_64x56x56_featuremap_modified.bin</span><br></pre></td></tr></table></figure></div>

<p><em>之后可以通过 <code>hb_model_info</code> 工具查看被删除节点信息，输出信息末尾会打印被删除节点的名称，同时会生成 <code>deleted_nodes_info.txt</code> 文件， 文件中每一行记录了对应被删除节点的初始信息(此处仅会记录 Quantize、Dequantize和Transpose类型的节点信息)。</em></p>
<p><em>打印被删除节点的名称步骤如下所示：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hb_model_info resnet50_64x56x56_featuremap_modified.bin</span><br><span class="line">Start hb_model_info....</span><br><span class="line">hb_model_info version 1.7.0</span><br><span class="line">********* resnet50_64x56x56_featuremap info *********</span><br><span class="line">...</span><br><span class="line">--------- deleted nodes -------------------</span><br><span class="line">deleted nodes: data_res2a_branch1_HzQuantize_TransposeInput0</span><br></pre></td></tr></table></figure></div>



<p><em><strong>使用方法</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_custom_op COMMAND</span><br></pre></td></tr></table></figure></div>



<p><em><strong>命令行参数</strong></em></p>
<p><em>hb_custom_op的命令行参数：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_custom_op create</span><br></pre></td></tr></table></figure></div>

<p><em>该命令会生成相应的python自定义OP的模板文件。</em></p>
<p><em><strong>输出内容说明</strong></em></p>
<p><em><code>hb_custom_op create</code> 命令将会生成含有自定义OP模板的python文件。</em></p>
<blockquote>
<p><em>hb_eval_preprocess 工具</em></p>
</blockquote>
<p><em>用于对模型精度进行评估时，在x86环境下对图片数据进行预处理。 所谓预处理是指图片数据在送入模型之前的特定处理操作。 比如：图片resize、crop和padding等。</em></p>
<p><em><strong>使用方法</strong></em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_eval_preprocess [OPTIONS]</span><br></pre></td></tr></table></figure></div>

<p><em><strong>命令行参数</strong></em></p>
<p><em>hb_eval_preprocess的命令行参数：</em></p>
<ul>
<li><p><em>–version</em></p>
<p><em>显示版本并退出。</em></p>
</li>
<li><p><em>-m, –model_name</em></p>
<p><em>设置模型名称，支持的模型范围可通过 <code>hb_eval_preprocess --help</code> 查看。</em></p>
</li>
<li><p><em>-i, –image_dir</em></p>
<p><em>输入图片路径。</em></p>
</li>
<li><p><em>-o, –output_dir</em></p>
<p><em>输出路径。</em></p>
</li>
<li><p><em>-v, –val_txt</em></p>
<p><em>设置评测所需图片的文件名称，预处理生成的图片将与此文件中的图片名称对应。</em></p>
</li>
<li><p><em>-h, –help</em></p>
<p><em>显示帮助信息。</em></p>
</li>
</ul>
<p><em><strong>输出内容说明</strong></em></p>
<p><em><code>hb_eval_preprocess</code> 命令将会在 <code>--output_dir</code> 指定的路径下生成图片二进制文件。</em></p>
<p><em>更多关于 <code>hb_eval_preprocess</code> 工具在上板模型精度评估中的应用示例请参见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/ai-benchmark.html#data-preprocess" >数据预处理 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节内容。</em></p>
<blockquote>
<p><em>精度debug工具</em></p>
</blockquote>
<p><em>模型转换工具链会基于您提供的校准样本对模型进行校准量化并保障模型高效的部署在地平线芯片上。 而在模型转换的过程中，难免会因为浮点到定点的量化过程而引入精度损失，通常情况下造成精度损失的主要原因可能有以下几点：</em></p>
<p><em>1.模型中的一部分节点对量化比较敏感会引入较大误差，即敏感节点量化问题。</em></p>
<p><em>2.模型中各个节点的误差累积导致模型整体出现较大的校准误差，主要包含：权重量化导致的误差累积、激活量化导致的误差累积以及全量量化导致的误差累积。</em></p>
<p><em>针对该情况，地平线提供了精度debug工具用以协助您自主定位模型量化过程中产生的精度问题。 该工具能够协助您对校准模型进行节点粒度的量化误差分析，最终帮助您快速定位出现精度异常的节点。</em></p>
<p><em>精度debug工具提供多种分析功能供您使用，例如：</em></p>
<ul>
<li><em>获取节点量化敏感度。</em></li>
<li><em>获取模型累积误差曲线。</em></li>
<li><em>获取指定节点的数据分布。</em></li>
<li><em>获取指定节点输入数据通道间数据分布箱线图等。</em></li>
</ul>
<p><em><strong>快速上手</strong></em></p>
<p><em>使用精度debug工具主要有以下几个步骤：</em></p>
<p><em>1.在yaml中配置参数 <code>debug_mode=&quot;dump_calibration_data&quot;</code> ，保存校准模型与校准数据。</em></p>
<p><em>2.导入debug模块，加载校准模型和数据。</em></p>
<p><em>3.通过精度debug工具提供的API，对精度损失明显的模型进行分析。</em></p>
<p><em>整体流程如下图所示：</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511151319223.png"
                      class="" title="image-20230511151319223"
                ></em></p>
<ul>
<li><em><strong>校准模型与数据的保存</strong></em></li>
</ul>
<p><em>首先需要在yaml文件中配置 <code>debug_mode=&quot;dump_calibration_data&quot;</code> ，以开启精度debug功能， 保存校准模型(calibrated_model.onnx)和对应的校准数据(calibration_data)。其中：</em></p>
<ul>
<li><em>校准数据(calibration_data)：在校准阶段，模型通过对这些数据进行前向推理来获取每个被量化节点的量化参数，包括：缩放因子(scale)和阈值(threshold)。</em></li>
<li><em>校准模型(calibrated_model.onnx)：将在校准阶段计算得到的每个被量化节点的量化参数保存在校准节点中，从而得到校准模型。</em></li>
</ul>
<p><em><strong>此处保存的校准数据与02_preprocess.sh生成的校准数据的区别？</strong></em></p>
<p><em><code>02_preprocess.sh</code> 得到的校准数据是bgr颜色空间的数据，<strong>在工具链内部会将数据从bgr转换到yuv444&#x2F;gray等模型实际输入的格式（转换）</strong>。 而此处保存的校准数据则是经过颜色空间转换以及预处理之后保存的.npy格式的数据，<strong>该数据可以通过np.load()直接送入模型进行推理。</strong></em></p>
<p><em><strong>校准模型(calibrated_model.onnx)解读</strong></em></p>
<p><em>校准模型是模型转换工具链将浮点模型经过结构优化后，通过校准数据计算得到的每个节点对应的量化参数并将其保存在校准节点中得到的中间产物。 校准模型的主要特点是模型中包含校准节点，校准节点的节点类型为HzCalibration。 这些校准节点主要分为两类： <strong>激活(activation)校准节点</strong> 和 <strong>权重(weight)校准节点</strong> 。</em></p>
<p><em><strong>激活校准节点</strong> 的输入是当前节点的上一个节点的输出，并基于当前激活校准节点中保存的量化参数(scales和thresholds)对输入数据进行量化及反量化后输出。</em></p>
<p><em><strong>权重校准节点</strong> 的输入为模型的原始浮点权重，基于当前权重校准节点中保存的量化参数(scales和thresholds)对输入的原始浮点权重进行量化及反量化后输出。</em></p>
<p><em>除却上述的校准节点，校准模型中的其他节点，精度debug工具将其称为 <strong>普通节点(node)</strong> 。 <strong>普通节点</strong> 的类型包括：Conv、Mul、Add等。</em></p>
<p><em><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511152328296.png"
                      class="" title="image-20230511152328296"
                ></em></p>
<p><em>calibration_data的文件夹结构如下：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">|--calibration_data ：校准数据</span><br><span class="line">|----input.1 ：文件夹名为模型的输入节点并保存对应的输入数据</span><br><span class="line">|--------0.npy</span><br><span class="line">|--------1.npy</span><br><span class="line">|-------- ...</span><br><span class="line">|----input.2 ：对于多输入模型将保存多个文件夹</span><br><span class="line">|--------0.npy</span><br><span class="line">|--------1.npy</span><br><span class="line">|-------- ...</span><br></pre></td></tr></table></figure></div>



<ul>
<li><em><strong>精度debug模块导入与API使用</strong></em></li>
</ul>
<p><em>接下来需要在代码中导入debug模块，并通过 <code>get_sensitivity_of_nodes</code> 接口获取节点量化敏感度（默认使用模型输出的余弦相似度）。 <code>get_sensitivity_of_nodes</code> 的详细参数说明可见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/accuracy_debug.html#get-sensitivity-of-nodes" >get_sensitivity_of_nodes <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入debug模块</span></span><br><span class="line"><span class="keyword">import</span> horizon_nn.debug <span class="keyword">as</span> dbg</span><br><span class="line"><span class="comment"># 导入log日志模块</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># 若verbose=True时，需要先设置log level为INFO</span></span><br><span class="line">logging.getLogger().setLevel(logging.INFO)</span><br><span class="line"><span class="comment"># 获取节点量化敏感度</span></span><br><span class="line">node_message = dbg.get_sensitivity_of_nodes(</span><br><span class="line">        model_or_file=<span class="string">&#x27;./calibrated_model.onnx&#x27;</span>,</span><br><span class="line">        metrics=[<span class="string">&#x27;cosine-similarity&#x27;</span>, <span class="string">&#x27;mse&#x27;</span>],</span><br><span class="line">        calibrated_data=<span class="string">&#x27;./calibration_data/&#x27;</span>,</span><br><span class="line">        output_node=<span class="literal">None</span>,</span><br><span class="line">        node_type=<span class="string">&#x27;node&#x27;</span>,</span><br><span class="line">        data_num=<span class="literal">None</span>,</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">        interested_nodes=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure></div>



<ul>
<li><em><strong>分析结果展示</strong></em></li>
</ul>
<p><em>下方为 <code>verbose=True</code> 时的打印结果：</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">==========================node==========================</span><br><span class="line">Node        cosine-similarity   mse</span><br><span class="line">--------------------------------------------------------</span><br><span class="line">Conv_3      0.999009567957658   0.027825591154396534</span><br><span class="line">MaxPool_2   0.9993462241612948  0.017706592209064044</span><br><span class="line">Conv_6      0.9998359175828787  0.004541242333988731</span><br><span class="line">MaxPool_5   0.9998616805443397  0.0038416787014844325</span><br><span class="line">Conv_0      0.9999297948984     0.0019312848587735342</span><br><span class="line">Gemm_19     0.9999609772975628  0.0010773885699633795</span><br><span class="line">Conv_8      0.9999629625907311  0.0010301886404004807</span><br><span class="line">Gemm_15     0.9999847687207736  0.00041888411550854263</span><br><span class="line">MaxPool_12  0.9999853235024673  0.0004039733791544747</span><br><span class="line">Conv_10     0.999985763659844   0.0004040437432614943</span><br><span class="line">Gemm_17     0.9999913985912616  0.0002379088904350423</span><br></pre></td></tr></table></figure></div>

<p><em>除此之外，该API会以字典(Dict)的形式将节点量化敏感度信息返回给您以供后续使用分析。</em></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Out:</span><br><span class="line">&#123;&#x27;Conv_3&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.999009567957658&#x27;, &#x27;mse&#x27;: &#x27;0.027825591154396534&#x27;&#125;,</span><br><span class="line"> &#x27;MaxPool_2&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9993462241612948&#x27;, &#x27;mse&#x27;: &#x27;0.017706592209064044&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_6&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9998359175828787&#x27;, &#x27;mse&#x27;: &#x27;0.004541242333988731&#x27;&#125;,</span><br><span class="line"> &#x27;MaxPool_5&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9998616805443397&#x27;, &#x27;mse&#x27;: &#x27;0.0038416787014844325&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_0&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999297948984&#x27;, &#x27;mse&#x27;: &#x27;0.0019312848587735342&#x27;&#125;,</span><br><span class="line"> &#x27;Gemm_19&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999609772975628&#x27;, &#x27;mse&#x27;: &#x27;0.0010773885699633795&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_8&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999629625907311&#x27;, &#x27;mse&#x27;: &#x27;0.0010301886404004807&#x27;&#125;,</span><br><span class="line"> &#x27;Gemm_15&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999847687207736&#x27;, &#x27;mse&#x27;: &#x27;0.00041888411550854263&#x27;&#125;,</span><br><span class="line"> &#x27;MaxPool_12&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999853235024673&#x27;, &#x27;mse&#x27;: &#x27;0.0004039733791544747&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_10&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.999985763659844&#x27;, &#x27;mse&#x27;: &#x27;0.0004040437432614943&#x27;&#125;,</span><br><span class="line"> &#x27;Gemm_17&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999913985912616&#x27;, &#x27;mse&#x27;: &#x27;0.0002379088904350423&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure></div>

<p><em>更多功能详见 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/accuracy_debug.html#debug-api" >API说明文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节。</em></p>
<p><strong>API说明文档</strong></p>
<ul>
<li><strong>get_sensitivity_of_nodes</strong>：获取节点量化敏感度</li>
</ul>
<p><strong>API参数组</strong>：</p>
<table>
<thead>
<tr>
<th align="left">编 号</th>
<th align="left">参数名称</th>
<th align="left">参数配置说明</th>
<th align="left">可选&#x2F;必选</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left"><code>model_or_file</code></td>
<td align="left"><strong>参数作用</strong>：指定校准模型。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定需要分析的校准模型。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left"><code>metrics</code></td>
<td align="left"><strong>参数作用</strong>：节点量化敏感度的度量方式。<strong>取值范围</strong>：<code>&#39;cosine-similarity&#39;</code> , <code>&#39;mse&#39;</code> , <code>&#39;mre&#39;</code> , <code>&#39;sqnr&#39;</code> , <code>&#39;chebyshev&#39;</code> 。<strong>默认配置</strong>：<code>&#39;cosine-similarity&#39;</code>。<strong>参数说明</strong>：指定节点量化敏感度的计算方式，该参数可以为列表(List)， 即以多种方式计算量化敏感度， 但是输出结果仅以列表中第一位的计算方式进行排序， 排名越靠前说明量化该节点引入的误差越大。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left"><code>calibrated_data</code></td>
<td align="left"><strong>参数作用</strong>：指定校准数据。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定分析所需要的校准数据。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left"><code>output_node</code></td>
<td align="left"><strong>参数作用</strong>：指定输出节点。<strong>取值范围</strong>：校准模型中的具有对应校准节点的普通节点。<strong>默认配置</strong>：None。<strong>参数说明：此参数支持您指定中间节点作为输出并计算节点量化敏感度。</strong> <strong>若保持默认参数None，则精度debug工具会获取模型的最终输出</strong> <strong>并在此基础上计算节点的量化敏感度。</strong></td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left"><code>node_type</code></td>
<td align="left"><strong>参数作用</strong>：节点类型。<strong>取值范围</strong>：<code>&#39;node&#39;</code> , <code>&#39;weight&#39;</code> , <code>&#39;activation&#39;</code>。<strong>默认配置</strong>：<code>&#39;node&#39;</code>。<strong>参数说明</strong>：需要计算量化敏感度的节点类型，包括：node（普通节点）、 weight（权重校准节点）、activation（激活校准节点）。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">6</td>
<td align="left"><code>data_num</code></td>
<td align="left"><strong>参数作用</strong>：计算量化敏感度需要的数据数量。<strong>取值范围</strong>：大于0，小于等于calibration_data中数据的总数。<strong>默认配置</strong>：None<strong>参数说明</strong>：设置计算节点量化敏感度时所需要的数据数量。 默认为None，此时默认使用calibration_data中的所有数据进行计算。 最小设置为1，最大为 calibration_data中的数据数量。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">7</td>
<td align="left"><code>verbose</code></td>
<td align="left"><strong>参数作用</strong>：选择是否将信息打印在终端上。<strong>取值范围</strong>：<code>True</code> 、 <code>False</code>。<strong>默认配置</strong>：<code>False</code>。<strong>参数说明</strong>：若为True，则将量化敏感度信息打印在终端上。 若metrics包含多种度量方式，则按照第一位进行排序。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">8</td>
<td align="left"><code>interested_nodes</code></td>
<td align="left"><strong>参数作用</strong>：设置感兴趣节点。<strong>取值范围</strong>：校准模型中的所有节点。<strong>默认配置</strong>：None。<strong>参数说明</strong>：若指定则只获取该节点的量化敏感度，其余节点不获取。 同时，若该参数被指定，将忽视node_type指定的节点类型， 也就是说该参数的优先级要高于node_type。 若保持默认参数None，则计算模型中所有可被量化节点的量化敏感度。</td>
<td align="left">可选</td>
</tr>
</tbody></table>
<p><strong>API分析结果展示</strong>：</p>
<p><strong>描述</strong>：首先您通过node_type设置需要计算敏感度的节点类型，然后工具获取校准模型中所有符合node_type的节点，并获取这些节点的量化敏感度。 当verbose设置为True时，工具会将节点量化敏感度进行排序后打印在终端，排序越靠前，说明该节点量化引入的量化误差越大。</p>
<p>verbose&#x3D;True时，打印结果如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">==========================node==========================</span><br><span class="line">Node        cosine-similarity   mse</span><br><span class="line">--------------------------------------------------------</span><br><span class="line">Conv_3      0.999009567957658   0.027825591154396534</span><br><span class="line">MaxPool_2   0.9993462241612948  0.017706592209064044</span><br><span class="line">Conv_6      0.9998359175828787  0.004541242333988731</span><br><span class="line">MaxPool_5   0.9998616805443397  0.0038416787014844325</span><br><span class="line">Conv_0      0.9999297948984     0.0019312848587735342</span><br><span class="line">Gemm_19     0.9999609772975628  0.0010773885699633795</span><br><span class="line">Conv_8      0.9999629625907311  0.0010301886404004807</span><br><span class="line">Gemm_15     0.9999847687207736  0.00041888411550854263</span><br><span class="line">MaxPool_12  0.9999853235024673  0.0004039733791544747</span><br><span class="line">Conv_10     0.999985763659844   0.0004040437432614943</span><br><span class="line">Gemm_17     0.9999913985912616  0.0002379088904350423</span><br></pre></td></tr></table></figure></div>

<p>函数返回值：</p>
<p>函数返回值为以字典格式（Key为节点名称，Value为节点的量化敏感度信息）保存的量化敏感度，格式如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Out:</span><br><span class="line">&#123;&#x27;Conv_3&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.999009567957658&#x27;, &#x27;mse&#x27;: &#x27;0.027825591154396534&#x27;&#125;,</span><br><span class="line"> &#x27;MaxPool_2&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9993462241612948&#x27;, &#x27;mse&#x27;: &#x27;0.017706592209064044&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_6&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9998359175828787&#x27;, &#x27;mse&#x27;: &#x27;0.004541242333988731&#x27;&#125;,</span><br><span class="line"> &#x27;MaxPool_5&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9998616805443397&#x27;, &#x27;mse&#x27;: &#x27;0.0038416787014844325&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_0&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999297948984&#x27;, &#x27;mse&#x27;: &#x27;0.0019312848587735342&#x27;&#125;,</span><br><span class="line"> &#x27;Gemm_19&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999609772975628&#x27;, &#x27;mse&#x27;: &#x27;0.0010773885699633795&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_8&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999629625907311&#x27;, &#x27;mse&#x27;: &#x27;0.0010301886404004807&#x27;&#125;,</span><br><span class="line"> &#x27;Gemm_15&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999847687207736&#x27;, &#x27;mse&#x27;: &#x27;0.00041888411550854263&#x27;&#125;,</span><br><span class="line"> &#x27;MaxPool_12&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999853235024673&#x27;, &#x27;mse&#x27;: &#x27;0.0004039733791544747&#x27;&#125;,</span><br><span class="line"> &#x27;Conv_10&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.999985763659844&#x27;, &#x27;mse&#x27;: &#x27;0.0004040437432614943&#x27;&#125;,</span><br><span class="line"> &#x27;Gemm_17&#x27;: &#123;&#x27;cosine-similarity&#x27;: &#x27;0.9999913985912616&#x27;, &#x27;mse&#x27;: &#x27;0.0002379088904350423&#x27;&#125;&#125; ...&#125;</span><br></pre></td></tr></table></figure></div>



<ul>
<li><strong>plot_acc_error</strong>：只量化浮点模型中的某一个节点，并依次计算该模型与浮点模型中节点输出的误差，获得累积误差曲线。</li>
</ul>
<p><strong>API参数组</strong>：</p>
<table>
<thead>
<tr>
<th align="left">编 号</th>
<th align="left">参数名称</th>
<th align="left">参数配置说明</th>
<th align="left">可选&#x2F;必选</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left"><code>save_dir</code></td>
<td align="left"><strong>参数作用</strong>：保存路径。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定分析结果的保存路径。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left"><code>calibrated_data</code></td>
<td align="left"><strong>参数作用</strong>：指定校准数据。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定需要分析的校准数据。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left"><code>model_or_file</code></td>
<td align="left"><strong>参数作用</strong>：指定校准模型。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定需要分析的校准模型。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left"><code>quantize_node</code></td>
<td align="left"><strong>参数作用</strong>：只量化模型中指定的节点，查看误差累积曲线。<strong>取值范围</strong>：校准模型中的所有节点。<strong>默认配置</strong>：None。<strong>参数说明</strong>：可选参数。指定模型中需要量化的节点，同时保证其余节点均不量化。 通过判断该参数是否为嵌套列表进而决定是单节点量化还是部分量化。例如：quantize_node&#x3D;[‘Conv_2’, ‘Conv_9’]：分别只量化Conv_2和Conv_9，同时保证其余节点不量化。quantize_node&#x3D;[[‘Conv_2’], [‘Conv_9’, ‘Conv_2’]]：只量化Conv_2以及同时量化Conv_2和Conv_9，分别测试模型累积误差。quantize_node 包含两个特殊参数：’weight’ 和 ‘activation’。当：quantize_node &#x3D; [‘weight’]：只量化权重，不量化激活。quantize_node &#x3D; [‘activation’]：只量化激活，不量化权重。quantize_node &#x3D; [‘weight’, ‘activation’]：权重和激活分别量化。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left"><code>non_quantize_node</code></td>
<td align="left"><strong>参数作用</strong>：指定累积误差的类型。<strong>取值范围</strong>：校准模型中的所有节点。<strong>默认配置</strong>：None。<strong>参数说明</strong>：可选参数。指定模型中不量化的节点，同时保证其余节点全都量化。 通过判断该参数是否为嵌套列表进而决定是单节点不量化还是部分量化。例如：non_quantize_node&#x3D;[‘Conv_2’, ‘Conv_9’]：分别解除Conv_2和Conv_9节点的量化，同时保证其余节点全部量化。non_quantize_node&#x3D;[[‘Conv_2’], [‘Conv_9’, ‘Conv_2’]]：只解除Conv_2量化以及同时解除Conv_2和Conv_9量化，分别测试模型累积误差。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">6</td>
<td align="left"><code>metric</code></td>
<td align="left"><strong>参数作用</strong>：误差度量方式。<strong>取值范围</strong>：<code>&#39;cosine-similarity&#39;</code> , <code>&#39;mse&#39;</code> , <code>&#39;mre&#39;</code> , <code>&#39;sqnr&#39;</code> , <code>&#39;chebyshev&#39;</code><strong>默认配置</strong>：<code>&#39;cosine-similarity&#39;</code>。<strong>参数说明</strong>：设置计算模型误差的计算方式。</td>
<td align="left">可选</td>
</tr>
<tr>
<td align="left">7</td>
<td align="left"><code>average_mode</code></td>
<td align="left"><strong>参数作用</strong>：指定累积误差曲线的输出模式。<strong>取值范围</strong>：<code>True</code> 、 <code>False</code>。<strong>默认配置</strong>：<code>False</code>。<strong>参数说明</strong>：默认为False。若为True，那么获取累积误差的平均值作为结果。</td>
<td align="left">可选</td>
</tr>
</tbody></table>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_acc_error(save_dir: str,</span><br><span class="line">                   calibrated_data: str or CalibrationDataSet,</span><br><span class="line">                   model_or_file: ModelProto or str,</span><br><span class="line">                   quantize_node: List or str,</span><br><span class="line">                   non_quantize_node: List or str,</span><br><span class="line">                   metric: str = &#x27;cosine-similarity&#x27;,</span><br><span class="line">                   average_mode: bool = False):</span><br></pre></td></tr></table></figure></div>


<p><strong>API分析结果展示</strong></p>
<p><strong>1.指定节点量化累积误差测试</strong></p>
<ul>
<li>指定单节点量化</li>
</ul>
<p><strong>配置方式</strong>：quantize_node&#x3D;[‘Conv_2’, ‘Conv_90’]，quantize_node为单列表。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_acc_error(save_dir=&#x27;./&#x27;,</span><br><span class="line">                   calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">                   model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">                   quantize_node=[&#x27;Conv_2&#x27;, &#x27;Conv_90&#x27;],</span><br><span class="line">                   metric=&#x27;cosine-similarity&#x27;,</span><br><span class="line">                   average_mode=False)</span><br></pre></td></tr></table></figure></div>

<p><strong>描述</strong>：当quantize_node为单列表时，针对您设置的quantize_node， 分别单独量化quantize_node中的节点并保持模型中其他节点不量化，得到对应的模型后， 对该模型中每个节点的输出计算其与浮点模型中对应节点输出的之间的误差，并得到对应的累积误差曲线。</p>
<p>average_mode &#x3D; False时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163529466.png"
                      class="" title="image-20230511163529466"
                >

<p>average_mode &#x3D; True时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163541846.png"
                      class="" title="image-20230511163541846"
                >

<p><strong>average_mode</strong></p>
<p>average_mode默认为False。对于一些模型，此时无法通过累积误差曲线判断哪种量化策略更加有效， 因此需要将average_mode设置为True，此时会对前n个节点的累积误差求均值作为第n个节点的累积误差。</p>
<p>具体计算方式如下，例如：</p>
<p>average_mode&#x3D;False时，accumulate_error&#x3D;[1.0, 0.9, 0.9, 0.8]。</p>
<p>而将average_mode&#x3D;True后，accumulate_error&#x3D;[1.0, 0.95, 0.933, 0.9]。</p>
<ul>
<li>指定多个节点量化</li>
</ul>
<p><strong>配置方式</strong>：quantize_node&#x3D;[[‘Conv_2’], [‘Conv_2’, ‘Conv_90’]]，quantize_node为嵌套列表</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_acc_error(save_dir=&#x27;./&#x27;,</span><br><span class="line">                   calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">                   model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">                   quantize_node=[[&#x27;Conv_2&#x27;], [&#x27;Conv_2&#x27;, &#x27;Conv_90&#x27;]],</span><br><span class="line">                   metric=&#x27;cosine-similarity&#x27;,</span><br><span class="line">                   average_mode=False)</span><br></pre></td></tr></table></figure></div>

<p><strong>描述</strong>：当quantize_node为嵌套列表时，针对您设置的quantize_node，分别量化quantize_node中的 每个单列表指定的节点并保持模型中其他节点不量化，得到对应的模型后，对该模型中每个节点的输出计算 其与浮点模型中对应节点输出的之间的误差，并得到对应的累积误差曲线。</p>
<ul>
<li>partial_qmodel_0：只量化Conv_2节点，其余节点不量化；</li>
<li>partial_qmodel_1：只量化Conv_2和Conv_90节点，其余节点不量化。</li>
</ul>
<p>average_mode&#x3D;False时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163640082.png"
                      class="" title="image-20230511163640082"
                >

<p>average_mode&#x3D;True时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163652416.png"
                      class="" title="image-20230511163652416"
                >



<p><strong>2.解除模型部分节点量化后累积误差测试</strong></p>
<ul>
<li>指定单节点不量化</li>
</ul>
<p><strong>配置方式</strong>：non_quantize_node&#x3D;[‘Conv_2’, ‘Conv_90’]，non_quantize_node为单列表。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_acc_error(save_dir=&#x27;./&#x27;,</span><br><span class="line">                   calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">                   model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">                   non_quantize_node=[&#x27;Conv_2&#x27;, &#x27;Conv_90&#x27;],</span><br><span class="line">                   metric=&#x27;cosine-similarity&#x27;,</span><br><span class="line">                   average_mode=True)</span><br></pre></td></tr></table></figure></div>

<p><strong>描述</strong>：当non_quantize_node为单列表时，针对您设置的non_quantize_node， 分别解除non_quantize_node中各个节点的量化同时保持其他节点全部量化，得到对应的模型后， 对该模型中每个节点的输出计算其与浮点模型中对应节点输出的之间的误差，并得到对应的累积误差曲线。</p>
<p>average_mode &#x3D; False时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163706141.png"
                      class="" title="image-20230511163706141"
                >

<p>average_mode &#x3D; True时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163716860.png"
                      class="" title="image-20230511163716860"
                >



<ul>
<li>指定多个节点不量化</li>
</ul>
<p><strong>配置方式</strong>：non_quantize_node&#x3D;[[‘Conv_2’], [‘Conv_2’, ‘Conv_90’]]，non_quantize_node为嵌套列表。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_acc_error(save_dir=&#x27;./&#x27;,</span><br><span class="line">                   calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">                   model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">                   non_quantize_node=[[&#x27;Conv_2&#x27;], [&#x27;Conv_2&#x27;, &#x27;Conv_90&#x27;]],</span><br><span class="line">                   metric=&#x27;cosine-similarity&#x27;,</span><br><span class="line">                   average_mode=False)</span><br></pre></td></tr></table></figure></div>

<p><strong>描述</strong>：当non_quantize_node为嵌套列表时，针对您设置的non_quantize_node， 分别不量化non_quantize_node中的每个单列表指定的节点并保持模型中其他节点均量化， 得到对应的模型后，对该模型中每个节点的输出计算其与浮点模型中对应节点输出的之间的误差， 并得到对应的累积误差曲线。</p>
<ul>
<li>partial_qmodel_0：不量化Conv_2节点，其余节点量化；</li>
<li>partial_qmodel_1：不量化Conv_2和Conv_90节点，其余节点量化。</li>
</ul>
<p>average_mode &#x3D; False时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163732112.png"
                      class="" title="image-20230511163732112"
                >

<p>average_mode &#x3D; True时：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163745405.png"
                      class="" title="image-20230511163745405"
                >

<p><strong>测试技巧</strong>：</p>
<p>测试部分量化精度时，您可能会按照量化敏感度排序进行多组量化策略的精度对比，此时可以参考以下用法：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line"># 首先使用量化敏感度排序函数获取模型中节点的量化敏感度排序</span><br><span class="line">node_message = dbg.get_sensitivity_of_nodes(</span><br><span class="line">        model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">        metrics=&#x27;cosine-similarity&#x27;,</span><br><span class="line">        calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">        output_node=None,</span><br><span class="line">        node_type=&#x27;node&#x27;,</span><br><span class="line">        verbose=False,</span><br><span class="line">        interested_nodes=None)</span><br><span class="line"></span><br><span class="line"># node_message为字典类型，其key值为节点名称</span><br><span class="line">nodes = list(node_message.keys())</span><br><span class="line"></span><br><span class="line"># 通过nodes来指定不量化节点，可以方便使用</span><br><span class="line">dbg.plot_acc_error(save_dir=&#x27;./&#x27;,</span><br><span class="line">                   calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">                   model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">                   non_quantize_node=[nodes[:1], nodes[:2]],</span><br><span class="line">                   metric=&#x27;cosine-similarity&#x27;,</span><br><span class="line">                   average_mode=True)</span><br></pre></td></tr></table></figure></div>

<p><strong>3.激活权重分别量化</strong></p>
<p><strong>配置方式</strong>：quantize_node&#x3D;[‘weight’,’activation’]。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_acc_error_copy(</span><br><span class="line">         save_dir=&#x27;./&#x27;,</span><br><span class="line">         calibrated_data=&#x27;./calibration_data/&#x27;,</span><br><span class="line">         model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">         quantize_node=[&#x27;weight&#x27;, &#x27;activation&#x27;],</span><br><span class="line">         metric=&#x27;cosine-similarity&#x27;,</span><br><span class="line">         average_mode=False)</span><br></pre></td></tr></table></figure></div>

<p><strong>描述</strong>：quantize_node也可直接指定’weight’或者’activation’。当：</p>
<ul>
<li>quantize_node &#x3D; [‘weight’]：只量化权重，不量化激活。</li>
<li>quantize_node &#x3D; [‘activation’]：只量化激活，不量化权重。</li>
<li>quantize_node &#x3D; [‘weight’, ‘activation’]：权重和激活分别量化。</li>
</ul>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511163951063.png"
                      class="" title="image-20230511163951063"
                >



<p><strong>plot_distribution</strong></p>
<p><strong>功能</strong>：选取节点，分别获取该节点在浮点模型和校准模型中的输出，得到输出数据分布。另外，将两个输出结果做差，获取两个输出之间的误差分布。</p>
<p><strong>API参数组</strong>：</p>
<table>
<thead>
<tr>
<th align="left">编 号</th>
<th align="left">参数名称</th>
<th align="left">参数配置说明</th>
<th align="left">可选&#x2F;必选</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left"><code>save_dir</code></td>
<td align="left"><strong>参数作用</strong>：保存路径。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定分析结果的保存路径。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left"><code>model_or_file</code></td>
<td align="left"><strong>参数作用</strong>：指定校准模型。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定需要分析的校准模型。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left"><code>calibrated_data</code></td>
<td align="left"><strong>参数作用</strong>：指定校准数据。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定分析所需要的校准数据。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left"><code>nodes_list</code></td>
<td align="left"><strong>参数作用</strong>：指定需要分析的节点。<strong>取值范围</strong>：校准模型中的所有节点。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定需要分析的节点。若nodes_list中的节点类型为：权重校准节点：绘制原始权重和经过校准之后的权重的数据分布。激活校准节点：绘制激活校准节点的输入数据分布。普通节点：绘制该节点在量化前后的输出数据分布，同时绘制二者之间的误差分布。注：nodes_list为 list 类型，可指定一系列节点，并且上述三种类型节点 可同时指定。</td>
<td align="left">必选</td>
</tr>
</tbody></table>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_distribution(save_dir: str,</span><br><span class="line">                      model_or_file: ModelProto or str,</span><br><span class="line">                      calibrated_data: str or CalibrationDataSet,</span><br><span class="line">                      nodes_list: List[str] or str)</span><br></pre></td></tr></table></figure></div>

<p><strong>API分析结果展示</strong>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.plot_distribution(save_dir=&#x27;./&#x27;,</span><br><span class="line">                      model_or_file=&#x27;./calibrated_model.onnx&#x27;,</span><br><span class="line">                      calibrated_data=&#x27;./calibration_data&#x27;,</span><br><span class="line">                      nodes_list=[&#x27;317_HzCalibration&#x27;, # 激活节点</span><br><span class="line">                                  &#x27;471_HzCalibration&#x27;, # 权重节点</span><br><span class="line">                                  &#x27;Conv_2&#x27;]) # 普通节点</span><br></pre></td></tr></table></figure></div>

<p>node_output：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511165306052.png"
                      class="" title="image-20230511165306052"
                >

<p>weight：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511165319688.png"
                      class="" title="image-20230511165319688"
                >

<p>activation：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511165339651.png"
                      class="" title="image-20230511165339651"
                >

<p><strong>上方三幅图中，蓝色三角表示：数据绝对值的最大值。红色虚线表示：最小的校准阈值。</strong></p>
<ul>
<li><strong>get_channelwise_data_distribution</strong></li>
</ul>
<p><strong>功能</strong>：绘制指定校准节点输入数据通道间数据分布的箱线图。</p>
<blockquote>
<p>箱线图（Box Plot）是一种<strong>用于展示数据分布情况的图表</strong>，也称为盒须图、箱形图等。箱线图最初由美国统计学家约翰·图基发明，用于展示自然科学和社会科学研究中的数据分布情况。<br>一个标准的箱线图通常由五个值组成，分别是：最小值（Minimum）、下四分位数（Q1）、中位数（Median）、上四分位数（Q3）和最大值（Maximum）。箱线图通常以矩形的形式呈现，矩形的上下边缘分别表示上四分位数和下四分位数，其高度表示该区间的距离，中位数则用一条垂直的线表示。数据可视化时，箱线图经常搭配着“胡须”和异常值来呈现数据的分布情况。胡须的长度范围通常是1.5倍的四分位距，小圆点表示数据中的异常值（outliers）。<br>箱线图非常适合于用于比较多组数据或同一组数据在不同条件下的分布情况，可以揭示数据分布的中心、差异和离群值的情况，从而帮助分析人员作出更加准确的判断。常用的箱线图软件包括Matplotlib和Seaborn等。</p>
</blockquote>
<p><strong>API参数组</strong>：</p>
<table>
<thead>
<tr>
<th align="left">编 号</th>
<th align="left">参数名称</th>
<th align="left">参数配置说明</th>
<th align="left">可选&#x2F;必选</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left"><code>save_dir</code></td>
<td align="left"><strong>参数作用</strong>：保存路径。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定分析结果的保存路径。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left"><code>model_or_file</code></td>
<td align="left"><strong>参数作用</strong>：指定校准模型。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定需要分析的校准模型。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left"><code>calibrated_data</code></td>
<td align="left"><strong>参数作用</strong>：指定校准数据。<strong>取值范围</strong>：无。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定分析所需要的校准数据。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left"><code>nodes_list</code></td>
<td align="left"><strong>参数作用</strong>：指定校准节点。<strong>取值范围</strong>：校准模型中的所有权重校准节点和激活校准节点。<strong>默认配置</strong>：无。<strong>参数说明</strong>：必选，指定校准节点。</td>
<td align="left">必选</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left"><code>axis</code></td>
<td align="left"><strong>参数作用</strong>：指定channel所在的维度。<strong>取值范围</strong>：小于节点输入数据的维度。<strong>默认配置</strong>：None。<strong>参数说明</strong>：channel信息所在shape中的位置。 <strong>参数默认为None，此时对于激活校准节点， 默认认为节点输入数据的第二个维度表示channel信息，即axis&#x3D;1； 对于权重校准节点，会读取该节点属性中的axis参数作为channel信息。</strong></td>
<td align="left">可选</td>
</tr>
</tbody></table>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 导入debug模块</span><br><span class="line">import horizon_nn.debug as dbg</span><br><span class="line"></span><br><span class="line">dbg.get_channelwise_data_distribution(save_dir: str,</span><br><span class="line">                                      model_or_file: ModelProto or str,</span><br><span class="line">                                      calibrated_data: str or CalibrationDataSet,</span><br><span class="line">                                      nodes_list: List[str],</span><br><span class="line">                                      axis: int = None)</span><br></pre></td></tr></table></figure></div>

<p><strong>API分析结果展示</strong>：</p>
<p><strong>描述</strong>：针对用户设置的校准节点列表node_list，从参数axis中获取channel所在的维度，获取节点输入数据通道间的数据分布。 其中axis默认为None，此时若节点为权重校准节点，则channel所在的维度默认为0；若节点为激活校准节点，则channel所在的维度默认为1。</p>
<p>权重校准节点：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511170356933.png"
                      class="" title="image-20230511170356933"
                >

<p>激活校准节点：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511170406799.png"
                      class="" title="image-20230511170406799"
                >

<p>输出结果如下图所示：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230511170417646.png"
                      class="" title="image-20230511170417646"
                >

<p>图中：</p>
<ul>
<li>横坐标表示节点输入数据的通道数，图例中输入数据有96个通道。</li>
<li>纵坐标表示每个channel的数据分布范围，其中红色实线表示该channel数据的中位数，蓝色虚线表示均值。</li>
</ul>
<h5 id="PTQ模型转换示例手册"><a href="#PTQ模型转换示例手册" class="headerlink" title="PTQ模型转换示例手册"></a>PTQ模型转换示例手册</h5><p><code>小技巧</code></p>
<ol>
<li>我们推荐您在使用本手册之前，先阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/preface/toolchain_overview.html" >工具链概览 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节 和 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/ptq_usage.html" >PTQ原理及步骤 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分， 以便对PTQ训练后量化方案（以下简称为 <strong>PTQ方案</strong>）有一个比较充分地了解。</li>
<li>如果您在进行自定义模型转换时需要了解PTQ浮点定点模型转换方案工具的使用， 请阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/ptq_tool.html" >PTQ工具文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</li>
<li>在使用手册完成PTQ示例包的模型转换工作之后，请继续阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/ai_benchmark/source/index.html" >AI_Benchmark手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 和 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/index.html" >BPU SDK API手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 章节进行嵌入式开发工作，将模型部署上板。</li>
</ol>
<p>PTQ示例包帮助开发者快速体验并上手PTQ训练后量化方案。 开发者使用PTQ示例包不仅能够体验将32位浮点（FLOAT32）精度的示例模型转换为可以在地平线J5平台上运行的8位定点整数(INT8)精度的bin模型， 还能够了解如何使用PTQ方案提供的工具，并且基于示例脚本设计自定义模型转换业务逻辑脚本。</p>
<p>本手册旨在指导开发者使用地平线J5芯片算法工具链的 <strong>PTQ模型转换示例包</strong> （以下简称为 <strong>PTQ示例包</strong>）。 您可以在地平线J5天工开物发布物（即：horizon_j5_open_explorer）中获取PTQ示例包： <code>ddk/samples/ai_toolchain/horizon_model_convert_sample</code>。</p>
<blockquote>
<p>发布包介绍</p>
</blockquote>
<p><strong>模型量化示例包 <code>horizon_model_convert_sample</code></strong></p>
<p>注意：OE包默认不携带示例对应的校准数据集和原始模型，您需要在对应的示例文件夹内执行 <code>00_init.sh</code> 获取当前示例所需的模型和校准数据集。</p>
<p>全部示例的原始模型和数据集获取完成后的模型转换示例包的目录结构如下所示:</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">├── 01_common                              # 此路径包含PTQ示例包通用脚本和数据</span><br><span class="line">|   ├── calibration_data</span><br><span class="line">|   ├── data -&gt; /data/horizon_j5/data/     # 用于放置公共数据集的软链接</span><br><span class="line">|   ├── model_zoo -&gt; ../../../model_zoo    # 用于放置模型发布物的软链接</span><br><span class="line">|   ├── python</span><br><span class="line">|   ├── README.md</span><br><span class="line">|   ├── test_data</span><br><span class="line">|   └── tools</span><br><span class="line">├── 02_preq_examples</span><br><span class="line">|   ├── 01_fcos_efficientnetb0</span><br><span class="line">|   ├── 02_fcos_efficientnetb2</span><br><span class="line">|   ├── 03_fcos_efficientnetb3</span><br><span class="line">|   ├── det_evaluate.py</span><br><span class="line">|   ├── det_inference.py</span><br><span class="line">|   ├── seg_evaluate.py</span><br><span class="line">|   └── seg_inference.py</span><br><span class="line">├── 03_classification                      # 算法模型示例</span><br><span class="line">|   ├── 01_mobilenet</span><br><span class="line">|   ├── 02_googlenet</span><br><span class="line">|   ├── 03_resnet18</span><br><span class="line">|   ├── 05_efficientnet_lite0_onnx</span><br><span class="line">|   ├── 06_efficientnet_lite1_onnx</span><br><span class="line">|   ├── 07_efficientnet_lite2_onnx</span><br><span class="line">|   ├── 08_efficientnet_lite3_onnx</span><br><span class="line">|   ├── 09_efficientnet_lite4_onnx</span><br><span class="line">|   ├── 10_vargconvnet</span><br><span class="line">|   ├── 11_efficientnasnet_m</span><br><span class="line">|   ├── 12_efficientnasnet_s</span><br><span class="line">|   ├── cls_evaluate.py</span><br><span class="line">|   └── cls_inference.py</span><br><span class="line">├── 04_detection</span><br><span class="line">|   ├── 01_yolov2_darknet19</span><br><span class="line">|   ├── 02_yolov3_darknet53</span><br><span class="line">|   ├── 03_yolov5x</span><br><span class="line">|   ├── 04_ssd_mobilenetv1</span><br><span class="line">|   ├── 05_efficientdetd0</span><br><span class="line">|   ├── 06_centernet_resnet101</span><br><span class="line">|   ├── 07_fcos_efficientnetb0</span><br><span class="line">|   ├── 08_yolov4</span><br><span class="line">|   ├── 09_yolov3_vargdarknet</span><br><span class="line">|   ├── 10_fcos_resnet50</span><br><span class="line">|   ├── 11_fcos_resnext101</span><br><span class="line">|   ├── det_evaluate.py</span><br><span class="line">|   └── det_inference.py</span><br><span class="line">├── 05_miscellaneous</span><br><span class="line">|   ├── 01_lenet_gray</span><br><span class="line">|   ├── 02_resnet50_feature</span><br><span class="line">|   ├── 03_vector_diff</span><br><span class="line">|   ├── 04_multi_input_example</span><br><span class="line">|   ├── 07_model_verifier</span><br><span class="line">|   ├── 08_model_info</span><br><span class="line">|   ├── 09_mobilenet_bgr</span><br><span class="line">|   ├── 11_mobilenet_yuv444</span><br><span class="line">|   └── mis_inference.py</span><br><span class="line">├── 06_custom_op</span><br><span class="line">|   └── mapper</span><br><span class="line">├── 07_segmentation</span><br><span class="line">|   ├── 01_unet_mobilenet</span><br><span class="line">|   ├── 02_deeplabv3plus_efficientnetb0</span><br><span class="line">|   ├── 03_fastscnn_efficientnetb0</span><br><span class="line">|   ├── 04_deeplabv3plus_dilation1248</span><br><span class="line">|   ├── 05_deeplabv3plus_efficientnetm1</span><br><span class="line">|   ├── 06_deeplabv3plus_efficientnetm2</span><br><span class="line">|   ├── seg_evaluate.py</span><br><span class="line">|   └── seg_inference.py</span><br><span class="line">├── data_preprocess.py</span><br><span class="line">└── version.txt</span><br></pre></td></tr></table></figure></div>

<p>示例包中包含的主要内容：</p>
<p><a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/algorithm_sample.html" >常见算法模型示例 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>常见算法模型示例是指 <code>02_preq_examples/</code> 、 <code>03_classification/</code> 、 <code>04_detection/</code> 和 <code>07_segmentation/</code> 文件夹中的示例。</p>
<p>这些示例的主要目标是指导用户：</p>
<ul>
<li>快速体验模型转换的流程。</li>
<li>快速评测模型转换的精度。</li>
<li>体验转换的效果。</li>
</ul>
<p><a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/misc_sample.html" >其他算法模型示例 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>其他算法模型示例是指 <code>05_miscellaneous/</code> 和 <code>06_custom_op/</code> 文件夹中的示例。</p>
<ul>
<li><code>05_miscellaneous</code> ，杂项示例，指导用户使用地平线芯片工具链提供的一些其他内容。 比如：如何使用地平线模型转换工具，使rgb数据训练的模型能在runtime运行时接受yuv数据。 <code>03_vector_diff</code> 指导用户如何使用 <code>vec_diff</code> 工具来定位问题的一个示例。</li>
<li><code>06_custom_op/</code> 为用户自定义OP示例，帮助用户了解如何在模型含有工具链不支持的算子的情况下添加自定义算子的功能。</li>
</ul>
<p><strong>模型发布物 <code>model_zoo</code></strong></p>
<p><code>model_zoo</code> 包含两个路径： <code>mapper</code> 和 <code>runtime</code>。 其中 <code>mapper</code> 路径下包含了PTQ和QAT方案进行模型转换时要使用的模型（ONNX或Caffe格式的浮点模型）， 其中fcos_efficientnetb0、fcos_efficientnetb2和fcos_efficientnetb3为QAT模型，其余为PTQ模型； <code>runtime</code> 路径下包含了嵌入式运行时开发要使用的bin模型。</p>
<p>以下仅展示PTQ和QAT示例要使用的模型发布物：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">├── classification</span><br><span class="line">│   ├── efficientnasnet</span><br><span class="line">│   │   ├── efficientnasnet-m.onnx</span><br><span class="line">│   │   ├── efficientnasnet.onnx</span><br><span class="line">│   │   └── efficientnasnet-s.onnx</span><br><span class="line">│   ├── efficientnet_lite_onnx</span><br><span class="line">│   │   ├── efficientnet_lite0_fp32.onnx</span><br><span class="line">│   │   ├── efficientnet_lite1_fp32.onnx</span><br><span class="line">│   │   ├── efficientnet_lite2_fp32.onnx</span><br><span class="line">│   │   ├── efficientnet_lite3_fp32.onnx</span><br><span class="line">│   │   └── efficientnet_lite4_fp32.onnx</span><br><span class="line">│   ├── googlenet</span><br><span class="line">│   │   └── googlenet.onnx</span><br><span class="line">│   ├── mobilenet</span><br><span class="line">│   │   ├── mobilenet.caffemodel</span><br><span class="line">│   │   ├── mobilenet_deploy.prototxt</span><br><span class="line">│   │   ├── mobilenet_v2.caffemodel</span><br><span class="line">│   │   └── mobilenet_v2_deploy.prototxt</span><br><span class="line">│   ├── mobilenet_onnx</span><br><span class="line">│   │   └── mobilenetv2.onnx</span><br><span class="line">│   ├── resnet18</span><br><span class="line">│   │   ├── resnet18.caffemodel</span><br><span class="line">│   │   └── resnet18_deploy.prototxt</span><br><span class="line">│   ├── resnet50</span><br><span class="line">│   │   ├── resnet_50.caffemodel</span><br><span class="line">│   │   └── resnet_50_deploy.prototxt</span><br><span class="line">│   ├── se_resnet_gray_onnx</span><br><span class="line">│   │   └── se_resnet_gray.onnx</span><br><span class="line">│   └── vargnet</span><br><span class="line">│       └── vargconvnet.onnx</span><br><span class="line">├── custom_op</span><br><span class="line">│   └── custom_op.onnx</span><br><span class="line">├── detection</span><br><span class="line">│   ├── centernet</span><br><span class="line">│   │   ├── centernet_resnet101_coco.onnx</span><br><span class="line">│   │   └── centernet_resnet50.onnx</span><br><span class="line">│   ├── efficientdetd0</span><br><span class="line">│   │   └── efficientdet_nhwc.onnx</span><br><span class="line">│   ├── fcos_efficientnetb0</span><br><span class="line">│   │   ├── fcos_effb0.onnx</span><br><span class="line">│   │   ├── fcos_efficientnetb0.onnx</span><br><span class="line">│   │   └── fcos.onnx</span><br><span class="line">│   ├── fcos_efficientnetb3</span><br><span class="line">│   │   └── fcos_effb3.onnx</span><br><span class="line">│   ├── fcos_resnet50</span><br><span class="line">│   │   └── fcos_resnet50.onnx</span><br><span class="line">│   ├── fcos_resnext101</span><br><span class="line">│   │   └── fcos_resnext101.onnx</span><br><span class="line">│   ├── ssd_mobilenetv1</span><br><span class="line">│   │   ├── mobilenet_iter_73000.caffemodel</span><br><span class="line">│   │   └── MobileNetSSD_deploy.prototxt</span><br><span class="line">│   ├── yolov2_darknet19</span><br><span class="line">│   │   ├── README.md</span><br><span class="line">│   │   ├── yolov2.caffemodel</span><br><span class="line">│   │   └── yolov2_transposed.prototxt</span><br><span class="line">│   ├── yolov3_darknet53</span><br><span class="line">│   │   ├── README.md</span><br><span class="line">│   │   ├── yolov3.caffemodel</span><br><span class="line">│   │   └── yolov3_transposed.prototxt</span><br><span class="line">│   ├── yolov3_vargdarknet</span><br><span class="line">│   │   └── yolov3_vargdarknet53.onnx</span><br><span class="line">│   ├── yolov4</span><br><span class="line">│   │   └── yolov4_efficientnetb0.onnx</span><br><span class="line">│   └── yolov5_onnx_optimized</span><br><span class="line">│       ├── YOLOv5l.onnx</span><br><span class="line">│       ├── YOLOv5m.onnx</span><br><span class="line">│       ├── YOLOv5s.onnx</span><br><span class="line">│       └── YOLOv5x.onnx</span><br><span class="line">├── other</span><br><span class="line">│   ├── fcos_efficientnetb0</span><br><span class="line">│   │   └── fcos_efficientnetb0_qat.onnx</span><br><span class="line">│   ├── lenet</span><br><span class="line">│   │   ├── lenet_iter_100000.caffemodel</span><br><span class="line">│   │   └── lenet_train_test.prototxt</span><br><span class="line">│   ├── mobilenetv2_three_inputs</span><br><span class="line">│   │   ├── mobilenetv2_three_inputs.caffemodel</span><br><span class="line">│   │   └── mobilenetv2_three_inputs.prototxt</span><br><span class="line">│   ├── multi_type</span><br><span class="line">│   │   └── original_float_model.onnx</span><br><span class="line">│   ├── resizer_model</span><br><span class="line">│   │   └── resizer_model.onnx</span><br><span class="line">│   └── resnet50_feature</span><br><span class="line">│       ├── resnet50_feature.caffemodel</span><br><span class="line">│       ├── resnet50_feature_deploy.prototxt</span><br><span class="line">│       ├── resnet50_pre.caffemodel</span><br><span class="line">│       └── resnet50_pre.prototxt</span><br><span class="line">├── preq_examples</span><br><span class="line">│   └── fcos_efficientnet</span><br><span class="line">│       ├── fcos_eff_b0.onnx</span><br><span class="line">│       ├── fcos_eff_b2.onnx</span><br><span class="line">│       └── fcos_eff_b3.onnx</span><br><span class="line">└── segmentation</span><br><span class="line">    ├── deeplabv3plus_efficientnetb0</span><br><span class="line">    │   ├── deeplabv3_cityscapes_dila1248_permute.onnx</span><br><span class="line">    │   └── deeplabv3plus_efficientnetb0.onnx</span><br><span class="line">    ├── deeplabv3plus_efficientnetm</span><br><span class="line">    │   ├── deeplabv3plus_efficientnetm1.onnx</span><br><span class="line">    │   └── deeplabv3plus_efficientnetm2.onnx</span><br><span class="line">    ├── fastscnn_efficientnetb0</span><br><span class="line">    │   └── fastscnn_efficientnetb0.onnx</span><br><span class="line">    ├── mobilenet_unet</span><br><span class="line">    │   └── tf_unet_trained.onnx</span><br><span class="line">    └── unet_mobilenet</span><br><span class="line">        └── tf_unet_trained.onnx</span><br></pre></td></tr></table></figure></div>

<p><strong>注意：此目录树是完整结构展示，实际上OE包并没有直接携带所有的模型。此目录树是完整结构展示，实际上OE包并没有直接携带所有的模型。</strong></p>
<blockquote>
<p>常见的算法模型示例</p>
</blockquote>
<p><strong>位置路径</strong></p>
<p>常见算法模型示例位于 <code>horizon_model_convert_sample</code> 路径的： <code>02_preq_examples/</code>、 <code>03_classification/</code>、 <code>04_detection/</code> 和 <code>07_segmentation/</code> 文件夹中。</p>
<p><strong>如何准备数据集</strong></p>
<p>数据集的下载地址可参考下表：</p>
<table>
<thead>
<tr>
<th align="left"><strong>数据集</strong></th>
<th align="left"><strong>下载地址</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">ImageNet</td>
<td align="left"><a class="link"   target="_blank" rel="noopener" href="https://www.image-net.org/download.php" >https://www.image-net.org/download.php <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></td>
</tr>
<tr>
<td align="left">COCO</td>
<td align="left"><a class="link"   target="_blank" rel="noopener" href="https://cocodataset.org/" >https://cocodataset.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></td>
</tr>
<tr>
<td align="left">VOC</td>
<td align="left"><a class="link"   target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/" >http://host.robots.ox.ac.uk/pascal/VOC/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> （需要下载2007和2012两个版本）</td>
</tr>
<tr>
<td align="left">Cityscapes</td>
<td align="left"><a class="link"   target="_blank" rel="noopener" href="https://github.com/mcordts/cityscapesScripts" >https://github.com/mcordts/cityscapesScripts <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></td>
</tr>
<tr>
<td align="left">CIFAR-10</td>
<td align="left"><a class="link"   target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar.html" >http://www.cs.toronto.edu/~kriz/cifar.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></td>
</tr>
</tbody></table>
<ul>
<li><strong>数据集参考结构</strong></li>
</ul>
<p><code>ImageNet</code></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">imagenet/</span><br><span class="line">├── calibration_data</span><br><span class="line">│   ├── ILSVRC2012_val_00000001.JPEG</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── ILSVRC2012_val_00000100.JPEG</span><br><span class="line">├── ILSVRC2017_val.txt</span><br><span class="line">├── val</span><br><span class="line">│   ├── ILSVRC2012_val_00000001.JPEG</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── ILSVRC2012_val_00050000.JPEG</span><br><span class="line">└── val.txt</span><br></pre></td></tr></table></figure></div>

<p><code>COCO </code></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">coco/</span><br><span class="line">├── calibration_data</span><br><span class="line">│   ├── COCO_val2014_000000181007.jpg</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── COCO_val2014_000000181739.jpg</span><br><span class="line">└── coco_val2017</span><br><span class="line">    ├── annotations</span><br><span class="line">    │   ├── instances_train2017.json</span><br><span class="line">    │   └── instances_val2017.json</span><br><span class="line">    └── images</span><br><span class="line">        ├── 000000000139.jpg</span><br><span class="line">        ├── 000000000285.jpg</span><br><span class="line">        ├── ...</span><br><span class="line">        ├── 000000581615.jpg</span><br><span class="line">        └── 000000581781.jpg</span><br></pre></td></tr></table></figure></div>

<p><code>VOC</code></p>
<p>注意：VOC2012目录下目前存储了VOC2017和VOC2012两份数据集，请您按照如下目录结构对评测数据集进行处理。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">VOCdevkit/</span><br><span class="line">└── VOC2012</span><br><span class="line">    ├── Annotations</span><br><span class="line">    │   ├── 2007_000027.xml</span><br><span class="line">    │   ├── ...</span><br><span class="line">    │   └── 2012_004331.xml</span><br><span class="line">    ├── ImageSets</span><br><span class="line">    │   ├── Action</span><br><span class="line">    │   │   ├── jumping_train.txt</span><br><span class="line">    │   │   ├── jumping_trainval.txt</span><br><span class="line">    │   │   ├── jumping_val.txt</span><br><span class="line">    │   │   ├── ...</span><br><span class="line">    │   │   ├── val.txt</span><br><span class="line">    │   │   ├── walking_train.txt</span><br><span class="line">    │   │   ├── walking_trainval.txt</span><br><span class="line">    │   │   └── walking_val.txt</span><br><span class="line">    │   ├── Layout</span><br><span class="line">    │   │   ├── train.txt</span><br><span class="line">    │   │   ├── trainval.txt</span><br><span class="line">    │   │   └── val.txt</span><br><span class="line">    │   ├── Main</span><br><span class="line">    │   │   ├── aeroplane_train.txt</span><br><span class="line">    │   │   ├── aeroplane_trainval.txt</span><br><span class="line">    │   │   ├── aeroplane_val.txt</span><br><span class="line">    │   │   ├── ...</span><br><span class="line">    │   │   ├── train.txt</span><br><span class="line">    │   │   ├── train_val.txt</span><br><span class="line">    │   │   ├── trainval.txt</span><br><span class="line">    │   │   ├── tvmonitor_train.txt</span><br><span class="line">    │   │   ├── tvmonitor_trainval.txt</span><br><span class="line">    │   │   ├── tvmonitor_val.txt</span><br><span class="line">    │   │   └── val.txt</span><br><span class="line">    │   └── Segmentation</span><br><span class="line">    │       ├── train.txt</span><br><span class="line">    │       ├── trainval.txt</span><br><span class="line">    │       └── val.txt</span><br><span class="line">    ├── JPEGImages</span><br><span class="line">    │   ├── 2007_000027.jpg</span><br><span class="line">    │   ├── ...</span><br><span class="line">    │   └── 2012_004331.jpg</span><br><span class="line">    ├── SegmentationClass</span><br><span class="line">    │   ├── 2007_000032.png</span><br><span class="line">    │   ├── ...</span><br><span class="line">    │   └── 2011_003271.png</span><br><span class="line">    ├── SegmentationObject</span><br><span class="line">    │   ├── 2007_000032.png</span><br><span class="line">    │   ├── ...</span><br><span class="line">    │   └── 2011_003271.png</span><br><span class="line">    └── train.txt</span><br></pre></td></tr></table></figure></div>

<p><code>Cityscapes</code></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cityscapes/</span><br><span class="line">├── cityscapes_calibration_data</span><br><span class="line">│   ├── aachen_000000_000019_leftImg8bit.png</span><br><span class="line">│   ├── ...</span><br><span class="line">│   └── aachen_000099_000019_leftImg8bit.png</span><br><span class="line">├── gtFine</span><br><span class="line">│   ├── test</span><br><span class="line">│   │   ├── berlin</span><br><span class="line">│   │   ├── ...</span><br><span class="line">│   │   └── munich</span><br><span class="line">│   ├── train</span><br><span class="line">│   │   ├── aachen</span><br><span class="line">│   │   ├── ...</span><br><span class="line">│   │   └── zurich</span><br><span class="line">│   └── val</span><br><span class="line">│       ├── frankfurt</span><br><span class="line">│       ├── lindau</span><br><span class="line">│       └── munster</span><br><span class="line">├── leftImg8bit</span><br><span class="line">│   ├── test</span><br><span class="line">│   │   ├── berlin</span><br><span class="line">│   │   ├── ...</span><br><span class="line">│   │   └── munich</span><br><span class="line">│   ├── train</span><br><span class="line">│   │   ├── aachen</span><br><span class="line">│   │   ├── ...</span><br><span class="line">│   │   └── zurich</span><br><span class="line">│   └── val</span><br><span class="line">│       ├── frankfurt</span><br><span class="line">│       ├── lindau</span><br><span class="line">│       └── munster</span><br><span class="line">├── license.txt</span><br><span class="line">└── README</span><br></pre></td></tr></table></figure></div>

<p><code>CIFAR=10</code></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cifar-10/</span><br><span class="line">├── batches.meta</span><br><span class="line">├── cifar10_val.txt</span><br><span class="line">├── data_batch_1</span><br><span class="line">├── data_batch_2</span><br><span class="line">├── data_batch_3</span><br><span class="line">├── data_batch_4</span><br><span class="line">├── data_batch_5</span><br><span class="line">├── readme.html</span><br><span class="line">└── test_batch</span><br></pre></td></tr></table></figure></div>



<p><strong>如何准备模型</strong></p>
<p>在使用模型转换示例包时，请您先准备好对应的浮点模型。</p>
<p>OE包默认不携带示例对应的校准数据集和原始模型，您需要在对应的示例文件夹内执行 <code>00_init.sh</code> 获取当前示例所需的模型和校准数据集。</p>
<p>请悉知，下方提供的模型精度数据为Python3.8环境下，地平线为您提供的参考数据。如您的Python版本为Python3.6，那么数据可能会有微小差距。</p>
<p><code>fcos_efficientnetb0</code></p>
<p>注意：</p>
<ul>
<li>该模型为采用QAT方式训练出来的模型。</li>
<li>为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 <code>remove_node_type</code> 参数进行了配置，将bin模型中的Dequantize节点做了删除的操作。</li>
</ul>
<blockquote>
<ol>
<li>在编译bin模型时，需要将模型优化为特定硬件的指令集，以提高模型的执行效率和性能。在特定的硬件平台上，有些节点类型可能无法被执行，或者执行效率很低，会导致模型的性能下降。因此，在编译bin模型的yaml文件中，可以指定需要删除的节点类型，以保证模型的性能达到最优。</li>
<li>在本例中，由于执行Dequantize操作会降低模型的执行效率，因此在编译bin模型的过程中，配置了”remove_node_type”参数，将bin模型中的Dequantize节点删除，从而提高板端的性能。</li>
</ol>
</blockquote>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/PreQQAT" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/PreQQAT <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">be2fe17530bc366b038f5309199bf712</td>
<td align="left">fcos_eff_b0.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.348(FLOAT)&#x2F;0.348(INT8)</p>
<p><code>fcos_efficientnetb2</code></p>
<p>注意：为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 <code>remove_node_type</code> 参数进行了配置，将bin模型中的Dequantize节点做了删除的操作。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/PreQQAT" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/PreQQAT <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">58ffc007a2ab9a053a559945fb27fac8</td>
<td align="left">fcos_eff_b2.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.447(FLOAT)&#x2F;0.447(INT8)</p>
<p><code> fcos_efficientnetb3</code></p>
<p>为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 <code>remove_node_type</code> 参数进行了配置，将bin模型中的Dequantize节点做了删除的操作。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/PreQQAT" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/PreQQAT <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">da37796ea8f2a4a54684a2520fdd6148</td>
<td align="left">fcos_eff_b3.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.472(FLOAT)&#x2F;0.473(INT8)</p>
<p><code>MobileNetv1/v2</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/shicai/MobileNet-Caffe" >https://github.com/shicai/MobileNet-Caffe <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">3fd6889ec48bda46451d67274144e2a8</td>
<td align="left">mobilenet.caffemodel</td>
</tr>
<tr>
<td align="left">8922f90f629d428fecf866e798ac7c08</td>
<td align="left">mobilenet_deploy.prototxt</td>
</tr>
<tr>
<td align="left">54aab8425ea068d472e8e4015f22360c</td>
<td align="left">mobilenet_v2.caffemodel</td>
</tr>
<tr>
<td align="left">13101ee86ab6d217d5fd6ed46f7a4faa</td>
<td align="left">mobilenet_v2_deploy.prototxt</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<ul>
<li>MobileNetv1：0.7061(FLOAT)&#x2F;0.7026(INT8)</li>
<li>MobileNetv2：0.7165(FLOAT)&#x2F;0.7119(INT8)</li>
</ul>
<p><code>GoogleNet</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/GoogleNet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/GoogleNet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">f107ae6806ea1016afbc718210b7a617</td>
<td align="left">googlenet.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：0.7001(FLOAT)&#x2F;0.6985(INT8)</p>
<p><code>ResNet18</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HolmesShuan/ResNet-18-Caffemodel-on-ImageNet" >https://github.com/HolmesShuan/ResNet-18-Caffemodel-on-ImageNet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">0904d601fc930d4f0c62a2a95b3c3b93</td>
<td align="left">resnet18.caffemodel</td>
</tr>
<tr>
<td align="left">ee8ac82cd693a0fe55af42cca3fc52e5</td>
<td align="left">resnet18_deploy.prototxt</td>
</tr>
</tbody></table>
<p>3.模型精度：0.6837(FLOAT)&#x2F;0.6831(INT8)</p>
<p><code>EfficientNet_Lite0/1/2/3/4</code></p>
<p>注意：</p>
<blockquote>
<p>为了快速运行示例，避免使用第三方工具带来的风险，强烈推荐您直接使用地平线模型发布物 <strong>model_zoo&#x2F;mapper&#x2F;</strong> 路径下准备好的ONNX浮点模型。 如果您有兴趣复现tflite2onnx的模型转换过程，也可以尝试使用以下三方工具。但地平线无法保证第三方工具的质量和转换成功率。</p>
</blockquote>
<p>注意</p>
<p>为了快速运行示例，避免使用第三方工具带来的风险，强烈推荐您直接使用地平线模型发布物 <strong>model_zoo&#x2F;mapper&#x2F;</strong> 路径下准备好的ONNX浮点模型。 如果您有兴趣复现tflite2onnx的模型转换过程，也可以尝试使用以下三方工具。但地平线无法保证第三方工具的质量和转换成功率。</p>
<p>1.模型来源：可从 <a class="link"   target="_blank" rel="noopener" href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite" >https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 获取tar包。</p>
<p>2.地平线模型发布物中转换后的ONNX模型md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">001a329bd367fbec22b415c7a33d7bdb</td>
<td align="left">efficientnet_lite0_fp32.onnx</td>
</tr>
<tr>
<td align="left">1205e95aea66650c71292bde236d55a9</td>
<td align="left">efficientnet_lite1_fp32.onnx</td>
</tr>
<tr>
<td align="left">474741c15494b79a89fe51d89e0c43c7</td>
<td align="left">efficientnet_lite2_fp32.onnx</td>
</tr>
<tr>
<td align="left">550455b41848d333f8359279c89a6bae</td>
<td align="left">efficientnet_lite3_fp32.onnx</td>
</tr>
<tr>
<td align="left">bde7fe57eadb4a30ef76f68da622dcd5</td>
<td align="left">efficientnet_lite4_fp32.onnx</td>
</tr>
</tbody></table>
<p>3.下载后可从tar包中得到 <code>.tflite</code> 文件，然后可通过tflite2onnx工具 (<a class="link"   target="_blank" rel="noopener" href="https://pypi.org/project/tflite2onnx/" >https://pypi.org/project/tflite2onnx/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>) 将tflite转换为ONNX模型。</p>
<p>不同版本的tflite2onnx转换出来的layout会不一样，若转换出来的ONNX模型的输入layout是NCHW排布，则build时 <code>input_type_train</code> 中：</p>
<ul>
<li>EfficientNet_Lite0应该选择 <code>NCHW</code>；</li>
<li>EfficientNet_Lite1应该选择 <code>NCHW</code>；</li>
<li>EfficientNet_Lite2应该选择 <code>NCHW</code>；</li>
<li>EfficientNet_Lite3应该选择 <code>NCHW</code>；</li>
<li>EfficientNet_Lite4应该选择 <code>NCHW</code>。</li>
</ul>
<p>4.模型精度：</p>
<ul>
<li>EfficientNet_Lite0：0.7490(FLOAT)&#x2F;0.7469(INT8)</li>
<li>EfficientNet_Lite1：0.7648(FLOAT)&#x2F;0.7624(INT8)</li>
<li>EfficientNet_Lite2：0.7738(FLOAT)&#x2F;0.7715(INT8)</li>
<li>EfficientNet_Lite3：0.7922(FLOAT)&#x2F;0.7902(INT8)</li>
<li>EfficientNet_Lite4：0.8069(FLOAT)&#x2F;0.8058(INT8)</li>
</ul>
<blockquote>
<p><code>tflite2onnx</code>是一个用于将TensorFlow Lite模型（TFLite模型）转换为ONNX（Open Neural Network Exchange）格式的工具。TensorFlow Lite是一种针对移动设备和嵌入式设备的轻量级深度学习推理框架，而ONNX是一种跨平台的开放式深度学习模型表示格式。</p>
<p>由于TensorFlow Lite和ONNX是不同的模型表示格式，因此在某些情况下需要将TFLite模型转换为ONNX格式，以便在其他框架或平台上进行进一步的处理和推理。</p>
<p><code>tflite2onnx</code>工具提供了将TFLite模型转换为ONNX模型的功能，它可以解析TFLite模型的结构和权重，并将其转换为与ONNX规范兼容的模型。这样，您就可以使用ONNX模型在支持ONNX的框架中进行推理，例如PyTorch、TensorFlow、ONNX Runtime等。</p>
<p>请注意，<code>tflite2onnx</code>是一个第三方工具，它不是官方的TensorFlow或ONNX项目的一部分。因此，在使用该工具时，请确保您已查看和理解了相关的文档和使用说明。</p>
</blockquote>
<p><code>vargconvnet</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/VargConvNet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/VargConvNet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">e21b8db17916f9046253bbe0bb8de3ef</td>
<td align="left">vargconvnet.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：0.7790(FLOAT)&#x2F;0.7785(INT8)</p>
<p><code>efficientnasnet_m</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/EfficientnasNet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/EfficientnasNet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">fc36c052c6f034c0b64a6197b91b0c62</td>
<td align="left">efficientnasnet-m.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：0.7973(FLOAT)&#x2F;0.7916(INT8)</p>
<p><code>efficientnasnet_s</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/EfficientnasNet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/EfficientnasNet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">e2744bd748f4265f4488676835a6ca24</td>
<td align="left">efficientnasnet-s.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：0.7578(FLOAT)&#x2F;0.7518(INT8)</p>
<p><code>YOLOv2_Darknet19</code></p>
<ul>
<li>为了快速运行示例，避免使用第三方工具带来的风险，强烈推荐您直接使用地平线模型发布物 <strong>model_zoo&#x2F;mapper&#x2F;</strong> 路径下准备好的Caffe浮点模型。 如果您有兴趣复现darknet2caffe的模型转换过程，也可以尝试使用以下三方工具。但地平线无法保证三方工具的质量和转换成功率。</li>
<li>为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 remove_node_type 参数进行了配置，将bin模型中的Dequantize节点做了删除的操作。</li>
</ul>
<p>1.YOLOv2_Darknet19模型需要首先从YOLO官网(<a class="link"   target="_blank" rel="noopener" href="https://pjreddie.com/darknet/yolo/)%EF%BC%8C%E4%B8%8B%E8%BD%BDYOLOv2" >https://pjreddie.com/darknet/yolo/)，下载YOLOv2 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 608x608的.cfg和.weight文件 并使用darknet2caffe (<a class="link"   target="_blank" rel="noopener" href="https://github.com/xingyanan/darknet2caffe" >https://github.com/xingyanan/darknet2caffe <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>) 转换工具将其转换为caffe model。</p>
<p><strong>注意：</strong></p>
<p>1.该转换工具（darknet2caffe）是一个简化版本，使用时，需要修改该工具生成的.prototxt文件，将其中的 <code>&#39;Reshape&#39;</code> 层修改成 <code>&#39;Passthrough&#39;</code> 层， Passthrough 层具体修改后的参数请见提供的yolov2.prototxt例子，并在输出节点增加一个NCHW2NHWC的Permute操作。</p>
<blockquote>
<p>该段话提到的是将darknet网络转换为caffe网络的问题。转换工具是一个简化版，它可以将darknet网络转换为caffe网络，并生成.prototxt文件。但是，在应用生成的.prototxt文件之前，需要按照以下方法对该文件进行修改：</p>
<ol>
<li>将 ‘Reshape’ 层修改成 ‘Passthrough’ 层。这是因为darknet网络中的 ‘Reshape’ 层在caffe中没有直接对应的层，需要修改成 ‘Passthrough’ 层，以保持网络结构一致。所谓的 ‘Passthrough’ 层实际上就是将输入数据直接传递到输出数据的层。</li>
<li>对 ‘Passthrough’ 层进行具体的参数修改。根据给出的例子，在 ‘Passthrough’ 层中添加一些参数，以适配yolov2.prototxt中的网络结构。</li>
<li>在输出节点增加一个NCHW2NHWC的Permute操作，以将数据从NCHW形式的格式（列优先）转换为NHWC形式的格式（行优先）。</li>
</ol>
</blockquote>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">7aa7a6764401cebf58e73e72fcbd2a45</td>
<td align="left">yolov2.caffemodel</td>
</tr>
<tr>
<td align="left">72e9a51c1e284e4b66e69f72ca9214c8</td>
<td align="left">yolov2_transposed.prototxt</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><code>YOLOv3_Darknet53</code></p>
<p>注意：为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 remove_node_type 参数进行了配置，将bin模型中的Dequantize节点做了删除的操作。</p>
<p>1.YOLOv3_Darknet53模型获取：</p>
<p>URL： <a class="link"   target="_blank" rel="noopener" href="https://github.com/ChenYingpeng/caffe-yolov3/" >https://github.com/ChenYingpeng/caffe-yolov3/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，caffemodel可以在该github的README.md提供的百度云下载路径中下载，并在输出节点增加一个NCHW2NHWC的Permute操作。</p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">935af6e1530af5c0017b3674adce95e9</td>
<td align="left">yolov3_transposed.prototxt</td>
</tr>
<tr>
<td align="left">9a0f09c850656913ec27a6da06d9f9cc</td>
<td align="left">yolov3.caffemodel</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.333(FLOAT)&#x2F;0.335(INT8)</p>
<p><code>YOLOv5x</code></p>
<p>1.YOLOv5x模型：可以从URL： <a class="link"   target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/releases/tag/v2.0" >https://github.com/ultralytics/yolov5/releases/tag/v2.0 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中下载相应的pt文件。</p>
<p><strong>注意：在clone代码时，请确认您使用的Tags是 v2.0，否则将导致转换失败。</strong></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">2e296b5e31bf1e1b6b8ea4bf36153ea5</td>
<td align="left">yolov5l.pt</td>
</tr>
<tr>
<td align="left">16150e35f707a2f07e7528b89c032308</td>
<td align="left">yolov5m.pt</td>
</tr>
<tr>
<td align="left">42c681cf466c549ff5ecfe86bcc491a0</td>
<td align="left">yolov5s.pt</td>
</tr>
<tr>
<td align="left">069a6baa2a741dec8a2d44a9083b6d6e</td>
<td align="left">yolov5x.pt</td>
</tr>
</tbody></table>
<ul>
<li>为了更好地适配后处理代码，我们在ONNX模型导出前对Github代码做了如下修改（代码参见：<a class="link"   target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/blob/v2.0/models/yolo.py%EF%BC%89%EF%BC%9A" >https://github.com/ultralytics/yolov5/blob/v2.0/models/yolo.py）： <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># x = x.copy()  # for profiling</span></span><br><span class="line">    z = []  <span class="comment"># inference output</span></span><br><span class="line">    self.training |= self.export</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.nl):</span><br><span class="line">        x[i] = self.m[i](x[i])  <span class="comment"># conv</span></span><br><span class="line">        bs, _, ny, nx = x[i].shape  <span class="comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span></span><br><span class="line">        <span class="comment">#  x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()</span></span><br><span class="line">        x[i] = x[i].permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous()</span><br></pre></td></tr></table></figure></div>

<p><strong>注意：去除了每个输出分支尾部从4维到5维的reshape（即不将channel从255拆分成3x85），然后将layout从NHWC转换成NCHW再输出。</strong></p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230512090436547.png"
                      class="" title="image-20230512090436547"
                >

<ul>
<li>下载完成后通过脚本 <a class="link"   target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5/blob/v2.0/models/export.py" >https://github.com/ultralytics/yolov5/blob/v2.0/models/export.py <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 进行pt文件到ONNX文件的转换。</li>
</ul>
<blockquote>
<p>在使用export.py脚本时，请注意：</p>
<ol>
<li>由于地平线芯片算法工具链支持的ONNX opset版本为 10 和 11，请将 <code>torch.onnx.export</code> 的 <code>opset_version</code> 参数根据您要使用的版本进行修改。</li>
<li>将 <code>torch.onnx.export</code> 部分的默认输入名称参数由 <code>&#39;images&#39;</code> 改为 <code>&#39;data&#39;</code>，与模型转换示例包的YOLOv5x示例脚本保持一致。</li>
<li>将 <code>parser.add_argument</code> 部分中默认的数据输入尺寸640x640改为模型转换示例包YOLOv5x示例中的672x672。</li>
</ol>
</blockquote>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.480(FLOAT)&#x2F;0.466(INT8)</p>
<p><code>SSD_MobileNetv1</code></p>
<p>1.SSD_MobileNetv1模型：可以从URL： <a class="link"   target="_blank" rel="noopener" href="https://github.com/chuanqi305/MobileNet-SSD" >https://github.com/chuanqi305/MobileNet-SSD <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 获得Caffe模型。</p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">bbcb3b6a0afe1ec89e1288096b5b8c66</td>
<td align="left">mobilenet_iter_73000.caffemodel</td>
</tr>
<tr>
<td align="left">3c230e4415195a50c6248be80c49882d</td>
<td align="left">MobileNetSSD_deploy.prototxt</td>
</tr>
</tbody></table>
<p>3.模型精度(mAP)：0.7342(FLOAT)&#x2F;0.7277(INT8)</p>
<p><code>Efficientdetd0</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/EfficientDet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/EfficientDet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ec4129c4b300cd04f1e8f71e0fe54ca5</td>
<td align="left">efficientdet_nhwc.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.324(FLOAT)&#x2F;0.315(INT8)</p>
<p><code>CenterNet_Resnet101</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Centernet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Centernet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ba58170ee7ad0338dce3d46719329850</td>
<td align="left">centernet_resnet101_coco.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.342(FLOAT)&#x2F;0.331(INT8)</p>
<p><code>fcos_efficientnetb0</code></p>
<p>该模型为采用PTQ方式训练出来的模型。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Fcos_Efficientnetb0" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Fcos_Efficientnetb0 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">9f9a1fe8508e2bd068e70146eb559b4f</td>
<td align="left">fcos_efficientnetb0.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.358(FLOAT)&#x2F;0.351(INT8)</p>
<p><code>Yolov4</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/YoloV4" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/YoloV4 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">aaa3c3e5e4c4c1d4830b6501b1720e4d</td>
<td align="left">yolov4.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.351(FLOAT)&#x2F;0.334(INT8)</p>
<p><code>YOLOv3_VargDarknet</code></p>
<p>.YOLOv3_VargDarknet模型获取：</p>
<p>URL： <a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Yolov3_VargDarknet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Yolov3_VargDarknet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，可以在该github的README.md提供的百度云下载路径中下载。</p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">fd4e46bc7c9798b51778d3aa09c5053a</td>
<td align="left">yolov3_vargdarknet53.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.335(FLOAT)&#x2F;0.327(INT8)</p>
<p><code>fcos_resnet50</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Fcos_Resnet50" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Fcos_Resnet50 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">0218942777615fac2f54cefdac4fbfa7</td>
<td align="left">fcos_resnet50.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.426(FLOAT)&#x2F;0.424(INT8)</p>
<p><code>fcos_resnext101</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Fcos_Resnext101" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/Fcos_Resnext101 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">4b80efd22448021721ac5a860909c59f</td>
<td align="left">fcos_resnext101.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.453(FLOAT)&#x2F;0.450(INT8)</p>
<p><code>unet_mobilenet</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/MobilenetUnet" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/MobilenetUnet <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">21c6c645ebca92befbebc8c39d385c1e</td>
<td align="left">tf_unet_trained.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.6411(FLOAT)&#x2F;0.6361(INT8)</p>
<p><code>deeplabV3plus_efficientnetb0</code></p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">c7a05f52619fafdc38178f2e7e41d748</td>
<td align="left">deeplabv3plus_efficientnetb0.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.7630(FLOAT)&#x2F;0.7568(INT8)</p>
<p><code>fastscnn_efficientnetb0</code></p>
<p>注意：为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 remove_node_type 参数进行了配置，将bin模型中的Reshape和Cast节点做了删除的操作。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/FastSCNN" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/FastSCNN <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">c1ace8f08a9c7b9c91509fa68327d0c8</td>
<td align="left">fastscnn_efficientnetb0.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.6997(FLOAT)&#x2F;0.6928(INT8)</p>
<p><code>deeplabv3plus_dilation1248</code></p>
<p>注意：为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 remove_node_type 参数进行了配置，将bin模型中的Transpose节点做了删除的操作。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">ad002e572cbb49e1e99d893aac69f3e3</td>
<td align="left">deeplabv3_cityscapes_dila1248_permute.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.7462(FLOAT)&#x2F;0.7452(INT8)</p>
<p><code>deeplabv3plus_efficientnetm1</code></p>
<p>注意：为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 remove_node_type 参数进行了配置，将bin模型中的Reshape、Cast和Transpose节点做了删除的操作。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">644656b17452b32cf9dd3c1964c30436</td>
<td align="left">deeplabv3plus_efficientnetm1.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.7794(FLOAT)&#x2F;0.7740(INT8)</p>
<p><code>deeplabv3plus_efficientnetm2</code></p>
<p>为保证板端性能达到最优，在编译bin模型的yaml文件中我们对 remove_node_type 参数进行了配置，将bin模型中的Reshape、Cast和Transpose节点做了删除的操作。</p>
<p>1.模型来源：<a class="link"   target="_blank" rel="noopener" href="https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus" >https://github.com/HorizonRobotics-Platform/ModelZoo/tree/master/DeeplabV3Plus <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>2.md5sum码：</p>
<table>
<thead>
<tr>
<th align="left">md5sum</th>
<th align="left">File</th>
</tr>
</thead>
<tbody><tr>
<td align="left">c11a2673c4b3cf6e5d7bf1a051925d38</td>
<td align="left">deeplabv3plus_efficientnetm2.onnx</td>
</tr>
</tbody></table>
<p>3.模型精度：</p>
<p><a href="0.276(FLOAT)/0.273(INT8)">IoU&#x3D;0.50:0.95</a>：0.7882(FLOAT)&#x2F;0.7856(INT8)</p>
<p><strong>算法模型示例的使用演示</strong></p>
<p>本小节以YOLOv2_Darknet19模型为例，使用算法模型示例包中 <code>04_detection/01_yolov2_darknet19/mapper/</code> 路径下脚本 分步骤演示浮点模型到定点模型转换过程中的模型检查、校准数据集准备、runtime模型构建及模型精度测试几个关键步骤。</p>
<p><code>进入Docker容器</code></p>
<p>首先，根据 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html#model-docker-env" >Docker容器部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节内容完成Docker环境的安装和配置并进入docker容器。</p>
<p><strong>验证模型是否能够执行</strong></p>
<ol>
<li>如下所示，运行脚本：</li>
</ol>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 1. 进入示例脚本放置的文件夹</span><br><span class="line">cd ddk/samples/ai_toolchain/horizon_model_convert_sample/04_detection/01_yolov2_darknet19/mapper</span><br><span class="line"># 2. 执行模型检查</span><br><span class="line">sh 01_check.sh</span><br></pre></td></tr></table></figure></div>

<ol>
<li>模型检查输出：</li>
</ol>
<p>上述脚本使用 <code>hb_mapper checker</code> 工具验证模型是否被地平线芯片支持。同时也会输出一个OP列表，表示每个OP会CPU还是BPU上执行。 如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">===================================================</span><br><span class="line">Node         ON   Subgraph  Type</span><br><span class="line">---------------------------------------------------</span><br><span class="line">layer1_conv      BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer1_act       BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer2_maxpool   BPU  id(0)     HzQuantizedMaxPool</span><br><span class="line">layer3_conv      BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer3_act       BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer4_maxpool   BPU  id(0)     HzQuantizedMaxPool</span><br><span class="line">layer5_conv      BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer5_act       BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer6_conv      BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer6_act       BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer7_conv      BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer7_act       BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer8_maxpool   BPU  id(0)     HzQuantizedMaxPool</span><br><span class="line">layer9_conv      BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer9_act       BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer10_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer10_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer11_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer11_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer12_maxpool  BPU  id(0)     HzQuantizedMaxPool</span><br><span class="line">layer13_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer13_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer14_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer14_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer15_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer15_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer16_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer16_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer17_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer17_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer18_maxpool  BPU  id(0)     HzQuantizedMaxPool</span><br><span class="line">layer19_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer19_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer20_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer20_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer21_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer21_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer22_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer22_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer23_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer23_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer24_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer24_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer25_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer25_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer27_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer27_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer28_reorg    BPU  id(0)     HzSpaceToDepth</span><br><span class="line">layer29_concat   BPU  id(0)     Concat</span><br><span class="line">layer30_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">layer30_act      BPU  id(0)     HzLeakyRelu</span><br><span class="line">layer31_conv     BPU  id(0)     HzSQuantizedConv</span><br><span class="line">----------------------End--------------------------</span><br></pre></td></tr></table></figure></div>



<p><strong>准备校准用的数据集</strong></p>
<p>在同一路径下继续执行 <code>02_preprocess.sh</code> 脚本，如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 将 01_common/data/coco/calibration_data中的图片</span><br><span class="line"># 转换到: ./calibration_data_rgb_f32</span><br><span class="line">sh 02_preprocess.sh</span><br></pre></td></tr></table></figure></div>

<p>注意：</p>
<ul>
<li>我们从COCO数据集抽取了50张图作为校准数据集，在校准前，我们对数据进行了预处理： <strong>pad-resize&#x2F;转为rgb</strong>。</li>
<li><code>hb_mapper</code> 工具会从转换得到二进制数据中读取数据，预处理过的二进制数据文件格式为：c-order的矩阵存储。每个矩阵值的数据类型为int8。</li>
</ul>
<p><strong>build异构模型</strong></p>
<p>在同一路径下继续执行 <code>03_build.sh</code> 脚本，如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh 03_build.sh</span><br></pre></td></tr></table></figure></div>

<p>上述脚本使用 <code>hb_mapper</code> 工具转换模型，最需要关注的是转换的配置文件， 请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_usage/quantize_compile.html#makertbin" >使用 hb_mapper makertbin 工具转换模型 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节的内容。</p>
<p>上述脚本的输出如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; ls model_output | cat</span><br><span class="line">full_yolov2_subgraph_0.html</span><br><span class="line">full_yolov2_subgraph_0.json</span><br><span class="line">yolov2_darknet19_608x608_nv12.bin</span><br><span class="line">yolov2_darknet19_608x608_nv12_optimized_float_model.onnx</span><br><span class="line">yolov2_darknet19_608x608_nv12_original_float_model.onnx</span><br><span class="line">yolov2_darknet19_608x608_nv12_quantized_model.onnx</span><br></pre></td></tr></table></figure></div>

<p>您暂时只需要关心 <strong>yolov2_darknet19_608x608_nv12.bin</strong> 文件，其他文件会在工具的介绍中进行说明。</p>
<p><strong>单张图片推理</strong></p>
<p>执行 <code>04_inference.sh</code> 脚本进行单张图片的推理过程，如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh 04_inference.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li>因为图片推理过程时，需要对图片进行 <strong>前处理</strong>，对模型数据进行 <strong>后处理</strong>，所以我们提供了一个示例Python脚本。具体请参考 <code>sh 04_inference.sh</code> 。</li>
<li>此脚本只是对单张图片进行推理，验证单张图片的推理结果是否符合预期，如果想做精度测评，可以参考 <code>05_evaluate.sh</code> 脚本。</li>
</ul>
<p><strong>精度测试</strong></p>
<p>继续执行 <code>05_evaluate.sh</code> 脚本进行精度评测，如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PARALLEL_PROCESS_NUM=$&#123;parallel_process_num&#125;</span><br><span class="line">sh 05_evaluate.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li>因为精度评测时，需要对图片进行 <strong>前处理</strong>，对模型数据进行 <strong>后处理</strong>，所以我们提供了一个示例Python脚本。具体请参考 <code>sh 05_evaluate.sh</code>。</li>
<li>为了加快评测速度，可以通过 <code>-p</code> 选项适当调整并发进程数，但需要注意内存的占用情况。当 <code>-p</code> 选项值不填或者设置为 <code>0</code> 时，CPU环境中的定点模型将按照10个进程数处理，其他场景均按1个进程数处理。</li>
</ul>
<p><strong>常见问题</strong></p>
<p><code>如何对齐开源框架训练得到的ONNX原始浮点模型与使用 </code>hb_mapper makertbin<code> 工具得到的***_original_float_model.onnx的结果</code></p>
<p><strong>原始浮点模型与转换得到ONNX浮点模型的差异由工具链产品保障，这种验证不是必须的标准流程。</strong></p>
<p><strong>1.明确两者的概念</strong></p>
<p>首先明确两个模型的概念。</p>
<p>前者是指开发者使用开源框架（如：TensorFlow、PyTorch、MXNet等）训练出浮点模型后，转成ONNX格式的原始浮点模型。</p>
<p>而后者是指使用芯片工具链浮点定点模型转换方案的 <code>hb_mapper makertbin</code> 工具， 或运行地平线模型转换示例包（即：horizon_model_convert_sample发布物）中03_classification&#x2F;${modelname}&#x2F;mapper&#x2F;03_build.sh将前者 转换成***_original_float_model.onnx中间格式模型，其中的***代表的是具体模型名称（如：MobileNetv1或GoogleNet等）。</p>
<p><strong>2.明确两者的差异</strong></p>
<p>***_original_float_model.onnx模型计算精度与转换输入的原始浮点模型是一模一样的， <code>有个重要的变化就是为了适配地平线平台添加了一些数据预处理计算</code>。 一般情况下，您不需要使用这个模型，在转换结果出现异常时，如果能把这个模型提供给地平线的技术支持，将有助于帮助您快速解决问题。</p>
<p><strong>3.编写脚本对齐两者结果</strong></p>
<p>下面以地平线模型转换示例包（即：horizon_model_convert_sample发布物）中的googlenet模型为例进行说明。</p>
<p>开发者需要自行编写脚本对齐两者的结果。</p>
<p>在编写脚本时，需要注意以下几点。</p>
<p><strong>注意：开发者自编写脚本中的图片数据处理逻辑应当与工具链示例包各模型的mapper&#x2F;preprocess.py图片数据预处理脚本中的逻辑一致， 以避免由图片数据预处理方法不一致造成的结果差异。 如遇模型示例包版本不同造成的代码逻辑差异，请参见您获取到的示例包版本的图片数据预处理脚本，或咨询地平线技术团队。 各预处理transformer方法参见以下代码块：</strong></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;../../../01_common/python/data/&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> transformer <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> dataloader <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片校正transformer</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calibration_transformers</span>():</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  step：</span></span><br><span class="line"><span class="string">      1、short size resize to 256</span></span><br><span class="line"><span class="string">      2、crop size 224 * 224 from center</span></span><br><span class="line"><span class="string">      3、NHWC to NCHW</span></span><br><span class="line"><span class="string">      4、bgr to rgb</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  transformers = [</span><br><span class="line">      ShortSideResizeTransformer(short_size=<span class="number">256</span>),</span><br><span class="line">      CenterCropTransformer(crop_size=<span class="number">224</span>),</span><br><span class="line">      HWC2CHWTransformer(),</span><br><span class="line">      BGR2RGBTransformer()</span><br><span class="line">  ]</span><br><span class="line">  <span class="keyword">return</span> transformers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片推理transformer</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">infer_transformers</span>(<span class="params">input_layout=<span class="string">&quot;NHWC&quot;</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  step：</span></span><br><span class="line"><span class="string">      1、PIL resize to 256</span></span><br><span class="line"><span class="string">      2、crop size 224*224 from PIL center</span></span><br><span class="line"><span class="string">      3、bgr to nv12</span></span><br><span class="line"><span class="string">      4、nv12 to yuv444</span></span><br><span class="line"><span class="string">  :param input_layout: input layout</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">    transformers = [</span><br><span class="line">        PILResizeTransformer(size=<span class="number">256</span>),</span><br><span class="line">        PILCenterCropTransformer(size=<span class="number">224</span>),</span><br><span class="line">        BGR2NV12Transformer(data_format=<span class="string">&quot;HWC&quot;</span>),</span><br><span class="line">        NV12ToYUV444Transformer((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                                yuv444_output_layout=input_layout[<span class="number">1</span>:]),</span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> transformers</span><br></pre></td></tr></table></figure></div>

<p>开发者可以参照以下代码块对齐图片数据预处理逻辑：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ShortSideResizeTransformer</span>(<span class="params">data, short_size</span>):</span><br><span class="line">    image = data</span><br><span class="line">    height, width, _ = image.shape</span><br><span class="line">    <span class="keyword">if</span> height &lt; width:</span><br><span class="line">        off = width / height</span><br><span class="line">        image = cv2.resize(image,</span><br><span class="line">                            (<span class="built_in">int</span>(short_size * off), short_size))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        off = height / width</span><br><span class="line">        image = cv2.resize(image,</span><br><span class="line">                            (short_size, <span class="built_in">int</span>(short_size * off)))</span><br><span class="line">    data = image</span><br><span class="line">    data = data.astype(np.float32)		<span class="comment">#将 “data” 的数据类型转化为 float32。</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">CenterCropTransformer</span>(<span class="params">data, crop_size</span>):		<span class="comment">#中心裁剪</span></span><br><span class="line">    image = data</span><br><span class="line">    resize_height, resize_width, _ = image.shape</span><br><span class="line">    resize_up = resize_height // <span class="number">2</span> - crop_size // <span class="number">2</span></span><br><span class="line">    resize_left = resize_width // <span class="number">2</span> - crop_size // <span class="number">2</span></span><br><span class="line">    data = image[resize_up:resize_up +</span><br><span class="line">                    crop_size, resize_left:resize_left +</span><br><span class="line">                    crop_size, :]		<span class="comment">#这行代码其实是利用 NumPy 数组切片的方式，从数组 “image” 中取出一个 crop 大小的矩形区域，并将其赋值给变量 “data”。	第一维为 “resize_up:resize_up + crop_size”，表示在 height 上取出一个从 “resize_up” 开始、长度为 “crop_size” 的区域。</span></span><br><span class="line"><span class="comment">#第二维为 “resize_left:resize_left + crop_size”，表示在 width 上取出一个从 “resize_left” 开始、长度为 “crop_size” 的区域。</span></span><br><span class="line"><span class="comment">#第三维为 “:”，表示在 channel 上取出所有的元素。</span></span><br><span class="line">    data = data.astype(np.float32)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">data</span>):</span><br><span class="line">    data = ShortSideResizeTransformer(data, short_size=<span class="number">256</span>)  <span class="comment"># ShortSideResize</span></span><br><span class="line">    data = CenterCropTransformer(data, crop_size=<span class="number">224</span>)  <span class="comment"># CenterCrop</span></span><br><span class="line">    data = np.transpose(data, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))   <span class="comment"># HWC2CHW</span></span><br><span class="line">    data = data * <span class="number">255</span>  <span class="comment"># (0, 1) --&gt; (0, 255)</span></span><br></pre></td></tr></table></figure></div>

<p>如下图所示，googlenet_224x224_nv12_original_float_model.onnx模型比原始浮点onnx模型多了HzPreprocess算子用来实现 googlenet_config.yaml文件中的 <code>data_mean_and_scale</code>。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230512102422982.png"
                      class="" title="image-20230512102422982"
                >

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Normalize</span></span><br><span class="line">data = data.astype(np.float32)</span><br><span class="line">mean = np.array([<span class="number">127.5</span>, <span class="number">127.5</span>, <span class="number">127.5</span>])</span><br><span class="line">scale = np.array([<span class="number">0.0078431</span>, <span class="number">0.0078431</span>, <span class="number">0.0078431</span>])</span><br><span class="line">norm_data = np.zeros(data.shape).astype(np.float32)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">    norm_data[i,:,:] = (data[i,:,:] - mean[i]) * scale[i]</span><br><span class="line">norm_data = norm_data.reshape(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>).astype(np.float32)</span><br></pre></td></tr></table></figure></div>

<p>注意：<strong>由于示例包中各模型 <code>mapper/04_inference.sh</code> 脚本默认执行的是定点模型推理</strong>，因此在验证浮点模型结果时， 需要将定点模型推理改为浮点模型推理。执行命令 <code>sh 04_inference.sh origin</code> 即可执行浮点模型推理。 代码逻辑可能由于发布物版本不同略有差异，可参见 <code>03_classification/02_googlenet/mapper/04_inference.sh</code> 脚本中的注释内容。</p>
<p>实现上述步骤后即可对齐原始浮点模型与googlenet_224x224_nv12_original_float_model.onnx模型的结果了。<strong>对齐的是输出结果</strong></p>
<p><strong>复现的精度为什么与文档中提供的指标有细微差异</strong></p>
<p>出现此种现象的原因可能有以下两点：</p>
<ol>
<li>在不同的服务器环境下，计算方式上可能会有细小的区别。就会导致不同的服务器环境中，编译出来的定点onnx模型的精度，与文档的记录值有细微数据波动。</li>
<li>用户侧使用的第三方库如 opencv、numpy等库的版本不同，导致图片经过前处理后的得到的结果不同，这种情况也会导致精度复现时与文档中的记录值有细微数据波动。</li>
</ol>
<p>出现这种情况，您可以不用过于担心，文档中提供的记录指标仅作为参考，您在复现时的精度与文档中的记录值有细微差异是正常现象，可以正常跑通精度即可。</p>
<p><strong>定点模型精度为何与ai_benchmark示例中的bin文件上板精度无法对齐</strong></p>
<p>在标准交付中，我们在添加示例的时候，定点模型精度和ai_benchmark示例中的bin文件上板精度是已经做了对齐处理的。</p>
<p>如果您发现定点模型精度与ai_benchmark示例中的bin文件上板精度无法对齐的情况，建议您优先检查模型输入是否一致。 由于执行定点模型评估脚本时，使用到的是图片类型的数据集；<strong>而上板使用到的 bin 模型，需要使用hb_eval_preprocess工具转换后的二进制数据集</strong>。 基于此点，如果您在上板时使用的数据集并非通过上述方式生成的, 我们建议您<strong>先在运行定点模型的精度的相同服务器上， 使用我们的数据预处理工具（即hb_eval_preprocess工具）重新生成上板需要的数据集，重跑上板精度，以保证模型输入一致。</strong>（<code>机器不同，数据集获取后的精度可能不同，导致了精度不同</code>）</p>
<p>注意：在使用hb_eval_preprocess工具生成数据集和运行定点模型精度时，两者使用的环境需要保证一致。</p>
<blockquote>
<p>其他算法模型示例</p>
</blockquote>
<p>其他算法模型示例是指 <code>05_miscellaneous/</code> 和 <code>06_custom_op/</code> 文件夹中的示例。</p>
<p>其中：</p>
<ul>
<li><code>05_miscellaneous/</code> 是杂项示例，用于指导使用j5工具链提供的一些其他内容， 比如：如何使用地平线模型转换工具使RGB数据训练的模型能在Runtime运行时接受YUV数据。</li>
<li><code>06_custom_op/</code> 为用户自定义OP示例，帮助用户了解如何在模型含有工具链不支持的算子的情况下添加自定义算子的功能。</li>
</ul>
<p><strong>如何使用</strong></p>
<p>如上所示，在各子文件夹下，每个使用示例都按照顺序封装成了shell脚本，按照shell脚本顺序执行， 即可了解相应的工具的使用、API的功能以及用法等。</p>
<p><strong>杂项示例</strong></p>
<p><code>lenet_gray</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">01_lenet_gray/</span><br><span class="line">.</span><br><span class="line">└── mapper</span><br><span class="line">    ├── 01_check.sh                 //对模型进行预验证</span><br><span class="line">    ├── 02_get_mnist.sh             //获取校准数据</span><br><span class="line">    ├── 03_build.sh                 //转换debug模型</span><br><span class="line">    ├── 04_inference.sh             //使用onnx runtime进行推理</span><br><span class="line">    ├── README.cn.md</span><br><span class="line">    ├── inference.py</span><br><span class="line">    ├── lenet_gray_config.yaml</span><br><span class="line">    └── process_mnist.py</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为灰度图模型的模型转换、模拟器运行及上板运行示例。</p>
<p><code>resnet50_feature</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">02_resnet50_feature</span><br><span class="line">.</span><br><span class="line">└── mapper</span><br><span class="line">    ├── 01_check.sh                 //对模型进行预验证</span><br><span class="line">    ├── 02_build.sh                 //转换debug模型</span><br><span class="line">    ├── 03_inference.sh             //使用onnx runtime进行推理</span><br><span class="line">    ├── README.cn.md</span><br><span class="line">    ├── inference.py</span><br><span class="line">    └── resnet50_feature_config.yaml</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为resnet50_feature的模型转换, 模拟器运行及上板运行示例。</p>
<p><code>vector-diff</code></p>
<p><strong>目录结构</strong></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">03_vector_diff</span><br><span class="line">.</span><br><span class="line">└── mobilenet_mapper</span><br><span class="line">    ├── 01_inference_rt.sh</span><br><span class="line">    ├── 02_vec_diff.sh                  // 使用vec_diff工具进行输出数据分析</span><br><span class="line">    ├── ILSVRC2012_val_00000001.bin</span><br><span class="line">    └── readme.txt</span><br></pre></td></tr></table></figure></div>

<p><strong>输出内容</strong></p>
<p>由 <code>vec_diff -o</code> 指定的CSV文件，列表（表项为：左侧文件名，右侧文件名，余弦相似度、相对欧拉距、最大绝对误差、方差），参考如下：</p>
<table>
<thead>
<tr>
<th align="left">Left Files</th>
<th align="left">Right Files</th>
<th align="left">Cosine Similarity</th>
<th align="left">Relative Euclidean Distance</th>
<th align="left">Max Absolute Error</th>
<th align="left">Mean Square Error</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Layerxxx-quanti-input.txt</td>
<td align="left">Layerxxx-float-input.txt</td>
<td align="left">xxx</td>
<td align="left">xxx</td>
<td align="left">xxx</td>
<td align="left">xxx</td>
</tr>
<tr>
<td align="left">Layerxxx-quanti-param.txt</td>
<td align="left">Layerxxx-float-param.txt</td>
<td align="left">xxx</td>
<td align="left">xxx</td>
<td align="left">xxx</td>
<td align="left">xxx</td>
</tr>
</tbody></table>
<p><code>multi_input_example</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">04_multi_input_example</span><br><span class="line">.</span><br><span class="line">└── mapper</span><br><span class="line">    ├── 01_check.sh                 //对模型进行预验证</span><br><span class="line">    ├── 02_preprocess.sh            // 对数据进行预处理</span><br><span class="line">    ├── 03_build.sh                 // 转换debug模型</span><br><span class="line">    ├── 04_inference.sh             // 单张图片进行推理</span><br><span class="line">    ├── data_preprocess.py</span><br><span class="line">    ├── data_transformer.py</span><br><span class="line">    ├── inference.py</span><br><span class="line">    ├── Readme.cn.md</span><br><span class="line">    └── mobilenetv2_multi_config.yaml</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为多输入模型的模型转换、模拟器运行及上板运行示例。</p>
<p><code>model_verifier</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">07_model_verifier</span><br><span class="line">.</span><br><span class="line">├── 01_preprocess.sh                // 对数据进行预处理</span><br><span class="line">├── 02_build.sh                     // 转换debug模型</span><br><span class="line">├── 03_model_verify.sh              // 执行模型验证</span><br><span class="line">├── calibration_data_feature</span><br><span class="line">├── data_preprocess.py</span><br><span class="line">├── data_transformer.py</span><br><span class="line">├── Readme.cn.md</span><br><span class="line">├── mobilenet_config_bgr.yaml</span><br><span class="line">├── mobilenet_config_yuv444.yaml</span><br><span class="line">└── resnet50_featuremap_config.yaml</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为模型验证工具的验证示例。</p>
<p><code>model_info</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">08_model_info</span><br><span class="line">.</span><br><span class="line">├── 01_preprocess.sh                // 对数据进行预处理</span><br><span class="line">├── 02_build.sh                     // 转换debug模型</span><br><span class="line">├── 03_model_info_check.sh          // 执行模型信息检测并打印</span><br><span class="line">├── Readme.cn.md</span><br><span class="line">├── mobilenet_config.yaml</span><br><span class="line">└── preprocess.py</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为模型信息输出工具的验证示例。</p>
<p><code>mobilenet_bgr</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">09_mobilenet_bgr</span><br><span class="line">.</span><br><span class="line">└── mapper</span><br><span class="line">    ├── 01_check.sh               // 对数据模型做校验</span><br><span class="line">    ├── 02_preprocess.sh          // 对数据进行预处理</span><br><span class="line">    ├── 03_build.sh               // 模型转换</span><br><span class="line">    ├── 04_inference.sh           // 单张图片进行推理</span><br><span class="line">    ├── README.cn.md</span><br><span class="line">    ├── mobilenet_config.yaml</span><br><span class="line">    ├── postprocess.py</span><br><span class="line">    └── preprocess.py</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为模型信息输出工具的验证示例。</p>
<p><code>mobilenet_yuv444</code></p>
<ul>
<li>目录结构</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">11_mobilenet_yuv444</span><br><span class="line">.</span><br><span class="line">└── mapper</span><br><span class="line">    ├── 01_check.sh               // 对数据模型做校验</span><br><span class="line">    ├── 02_preprocess.sh          // 对数据进行预处理</span><br><span class="line">    ├── 03_build.sh               // 模型转换</span><br><span class="line">    ├── 04_inference.sh           // 单张图片进行推理</span><br><span class="line">    ├── README.cn.md</span><br><span class="line">    ├── mobilenet_config.yaml</span><br><span class="line">    ├── postprocess.py</span><br><span class="line">    └── preprocess.py</span><br></pre></td></tr></table></figure></div>

<ul>
<li>示例内容</li>
</ul>
<p>该示例为模型信息输出工具的验证示例。</p>
<p><strong>用户自定义OP示例</strong></p>
<p><code>目录结构</code></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">06_custom_op</span><br><span class="line">.</span><br><span class="line">└── mapper</span><br><span class="line">    ├── 02_preprocess.sh</span><br><span class="line">    ├── 03_build.sh</span><br><span class="line">    ├── 04_inference.sh</span><br><span class="line">    ├── 05_evaluate.sh</span><br><span class="line">    ├── cls_evaluate.py</span><br><span class="line">    ├── cls_inference.py</span><br><span class="line">    ├── googlenet_cop_config.yaml</span><br><span class="line">    ├── onnx_modify.py</span><br><span class="line">    ├── postprocess.py</span><br><span class="line">    ├── preprocess.py</span><br><span class="line">    ├── README.cn.md</span><br><span class="line">    ├── sample_custom.py</span><br><span class="line">    └── torch_export.py</span><br></pre></td></tr></table></figure></div>

<p><code>示例介绍</code></p>
<p>开发者使用地平线工具链将各开源框架训练得到的浮点模型转换为定点模型时， 如果浮点模型中包含了工具链不支持的算子（以下简称为OP），则会转换失败。 在此情况下，开发者可以使用工具链的自定义OP功能自行添加不支持的OP，完成模型转换。</p>
<p>mapper文件夹中包含了执行本示例所需要的脚本和配置文件。</p>
<h5 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h5><p>本节包括 <strong>norm_type配置说明</strong> 、 <strong>transformer说明</strong> 及 <strong>常见故障处理</strong> 说明， 为您介绍norm_type相关参数、相关计算公式的说明与解析，图片缩放裁剪时使用的各个transformer的概念、参数说明及示例，常见异常故障现象通用解决建议。</p>
<blockquote>
<p>norm_type配置说明</p>
</blockquote>
<p><strong>参数说明解析</strong></p>
<p><code>norm_type 参数讲解</code></p>
<ul>
<li>参数作用：此参数为在模型中添加的输入数据预处理方法。</li>
<li>参数取值范围及说明：<ul>
<li><code>no_preprocess</code> 表示不添加任何数据预处理。</li>
<li><code>data_mean</code> 表示提供减均值预处理。</li>
<li><code>data_scale</code> 表示提供乘scale系数预处理。</li>
<li><code>data_mean_and_scale</code> 表示提供先减均值再乘scale系数前处理。</li>
</ul>
</li>
</ul>
<p><strong>注意:当输入节点多于一个时，设置的节点顺序需要与 <code>input_name</code> 中的顺序严格保持一致。</strong></p>
<p><code>mean_value参数讲解</code></p>
<ul>
<li>参数作用：此参数表示指定预处理方法的图像减去的均值。</li>
<li>使用说明：当 <code>norm_type</code> 取值为 <code>data_mean_and_scale</code> 或 <code>data_mean</code> 时需要配置该参数。</li>
<li>参数说明：<ul>
<li>当只有一个输入节点时，仅需要配置一个数值，表示所有通道都减去这个均值。</li>
<li>当有多个节点时，提供与通道数量一致的数值（这些数值以空格分隔开），表示每个通道都会减去不同的均值。</li>
</ul>
</li>
</ul>
<p>注意：</p>
<blockquote>
<ol>
<li>配置的输入节点数量必须与 <code>norm_type</code> 配置的节点数量一致。</li>
<li>如果存在某个节点不需要 <code>mean</code> 处理，则为该节点配置 <code>&#39;None&#39;</code>。</li>
</ol>
</blockquote>
<p><code>scale_value参数讲解</code></p>
<ul>
<li>参数作用：此参数表示指定预处理方法的数值scale系数。</li>
<li>使用说明：当 <code>norm_type</code> 取值为 <code>data_mean_and_scale</code> 或 <code>data_scale</code> 时需要配置该参数。</li>
<li>参数说明：<ul>
<li>当只有一个输入节点时，仅需要配置一个数值，表示所有通道都乘以这个系数。</li>
<li>当有多个节点时，提供与通道数量一致的数值（这些数值以空格分隔开），表示每个通道都会乘以不同的系数。</li>
</ul>
</li>
</ul>
<p>注意：</p>
<blockquote>
<ol>
<li>配置的输入节点数量必须与 <code>norm_type</code> 配置的节点数量一致。</li>
<li>如果存在某个节点不需要 <code>scale</code> 处理，则为该节点配置 <code>&#39;None&#39;</code>。</li>
</ol>
</blockquote>
<p><strong>计算公式及示例说明</strong></p>
<p><code>模型训练时的数据标准化处理计算公式</code></p>
<p>yaml文件中的mean和scale参数与训练时的mean、std需要进行换算。</p>
<p>预处理节点中数据标准化操作的计算方式（即HzPreprocess节点中的计算公式）为：����_����&#x3D;(����−����)∗����� 。</p>
<p>以yolov3为例，其训练时的预处理代码为：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def base_transform(image, size, mean, std):</span><br><span class="line">    x = cv2.resize(image, (size, size).astype(np.float32))</span><br><span class="line">    x /= 255</span><br><span class="line">    x -= mean</span><br><span class="line">    x /= std</span><br><span class="line">    return x</span><br><span class="line"></span><br><span class="line">class BaseTransform:</span><br><span class="line">    def __init__(self, size, mean=(0.406, 0.456, 0.485), std=(0.225, 0.224, 0.229)):</span><br><span class="line">        self.size = size</span><br><span class="line">        self.mean = np.array(mean, dtype=np.float32)</span><br><span class="line">        self.std = np.array(std, dtype=np.float32)</span><br></pre></td></tr></table></figure></div>

<p>则计算公式为：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230512140850527.png"
                      class="" title="image-20230512140850527"
                ></p>
<p>改写为HzPreprocess节点的计算方式：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230512140907489.png"
                      class="" title="image-20230512140907489"
                ></p>
<p>则：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230512140915597.png"
                      class="" title="image-20230512140915597"
                ></p>
<p><strong>模型推理时的计算公式</strong></p>
<p>通过对yaml配置文件中的配置参数，决定是否加入HzPreprocess节点。 当配置mean&#x2F;scale时，做模型转换时，会在输入端新增一个HzPreprocess节点，HzPreprocess节点可以理解为对输入数据做了一个conv操作。</p>
<p>HzPreprocess内的计算公式为： * scale&#96; 。</p>
<p>注意：</p>
<ol>
<li>在yaml中添加mean&#x2F;scale后，就不需要在前处理内添加MeanTransformer和ScaleTransformer了。</li>
<li><strong>在yaml中添加mean&#x2F;scale，会将参数放入到HzPreprocess节点内，HzPreprocess节点为BPU 节点。</strong></li>
</ol>
<blockquote>
<p>图片处理transformer说明</p>
</blockquote>
<p>本章节将对在进行图片缩放裁剪时使用的各个transformer的概念及参数进行说明，并为提供参考使用示例，方便进行tranformer操作。</p>
<p><strong>注意：图片数据为三维数据，但地平线提供的transformer都是以四维数据的方式来进行获取和处理的，transformer只会对输入数据中的第0张图片做该操作。</strong></p>
<p><code>AddTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>对输入图片中的所有像素值做增加value的操作。该transformer会在输出时, 将数据格式转为float32。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>value: 对每个像素做增加的数值, 注意value的取值可以为负数, 如 -128。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对图像数据做减去128的操作</span></span><br><span class="line">``AddTransformer(-<span class="number">128</span>)``</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像数据做增加127的操作</span></span><br><span class="line">``AddTransformer(<span class="number">127</span>)``</span><br></pre></td></tr></table></figure></div>



<p><code>MeanTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>对输入图片中的所有像素值做减去 mean_value 的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>means: 对每个像素做增加的数值, 注意value的取值可以为负数, 如 -128。</li>
<li>data_format: 输入的layout类型，取值范围为[“CHW”,”HWC”], 默认 “CHW”。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个像素减去128.0 输入的类型为CHW</span></span><br><span class="line">MeanTransformer(np.array([<span class="number">128.0</span>, <span class="number">128.0</span>, <span class="number">128.0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个像素减去不同的数值，103.94, 116.78, 123.68，输入的类型为 HWC</span></span><br><span class="line">MeanTransformer(np.array([<span class="number">103.94</span>, <span class="number">116.78</span>, <span class="number">123.68</span>]), data_format=<span class="string">&quot;HWC&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>ScaleTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>对输入图片中的所有像素值做乘以data_scale系数的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>scale_value: 需要乘以的系数，如0.0078125 或者1&#x2F;128。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将取值范围-128~127，所有的像素的调整到-1~1之间</span></span><br><span class="line">ScaleTransformer(<span class="number">0.0078125</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">ScaleTransformer(<span class="number">1</span>/<span class="number">128</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>NormalizeTransformer</code></p>
<p>用于对输入图片进行归一化的操作。该transformer会在输出时, 将数据格式转为float32。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>std：输入的第一张图片，需要除以的数值。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将取值范围[-128, 127] 所有的像素的调整到-1~1之间</span></span><br><span class="line">NormalizeTransformer(<span class="number">128</span>)</span><br></pre></td></tr></table></figure></div>



<p><strong>TransposeTransformer</strong></p>
<p><strong>说明</strong>：</p>
<p>用于做layout转换的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>order: 对输入图片做layout转换后的顺序（顺序与原有的layout顺序有关）。如：<strong>HWC的顺序为0,1,2</strong>，需要转为CHW时，order为(2,0,1)。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HWC转到CHW</span></span><br><span class="line">TransposeTransformer((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># CHW转到HWC</span></span><br><span class="line">TransposeTransformer((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure></div>



<p><code>HWC2CHWTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>用于将NHWC转换为NCHW的操作。</p>
<p><strong>参数</strong>：不涉及。</p>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># NHWC转到NCHW</span><br><span class="line">HWC2CHWTransformer()</span><br></pre></td></tr></table></figure></div>



<p><code> CHW2HWCTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>用于将NCHW转换为NHWC的操作。</p>
<p><strong>参数</strong>：不涉及。</p>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># NCHW转到 NHWC</span><br><span class="line">CHW2HWCTransformer()</span><br></pre></td></tr></table></figure></div>



<p><code>CenterCropTransformer</code></p>
<p><strong>明</strong>：</p>
<p>以直接截断取值的方式从图片中心裁剪出一个正方形的图片的操作。该transformer会在输出时, 将数据格式转为float32。当data_type的值为uint8时，输出为uint8。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>crop_size: 中心裁剪的正方形的边长size。</li>
<li>data_type: 输出结果的类型，取值范围为[“float”, “uint8”]。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以224*224的方式，做中心裁剪，默认输出类型为float32</span></span><br><span class="line">CenterCropTransformer(crop_size=<span class="number">224</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以224*224的方式，做中心裁剪，输出类型为uint8</span></span><br><span class="line">CenterCropTransformer(crop_size=<span class="number">224</span>, data_type=<span class="string">&quot;uint8&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>PILCenterCropTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>使用PIL的方式从图片中心裁剪出一个正方形的图片的操作。该transformer会在输出时, 将数据格式转为float32。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>size: 中心裁剪的正方形的边长size。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以224*224的方式，使用PIL的方式做中心裁剪</span></span><br><span class="line">PILCenterCropTransformer(size=<span class="number">224</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>LongSideCropTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>用于做长边裁剪的操作。该 transformer 会在输出时, 将数据格式转为float32。</p>
<p>当宽度比高度的数值大时，会裁剪出一个中心以高度大小为准的正方形，如宽100，高70，裁剪之后大小为70*70。</p>
<p>当高度比宽度的数值大时，会裁剪出一个中心以宽度大小不变，高度为差值的一半+宽度 的长方形，如宽70，高100，裁剪之后大小为 70<em>（100-70）&#x2F;2+70 ，即70</em> 85大小的长方形。</p>
<p><strong>参数</strong>：不涉及。</p>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LongSideCropTransformer()</span><br></pre></td></tr></table></figure></div>



<p><code>PadResizeTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>使用填充的方式做图像放大的操作。该 transformer 会在输出时, 将数据格式转为float32。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>target_size：目标大小，值为元组，如(240,240)。</li>
<li>pad_value：填充到数组中的值，默认值为127。</li>
<li>pad_position：填充的位置，取值范围为[“boundary”， “bottom_right”]，默认值为 “boundary”。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 裁剪一个大小为512*512，填充到右下角，填充值为0</span></span><br><span class="line">PadResizeTransformer((<span class="number">512</span>, <span class="number">512</span>), pad_position=<span class="string">&#x27;bottom_right&#x27;</span>, pad_value=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 裁剪一个大小为608*608，填充到边框，填充值为 127</span></span><br><span class="line">PadResizeTransformer(target_size=(<span class="number">608</span>, <span class="number">608</span>))</span><br></pre></td></tr></table></figure></div>



<p><code>ResizeTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>用于调整图像大小的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li><p>target_size：目标大小，值为元组，如(240,240)。(240,240)：前一个240代表高度为240，后一个240代表宽度为240。</p>
</li>
<li><p>mode：图片处理模式，取值范围为(“skimage”，”opencv”)，默认值为 “skimage”。</p>
</li>
<li><p>method：插值的方法，此参数仅在mode为skimage时生效。取值范围为0-5，默认值为1，其中：</p>
<ul>
<li>0代表Nearest-neighbor；</li>
<li>1代表Bi-linear(default)；</li>
<li>2代表Bi-quadratic;</li>
<li>3代表Bi-cubic;</li>
<li>4代表Bi-quartic;</li>
<li>5代表Bi-quintic。</li>
</ul>
</li>
<li><p>data_type：输出的类型，取值范围为(uint8，float)，默认为float类型。当被设置为uint8时，输出类型为uint8 ，其他情况为float32。</p>
</li>
<li><p>interpolation：插值的方法，此参数仅在mode为opencv时生效。默认为空，取值范围为(opencv的插值方式)， <strong>目前interpolation仅支持为空或opencv中的INTER_CUBIC两种插值方法，当interpolation为空时，默认使用INTER_LINEAR方式。</strong></p>
<p>以下为opencv中支持的插值方式及说明（目前未支持的插值方式将在后续迭代中逐步支持）：</p>
<ul>
<li>INTER_NEAREST，最近邻插值；</li>
<li>INTER_LINEAR，双线性插值，当interpolation为空时，默认使用这种方法。</li>
<li>INTER_CUBIC，双三次插值4x4像素邻域内的双立方插值。</li>
<li>INTER_AREA，使用像素面积关系重采样。它可能是图像抽取的首选方法，因为它可以提供无莫尔条纹的结果。但是当图像被缩放时，它类似于INTER_NEAREST方法。</li>
<li>INTER_LANCZOS4，8x8邻域的Lanczos插值。</li>
<li>INTER_LINEAR_EXACT，位精确双线性插值。</li>
<li>INTER_NEAREST_EXACT，位精确最近邻插值。这将产生与PIL、scikit-image或Matlab中的最近邻方法相同的结果。</li>
<li>INTER_MAX，插值代码的掩码。</li>
<li>WARP_FILL_OUTLIERS，标志，填充所有目标图像像素。如果其中一些对应于源图像中的异常值，则将它们设置为零。</li>
<li>WARP_INVERSE_MAP，标志，逆变换。</li>
</ul>
</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将输入图片大小调整为224*224，采用 opencv 的方式处理图片，插值的方式为双线性，输出为float32</span></span><br><span class="line">ResizeTransformer(target_size=(<span class="number">224</span>, <span class="number">224</span>), mode=<span class="string">&#x27;opencv&#x27;</span>, method=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将输入图片大小调整为256*256，采用skimage的方式处理图片，插值的方式为双线性，输出为float32</span></span><br><span class="line">ResizeTransformer(target_size=(<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将输入图片大小调整为256*256，采用skimage的方式处理图片，插值的方式为双线性，输出为uint8</span></span><br><span class="line">ResizeTransformer(target_size=(<span class="number">256</span>, <span class="number">256</span>), data_type=<span class="string">&quot;uint8&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>PILResizeTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>使用PIL库做调整图像大小的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>size：目标大小，值为元组，如(240,240)。</li>
<li>interpolation：指定插值的方式，取值范围：(Image.NEAREST，Image.BILINEAR，Image.BICUBIC，Image.LANCZOS)， 默认值为Image.BILINEAR。<ul>
<li>Image.NEAREST：最近邻采样；</li>
<li>Image.BILINEAR：线性插值；</li>
<li>Image.BICUBIC：三次样条插值；</li>
<li>Image.LANCZOS：高质量下采样滤波器。</li>
</ul>
</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将输入图片大小调整为256*256 插值的方式为线性插值</span></span><br><span class="line">PILResizeTransformer(size=<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将输入图片大小调整为256*256 插值的方式为高质量下采样滤波器</span></span><br><span class="line">PILResizeTransformer(size=<span class="number">256</span>, interpolation=Image.LANCZOS)</span><br></pre></td></tr></table></figure></div>



<p><code>ShortLongResizeTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>按照原比例对输入图片进行缩放的操作，新图片的大小与设置的参数有关。操作方式如下：</p>
<ol>
<li>先以short_size的大小除以原图片的宽和高里最小值，以这个值为缩放比例系数。</li>
<li>当缩放比例系数乘以原图片的宽和高中的最大值，得到的结果大于long_size的数值时，缩放比例系数将变更为long_size除以原图片的宽和高中的最大值。</li>
<li>使用opencv中的resize方法，根据上方得到的缩放比例系数重新裁剪图片。</li>
</ol>
<p><strong>参数</strong>：</p>
<ul>
<li>short_size：预期裁剪后的短边的长度。</li>
<li>long_size：预期裁剪后的长边的长度。</li>
<li>include_im：默认值为True，设置为True时, 会在返回时除了返回处理后的图片, 还会返回原图片。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 短边长度为20，长边长度为100，返回处理后的图片及原图片</span><br><span class="line">ShortLongResizeTransformer(short_size=20, long_size=100)</span><br></pre></td></tr></table></figure></div>



<p><code>PadTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>通过用目标大小的size值除以输入图片宽或者高里的最大值为系数，然后使用这个系数乘以原有的宽高，resize图片。 然后根据新图片的大小，除以size_divisor后向上取整后，再乘以size_divisor，为新的宽高，生成新的图片的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>size_divisor：大小除数 ，默认值为128。</li>
<li>target_size：目标大小，默认值为512。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># pad大小为1024*1024</span><br><span class="line">PadTransformer(size_divisor=1024, target_size=1024)</span><br></pre></td></tr></table></figure></div>



<p><code>ShortSideResizeTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>根据期望的短边的长度，使用现在的长短边的比例，中心裁剪出新的图片大小的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li><p>short_size：预期的短边的长度。</p>
</li>
<li><p>data_type：输出结果的类型，取值范围为(“float”,”uint8”)，默认取值”float32”, 以 float32 类型输出，设置为uint8时，输出类型将为uint8。</p>
</li>
<li><p>interpolation：指定插值的方式，取值范围为 opencv 中采用的插值方式，默认为空。</p>
<p>目前interpolation仅支持为空或opencv中的INTER_CUBIC两种插值方法，当interpolation为空时，默认使用INTER_LINEAR方式。</p>
<p>以下为opencv中支持的插值方式及说明（目前未支持的插值方式将在后续迭代中逐步支持）：</p>
<ul>
<li>INTER_NEAREST，最近邻插值；</li>
<li>INTER_LINEAR，双线性插值，当interpolation为空时，默认使用这种方法。</li>
<li>INTER_CUBIC，双三次插值4x4像素邻域内的双立方插值。</li>
<li>INTER_AREA，使用像素面积关系重采样。它可能是图像抽取的首选方法，因为它可以提供无莫尔条纹的结果。但是当图像被缩放时，它类似于INTER_NEAREST方法。</li>
<li>INTER_LANCZOS4，8x8邻域的Lanczos插值。</li>
<li>INTER_LINEAR_EXACT，位精确双线性插值。</li>
<li>INTER_NEAREST_EXACT，位精确最近邻插值。这将产生与PIL、scikit-image或Matlab中的最近邻方法相同的结果。</li>
<li>INTER_MAX，插值代码的掩码。</li>
<li>WARP_FILL_OUTLIERS，标志，填充所有目标图像像素。如果其中一些对应于源图像中的异常值，则将它们设置为零。</li>
<li>WARP_INVERSE_MAP，标志，逆变换。</li>
</ul>
</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将短边大小调整为256，插值方式为双线性插值</span></span><br><span class="line">ShortSideResizeTransformer(short_size=<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将短边大小调整为256，插值方式为 8x8像素邻域内的Lanczos插值</span></span><br><span class="line">ShortSideResizeTransformer(short_size=<span class="number">256</span>, interpolation=Image.LANCZOS4)</span><br></pre></td></tr></table></figure></div>



<p><code>PaddedCenterCropTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>使用填充的方式对图片中心进行裁剪的操作。</p>
<p>注意</p>
<blockquote>
<p>仅适用于EfficientNet-lite相关实例模型。</p>
<p>计算方式为：</p>
<ol>
<li>计算系数，int((float( image_size ) &#x2F; ( image_size + crop_pad ))。</li>
<li>计算中心size的大小， 系数 * np.minimum( 原始图片的高度, 原始图片的宽度 ))。</li>
<li>根据计算出来的size大小，做中心裁剪。</li>
</ol>
</blockquote>
<p><strong>参数</strong>：</p>
<ul>
<li>image_size：图片的大小，默认值为224。</li>
<li>crop_pad：中心填充的大小，默认值为32。</li>
</ul>
<p><code>BGR2RGBTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由BGR转成RGB的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：数据格式，取值范围为(CHW,HWC)，默认值为CHW。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做BGR转为RGB</span></span><br><span class="line">BGR2RGBTransformer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做BGR转为RGB</span></span><br><span class="line">BGR2RGBTransformer(data_format=<span class="string">&quot;HWC&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2BGRTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由RGB转成BGR的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：数据格式，取值范围为(CHW,HWC)，默认值为CHW。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做RGB转成BGR</span></span><br><span class="line">RGB2BGRTransformer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做RGB转成BGR</span></span><br><span class="line">RGB2BGRTransformer(data_format=<span class="string">&quot;HWC&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2GRAYTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由RGB转成GRAY的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围(“CHW”,”HWC”)，默认为”CHW”。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做RGB转成GRAY</span></span><br><span class="line">RGB2GRAYTransformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做RGB转成GRAY</span></span><br><span class="line">RGB2GRAYTransformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>BGR2GRAYTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由 BGR 转成 GRAY 的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围 [“CHW”,”HWC”]，默认值为”CHW”。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做BGR转成GRAY</span></span><br><span class="line">BGR2GRAYTransformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做BGR转成GRAY</span></span><br><span class="line">BGR2GRAYTransformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2GRAY_128Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>输入格式由RGB转成GRAY_128的操作。GRAY_128取值范围为(-128,127)。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为”CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做RGB转成GRAY_128</span></span><br><span class="line">RGB2GRAY_128Transformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做RGB转成GRAY_128</span></span><br><span class="line">RGB2GRAY_128Transformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2YUV444Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由RGB转成YUV444的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”, “HWC”]，默认值为”CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout 为 NCHW 时，做 RGB 转成 YUV444</span></span><br><span class="line">RGB2YUV444Transformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout 为 NHWC 时，做 RGB 转成 YUV444</span></span><br><span class="line">RGB2YUV444Transformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>BGR2YUV444Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由BGR转成YUV444的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为 “CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做BGR转成YUV444</span></span><br><span class="line">BGR2YUV444Transformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做BGR转成YUV444</span></span><br><span class="line">BGR2YUV444Transformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>BGR2YUV444_128Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由BGR转成YUV444_128的操作。YUV444_128取值范围为(-128,127)。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为 “CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做BGR转成YUV444_128</span></span><br><span class="line">BGR2YUV444_128Transformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做BGR转成YUV444_128</span></span><br><span class="line">BGR2YUV444_128Transformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2YUV444_128Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由RGB转成YUV444_128的操作。YUV444_128取值范围为(-128,127)。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为”CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW 时，做RGB转成YUV444_128</span></span><br><span class="line">RGB2YUV444_128Transformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做RGB转成 YUV444_128</span></span><br><span class="line">RGB2YUV444_128Transformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>BGR2YUVBT601VIDEOTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由BGR转成YUV_BT601_Video_Range的操作。</p>
<p>YUV_BT601_Video_Range，某些摄像头输入数据都是YUV BT601(Video Range)格式的，取值范围为16~235，该transformer就是适配这种格式的数据产生的。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为”CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为 NCHW时，做BGR转成YUV_BT601_Video_Range</span></span><br><span class="line">BGR2YUVBT601VIDEOTransformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做BGR转成YUV_BT601_Video_Range</span></span><br><span class="line">BGR2YUVBT601VIDEOTransformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2YUVBT601VIDEOTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由RGB转成YUV_BT601_Video_Range的操作。</p>
<p>YUV_BT601_Video_Range，某些摄像头输入数据都是YUV BT601(Video Range)格式的，取值范围为16~235，该transformer就是适配这种格式的数据产生的。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为”CHW”，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，做RGB转成YUV_BT601_Video_Range</span></span><br><span class="line">RGB2YUVBT601VIDEOTransformer(data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，做RGB转成YUV_BT601_Video_Range</span></span><br><span class="line">RGB2YUVBT601VIDEOTransformer(data_format=<span class="string">&#x27;HWC&#x27;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>YUVTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式转成YUV444的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>color_sequence：颜色序列，此项为必填项。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将BGR读入的图片转为YUV444</span></span><br><span class="line">YUVTransformer(color_sequence=<span class="string">&quot;BGR&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将RGB读入的图片转为YUV444</span></span><br><span class="line">YUVTransformer(color_sequence=<span class="string">&quot;RGB&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>ReduceChannelTransformer</code></p>
<p><strong>说明</strong>：</p>
<p>将C通道缩减为单通道的操作。该transformer主要是针对于C通道，如shape为1<em>3</em>224<em>224 改为1</em>1<em>224</em>224。 使用时layout一定要和data_format值对齐，避免造成删错通道。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”, “HWC”]，默认值为”CHW”。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除layout为NCHW的C通道</span></span><br><span class="line">ReduceChannelTransformer()</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">ReduceChannelTransformer(data_format=<span class="string">&quot;CHW&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除layout为NHWC的C通道</span></span><br><span class="line">ReduceChannelTransformer(data_format=<span class="string">&quot;HWC&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>BGR2NV12Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由BGR转成NV12的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的layout类型，取值范围为[“CHW”,”HWC”]，默认值为”CHW”。</li>
<li>cvt_mode：cvt模式，取值范围为(rgb_calc，opencv)，默认值为rgb_calc。<ul>
<li>rgb_calc，采用mergeUV的方式处理图片；</li>
<li>opencv，采用opencv的方式处理图片。</li>
</ul>
</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，由BGR转为NV12，采用rgb_calc模式处理图片</span></span><br><span class="line">BGR2NV12Transformer()</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">BGR2NV12Transformer(data_format=<span class="string">&quot;CHW&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，由BGR转为NV12，采用opencv模式处理图片</span></span><br><span class="line">BGR2NV12Transformer(data_format=<span class="string">&quot;HWC&quot;</span>, cvt_mode=<span class="string">&quot;opencv&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>RGB2NV12Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由RGB转成NV12的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>data_format：输入的 layout 类型，取值范围 [“CHW”, “HWC”], 默认值为”CHW”。</li>
<li>cvt_mode：cvt模式，取值范围为(rgb_calc,opencv)，默认值为rgb_calc。<ul>
<li>rgb_calc，采用mergeUV的方式处理图片；</li>
<li>opencv，采用opencv的方式处理图片。</li>
</ul>
</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW时，有RGB转为NV12，采用rgb_calc模式处理图片</span></span><br><span class="line">RGB2NV12Transformer()</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">RGB2NV12Transformer(data_format=<span class="string">&quot;CHW&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC时，有RGB转为NV12，采用opencv模式处理图片</span></span><br><span class="line">RGB2NV12Transformer(data_format=<span class="string">&quot;HWC&quot;</span>, cvt_mode=<span class="string">&quot;opencv&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>NV12ToYUV444Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>将输入格式由NV12转成YUV444的操作。</p>
<p><strong>参数</strong>：</p>
<ul>
<li>target_size：目标大小，值为元组，如(240,240)。</li>
<li>yuv444_output_layout：yuv444输出的layout，取值范围为(HWC,CHW)，默认值为”HWC”。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layout为NCHW ，大小为768*768, nv12转yuv444</span></span><br><span class="line">NV12ToYUV444Transformer(target_size=(<span class="number">768</span>, <span class="number">768</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># layout为NHWC ，大小为224*224, nv12转yuv444</span></span><br><span class="line">NV12ToYUV444Transformer((<span class="number">224</span>, <span class="number">224</span>), yuv444_output_layout=<span class="string">&quot;HWC&quot;</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>WarpAffineTransformer</code></p>
<p><strong>说明</strong>：</p>
<p><strong>用于做图像仿射变换的操作。</strong></p>
<blockquote>
<p>图像放射变换（Affine Transform）是图像处理中一种常见的变换方式，具体来说，它是通过对图像上的<strong>每一个像素点</strong>进行线性变换，来改变图像的位置、大小、旋转和剪切等几何形状的一种变换。</p>
<p>常见的图像放射变换包括平移、旋转、缩放、翻转、镜像和剪切等。</p>
<p>其中，平移是指将整个图像在水平方向和竖直方向上进行移动；旋转是指将图像按照一个指定的角度进行旋转；缩放是指将图像的大小进行缩放；翻转是指将图像在水平或竖直方向上进行翻转；镜像是指将图像进行对称镜像；剪切是指将图像在水平或竖直方向上进行裁剪。</p>
</blockquote>
<p><strong>参数</strong>：</p>
<ul>
<li>input_shape：输入的shape值。</li>
<li>scale：乘以的系数。</li>
</ul>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 大小为512*512，长边长度为1.0</span></span><br><span class="line">WarpAffineTransformer((<span class="number">512</span>, <span class="number">512</span>), <span class="number">1.0</span>)</span><br></pre></td></tr></table></figure></div>



<p><code>F32ToS8Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>用于做输入格式从float32转换为int8的操作。</p>
<p><strong>参数</strong>：不涉及。</p>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入格式从 float32转为 int8</span></span><br><span class="line">F32ToS8Transformer()</span><br></pre></td></tr></table></figure></div>



<p><code>F32ToU8Transformer</code></p>
<p><strong>说明</strong>：</p>
<p>用于做输入格式从float32转换为uint8的操作。</p>
<p><strong>参数</strong>：不涉及。</p>
<p><strong>使用举例</strong>：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入格式从 float32 转为 uint8</span></span><br><span class="line">F32ToU8Transformer()</span><br></pre></td></tr></table></figure></div>



<h4 id="量化感知训练（QAT）"><a href="#量化感知训练（QAT）" class="headerlink" title="量化感知训练（QAT）"></a>量化感知训练（QAT）</h4><p><strong>量化是指以低于浮点精度的比特宽度执行计算和存储张量的技术。量化模型使用整数而不是浮点值对张量执行部分或全部操作。</strong>与典型的 FP32 模型相比，<code>horizon_plugin_pytorch</code> 支持 INT8 量化，从而使模型大小减少 4 倍，内存带宽需求减少 4 倍。对 INT8 计算的硬件支持通常比 FP32 计算快 2 到 4 倍。<strong>量化主要是一种加速推理的技术，量化运算只支持前向计算。</strong></p>
<p><code>horizon_plugin_pytorch</code> 提供了适配 BPU 的量化操作，支持量化感知训练，该训练使用伪量化模块对前向计算和反向传播中的量化误差进行建模。<strong>请注意，量化训练的整个计算过程是使用浮点运算执行的</strong>。在量化感知训练结束时，<code>horizon_plugin_pytorch</code> 提供转换函数，将训练后的模型转换为定点模型，在 BPU 上使用更紧凑的模型表示和高性能矢量化操作。</p>
<blockquote>
<ol>
<li>前向运算是深度学习模型最常用的运算阶段，也是性能瓶颈所在。通过量化前向运算，可以显著降低计算资源的需求，提高推理速度。<strong>量化只支持前向运算是因为量化主要应用于推理阶段，通过将模型转换为定点数模型来提高计算效率</strong></li>
<li>后向运算（反向传播）是用于训练模型的阶段，需要使用浮点数精度进行梯度计算和参数更新。由于量化会降低模型的精度，因此在后向运算中使用量化后的模型可能会导致梯度计算和参数更新的错误。</li>
<li>量化主要用于优化推理阶段的计算效率，而在训练阶段，通常使用浮点数模型进行梯度计算和参数更新，以保证训练的准确性和收敛性。</li>
</ol>
</blockquote>
<p>为行文简洁，文档中代码默认进行了如下别名替换：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> horizon_plugin_pytorch <span class="keyword">as</span> horizon</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>伪量化：<code>fake_quant_x = clip(round(x / scale), -128, 127) * scale</code>。作用是对输入张量 x 进行量化操作，将其转换为一个定点数表示。</p>
<p>Traced模型：<strong>由于 <code>PyTorch </code>是动态图，而编译和部署只支持静态图，因此，需要对训练好的模型进行 trace 得到静态图，该静态图对应的模型称为 traced 模型。</strong></p>
<ul>
<li><p>动态图是指在每次计算时都构建计算图的方式。在动态图中，计算图是根据实际执行流程动态生成的，每次前向传播都会重新构建计算图。这意味着可以使用常规的编程控制流语句（如条件语句和循环），并且可以在运行时改变计算图的结构。</p>
</li>
<li><p>与之对应的是静态图，静态图在执行前需要先定义计算图的结构，然后再执行计算。典型的静态图框架是TensorFlow。在静态图中，计算图是预先定义好的，并且在执行前不可更改。</p>
</li>
<li><p>动态图和静态图的主要区别在于计算图的构建时机和灵活性。动态图更加灵活，可以根据需要动态地构建计算图，支持动态的控制流，适合于动态、复杂的模型。而静态图更注重计算图的预定义和编译过程，具有更高的执行效率，适合于静态、固定的模型。</p>
</li>
</ul>
<p><code>TorchScript</code>模型：<code>TorchScript</code>是<code>PyTorch</code>的一种模型表示格式和执行环境。<strong>它可以将<code>PyTorch</code>模型转换为一种静态图表示形式，以提供更高的执行性能和部署灵活性。</strong></p>
</blockquote>
<h5 id="快速入门-1"><a href="#快速入门-1" class="headerlink" title="快速入门"></a>快速入门</h5><blockquote>
<p>基本流程</p>
</blockquote>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230704120423250.png"
                      class="" title="image-20230704120423250"
                >













<h2 id="嵌入式应用开发（runtime）手册"><a href="#嵌入式应用开发（runtime）手册" class="headerlink" title="嵌入式应用开发（runtime）手册"></a>嵌入式应用开发（runtime）手册</h2><p>本章内容包括 <strong>嵌入式应用开发指导手册</strong> 、 <strong>runtime BPU SDK API手册</strong> 、 <strong>runtime 基础示例包使用说明</strong> 、 <strong>runtime ai_benchmark使用说明</strong> 、 <strong>工具介绍</strong> 。 为您详细介绍在地平线平台进行应用开发的步骤，并提供API、数据、结构体、排布、对齐规则、应用开发示例、工具介绍等内容， 供您进行参考。</p>
<h3 id="嵌入式应用开发指导"><a href="#嵌入式应用开发指导" class="headerlink" title="嵌入式应用开发指导"></a>嵌入式应用开发指导</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>本章节介绍如何在地平线平台进行应用开发，将经过转换后的模型部署到J5开发板上运行起来，需要您注意的相关注意事项在此章节也会介绍。</p>
<p>最简易的开发过程包括工程创建、工程实现、工程编译与运行三个阶段。 考虑到实际业务场景开发的较复杂需求，对于常用的多模型控制概念和应用调优建议也都提供了一些说明。</p>
<h4 id="工程创建"><a href="#工程创建" class="headerlink" title="工程创建"></a>工程创建</h4><h5 id="CMake工具"><a href="#CMake工具" class="headerlink" title="CMake工具"></a>CMake工具</h5><p>Make是一种构建工具，<strong>它用于自动化构建和管理软件项目的编译过程</strong>。Make工具通过读取Makefile文件中的规则和依赖关系来确定哪些源文件需要重新编译，然后调用适当的编译器和链接器来生成可执行文件、库文件或其他生成物。</p>
<p> <a class="link"   target="_blank" rel="noopener" href="https://www.hahack.com/wiki/tools-makefile.html" >GNU Make <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，QT 的 <a class="link"   target="_blank" rel="noopener" href="http://qt-project.org/doc/qt-4.8/qmake-manual.html" >qmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，微软的 <a class="link"   target="_blank" rel="noopener" href="http://msdn.microsoft.com/en-us/library/ms930369.aspx" >MS nmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，BSD Make（<a class="link"   target="_blank" rel="noopener" href="http://www.freebsd.org/doc/en/books/pmake/" >pmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>），<a class="link"   target="_blank" rel="noopener" href="http://makepp.sourceforge.net/" >Makepp <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，等等。这些 Make 工具遵循着不同的规范和标准，所执行的 Makefile 格式也千差万别。这样就带来了一个严峻的问题：如果软件想跨平台，必须要保证能够在不同平台编译。而如果使用上面的 Make 工具，就得为每一种标准写一次 Makefile ，这将是一件让人抓狂的工作。</p>
<p>CMake 就是针对上面问题所设计的工具：<strong>它首先允许开发者编写一种平台无关的 CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件</strong>，如 Unix 的 Makefile 或 Windows 的 Visual Studio 工程。从而做到“Write once, run everywhere”。显然，CMake 是一个比上述几种 make 更高级的编译配置工具。一些使用 CMake 作为项目架构系统的知名开源项目有 <a class="link"   target="_blank" rel="noopener" href="http://www.vtk.org/" >VTK <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>、<a class="link"   target="_blank" rel="noopener" href="http://www.itk.org/" >ITK <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>、<a class="link"   target="_blank" rel="noopener" href="http://kde.org/" >KDE <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>、<a class="link"   target="_blank" rel="noopener" href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/modules/core/doc/intro.html" >OpenCV <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>、<a class="link"   target="_blank" rel="noopener" href="http://www.openscenegraph.org/" >OSG <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 等 [<a class="link"   target="_blank" rel="noopener" href="https://www.hahack.com/codes/cmake/#fn1" >1] <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。</p>
<p>在 linux 平台下使用 CMake 生成 Makefile 并编译的流程如下：</p>
<ol>
<li>编写 CMake 配置文件 CMakeLists.txt 。</li>
<li>执行命令 <code>cmake PATH</code> 或者 <code>ccmake PATH</code> 生成 Makefile（<code>ccmake</code> 和 <code>cmake</code> 的区别在于前者提供了一个交互式的界面）。其中， <code>PATH</code> 是 CMakeLists.txt 所在的目录。</li>
<li>使用 <code>make</code> 命令进行编译。</li>
</ol>
<p>本文将从实例入手，一步步讲解 CMake 的常见用法，文中所有的实例代码可以在<a class="link"   target="_blank" rel="noopener" href="https://github.com/wzpan/cmake-demo" >这里 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>找到。如果你读完仍觉得意犹未尽，可以继续学习我在文章末尾提供的其他资源。</p>
<h6 id="入门案例：单个源文件"><a href="#入门案例：单个源文件" class="headerlink" title="入门案例：单个源文件"></a>入门案例：单个源文件</h6><p>对于简单的项目，只需要写几行代码就可以了。例如，假设现在我们的项目中只有一个源文件 <a class="link"   target="_blank" rel="noopener" href="http://main.cc/" >main.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，该程序的用途是计算一个数的指数幂。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * power - Calculate the power of number.</span></span><br><span class="line"><span class="comment"> * @param base: Base value.</span></span><br><span class="line"><span class="comment"> * @param exponent: Exponent value.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @return base raised to the power exponent.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">power</span><span class="params">(<span class="type">double</span> base, <span class="type">int</span> exponent)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> result = base;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (exponent == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">1</span>; i &lt; exponent; ++i)&#123;</span><br><span class="line">        result = result * base;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc &lt; <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Usage: %s base exponent \n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">double</span> base = <span class="built_in">atof</span>(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="type">int</span> exponent = <span class="built_in">atoi</span>(argv[<span class="number">2</span>]);</span><br><span class="line">    <span class="type">double</span> result = <span class="built_in">power</span>(base, exponent);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%g ^ %d is %g\n&quot;</span>, base, exponent, result);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>编写 CMakeLists.txt</p>
</blockquote>
<p>首先编写 CMakeLists.txt 文件，并保存在与 <a class="link"   target="_blank" rel="noopener" href="http://main.cc/" >main.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 源文件同个目录下：</p>
<p>CMakeLists.txt 的语法比较简单，由命令、注释和空格组成，其中命令是不区分大小写的。符号 <code>#</code> 后面的内容被认为是注释。命令由命令名称、小括号和参数组成，参数之间使用空格进行间隔。</p>
<p>对于上面的 CMakeLists.txt 文件，依次出现了几个命令：</p>
<ol>
<li><code>cmake_minimum_required</code>：指定运行此配置文件所需的 CMake 的最低版本；</li>
<li><code>project</code>：参数值是 <code>Demo1</code>，该命令表示项目的名称是 <code>Demo1</code> 。</li>
<li><code>add_executable</code>： <strong>将名为 <a class="link"   target="_blank" rel="noopener" href="http://main.cc/" >main.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 的源文件编译成一个名称为 Demo 的可执行文件。</strong></li>
</ol>
<blockquote>
<p>编译项目</p>
</blockquote>
<p>之后，在当前目录执行 <code>cmake .</code> ，得到 Makefile 后再使用 <code>make</code> 命令编译得到 Demo1 可执行文件。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo1]$ cmake .</span><br><span class="line">-- The C compiler identification is GNU 4.8.2</span><br><span class="line">-- The CXX compiler identification is GNU 4.8.2</span><br><span class="line">-- Check for working C compiler: /usr/sbin/cc</span><br><span class="line">-- Check for working C compiler: /usr/sbin/cc -- works</span><br><span class="line">-- Detecting C compiler ABI info</span><br><span class="line">-- Detecting C compiler ABI info - done</span><br><span class="line">-- Check for working CXX compiler: /usr/sbin/c++</span><br><span class="line">-- Check for working CXX compiler: /usr/sbin/c++ -- works</span><br><span class="line">-- Detecting CXX compiler ABI info</span><br><span class="line">-- Detecting CXX compiler ABI info - done</span><br><span class="line">-- Configuring done</span><br><span class="line">-- Generating done</span><br><span class="line">-- Build files have been written to: /home/ehome/Documents/programming/C/power/Demo1</span><br><span class="line">[ehome@xman Demo1]$ make</span><br><span class="line">Scanning dependencies of target Demo</span><br><span class="line">[100%] Building C object CMakeFiles/Demo.dir/main.cc.o</span><br><span class="line">Linking C executable Demo</span><br><span class="line">[100%] Built target Demo</span><br><span class="line">[ehome@xman Demo1]$ ./Demo 5 4</span><br><span class="line">5 ^ 4 is 625</span><br><span class="line">[ehome@xman Demo1]$ ./Demo 7 3</span><br><span class="line">7 ^ 3 is 343</span><br><span class="line">[ehome@xman Demo1]$ ./Demo 2 10</span><br><span class="line">2 ^ 10 is 1024</span><br></pre></td></tr></table></figure></div>

<h6 id="多个源文件"><a href="#多个源文件" class="headerlink" title="多个源文件"></a>多个源文件</h6><blockquote>
<p>同一目录，多个源文件</p>
</blockquote>
<p>上面的例子只有单个源文件。现在假如把 <code>power</code> 函数单独写进一个名为 <code>MathFunctions.c</code> 的源文件里，使得这个工程变成如下的形式：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./Demo2</span><br><span class="line">    |</span><br><span class="line">    +--- main.cc</span><br><span class="line">    |</span><br><span class="line">    +--- MathFunctions.cc</span><br><span class="line">    |</span><br><span class="line">    +--- MathFunctions.h</span><br></pre></td></tr></table></figure></div>

<p>这个时候，CMakeLists.txt 可以改成如下的形式：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo main.cc MathFunctions.cc)</span><br></pre></td></tr></table></figure></div>

<p>唯一的改动只是在 <code>add_executable</code> 命令中增加了一个 <code>MathFunctions.cc</code> 源文件。这样写当然没什么问题，但是如果源文件很多，把所有源文件的名字都加进去将是一件烦人的工作。更省事的方法是使用 <code>aux_source_directory</code> 命令，该命令会查找指定目录下的所有源文件，然后将结果存进指定变量名。其语法如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aux_source_directory(&lt;dir&gt; &lt;variable&gt;)</span><br></pre></td></tr></table></figure></div>

<p>因此，可以修改 CMakeLists.txt 如下：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标</span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo <span class="variable">$&#123;DIR_SRCS&#125;</span>)</span><br></pre></td></tr></table></figure></div>

<p><strong>这样，CMake 会将当前目录所有源文件的文件名赋值给变量 <code>DIR_SRCS</code> ，再指示变量 <code>DIR_SRCS</code> 中的源文件需要编译成一个名称为 Demo 的可执行文件。</strong></p>
<blockquote>
<p>多个目录，多个源文件</p>
</blockquote>
<p>现在进一步将 MathFunctions.h 和 <a class="link"   target="_blank" rel="noopener" href="http://mathfunctions.cc/" >MathFunctions.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件移动到 math 目录下。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./Demo3</span><br><span class="line">    |</span><br><span class="line">    +--- main.cc</span><br><span class="line">    |</span><br><span class="line">    +--- math/</span><br><span class="line">          |</span><br><span class="line">          +--- MathFunctions.cc</span><br><span class="line">          |</span><br><span class="line">          +--- MathFunctions.h</span><br></pre></td></tr></table></figure></div>

<p>对于这种情况，需要分别在项目根目录 Demo3 和 math 目录里各编写一个 CMakeLists.txt 文件。为了方便，我们可以先将 math 目录里的文件编译成<strong>静态库</strong>再由 main 函数调用。</p>
<blockquote>
<p><strong>静态链接库（Static Linking Library）是一种在编译时将库文件的代码和程序代码合并成一个可执行文件的方式</strong>。在静态链接过程中，编译器会将程序所依赖的静态链接库的目标代码直接嵌入到最终生成的可执行文件中，形成一个独立的、包含所有必要代码的可执行文件。</p>
<p>使用静态链接库的主要优点包括：</p>
<ol>
<li>独立性：静态链接库使得可执行文件具有完全的独立性，<strong>不依赖于系统中是否存在特定的库文件</strong>。这样可以确保程序在其他系统中运行时不会因为缺少库文件而出错。</li>
<li>性能：静态链接库在编译时被嵌入到可执行文件中，不需要在运行时进行库文件的加载和链接，因此可以减少程序的启动时间，并且在运行过程中也可以提高一定的执行效率。</li>
<li>版本控制：静态链接库可以确保程序使用的是指定版本的库文件，避免了在不同版本的库文件之间出现兼容性问题。</li>
<li>分发简单：使用静态链接库的程序可以更方便地进行分发，因为只需要将一个独立的可执行文件交付给用户，而不需要额外提供库文件。</li>
</ol>
</blockquote>
<p>根目录中的 CMakeLists.txt ：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 math 子目录</span></span><br><span class="line"><span class="keyword">add_subdirectory</span>(<span class="keyword">math</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标 </span></span><br><span class="line"><span class="keyword">add_executable</span>(Demo main.cc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加链接库</span></span><br><span class="line"><span class="keyword">target_link_libraries</span>(Demo MathFunctions)</span><br></pre></td></tr></table></figure></div>

<p>该文件添加了下面的内容: 第3行，使用命令 <code>add_subdirectory</code> 指明本项目包含一个子目录 math，这样 math 目录下的 CMakeLists.txt 文件和源代码也会被处理 。第6行，使用命令 <code>target_link_libraries</code> 指明可执行文件 main 需要连接一个名为 MathFunctions 的链接库 。</p>
<p>子目录中的 CMakeLists.txt：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_LIB_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_LIB_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成链接库</span></span><br><span class="line"><span class="keyword">add_library</span> (MathFunctions <span class="variable">$&#123;DIR_LIB_SRCS&#125;</span>)</span><br></pre></td></tr></table></figure></div>

<p>在该文件中使用命令 <code>add_library</code> 将 src 目录中的源文件编译为静态链接库。</p>
<h6 id="自定义编译选项"><a href="#自定义编译选项" class="headerlink" title="自定义编译选项"></a>自定义编译选项</h6><p>CMake 允许为项目增加编译选项，从而可以根据用户的环境和需求选择最合适的编译方案。</p>
<p>例如，可以将 MathFunctions 库设为一个可选的库，如果该选项为 <code>ON</code> ，就使用该库定义的数学函数来进行运算。否则就调用标准库中的数学函数库。</p>
<blockquote>
<p>修改 CMakeLists 文件</p>
</blockquote>
<p>我们要做的第一步是在顶层的 CMakeLists.txt 文件中添加该选项：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CMake 最低版本号要求</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span> (VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 项目信息</span></span><br><span class="line"><span class="keyword">project</span> (Demo4)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_INCLUDE_CURRENT_DIR <span class="keyword">ON</span>)				<span class="comment"># 设置 CMake 包含当前目录。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否使用自己的 MathFunctions 库</span></span><br><span class="line"><span class="keyword">option</span> (USE_MYMATH</span><br><span class="line">	   <span class="string">&quot;Use provided math implementation&quot;</span> <span class="keyword">ON</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入一个配置头文件，用于处理 CMake 对源码的设置</span></span><br><span class="line"><span class="keyword">configure_file</span> (</span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/config.h.in&quot;</span></span><br><span class="line">  <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/config.h&quot;</span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否加入 MathFunctions 库</span></span><br><span class="line"><span class="keyword">if</span> (USE_MYMATH)</span><br><span class="line">  <span class="keyword">include_directories</span> (<span class="string">&quot;$&#123;PROJECT_SOURCE_DIR&#125;/math&quot;</span>)</span><br><span class="line">  <span class="keyword">add_subdirectory</span> (<span class="keyword">math</span>)</span><br><span class="line">  <span class="keyword">set</span> (EXTRA_LIBS <span class="variable">$&#123;EXTRA_LIBS&#125;</span> MathFunctions)		<span class="comment">#将 MathFunctions 添加到 EXTRA_LIBS 变量中。</span></span><br><span class="line"><span class="keyword">endif</span> (USE_MYMATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找当前目录下的所有源文件</span></span><br><span class="line"><span class="comment"># 并将名称保存到 DIR_SRCS 变量</span></span><br><span class="line"><span class="keyword">aux_source_directory</span>(. DIR_SRCS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定生成目标</span></span><br><span class="line"><span class="keyword">add_executable</span> (Demo <span class="variable">$&#123;DIR_SRCS&#125;</span>)</span><br><span class="line"><span class="keyword">target_link_libraries</span> (Demo  <span class="variable">$&#123;EXTRA_LIBS&#125;</span>)</span><br></pre></td></tr></table></figure></div>

<p>其中：</p>
<ol>
<li>第7行的 <code>configure_file</code> 命令用于加入一个配置头文件 <strong>config.h ，这个文件由 CMake 从 <a class="link"   target="_blank" rel="noopener" href="http://config.h.in/" >config.h.in <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 生</strong>成，通过这样的机制，将可以通过预定义一些参数和变量来控制代码的生成。</li>
<li>第13行的 <code>option</code> 命令添加了一个 <code>USE_MYMATH</code> 选项，并且默认值为 <code>ON</code> 。</li>
<li>第17行根据 <code>USE_MYMATH</code> 变量的值来决定是否使用我们自己编写的 MathFunctions 库。</li>
</ol>
<blockquote>
<p>修改 <a class="link"   target="_blank" rel="noopener" href="http://main.cc/" >main.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件</p>
</blockquote>
<p>之后修改 <a class="link"   target="_blank" rel="noopener" href="http://main.cc/" >main.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件，让其根据 <code>USE_MYMATH</code> 的预定义值来决定是否调用标准库还是 MathFunctions 库：</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;config.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_MYMATH</span></span><br><span class="line">  <span class="meta">#<span class="keyword">include</span> <span class="string">&quot;math/MathFunctions.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">  <span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc &lt; <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Usage: %s base exponent \n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">double</span> base = <span class="built_in">atof</span>(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="type">int</span> exponent = <span class="built_in">atoi</span>(argv[<span class="number">2</span>]);</span><br><span class="line">    </span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_MYMATH</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Now we use our own Math library. \n&quot;</span>);</span><br><span class="line">    <span class="type">double</span> result = <span class="built_in">power</span>(base, exponent);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Now we use the standard library. \n&quot;</span>);</span><br><span class="line">    <span class="type">double</span> result = <span class="built_in">pow</span>(base, exponent);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%g ^ %d is %g\n&quot;</span>, base, exponent, result);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>编写 <a class="link"   target="_blank" rel="noopener" href="http://config.h.in/" >config.h.in <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件</p>
</blockquote>
<p>上面的程序值得注意的是第3行，这里引用了一个 config.h 文件，这个文件预定义了 <code>USE_MYMATH</code> 的值。但我们并不直接编写这个文件，为了方便从 CMakeLists.txt 中导入配置，我们编写一个 <a class="link"   target="_blank" rel="noopener" href="http://config.h.in/" >config.h.in <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件，内容如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#cmakedefine USE_MYMATH</span><br></pre></td></tr></table></figure></div>

<p>这样 CMake 会自动根据 CMakeLists 配置文件中的设置自动生成 config.h 文件。</p>
<h6 id="编译项目"><a href="#编译项目" class="headerlink" title="编译项目"></a>编译项目</h6><p>现在编译一下这个项目，为了便于交互式的选择该变量的值，可以使用 <code>ccmake</code> 命令（也可以使用 <code>cmake -i</code> 命令，该命令会提供一个会话式的交互式配置界面）：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230518135248836.png"
                      class="" title="image-20230518135248836"
                >



<p>从中可以找到刚刚定义的 <code>USE_MYMATH</code> 选项，按键盘的方向键可以在不同的选项窗口间跳转，按下 <code>enter</code> 键可以修改该选项。修改完成后可以按下 <code>c</code> 选项完成配置，之后再按 <code>g</code> 键确认生成 Makefile 。ccmake 的其他操作可以参考窗口下方给出的指令提示。</p>
<p>我们可以试试分别将 <code>USE_MYMATH</code> 设为 <code>ON</code> 和 <code>OFF</code> 得到的结果：</p>
<blockquote>
<p>USE_MYMATH 为 ON</p>
</blockquote>
<p>运行结果：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo4]$ ./Demo</span><br><span class="line">Now we use our own MathFunctions library. </span><br><span class="line"> 7 ^ 3 = 343.000000</span><br><span class="line"> 10 ^ 5 = 100000.000000</span><br><span class="line"> 2 ^ 10 = 1024.000000</span><br></pre></td></tr></table></figure></div>

<p>此时 config.h 的内容为：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define USE_MYMATH</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>USE_MYMATH 为 OFF</p>
</blockquote>
<p>运行结果：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo4]$ ./Demo</span><br><span class="line">Now we use the standard library. </span><br><span class="line"> 7 ^ 3 = 343.000000</span><br><span class="line"> 10 ^ 5 = 100000.000000</span><br><span class="line"> 2 ^ 10 = 1024.000000</span><br></pre></td></tr></table></figure></div>

<p>此时 config.h 的内容为：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/* #undef USE_MYMATH */</span><br></pre></td></tr></table></figure></div>

<h6 id="安装和测试"><a href="#安装和测试" class="headerlink" title="安装和测试"></a>安装和测试</h6><p><strong>CMake 也可以指定安装规则，以及添加测试</strong>。这两个功能分别可以通过在产生 Makefile 后使用 <code>make install</code> 和 <code>make test</code> 来执行。在以前的 GNU Makefile 里，你可能需要为此编写 <code>install</code> 和 <code>test</code> 两个伪目标和相应的规则，但在 CMake 里，这样的工作同样只需要简单的调用几条命令。</p>
<blockquote>
<p><strong>安装规则告诉CMake应该将哪些文件复制到安装目录，并且可以指定文件的权限、安装路径和其他属性。</strong></p>
<p>安装规则通常用于将生成的可执行文件、库文件、头文件、配置文件和其他必要的资源安装到系统中的适当位置，以供其他程序或用户使用。通过指定安装规则，开发人员可以在构建过程中自定义安装的文件和目录结构，以满足特定项目或系统的需求。</p>
</blockquote>
<blockquote>
<p>定制安装规则</p>
</blockquote>
<p>首先先在 math&#x2F;CMakeLists.txt 文件里添加下面两行：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定 MathFunctions 库的安装路径</span></span><br><span class="line"><span class="keyword">install</span> (TARGETS MathFunctions DESTINATION bin)</span><br><span class="line"><span class="keyword">install</span> (FILES MathFunctions.h DESTINATION <span class="keyword">include</span>)</span><br></pre></td></tr></table></figure></div>

<p>指明 MathFunctions 库的安装路径。之后同样修改根目录的 CMakeLists 文件，在末尾添加下面几行：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定安装路径</span></span><br><span class="line"><span class="keyword">install</span> (TARGETS Demo DESTINATION bin)</span><br><span class="line"><span class="keyword">install</span> (FILES <span class="string">&quot;$&#123;PROJECT_BINARY_DIR&#125;/config.h&quot;</span></span><br><span class="line">         DESTINATION <span class="keyword">include</span>)</span><br></pre></td></tr></table></figure></div>

<p>通过上面的定制，生成的 Demo 文件和 MathFunctions 函数库 libMathFunctions.o 文件将会被复制到 <code>/usr/local/bin</code> 中，而 MathFunctions.h 和生成的 config.h 文件则会被复制到 <code>/usr/local/include</code> 中。我们可以验证一下（顺带一提的是，这里的 <code>/usr/local/</code> 是默认安装到的根目录，可以通过修改 <code>CMAKE_INSTALL_PREFIX</code> 变量的值来指定这些文件应该拷贝到哪个根目录）：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo5]$ sudo make install</span><br><span class="line">[ 50%] Built target MathFunctions</span><br><span class="line">[100%] Built target Demo</span><br><span class="line">Install the project...</span><br><span class="line">-- Install configuration: &quot;&quot;</span><br><span class="line">-- Installing: /usr/local/bin/Demo</span><br><span class="line">-- Installing: /usr/local/include/config.h</span><br><span class="line">-- Installing: /usr/local/bin/libMathFunctions.a</span><br><span class="line">-- Up-to-date: /usr/local/include/MathFunctions.h</span><br><span class="line">[ehome@xman Demo5]$ ls /usr/local/bin</span><br><span class="line">Demo  libMathFunctions.a</span><br><span class="line">[ehome@xman Demo5]$ ls /usr/local/include</span><br><span class="line">config.h  MathFunctions.h</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>在CMake中，<code>$&#123;PROJECT_BINARY_DIR&#125;</code>是一个变量，用于表示项目构建过程中生成的目标文件的输出目录（即构建目录）的路径。</p>
</blockquote>
<blockquote>
<p>为工程添加测试</p>
</blockquote>
<p>添加测试同样很简单。CMake 提供了一个称为 CTest 的测试工具。我们要做的只是在项目根目录的 CMakeLists 文件中调用一系列的 <code>add_test</code> 命令。</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用测试</span></span><br><span class="line"><span class="keyword">enable_testing</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试程序是否成功运行</span></span><br><span class="line"><span class="keyword">add_test</span> (test_run Demo <span class="number">5</span> <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试帮助信息是否可以正常提示</span></span><br><span class="line"><span class="keyword">add_test</span> (test_usage Demo)</span><br><span class="line"><span class="keyword">set_tests_properties</span> (test_usage		<span class="comment">#用于设置测试用例的属性。它允许您修改与测试相关的属性，例如测试用例的名称、超时时间、工作目录、依赖关系等。</span></span><br><span class="line">  PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;Usage: .* base exponent&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 5 的平方</span></span><br><span class="line"><span class="keyword">add_test</span> (test_5_2 Demo <span class="number">5</span> <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set_tests_properties</span> (test_5_2</span><br><span class="line"> PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;is 25&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 10 的 5 次方</span></span><br><span class="line"><span class="keyword">add_test</span> (test_10_5 Demo <span class="number">10</span> <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set_tests_properties</span> (test_10_5</span><br><span class="line"> PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;is 100000&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试 2 的 10 次方</span></span><br><span class="line"><span class="keyword">add_test</span> (test_2_10 Demo <span class="number">2</span> <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set_tests_properties</span> (test_2_10</span><br><span class="line"> PROPERTIES PASS_REGULAR_EXPRESSION <span class="string">&quot;is 1024&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<p>上面的代码包含了四个测试。第一个测试 <code>test_run</code> 用来测试程序是否成功运行并返回 0 值。剩下的三个测试分别用来测试 5 的 平方、10 的 5 次方、2 的 10 次方是否都能得到正确的结果。<strong>其中 <code>PASS_REGULAR_EXPRESSION</code> 用来测试输出是否包含后面跟着的字符串。</strong></p>
<blockquote>
<p>设置了名为<code>test_usage</code>的测试用例的属性。属性<code>PASS_REGULAR_EXPRESSION</code>指定了一个正则表达式，用于匹配测试的输出结果。这里，它用于检查测试是否按预期显示了帮助信息的提示。</p>
<p>同样地，其他测试用例也使用<code>set_tests_properties</code>来设置期望的输出结果，以确保测试的正确性。这样，在执行<code>ctest</code>命令运行测试时，CTest将根据设置的属性来判断测试是否通过。</p>
</blockquote>
<p>让我们看看测试的结果：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo5]$ make test</span><br><span class="line">Running tests...</span><br><span class="line">Test project /home/ehome/Documents/programming/C/power/Demo5</span><br><span class="line">    Start 1: test_run</span><br><span class="line">1/4 Test #1: test_run .........................   Passed    0.00 sec</span><br><span class="line">    Start 2: test_5_2</span><br><span class="line">2/4 Test #2: test_5_2 .........................   Passed    0.00 sec</span><br><span class="line">    Start 3: test_10_5</span><br><span class="line">3/4 Test #3: test_10_5 ........................   Passed    0.00 sec</span><br><span class="line">    Start 4: test_2_10</span><br><span class="line">4/4 Test #4: test_2_10 ........................   Passed    0.00 sec</span><br><span class="line"></span><br><span class="line">100% tests passed, 0 tests failed out of 4</span><br><span class="line"></span><br><span class="line">Total Test time (real) =   0.01 sec</span><br></pre></td></tr></table></figure></div>

<p>如果要测试更多的输入数据，像上面那样一个个写测试用例未免太繁琐。这时可以通过编写宏来实现：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个宏，用来简化测试工作</span></span><br><span class="line"><span class="keyword">macro</span> (do_test arg1 arg2 result)	<span class="comment">#创建一个do_test的宏</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">add_test</span> (test_<span class="variable">$&#123;arg1&#125;</span>_<span class="variable">$&#123;arg2&#125;</span> Demo <span class="variable">$&#123;arg1&#125;</span> <span class="variable">$&#123;arg2&#125;</span>)	<span class="comment">#add_test创建一个测试用例，test_$&#123;arg1&#125;_$&#123;arg2&#125;是名称，Demo $&#123;arg1&#125; $&#123;arg2&#125;是可执行文件及参数</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">set_tests_properties</span> (test_<span class="variable">$&#123;arg1&#125;</span>_<span class="variable">$&#123;arg2&#125;</span></span><br><span class="line">    PROPERTIES PASS_REGULAR_EXPRESSION <span class="variable">$&#123;result&#125;</span>)	<span class="comment">#设置测试用例的属性，指明预期输出结果</span></span><br><span class="line"><span class="keyword">endmacro</span> (do_test)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用该宏进行一系列的数据测试</span></span><br><span class="line">do_test (<span class="number">5</span> <span class="number">2</span> <span class="string">&quot;is 25&quot;</span>)</span><br><span class="line">do_test (<span class="number">10</span> <span class="number">5</span> <span class="string">&quot;is 100000&quot;</span>)</span><br><span class="line">do_test (<span class="number">2</span> <span class="number">10</span> <span class="string">&quot;is 1024&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<p>关于 CTest 的更详细的用法可以通过 <code>man 1 ctest</code> 参考 CTest 的文档。</p>
<blockquote>
<p>支持gdb</p>
</blockquote>
<p>让 CMake 支持 gdb 的设置也很容易，在<code>CMakeLists.txt</code>文件只需要指定 <code>Debug</code> 模式下开启 <code>-g</code> 选项：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_TYPE <span class="string">&quot;Debug&quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS_DEBUG <span class="string">&quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="string">&quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<p>之后可以直接对生成的程序使用 gdb 来调试。<code>gdb Demo</code></p>
<h6 id="添加环境检查"><a href="#添加环境检查" class="headerlink" title="添加环境检查"></a>添加环境检查</h6><p>有时候可能要对系统环境做点检查，例如要使用一个平台相关的特性的时候。在这个例子中，我们检查系统是否自带 pow 函数。如果带有 pow 函数，就使用它；否则使用我们定义的 power 函数。</p>
<blockquote>
<p>添加 CheckFunctionExists 宏</p>
</blockquote>
<p>首先在顶层 CMakeLists 文件中添加 CheckFunctionExists.cmake 宏，并调用 <code>check_function_exists</code> 命令测试链接器是否能够在链接阶段找到 <code>pow</code> 函数。</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查系统是否支持 pow 函数</span></span><br><span class="line"><span class="keyword">include</span> (<span class="variable">$&#123;CMAKE_ROOT&#125;</span>/Modules/CheckFunctionExists.cmake)		<span class="comment">#将CheckFunctionExists.cmake包含检查指定的函数是否存在。</span></span><br><span class="line">check_function_exists (pow HAVE_POW)	<span class="comment">#用于检查函数pow是否存在。该函数的第一个参数是要检查的函数名，第二个参数是一个变量名，用于存储检查结果。</span></span><br></pre></td></tr></table></figure></div>

<p><strong>将上面这段代码放在 <code>configure_file</code> 命令前。</strong></p>
<blockquote>
<p>预定义相关宏变量</p>
</blockquote>
<p>接下来修改 <a class="link"   target="_blank" rel="noopener" href="http://config.h.in/" >config.h.in <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件，预定义相关的宏变量。</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// does the platform provide pow <span class="keyword">function</span>?</span><br><span class="line"><span class="comment">#cmakedefine HAVE_POW</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>在代码中使用宏和函数</p>
</blockquote>
<p>最后一步是修改 <a class="link"   target="_blank" rel="noopener" href="http://main.cc/" >main.cc <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ，在代码中使用宏和函数：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ifdef HAVE_POW</span></span><br><span class="line">    printf(<span class="string">&quot;Now we use the standard library. \n&quot;</span>);</span><br><span class="line">    double result = pow(base, exponent);</span><br><span class="line"><span class="comment">#else</span></span><br><span class="line">    printf(<span class="string">&quot;Now we use our own Math library. \n&quot;</span>);</span><br><span class="line">    double result = power(base, exponent);</span><br><span class="line"><span class="comment">#endif</span></span><br></pre></td></tr></table></figure></div>

<h6 id="添加版本号"><a href="#添加版本号" class="headerlink" title="添加版本号"></a>添加版本号</h6><p>给项目添加和维护版本号是一个好习惯，这样有利于用户了解每个版本的维护情况，并及时了解当前所用的版本是否过时，或是否可能出现不兼容的情况。</p>
<p><strong>首先修改顶层 CMakeLists 文件，在 <code>project</code> 命令之后加入如下两行：</strong></p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> (Demo_VERSION_MAJOR <span class="number">1</span>)</span><br><span class="line"><span class="keyword">set</span> (Demo_VERSION_MINOR <span class="number">0</span>)</span><br></pre></td></tr></table></figure></div>

<p>分别指定当前的项目的主版本号和副版本号。</p>
<p>之后，为了在代码中获取版本信息，我们可以修改 <a class="link"   target="_blank" rel="noopener" href="http://config.h.in/" >config.h.in <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 文件，添加两个预定义变量：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// the configured options <span class="keyword">and</span> settings for Tutorial</span><br><span class="line"><span class="comment">#define Demo_VERSION_MAJOR @Demo_VERSION_MAJOR@</span></span><br><span class="line"><span class="comment">#define Demo_VERSION_MINOR @Demo_VERSION_MINOR@</span></span><br></pre></td></tr></table></figure></div>

<p>这样就可以直接在代码中打印版本信息了：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;stdlib.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;math.h&gt;</span></span><br><span class="line"><span class="comment">#include &quot;config.h&quot;</span></span><br><span class="line"><span class="comment">#include &quot;math/MathFunctions.h&quot;</span></span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (argc &lt; <span class="number">3</span>)&#123;</span><br><span class="line">        // print version info</span><br><span class="line">        printf(<span class="string">&quot;%s Version %d.%d\n&quot;</span>,</span><br><span class="line">            argv[<span class="number">0</span>],</span><br><span class="line">            Demo_VERSION_MAJOR,</span><br><span class="line">            Demo_VERSION_MINOR);</span><br><span class="line">        printf(<span class="string">&quot;Usage: %s base exponent \n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    double base = atof(argv[<span class="number">1</span>]);</span><br><span class="line">    int exponent = atoi(argv[<span class="number">2</span>]);</span><br><span class="line">    </span><br><span class="line"><span class="comment">#if defined (HAVE_POW)</span></span><br><span class="line">    printf(<span class="string">&quot;Now we use the standard library. \n&quot;</span>);</span><br><span class="line">    double result = pow(base, exponent);</span><br><span class="line"><span class="comment">#else</span></span><br><span class="line">    printf(<span class="string">&quot;Now we use our own Math library. \n&quot;</span>);</span><br><span class="line">    double result = power(base, exponent);</span><br><span class="line"><span class="comment">#endif</span></span><br><span class="line">    </span><br><span class="line">    printf(<span class="string">&quot;%g ^ %d is %g\n&quot;</span>, base, exponent, result);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h6 id="生成安装包"><a href="#生成安装包" class="headerlink" title="生成安装包"></a>生成安装包</h6><p>本节将学习如何配置生成各种平台上的安装包，包括二进制安装包和源码安装包。为了完成这个任务，我们需要用到 CPack ，它同样也是由 CMake 提供的一个工具，专门用于打包。</p>
<p>首先在顶层的 CMakeLists.txt 文件尾部添加下面几行：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 构建一个 CPack 安装包</span><br><span class="line">include (InstallRequiredSystemLibraries)</span><br><span class="line">set (CPACK_RESOURCE_FILE_LICENSE</span><br><span class="line">  &quot;$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/License.txt&quot;)</span><br><span class="line">set (CPACK_PACKAGE_VERSION_MAJOR &quot;$&#123;Demo_VERSION_MAJOR&#125;&quot;)</span><br><span class="line">set (CPACK_PACKAGE_VERSION_MINOR &quot;$&#123;Demo_VERSION_MINOR&#125;&quot;)</span><br><span class="line">include (CPack)</span><br></pre></td></tr></table></figure></div>

<p>上面的代码做了以下几个工作：</p>
<ol>
<li>导入 InstallRequiredSystemLibraries 模块，以便之后导入 CPack 模块；</li>
<li>设置一些 CPack 相关变量，包括版权信息和版本信息，其中版本信息用了上一节定义的版本号；</li>
<li>导入 CPack 模块。</li>
</ol>
<p><strong>接下来的工作是像往常一样构建工程，并执行 <code>cpack</code> 命令。（注意编译前需要导入License.txt文件）</strong></p>
<ul>
<li>生成二进制安装包：</li>
</ul>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cpack -C CPackConfig.cmake</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p><code>cpack</code> 是 CMake 中的一个命令行工具，用于生成软件包（package）文件，如安装程序、压缩文件等，以便进行软件的分发和安装。<code>-C</code> 选项用于指定 CPack 的配置文件，<strong>其中 <code>CPackConfig.cmake</code> 是一个用户定义的 CPack 配置文件的名称</strong></p>
</blockquote>
<ul>
<li>生成源码安装包</li>
</ul>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cpack -C CPackSourceConfig.cmake</span><br></pre></td></tr></table></figure></div>

<p>我们可以试一下。在生成项目后，执行 <code>cpack -C CPackConfig.cmake</code> 命令：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo8]$ cpack -C CPackSourceConfig.cmake</span><br><span class="line">CPack: Create package using STGZ</span><br><span class="line">CPack: Install projects</span><br><span class="line">CPack: - Run preinstall target for: Demo8</span><br><span class="line">CPack: - Install project: Demo8</span><br><span class="line">CPack: Create package</span><br><span class="line">CPack: - package: /home/ehome/Documents/programming/C/power/Demo8/Demo8-1.0.1-Linux.sh generated.</span><br><span class="line">CPack: Create package using TGZ</span><br><span class="line">CPack: Install projects</span><br><span class="line">CPack: - Run preinstall target for: Demo8</span><br><span class="line">CPack: - Install project: Demo8</span><br><span class="line">CPack: Create package</span><br><span class="line">CPack: - package: /home/ehome/Documents/programming/C/power/Demo8/Demo8-1.0.1-Linux.tar.gz generated.</span><br><span class="line">CPack: Create package using TZ</span><br><span class="line">CPack: Install projects</span><br><span class="line">CPack: - Run preinstall target for: Demo8</span><br><span class="line">CPack: - Install project: Demo8</span><br><span class="line">CPack: Create package</span><br><span class="line">CPack: - package: /home/ehome/Documents/programming/C/power/Demo8/Demo8-1.0.1-Linux.tar.Z generated.</span><br></pre></td></tr></table></figure></div>

<p>此时会在该目录下创建 3 个不同格式的二进制包文件：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo8]$ ls Demo8-*</span><br><span class="line">Demo8-1.0.1-Linux.sh  Demo8-1.0.1-Linux.tar.gz  Demo8-1.0.1-Linux.tar.Z</span><br></pre></td></tr></table></figure></div>

<p>这 3 个二进制包文件所包含的内容是完全相同的。我们可以执行其中一个。此时会出现一个由 CPack 自动生成的交互式安装界面：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo8]$ sh Demo8-1.0.1-Linux.sh </span><br><span class="line">Demo8 Installer Version: 1.0.1, Copyright (c) Humanity</span><br><span class="line">This is a self-extracting archive.</span><br><span class="line">The archive will be extracted to: /home/ehome/Documents/programming/C/power/Demo8</span><br><span class="line"></span><br><span class="line">If you want to stop extracting, please press &lt;ctrl-C&gt;.</span><br><span class="line">The MIT License (MIT)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2013 Joseph Pan(http://hahack.com)</span><br><span class="line"></span><br><span class="line">Permission is hereby granted, free of charge, to any person obtaining a copy of</span><br><span class="line">this software and associated documentation files (the &quot;Software&quot;), to deal in</span><br><span class="line">the Software without restriction, including without limitation the rights to</span><br><span class="line">use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of</span><br><span class="line">the Software, and to permit persons to whom the Software is furnished to do so,</span><br><span class="line">subject to the following conditions:</span><br><span class="line"></span><br><span class="line">The above copyright notice and this permission notice shall be included in all</span><br><span class="line">copies or substantial portions of the Software.</span><br><span class="line"></span><br><span class="line">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span><br><span class="line">IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS</span><br><span class="line">FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR</span><br><span class="line">COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER</span><br><span class="line">IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN</span><br><span class="line">CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Do you accept the license? [yN]: </span><br><span class="line">y</span><br><span class="line">By default the Demo8 will be installed in:</span><br><span class="line">  &quot;/home/ehome/Documents/programming/C/power/Demo8/Demo8-1.0.1-Linux&quot;</span><br><span class="line">Do you want to include the subdirectory Demo8-1.0.1-Linux?</span><br><span class="line">Saying no will install in: &quot;/home/ehome/Documents/programming/C/power/Demo8&quot; [Yn]: </span><br><span class="line">y</span><br><span class="line"></span><br><span class="line">Using target directory: /home/ehome/Documents/programming/C/power/Demo8/Demo8-1.0.1-Linux</span><br><span class="line">Extracting, please wait...</span><br><span class="line"></span><br><span class="line">Unpacking finished successfully</span><br></pre></td></tr></table></figure></div>

<p>完成后提示安装到了 Demo8-1.0.1-Linux 子目录中，我们可以进去执行该程序：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ehome@xman Demo8]$ ./Demo8-1.0.1-Linux/bin/Demo 5 2</span><br><span class="line">Now we use our own Math library. </span><br><span class="line">5 ^ 2 is 25</span><br></pre></td></tr></table></figure></div>

<p>关于 CPack 的更详细的用法可以通过 <code>man 1 cpack</code> 参考 CPack 的文档。</p>
<h6 id="将其他平台的项目迁移到CMake"><a href="#将其他平台的项目迁移到CMake" class="headerlink" title="将其他平台的项目迁移到CMake"></a>将其他平台的项目迁移到CMake</h6><blockquote>
<p>通过CMake可以编写一个通用的CMakeLists.txt文件，然后在不同的操作系统上生成相应的构建文件。例如，在Windows上可以生成Visual Studio解决方案或使用MinGW生成Makefile，在Linux上可以生成Makefile，在macOS上可以生成Xcode项目等。这样开发者可以使用相同的CMake配置文件在不同的平台上构建项目。</p>
</blockquote>
<p>CMake 可以很轻松地构建出在适合各个平台执行的工程环境。而如果当前的工程环境不是 CMake ，而是基于某个特定的平台，是否可以迁移到 CMake 呢？答案是可能的。下面针对几个常用的平台，列出了它们对应的迁移方案。</p>
<blockquote>
<p>autotools</p>
</blockquote>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="https://projects.kde.org/projects/kde/kdesdk/kde-dev-scripts/repository/revisions/master/changes/cmake-utils/scripts/am2cmake" >am2cmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 可以将 autotools 系的项目转换到 CMake，这个工具的一个成功案例是 KDE 。</li>
<li><a class="link"   target="_blank" rel="noopener" href="http://emanuelgreisen.dk/stuff/kdevelop_am2cmake.php.tgz" >Alternative Automake2CMake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 可以转换使用 automake 的 KDevelop 工程项目。</li>
<li><a class="link"   target="_blank" rel="noopener" href="http://www.cmake.org/Wiki/GccXmlAutoConfHints" >Converting autoconf tests <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<blockquote>
<p>qmake</p>
</blockquote>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="http://www.cmake.org/Wiki/CMake:ConvertFromQmake" >qmake converter <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 可以转换使用 QT 的 qmake 的工程。</li>
</ul>
<blockquote>
<p>Visual Studio</p>
</blockquote>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="http://vcproj2cmake.sf.net/" >vcproj2cmake.rb <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 可以根据 Visual Studio 的工程文件（后缀名是 <code>.vcproj</code> 或 <code>.vcxproj</code>）生成 CMakeLists.txt 文件。</li>
<li><a class="link"   target="_blank" rel="noopener" href="http://nberserk.blogspot.com/2010/11/converting-vc-projectsvcproj-to.html" >vcproj2cmake.ps1 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> vcproj2cmake 的 PowerShell 版本。</li>
<li><a class="link"   target="_blank" rel="noopener" href="http://sourceforge.net/projects/folders4cmake/" >folders4cmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 根据 Visual Studio 项目文件生成相应的 “source_group” 信息，这些信息可以很方便的在 CMake 脚本中使用。支持 Visual Studio 9&#x2F;10 工程文件。</li>
</ul>
<blockquote>
<p>CMakeLists.txt 自动推导</p>
</blockquote>
<ul>
<li><a class="link"   target="_blank" rel="noopener" href="http://websvn.kde.org/trunk/KDE/kdesdk/cmake/scripts/" >gencmake <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 根据现有文件推导 CMakeLists.txt 文件。</li>
<li><a class="link"   target="_blank" rel="noopener" href="http://www.vanvelzensoftware.com/postnuke/index.php?name=Downloads&req=viewdownload&cid=7" >CMakeListGenerator <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 应用一套文件和目录分析创建出完整的 CMakeLists.txt 文件。仅支持 Win32 平台。</li>
</ul>
<h5 id="工程创建-1"><a href="#工程创建-1" class="headerlink" title="工程创建"></a>工程创建</h5><p>地平线开发库提供了arm的依赖环境和板端应用程序。我们提供的工程依赖信息如下：</p>
<ul>
<li>地平线评测库libdnn.so，路径： <code>~/.horizon/ddk/j5_aarch64/dnn/lib/</code>。</li>
<li>地平线编译器依赖 <code>libhbrt_bayes_aarch64.so</code>，路径： <code>~/.horizon/ddk/j5_aarch64/dnn/lib/</code>。</li>
<li>地平线J5芯片系统依赖，路径： <code>~/.horizon/ddk/j5_aarch64/appsdk/appuser/</code>。</li>
<li>C编译器 aarch64-linux-gnu-gcc。</li>
<li>C++编译器 aarch64-linux-gnu-g++。</li>
</ul>
<p>创建一个工程，用户需要编写 <code>CMakeLists.txt</code> 文件。 脚本中定义了编译工具路径， <code>CMakeLists.txt</code> 文件中定义了一些编译选项，以及依赖库、头文件的路径。参考如下：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(your_project_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS <span class="string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11&quot;</span>)	<span class="comment">#设置C++编译器的编译选项，这里将标准设置为C++11。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#CMAKE_CXX_FLAGS_DEBUG和CMAKE_C_FLAGS_DEBUG用于设置Debug模式下的编译选项，CMAKE_CXX_FLAGS_RELEASE和CMAKE_C_FLAGS_RELEASE用于设置Release模式下的编译选项。</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS_DEBUG <span class="string">&quot; -Wall -Werror -g -O0 &quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_C_FLAGS_DEBUG <span class="string">&quot; -Wall -Werror -g -O0 &quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="string">&quot; -Wall -Werror -O3 &quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_C_FLAGS_RELEASE <span class="string">&quot; -Wall -Werror -O3 &quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">NOT</span> CMAKE_BUILD_TYPE)		<span class="comment">#用于设置默认的构建类型为Release，如果未指定构建类型。</span></span><br><span class="line">    <span class="keyword">set</span>(CMAKE_BUILD_TYPE Release)</span><br><span class="line"><span class="keyword">endif</span> ()</span><br><span class="line"></span><br><span class="line"><span class="keyword">message</span>(STATUS <span class="string">&quot;Build type: $&#123;CMAKE_BUILD_TYPE&#125;&quot;</span>)	<span class="comment">#输出当前构建类型。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define dnn lib path</span></span><br><span class="line"><span class="keyword">set</span>(DNN_PATH <span class="string">&quot;~/.horizon/ddk/j5_aarch64/dnn/&quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(APPSDK_PATH <span class="string">&quot;~/.horizon/ddk/j5_aarch64/appsdk/appuser/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(DNN_LIB_PATH <span class="variable">$&#123;DNN_PATH&#125;</span>/lib)</span><br><span class="line"><span class="keyword">set</span>(BPU_libs dnn cnn_intf hbrt_bayes_aarch64)	<span class="comment">#定义 BPU_libs 为需要链接的库的名称。dnn cnn_intf hbrt_bayes_aarch64分别都是库的名称，通过BUU_libs链接到可执行文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;DNN_PATH&#125;</span>/<span class="keyword">include</span></span><br><span class="line">                    <span class="variable">$&#123;APPSDK_PATH&#125;</span>/<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">link_directories</span>(<span class="variable">$&#123;DNN_LIB_PATH&#125;</span></span><br><span class="line">                <span class="variable">$&#123;APPSDK_PATH&#125;</span>/lib)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(user_app main.cc)</span><br><span class="line"><span class="keyword">target_link_libraries</span>(user_app</span><br><span class="line">                      <span class="variable">$&#123;BPU_libs&#125;</span></span><br><span class="line">                      pthread</span><br><span class="line">                      rt</span><br><span class="line">                      dl)</span><br></pre></td></tr></table></figure></div>

<p><strong>注意在以上示例中，我们没有指定编译器位置，会在配合工程编译阶段补充编译器指定</strong></p>
<h4 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h4><p>工程实现部分，我们主要为您介绍如何将前文浮点转换得到的bin模型在地平线平台运行起来。 最简单的步骤应该包括模型加载、准备输入数据、准备输出内存、推理和结果解析，以下是一份简单的加载部署模型参考代码：</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;dnn/hb_dnn.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;dnn/hb_sys.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">float</span> <span class="title">quanti_shift</span><span class="params">(<span class="type">int32_t</span> data, <span class="type">uint32_t</span> shift)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;<span class="type">float</span>&gt;(data) / <span class="built_in">static_cast</span>&lt;<span class="type">float</span>&gt;(<span class="number">1</span> &lt;&lt; shift);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">float</span> <span class="title">quanti_scale</span><span class="params">(<span class="type">int32_t</span> data, <span class="type">float</span> scale)</span> </span>&#123; <span class="keyword">return</span> data * scale; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 第一步加载模型</span></span><br><span class="line">  hbPackedDNNHandle_t packed_dnn_handle;</span><br><span class="line">  <span class="type">const</span> <span class="type">char</span>* model_file_name= <span class="string">&quot;./mobilenetv1/mobilenetv1_224x224_nv12.bin&quot;</span>;</span><br><span class="line">  <span class="built_in">hbDNNInitializeFromFiles</span>(&amp;packed_dnn_handle, &amp;model_file_name, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第二步获取模型名称</span></span><br><span class="line">  <span class="type">const</span> <span class="type">char</span> **model_name_list;</span><br><span class="line">  <span class="type">int</span> model_count = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">hbDNNGetModelNameList</span>(&amp;model_name_list, &amp;model_count, packed_dnn_handle);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第三步获取dnn_handle</span></span><br><span class="line">  hbDNNHandle_t dnn_handle;</span><br><span class="line">  <span class="built_in">hbDNNGetModelHandle</span>(&amp;dnn_handle, packed_dnn_handle, model_name_list[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第四步准备输入数据</span></span><br><span class="line">  hbDNNTensor input;</span><br><span class="line">  hbDNNTensorProperties input_properties;</span><br><span class="line">  <span class="built_in">hbDNNGetInputTensorProperties</span>(&amp;input_properties, dnn_handle, <span class="number">0</span>);</span><br><span class="line">  input.properties = input_properties;</span><br><span class="line">  <span class="keyword">auto</span> &amp;mem = input.sysMem[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> yuv_length = <span class="number">224</span> * <span class="number">224</span> * <span class="number">3</span> / <span class="number">2</span>;</span><br><span class="line">  <span class="built_in">hbSysAllocCachedMem</span>(&amp;mem, yuv_length);</span><br><span class="line">  <span class="comment">//memcpy(mem.virAddr, yuv_data, yuv_length);</span></span><br><span class="line">  <span class="comment">//hbSysFlushMem(&amp;mem, HB_SYS_MEM_CACHE_CLEAN);</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第五步准备模型输出数据的空间</span></span><br><span class="line">  <span class="type">int</span> output_count;</span><br><span class="line">  <span class="built_in">hbDNNGetOutputCount</span>(&amp;output_count, dnn_handle);</span><br><span class="line">  hbDNNTensor *output = <span class="keyword">new</span> hbDNNTensor[output_count];</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; output_count; i++) &#123;</span><br><span class="line">    hbDNNTensorProperties &amp;output_properties = output[i].properties;</span><br><span class="line">    <span class="built_in">hbDNNGetOutputTensorProperties</span>(&amp;output_properties, dnn_handle, i);</span><br><span class="line">    <span class="type">int</span> out_aligned_size = output_properties.alignedByteSize;</span><br><span class="line">    hbSysMem &amp;mem = output[i].sysMem[<span class="number">0</span>];</span><br><span class="line">    <span class="built_in">hbSysAllocCachedMem</span>(&amp;mem, out_aligned_size);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第六步推理模型</span></span><br><span class="line">  hbDNNTaskHandle_t task_handle = <span class="literal">nullptr</span>;</span><br><span class="line">  hbDNNInferCtrlParam infer_ctrl_param;</span><br><span class="line">  <span class="built_in">HB_DNN_INITIALIZE_INFER_CTRL_PARAM</span>(&amp;infer_ctrl_param);</span><br><span class="line">  <span class="built_in">hbDNNInfer</span>(&amp;task_handle,</span><br><span class="line">              &amp;output,</span><br><span class="line">              &amp;input,</span><br><span class="line">              dnn_handle,</span><br><span class="line">              &amp;infer_ctrl_param);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第七步等待任务结束</span></span><br><span class="line">  <span class="built_in">hbDNNWaitTaskDone</span>(task_handle, <span class="number">0</span>);</span><br><span class="line">  <span class="comment">//第八步解析模型输出，例子就获取mobilenetv1的top1分类</span></span><br><span class="line">  <span class="type">float</span> max_prob = <span class="number">-1.0</span>;</span><br><span class="line">  <span class="type">int</span> max_prob_type_id = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">hbSysFlushMem</span>(&amp;(output-&gt;sysMem[<span class="number">0</span>]), HB_SYS_MEM_CACHE_INVALIDATE);</span><br><span class="line">  <span class="type">float</span> *data = <span class="built_in">reinterpret_cast</span>&lt; <span class="type">float</span> *&gt;(output-&gt;sysMem[<span class="number">0</span>].virAddr);</span><br><span class="line">  <span class="type">int</span> *shape = output-&gt;properties.validShape.dimensionSize;</span><br><span class="line">  <span class="type">int</span> * aligned_shape = output-&gt;properties.alignedShape.dimensionSize;</span><br><span class="line">  <span class="keyword">auto</span> properties = output-&gt;properties;</span><br><span class="line">  <span class="type">int</span> offset = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (properties.tensorLayout == HB_DNN_LAYOUT_NCHW) &#123;</span><br><span class="line">    offset = aligned_shape[<span class="number">2</span>] * aligned_shape[<span class="number">3</span>];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; shape[<span class="number">1</span>] * shape[<span class="number">2</span>] * shape[<span class="number">3</span>]; i++) &#123;</span><br><span class="line">    <span class="type">float</span> score;</span><br><span class="line">    <span class="keyword">if</span> (properties.quantiType == SHIFT) &#123;</span><br><span class="line">      score = <span class="built_in">quanti_shift</span>(data[i * offset], properties.shift.shiftData[i]);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (properties.quantiType == SCALE) &#123;</span><br><span class="line">      score = <span class="built_in">quanti_scale</span>(data[i * offset], properties.scale.scaleData[i]);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (properties.quantiType == NONE)&#123;</span><br><span class="line">      score = data[i * offset];</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;quanti type error!&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(score &lt; max_prob)</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    max_prob = score;</span><br><span class="line">    max_prob_type_id = i;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;max id: &quot;</span> &lt;&lt; max_prob_type_id &lt;&lt; std::endl;</span><br><span class="line">  <span class="comment">// 释放任务</span></span><br><span class="line">  <span class="built_in">hbDNNReleaseTask</span>(task_handle);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 释放内存</span></span><br><span class="line">  <span class="built_in">hbSysFreeMem</span>(&amp;(input.sysMem[<span class="number">0</span>]));</span><br><span class="line">  <span class="built_in">hbSysFreeMem</span>(&amp;(output-&gt;sysMem[<span class="number">0</span>]));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 释放模型</span></span><br><span class="line">  <span class="built_in">hbDNNRelease</span>(packed_dnn_handle);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>示例代码中，为了缩减篇幅，对于部分数据就直接使用了已知的常数。 在实际使用过程中，您应该通过 <code>hbDNNGetInputTensorProperties/hbDNNGetOutputTensorProperties</code> 等接口获取尺寸和数据类型等信息。</p>
<p>需要您注意的是，在输入数据准备阶段，我们注释掉了一段 <code>memcpy</code> 代码。 这里应当是根据模型的输入格式要求准备输入样本，并将其拷贝到 <code>input.sysMem[0]</code> 中。</p>
<p>更加全面的工程实现指导请阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/index.html" >BPU SDK API手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</p>
<h4 id="工程编译与运行"><a href="#工程编译与运行" class="headerlink" title="工程编译与运行"></a>工程编译与运行</h4><p>结合 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/runtime_dev.html#create-your-project" >工程创建 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节中的cmake工程配置，参考如下编译脚本：</p>
<div class="highlight-container" data-rel="Cmake"><figure class="iseeu highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为arm定义gcc路径</span></span><br><span class="line">LINARO_GCC_ROOT=/opt/gcc-ubuntu-<span class="number">9.3</span>.<span class="number">0</span>-<span class="number">2020.03</span>-x86_64-aarch64-linux-gnu/</span><br><span class="line">DIR=$(cd <span class="string">&quot;$(dirname &quot;</span>$<span class="number">0</span><span class="string">&quot;)&quot;</span>;pwd)		<span class="comment">#使用cd命令将指针移到当前目录的绝对路径，保存在变量$DIR中。</span></span><br><span class="line"><span class="keyword">export</span> CC=<span class="variable">$&#123;LINARO_GCC_ROOT&#125;</span>/bin/aarch64-linux-gnu-gcc</span><br><span class="line"><span class="keyword">export</span> CXX=<span class="variable">$&#123;LINARO_GCC_ROOT&#125;</span>/bin/aarch64-linux-gnu-g++</span><br><span class="line"></span><br><span class="line">rm -rf build_arm</span><br><span class="line">mkdir build_arm</span><br><span class="line">cd build_arm</span><br><span class="line"></span><br><span class="line">cmake <span class="variable">$&#123;DIR&#125;</span></span><br><span class="line"></span><br><span class="line">make -j8		<span class="comment">#以使用8个并行任务进行构建。</span></span><br></pre></td></tr></table></figure></div>

<p>根据 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/env_install/env_deploy.html" >环境部署 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 部分的指引，您的开发机中应该已经安装有相应编译器，将上述脚本中的编译器配置指定为您的安装项目即可。</p>
<p>arm程序拷贝到地平线开发板上可运行，注意程序依赖的文件也需要一同拷贝到开发板，并在启动脚本中配置依赖。 例如我们的示例程序依赖库有： <code>libhbrt_bayes_aarch64.so、libdnn.so</code> ， 这两个依赖库在本地的位置为： <code>~/.horizon/ddk/j5_aarch64/dnn/lib/</code> ，需要将之上传到板子的运行环境中。 <strong>我们建议您在板端的 <code>/userdata</code> 路径下新建 <code>lib</code> 路径并将库传送至该目录下，则在板端运行程序前，需指定的依赖库路径信息如下：</strong></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/userdata/lib</span><br></pre></td></tr></table></figure></div>

<h4 id="多模型控制策略"><a href="#多模型控制策略" class="headerlink" title="多模型控制策略"></a>多模型控制策略</h4><p>多模型场景中，每个模型都需要使用有限的计算资源完成推理，不可避免地会出现计算资源的争夺情况。 为了便于您控制多模型的执行，地平线提供了模型优先级的控制策略供您使用。</p>
<p><strong>注意：此功能仅支持在开发板端实现，x86模拟器不支持此功能。</strong></p>
<p>J5芯片BPU计算单元硬件本身没有任务抢占功能，对于每一个推理任务，一旦它进到BPU模型计算之后，在该任务执行完成之前都会一直占用BPU， 其他任务只能排队等待。此时很容易出现BPU计算资源被一个大模型推理任务所独占，进而影响其他高优先级模型的推理任务执行。 针对这种问题，<strong>Runtime SDK基于模型的优先级通过软件的方式实现了BPU资源抢占的功能。</strong></p>
<p>其中有以下点需要被关注：</p>
<ul>
<li>编译后的数据指令模型在BPU上进行推理计算时，它将表现为1个或者多个function-call的调用，其中function-call是BPU的执行粒度， 多个function-call调用任务将在BPU的硬件队列上按序进行调度，当一个模型所有的function-call都执行完成， 那么一个模型推理任务也就执行完成了。</li>
<li>基于上述描述，BPU模型任务抢占粒度设计为function-call更为简单，即BPU执行完一个function-call之后，暂时挂起当前模型， 然后切入执行另外一个模型，当新模型执行完成之后，再恢复原来模型的状态继续运行。 但是这里存在两个问题，第一是经过编译器编译出来的模型function-call都是merge在一起，此时模型只有一个大的function-call， 它无法被被抢占；第二是每个function-call的执行时间比较长或者不固定，也会造成抢占时机不固定，影响抢占效果。</li>
</ul>
<p>为了解决上述的两个问题，地平线在模型编译和系统软件层面都给予了支持，下面分别介绍其实现原理和操作方法：</p>
<ul>
<li>首先，如果您选择使用QAT方案处理模型，则在 <strong>模型编译</strong> 阶段， 您需要在编译接口中的额外参数配置中添加 <code>max-time-per-fc</code> 选项，用于设置每个function call的执行时间（以微秒为单位）， 其默认取值为 <code>0</code> （即做不限制）。 用户可以自行设置这个选项控制上板运行阶段个别大function-call的执行时间。 假设某function-call执行时间为10ms，当模型编译时 将 <code>max-time-per-fc</code> 设置为 <code>500</code>， 则这个function-call将会被拆分成20个。 而如果您使用PTQ方案处理模型，则在 <strong>模型转换</strong> 阶段，<strong>可以在模型的YAML配置文件中的编译器相关参数( <code>compiler_parameters</code> )中，添加 <code>max_time_per_fc</code> 参数。</strong></li>
<li>其次，系统软件层面设计了 <code>BPLAT_CORELIMIT</code> 环境变量用于设置可抢占的粒度。 如将此参数设置为 <code>2</code>，则高优先级被调度执行的时间为前面2个低优先级function-call的处理时间。 如果为 <code>0</code>，则不抢占。因此，为了尽早执行高优先级的任务，可在 <strong>上板</strong> 时，先运行 <code>export BPLAT_CORELIMIT=1</code> 将此环境变量的取值设置为 <code>1</code>。 <em><strong>这样当系统底层收到模型的function-call时，会判断其优先级，对于优先级高的function-call则放入单独队列，以便能够在一个function-call 执行完成之后，抢占到BPU资源。</strong></em></li>
<li>接着，由于模型抢占机制是在libdnn中实现的，继续设置 <code>dnn</code> 的 <code>infer</code> 接口提供的 <code>hbDNNInferCtrlParam.priority</code> 参数。如：配置 <code>infer</code> 任务为 <code>HB_DNN_PRIORITY_PREEMP(255)</code>，则为抢占任务，可支持function-call级别抢占。</li>
</ul>
<h4 id="应用调优建议"><a href="#应用调优建议" class="headerlink" title="应用调优建议"></a>应用调优建议</h4><p>地平线建议的应用调优策略包括工程任务调度和算法任务整合两个方面。</p>
<p><strong>工程任务调度</strong> 方面，我们推荐您使用一些workflow调度管理工具，充分发挥不同任务阶段的并行能力。 一般AI应用可以简单拆分为输入前处理、模型推理、输出后处理三个阶段，在简易流程下，其处理流程如下图。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523141923963.png"
                      class="" title="image-20230523141923963"
                >

<p><strong>算法任务整合</strong> 方面，地平线推荐您使用<strong>多任务模型</strong>。 这样一方面可以在一定程度上避免多模型调度管理的困难； 另一方面多任务模型也能充分共享主干网络的计算量，较于使用各个独立的模型，可以在整个AI应用级别明显减少计算量，从而达到更高的整体性能。 在地平线内部和许多合作客户的业务实践中，多任务也是常见的应用级优化策略。</p>
<h4 id="其他应用开发工具"><a href="#其他应用开发工具" class="headerlink" title="其他应用开发工具"></a>其他应用开发工具</h4><ul>
<li><code>hrt_bin_dump</code> 是ptq debug模型的layer dump工具，工具的输出文件为二进制文件，工具使用方法请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/tool_introduction/source/hrt_bin_dump.html" >hrt_bin_dump工具介绍 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</li>
<li><code>hrt_model_exec</code> 是一个模型执行工具，可直接在开发板上评测模型的推理性能、获取模型信息。一方面可以让用户拿到模型时实际了解模型真实性能； 另一方面也可以帮助用户了解模型可以做到的速度极限，对于应用调优的目标极限具有指导意义。 <code>hrt_model_exec</code> 工具分别提供了模型推理 <code>infer</code> 、模型性能分析 <code>perf</code> 和查看模型信息 <code>model_info</code> 三类功能，工具使用方法请参考 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/tool_introduction/source/hrt_model_exec.html" >hrt_model_exec工具介绍 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 。</li>
</ul>
<h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><p>在 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/index.html" >BPU SDK API手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中，我们提供了BPU内存函数 <code>hbSysAllocCachedMem</code> 和 <code>hbSysAllocMem</code> 来分配BPU读写内存。 其中 <code>hbSysAllocCachedMem</code> 表示分配可以被cache的内存， 并配套了 <code>hbSysFlushMem</code> 函数来对Cache进行刷新。</p>
<p>Cache机制是由芯片BPU的Bayes内存架构来决定的，详细参考如下图所示。 CPU与主存之间存在的Cache会缓存数据，而BPU与主存之间则没有cache。 此时若错误使用Cache将会直接影响最终数据读写的准确性和效率。</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523142304073.png"
                      class="" title="image-20230523142304073"
                >

<ul>
<li>当CPU写完数据后，需要主动将Cache中的数据flush到memory中，否则BPU会读取到之前的旧数据；</li>
<li>而当BPU写完数据后，也需要主动将Cache中的数据invalidate掉，否则CPU会优先读取到之前缓存在cache中的旧数据；</li>
<li>在模型连续推理过程中，输入输出建议申请带Cache的内存，以加速CPU反复读写的效率。</li>
</ul>
<h4 id="理解BPU内存中的物理地址和虚拟地址"><a href="#理解BPU内存中的物理地址和虚拟地址" class="headerlink" title="理解BPU内存中的物理地址和虚拟地址"></a>理解BPU内存中的物理地址和虚拟地址</h4><p>在J5芯片架构中，BPU和CPU内存共享，通过 <code>hbSysAllocCachedMem</code> 和 <code>hbSysAllocMem</code> 接口可以申请到一段物理空间连续的内存， 其函数返回值被包装在 <code>hbSysMem</code> 数据结构体中， <code>phyAddr</code> 和 <code>virAddr</code> 两个字段分别对应其内存空间的物理地址和虚拟地址。 由于这段内存空间是连续的，所以物理地址和虚拟地址都可以通过首地址进行表示和读写。<strong>但是在实际使用过程中，建议优先使用虚拟地址，非必须场景请勿直接使用物理地址。</strong></p>
<h3 id="BPU-SDK-API手册"><a href="#BPU-SDK-API手册" class="headerlink" title="BPU SDK API手册"></a>BPU SDK API手册</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><p>本文档主要介绍了地平线天工开物工具链Runtime的API、数据、结构体、排布及对齐规则等。 通过阅读本文档，用户可以在Horizon开发板上利用API完成模型的加载与释放，模型信息的获取，以及模型的推理等操作。</p>
<h4 id="数据类型和数据结构"><a href="#数据类型和数据结构" class="headerlink" title="数据类型和数据结构"></a>数据类型和数据结构</h4><h5 id="版本信息类"><a href="#版本信息类" class="headerlink" title="版本信息类"></a>版本信息类</h5><p><strong>注意：本小节中的版本信息类型的版本号随版本变化有所不同，此处的版本号仅供参考，实际版本请以您获取到的发布物为准。</strong></p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> HB_DNN_VERSION_MAJOR 1U     <span class="comment">//DNN主版本号信息。</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HB_DNN_VERSION_MINOR 1U		<span class="comment">//DNN次版本号信息。</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HB_DNN_VERSION_PATCH 0U		<span class="comment">//DNN补丁版本号信息。</span></span></span><br></pre></td></tr></table></figure></div>

<h5 id="模型类"><a href="#模型类" class="headerlink" title="模型类"></a>模型类</h5><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> HB_DNN_TENSOR_MAX_DIMENSIONS 8		<span class="comment">//张量最大的维度设置为 8。</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HB_DNN_INITIALIZE_INFER_CTRL_PARAM(param) \		<span class="comment">//初始化控制参数。</span></span></span><br><span class="line">&#123;                                                 \</span><br><span class="line">    (param)-&gt;bpuCoreId = HB_BPU_CORE_ANY;         \</span><br><span class="line">    (param)-&gt;dspCoreId = HB_DSP_CORE_ANY;         \</span><br><span class="line">    (param)-&gt;priority = HB_DNN_PRIORITY_LOWEST;   \</span><br><span class="line">    (param)-&gt;more = <span class="literal">false</span>;                        \</span><br><span class="line">    (param)-&gt;customId = <span class="number">0</span>;                        \</span><br><span class="line">    (param)-&gt;reserved1 = <span class="number">0</span>;                       \</span><br><span class="line">    (param)-&gt;reserved2 = <span class="number">0</span>;                       \</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">void</span> *hbPackedDNNHandle_t;		<span class="comment">//DNN句柄，指向打包的多个模型。</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">void</span> *hbDNNHandle_t;			<span class="comment">//DNN句柄，指向单一模型。</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">void</span> *hbDNNTaskHandle_t;		<span class="comment">//任务句柄，指向一个任务。</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> &#123;							<span class="comment">//张量的排布形式。NHWC 分别代表Number、Height、Width和Channel。</span></span><br><span class="line">  HB_DNN_LAYOUT_NHWC = <span class="number">0</span>,				<span class="comment">//排布形式为 NHWC。</span></span><br><span class="line">  HB_DNN_LAYOUT_NCHW = <span class="number">2</span>,				<span class="comment">//排布形式为 NCHW。</span></span><br><span class="line">  HB_DNN_LAYOUT_NONE = <span class="number">255</span>,				<span class="comment">//没有定义排布形式。</span></span><br><span class="line">&#125; hbDNNTensorLayout;</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> &#123;							</span><br><span class="line">  HB_DNN_IMG_TYPE_Y,					<span class="comment">//	张量类型为仅有Y通道的图片。</span></span><br><span class="line">  HB_DNN_IMG_TYPE_NV12,					<span class="comment">//张量类型为一张NV12的图片。	</span></span><br><span class="line">  HB_DNN_IMG_TYPE_NV12_SEPARATE,		<span class="comment">//张量类型为Y通道及UV通道为输入的图片。</span></span><br><span class="line">  HB_DNN_IMG_TYPE_YUV444,				<span class="comment">//张量类型为YUV444为输入的图片。</span></span><br><span class="line">  HB_DNN_IMG_TYPE_RGB,					<span class="comment">//	张量类型为RGB为输入的图片</span></span><br><span class="line">  HB_DNN_IMG_TYPE_BGR,					<span class="comment">//张量类型为BGR为输入的图片。</span></span><br><span class="line">  HB_DNN_TENSOR_TYPE_S4,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_U4,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_S8,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_U8,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_F16,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_S16,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_U16,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_F32,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_S32,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_U32,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_F64,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_S64,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_U64,</span><br><span class="line">  HB_DNN_TENSOR_TYPE_MAX				<span class="comment">//代表最大的张量类型编号。</span></span><br><span class="line">&#125; hbDNNDataType;						<span class="comment">//张量的类型。</span></span><br></pre></td></tr></table></figure></div>

<p><code>S</code> 代表有符号， <code>U</code> 代表无符号， <code>F</code> 代表浮点型，后面的数字代表bit数。</p>
<p><code>HB_DNN_IMG_TYPE_NV12</code> 与 <code>HB_DNN_IMG_TYPE_NV12_SEPARATE</code> 都代表NV12的数据，只是在存储上有差异。</p>
<p>推理NV12输入的模型时，用户可根据实际情况更改张量的 <code>tensorType</code> 属性为 <code>HB_DNN_IMG_TYPE_NV12</code> 或 <code>HB_DNN_IMG_TYPE_NV12_SEPARATE</code>。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="type">int32_t</span> dimensionSize[HB_DNN_TENSOR_MAX_DIMENSIONS];			<span class="comment">//张量每个维度的大小。</span></span><br><span class="line">  <span class="type">int32_t</span> numDimensions;				<span class="comment">//张量的维度。</span></span><br><span class="line">&#125; hbDNNTensorShape;</span><br><span class="line"><span class="comment">//例如一张224x224的bgr彩色空间的图片 numDimensions=4，若排布形式为NHWC， 则 dimensionSize 数组中按顺序存储图片 Number=1、 Height=224、 Width=224、 Channel=3。</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="type">int32_t</span> shiftLen;			<span class="comment">//移位数据的长度。</span></span><br><span class="line">  <span class="type">uint8_t</span> *shiftData;		<span class="comment">//移位数据的首地址。</span></span><br><span class="line">&#125; hbDNNQuantiShift;  <span class="comment">//量化/反量化的移位数据。</span></span><br></pre></td></tr></table></figure></div>

<p><strong>对于输入</strong> ：若采集到浮点数据 <code>data[i]</code>, 对应的移位数据是 <code>shift[i]</code>， 则送入模型的推理数据为: <img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523145446009.png"
                      class="" title="image-20230523145446009"
                >取整；</p>
<p><strong>对于输出</strong> ：若推理结果 <code>data[i]</code>, 对应的移位数据是 <code>shift[i]</code>， 则最终的推理结果为：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523145458269.png"
                      class="" title="image-20230523145458269"
                >。</p>
<p>其中 <code>shiftLen</code> 由数据 <code>data</code> 按照 <code>per-axis</code> 或 <code>per-tensor</code> （反）量化方式决定。 当数据 <code>data</code> 按 <code>per-tensor</code> （反）量化时， <code>shiftLen</code> 等于 <code>1</code>，此时不需要关注 <code>quantizeAxis</code> 数值； 否则等于数据 <code>data</code> 的第 <code>quantizeAxis</code> 维度大小。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="type">int32_t</span> scaleLen;			<span class="comment">//缩放数据的长度。</span></span><br><span class="line">  <span class="type">float</span> *scaleData;			<span class="comment">//缩放数据的首地址。</span></span><br><span class="line">  <span class="type">int32_t</span> zeroPointLen;		<span class="comment">//零点偏移数据的长度。</span></span><br><span class="line">  <span class="type">int8_t</span> *zeroPointData;	<span class="comment">//零点偏移数据的首地址。</span></span><br><span class="line">&#125; hbDNNQuantiScale;		<span class="comment">//量化/反量化的缩放数据。</span></span><br></pre></td></tr></table></figure></div>

<p><strong>对于输入</strong> ：若采集到浮点数据 <code>data[i]</code>, 对应的缩放数据是 <code>scale[i]</code>， 零点偏移数据是 <code>zeroPoint[i]</code>，则送入模型的推理数据为: <img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/J5/image-20230523145847126.png"
                      alt="image-20230523145847126"
                >, 其中：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/J5/image-20230523145906154.png"
                      alt="image-20230523145906154"
                >, 使用fesetround(FE_TONEAREST)舍入方法, 截断到：<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/J5/image-20230523145919210.png"
                      alt="image-20230523145919210"
                ></p>
<p><strong>对于输出</strong> ：若推理结果 <code>data[i]</code>, 对应的缩放数据是 <code>scale[i]</code>， 零点偏移数据是 <code>zeroPoint[i]</code>，则最终的推理结果为： <img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523145932256.png"
                      class="" title="image-20230523145932256"
                >。</p>
<p>其中 <code>scaleLen</code> 由数据 <code>data</code> 按照 <code>per-axis</code> 或 <code>per-tensor</code> （反）量化方式决定。 当数据 <code>data</code> 按 <code>per-tensor</code> （反）量化时， <code>scaleLen</code> 等于 <code>1</code>，此时不需要关注 <code>quantizeAxis</code> 数值； 否则等于数据 <code>data</code> 第 <code>quantizeAxis</code> 维度大小。 <code>zeroPointLen</code> 与 <code>scaleLen</code> 保持一致。</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> &#123;</span><br><span class="line">  NONE,					<span class="comment">//NONE 代表不需要对数据做任何处理；</span></span><br><span class="line">  SHIFT,				<span class="comment">//SHIFT 类型对应的量化/反量化参数存储在 hbDNNQuantiShift 结构体中；</span></span><br><span class="line">  SCALE,				<span class="comment">//SCALE 对应的量化/反量化参数存储在 hbDNNQuantiScale 结构体中。</span></span><br><span class="line">&#125; hbDNNQuantiType;		<span class="comment">//定点浮点转换的量化/反量化类型。</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">  hbDNNTensorShape validShape;			<span class="comment">//张量有效内容的形状。</span></span><br><span class="line">  hbDNNTensorShape alignedShape;		<span class="comment">//张量对齐内容的形状。</span></span><br><span class="line">  <span class="type">int32_t</span> tensorLayout;					<span class="comment">//张量的排布形式</span></span><br><span class="line">  <span class="type">int32_t</span> tensorType;					<span class="comment">//张量的类型</span></span><br><span class="line">  hbDNNQuantiShift shift;				<span class="comment">//量化偏移量。</span></span><br><span class="line">  hbDNNQuantiScale scale;				<span class="comment">//量化缩放量。</span></span><br><span class="line">  hbDNNQuantiType quantiType;			<span class="comment">//量化类型。</span></span><br><span class="line">  <span class="type">int32_t</span> quantizeAxis;					<span class="comment">//量化通道，仅按per-axis量化时生效。</span></span><br><span class="line">  <span class="type">int32_t</span> alignedByteSize;				<span class="comment">//张量对齐内容的内存大小。</span></span><br><span class="line">  <span class="type">int32_t</span> stride[HB_DNN_TENSOR_MAX_DIMENSIONS];		<span class="comment">//张量中validShape各维度步长。</span></span><br><span class="line">&#125; hbDNNTensorProperties;				<span class="comment">//张量的信息。</span></span><br></pre></td></tr></table></figure></div>





<h4 id="API接口"><a href="#API接口" class="headerlink" title="API接口"></a>API接口</h4><blockquote>
<p><strong>DNN句柄指针是指一个指针变量，它可以用于访问在神经网络推理过程中的各个阶段创建的数据结构。</strong>这些数据结构通常由启动器（launcher）和运行时（runtime）组成，通过DNN句柄指针可以在启动器和运行时之间共享数据。DNN句柄指针通常被用于：</p>
<ol>
<li>神经网络模型的初始化：DNN句柄指针可以用于初始化神经网络的模型，包括网络中的各种层和节点，以及与各种硬件的连接；</li>
<li>神经网络模型的配置：DNN句柄指针可以用于配置神经网络，包括设置模型的输入和输出尺寸、数据类型及处理方法；</li>
<li>神经网络推理的执行：DNN句柄指针可以用于在运行时中执行神经网络推理操作，包括加载模型、进行推理计算和获取计算结果。</li>
</ol>
</blockquote>
<h6 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h6><blockquote>
<p>hbDNNGetVersion()</p>
</blockquote>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">const</span> <span class="type">char</span> *<span class="title">hbDNNGetVersion</span><span class="params">()</span></span>;		<span class="comment">//获取 `DNN` 预测库版本信息。</span></span><br></pre></td></tr></table></figure></div>



<h6 id="模型加载-x2F-释放"><a href="#模型加载-x2F-释放" class="headerlink" title="模型加载&#x2F;释放"></a>模型加载&#x2F;释放</h6><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNInitializeFromFiles</span><span class="params">(hbPackedDNNHandle_t *packedDNNHandle,		<span class="comment">//从文件完成对 packedDNNHandle 的创建和初始化。调用方可以跨函数、跨线程使用返回的 packedDNNHandle。		[out] packedDNNHandle Horizon DNN句柄，指向多个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">const</span> <span class="type">char</span> **modelFileNames,		<span class="comment">//[in] modelFileNames 模型文件的路径。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">int32_t</span> modelFileCount)</span></span>;			<span class="comment">//[in] modelFileCount 模型文件的个数。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNInitializeFromDDR</span><span class="params">(hbPackedDNNHandle_t *packedDNNHandle,	<span class="comment">//从内存完成对 packedDNNHandle 的创建和初始化。调用方可以跨函数、跨线程使用返回的 packedDNNHandle。	[out] packedDNNHandle Horizon DNN句柄，指向多个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                               <span class="type">const</span> <span class="type">void</span> **modelData,			<span class="comment">//[in] modelData 模型文件的指针。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                               <span class="type">int32_t</span> *modelDataLengths,		<span class="comment">//[in] modelDataLengths 模型数据的长度。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                               <span class="type">int32_t</span> modelDataCount)</span></span>;			<span class="comment">//[in] modelDataCount 模型数据的个数。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNRelease</span><span class="params">(hbPackedDNNHandle_t packedDNNHandle)</span></span>;		<span class="comment">//将 packedDNNHandle 所指向的模型释放。	[in] packedDNNHandle Horizon DNN句柄，指向多个模型。</span></span><br></pre></td></tr></table></figure></div>



<blockquote>
<p>模型信息</p>
</blockquote>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetModelNameList</span><span class="params">(<span class="type">const</span> <span class="type">char</span> ***modelNameList,			<span class="comment">//获取 packedDNNHandle 所指向模型的名称列表和个数。		[out] modelNameList 模型名称列表。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">int32_t</span> *modelNameCount,				<span class="comment">//[out] modelNameCount 模型名称个数。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                              hbPackedDNNHandle_t packedDNNHandle)</span></span>;		<span class="comment">//[in] packedDNNHandle Horizon DNN句柄，指向多个模型。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetModelHandle</span><span class="params">(hbDNNHandle_t *dnnHandle,			<span class="comment">//从 packedDNNHandle 所指向模型列表中获取一个模型的句柄。调用方可以跨函数、跨线程使用返回的 dnnHandle。	[out] dnnHandle DNN句柄，指向一个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                            hbPackedDNNHandle_t packedDNNHandle,		<span class="comment">//[in] packedDNNHandle DNN句柄，指向多个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> <span class="type">char</span> *modelName)</span></span>;		<span class="comment">//[in] modelName 模型名称。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetInputCount</span><span class="params">(<span class="type">int32_t</span> *inputCount,			<span class="comment">//获取 dnnHandle 所指向模型输入张量的个数。 [out] inputCount 模型输入张量的个数。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                           hbDNNHandle_t dnnHandle)</span></span>;	<span class="comment">//[in] dnnHandle DNN句柄，指向一个模型。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetInputName</span><span class="params">(<span class="type">const</span> <span class="type">char</span> **name,			<span class="comment">//获取 dnnHandle 所指向模型输入张量的名称。 [out] name 模型输入张量的名称。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                          hbDNNHandle_t dnnHandle,		<span class="comment">//[in] dnnHandle DNN句柄，指向一个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                          <span class="type">int32_t</span> inputIndex)</span></span>;			<span class="comment">//[in] inputIndex 模型输入张量的编号。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetInputTensorProperties</span><span class="params">(hbDNNTensorProperties *properties,		<span class="comment">//获取 dnnHandle 所指向模型特定输入张量的属性。 [out] properties 输入张量的信息。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                      hbDNNHandle_t dnnHandle,	<span class="comment">//[in] dnnHandle DNN句柄，指向一个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                      <span class="type">int32_t</span> inputIndex)</span></span>;		<span class="comment">//[in] inputIndex 模型输入张量的编号。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetOutputCount</span><span class="params">(<span class="type">int32_t</span> *outputCount,		<span class="comment">//获取 dnnHandle 所指向模型输出张量的个数。[out] outputCount 模型输出张量的个数。	</span></span></span></span><br><span class="line"><span class="params"><span class="function">                            hbDNNHandle_t dnnHandle)</span></span>;		<span class="comment">//[in] dnnHandle DNN句柄，指向一个模型。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetOutputName</span><span class="params">(<span class="type">const</span> <span class="type">char</span> **name,		<span class="comment">//获取 dnnHandle 所指向模型输出张量的名称。 [out] name 模型输出张量的名称。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                           hbDNNHandle_t dnnHandle,		<span class="comment">//[in] dnnHandle DNN句柄，指向一个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">int32_t</span> outputIndex)</span></span>;		<span class="comment">//[in] outputIndex 模型输出张量的编号。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNGetOutputTensorProperties</span><span class="params">(hbDNNTensorProperties *properties,		<span class="comment">//获取 dnnHandle 所指向模型特定输出张量的属性。[out] properties 输出张量的信息。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                       hbDNNHandle_t dnnHandle,	<span class="comment">//[in] dnnHandle DNN句柄，指向一个模型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                       <span class="type">int32_t</span> outputIndex)</span></span>;		<span class="comment">//[in] outputIndex 模型输出张量的编号。</span></span><br></pre></td></tr></table></figure></div>



<h6 id="模型推理"><a href="#模型推理" class="headerlink" title="模型推理"></a>模型推理</h6><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNInfer</span><span class="params">(hbDNNTaskHandle_t *taskHandle,	<span class="comment">//根据输入参数执行推理任务。调用方可以跨函数、跨线程使用返回的 taskHandle。[out] taskHandle 任务句柄指针。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                   hbDNNTensor **output,	<span class="comment">//[in/out] output 推理任务的输出。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> hbDNNTensor *input,	<span class="comment">//[in] input 推理任务的输入。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                   hbDNNHandle_t dnnHandle,		<span class="comment">//[in] dnnHandle DNN句柄指针。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                   hbDNNInferCtrlParam *inferCtrlParam)</span></span>;		<span class="comment">//[in] inferCtrlParam 控制推理任务的参数。</span></span><br></pre></td></tr></table></figure></div>

<p>注意：</p>
<blockquote>
<p>使用该接口提交任务时应提前将 <code>taskHandle</code> 置为 <code>nullptr</code>，除非是给指定 <code>taskHandle</code> 追加任务（即使用 <code>inferCtrlParam::more</code> 功能）。</p>
<p>最多支持同时存在32个模型任务。</p>
<p>对于batch模型，允许分开设置输入张量的内存地址。例如：模型的输入validShape&#x2F;alignedShape为[4, 3, 224, 224], 可以申请四个hbDNNTensor， 每个hbDNNTensor的validShape&#x2F;alignedShape都设置为[1, 3, 224, 224],存放每个batch的数据。当模型有多个输入时， <code>input</code> 的顺序应为input0[batch0], input0[batch1], …, inputn[batch0], inputn[batch1], …。</p>
</blockquote>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//根据输入参数执行ROI推理任务。调用方可以跨函数、跨线程使用返回的 taskHandle。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNRoiInfer</span><span class="params">(hbDNNTaskHandle_t *taskHandle,		<span class="comment">//[out] taskHandle 任务句柄指针。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                      hbDNNTensor **output,					<span class="comment">//[in/out] output 推理任务的输出。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> hbDNNTensor *input,				<span class="comment">//[in] input 推理任务的输入。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                      hbDNNRoi *rois,						<span class="comment">//[in] rois Roi框信息。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">int32_t</span> roiCount,						<span class="comment">//[in] roiCount Roi框数量。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                      hbDNNHandle_t dnnHandle,				<span class="comment">//[in] dnnHandle dnn句柄指针。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                      hbDNNInferCtrlParam *inferCtrlParam)</span></span>;		<span class="comment">//[in] inferCtrlParam 控制推理任务的参数。</span></span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>该接口支持批处理操作，假设需要推理的数据批数为 <code>batch</code>，模型输入个数为 <code>input_count</code>，其中resizer输入源的数量为 <code>resizer_count</code>。</p>
<p>准备输入参数 <code>input</code>：第i个 <code>batch</code> 对应的 <code>input</code> 数组下标范围是<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523154854692.png"
                      class="" title="image-20230523154854692"
                ></p>
<p>准备输入参数 <code>rois</code>：每个resizer输入源的输入都应匹配一个roi，第i个 <code>batch</code> 对应的 <code>rois</code> 数组下标范围是 <img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/J5/image-20230523154924792.png"
                      alt="image-20230523154924792"
                ><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/J5/image-20230523154943236.png"
                      alt="image-20230523154943236"
                >; 每个batch的roi顺序应和输入的顺序保持一致；</p>
<p>关于 <code>batch</code> 数量限制：其范围应该在[1, 255];</p>
<p>使用该接口提交任务时应提前将 <code>taskHandle</code> 置为 <code>nullptr</code>，除非是给指定 <code>taskHandle</code> 追加任务（即使用 <code>inferCtrlParam::more</code> 功能）。</p>
<p>最多支持同时存在32个模型任务。</p>
</blockquote>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//等待任务完成或超时。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNWaitTaskDone</span><span class="params">(hbDNNTaskHandle_t taskHandle,		<span class="comment">//[in] taskHandle 任务句柄指针。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                          <span class="type">int32_t</span> timeout)</span></span>;					<span class="comment">//[in] timeout 超时配置（单位：毫秒）。timeout &gt; 0 表示等待时间；timeout &lt;= 0 表示一直等待，直到任务完成。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//释放任务，如果任务未执行则会直接取消并释放任务，如果已经执行则会在运行到某些节点后取消并释放任务。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNReleaseTask</span><span class="params">(hbDNNTaskHandle_t taskHandle)</span></span>;		<span class="comment">//[in] taskHandle 任务句柄指针。</span></span><br></pre></td></tr></table></figure></div>



<h6 id="内存操作"><a href="#内存操作" class="headerlink" title="内存操作"></a>内存操作</h6><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//申请BPU内存。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbSysAllocMem</span><span class="params">(hbSysMem *mem, <span class="type">uint32_t</span> size)</span></span>;		<span class="comment">//[in] size 申请内存的大小。[out] mem 内存指针。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//申请缓存的BPU内存。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbSysAllocCachedMem</span><span class="params">(hbSysMem *mem, <span class="type">uint32_t</span> size)</span></span>;		<span class="comment">//[in] size 申请内存的大小。[out] mem 内存指针。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//对缓存的BPU内存进行刷新。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbSysFlushMem</span><span class="params">(hbSysMem *mem, <span class="type">int32_t</span> flag)</span></span>;		<span class="comment">//[in] mem 内存指针。[in] flag 刷新标志符。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//释放BPU内存。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbSysFreeMem</span><span class="params">(hbSysMem *mem)</span></span>;		<span class="comment">//[in] mem 内存指针。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//写入BPU内存。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbSysWriteMem</span><span class="params">(hbSysMem *dest, <span class="type">char</span> *src, <span class="type">uint32_t</span> size)</span></span>;		<span class="comment">//[out] dest 内存指针。[in] src 数据指针。[in] size 数据大小。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//读取BPU内存。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbSysReadMem</span><span class="params">(<span class="type">char</span> *dest, hbSysMem *src, <span class="type">uint32_t</span> size)</span></span>;		<span class="comment">//[out] dest 数据指针。[in] src 内存指针。[in] size 数据大小。</span></span><br></pre></td></tr></table></figure></div>



<h6 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h6><div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//注册Layer创建方法。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNRegisterLayerCreator</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *layerType,		<span class="comment">//[in] layerType Layer类型。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                                  hbDNNLayerCreator layerCreator)</span></span>;		<span class="comment">//[in] layerCreator Layer创建方法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//注销Layer。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNUnregisterLayerCreator</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *layerType)</span></span>;		<span class="comment">//[in] layerType Layer类型。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//注册一个任务完成后需要执行的回调函数。</span></span><br><span class="line"><span class="function"><span class="type">int32_t</span> <span class="title">hbDNNSetTaskDoneCb</span><span class="params">(hbDNNTaskHandle_t taskHandle, hbDNNTaskDoneCb cb,		<span class="comment">//[in] taskHandle 任务句柄指针。[in] cb 回调函数指针。[in] userData 用户自定义的数据。</span></span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">void</span> *userdata)</span></span>;</span><br></pre></td></tr></table></figure></div>

<p><strong>该接口可以注册一个回调函数，任务执行完成后会调用这个回调函数去执行用户自定义的功能。</strong></p>
<h4 id="数据排布及对齐规则"><a href="#数据排布及对齐规则" class="headerlink" title="数据排布及对齐规则"></a>数据排布及对齐规则</h4><h5 id="数据排布"><a href="#数据排布" class="headerlink" title="数据排布"></a>数据排布</h5><p><strong>硬件内部为了提高计算效率，其数据使用特殊的排布方式以使得卷积运算中同一批次乘加用到的feature map和kernel在内存中相邻排放。</strong> 下面简要介绍J5中数据排布（layout）的概念。</p>
<p>神经网络模型中的变量可以用一个4维的张量表示，每个数字是这个张量中的元素，我们称之为自然排布。 将不同维度的不同元素按一定规则紧密排列在一起，形成一个独立的小块（block），然后将这些小块看成新的元素，组成新的4维张量， 我们称之为带有数据排布的张量。</p>
<p>输入输出数据会用到不同的layout数据排布，用户可通过API获取layout描述信息，<strong>不同的layout数据不可以直接比较。</strong></p>
<p><strong>需要注意的是，在进行数据排布转换时，如果需要padding，则padding的值建议设置为零。</strong></p>
<p>此处介绍两种数据排布： <code>NHWC_NATIVE</code> 和 <code>NCHW_NATIVE</code> ，以 <code>NHWC_NATIVE</code> 为例，其数据排布如下：</p>
<table>
<thead>
<tr>
<th>N0H0W0C0</th>
<th>N0H0W0C1</th>
<th>……</th>
</tr>
</thead>
<tbody><tr>
<td>N0H0W1C0</td>
<td>N0H0W1C1</td>
<td>……</td>
</tr>
<tr>
<td>……</td>
<td>……</td>
<td>……</td>
</tr>
<tr>
<td>N0H1W0C0</td>
<td>N0H1W0C1</td>
<td>……</td>
</tr>
<tr>
<td>……</td>
<td>……</td>
<td>……</td>
</tr>
<tr>
<td>N1H0W0C0</td>
<td>N1H0W0C1</td>
<td>……</td>
</tr>
<tr>
<td>……</td>
<td>……</td>
<td>……</td>
</tr>
</tbody></table>
<p>一个N<em>H</em>W*C大小的张量可用如下4重循环表示：</p>
<div class="highlight-container" data-rel="C++"><figure class="iseeu highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int32_t</span> n = <span class="number">0</span>; n &lt; N; n++) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int32_t</span> h = <span class="number">0</span>; h &lt; H; h++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int32_t</span> w = <span class="number">0</span>; w &lt; W; w++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int32_t</span> c = <span class="number">0</span>; c &lt; C; c++) &#123;</span><br><span class="line">                <span class="type">int32_t</span> native_offset = n*H*W*C + h*W*C + w*C + c;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>其中 <code>NCHW_NATIVE</code> 和 <code>NHWC_NATIVE</code> 相比，只是排布循环顺序不一样，此处不再单独列出。</p>
<p><strong>下文中提到的native都特指该layout（NHWC）。</strong></p>
<h5 id="BPU对齐限制规则"><a href="#BPU对齐限制规则" class="headerlink" title="BPU对齐限制规则"></a>BPU对齐限制规则</h5><blockquote>
<p>模型输入要求</p>
</blockquote>
<p>BPU不限制模型输入大小或者奇偶。既像YOLO这种416x416的输入可以支持，对于像SqueezeNet这种227x227的输入也可以支持。 <strong>对于NV12输入比较特别，要求HW都是偶数，是为了满足UV是Y的一半的要求。</strong></p>
<blockquote>
<p>对齐和有效数据</p>
</blockquote>
<p>BPU对数据有对齐限制。对齐要求和真实的数据排布用 <code>hbDNNTensorProperties</code> 中的 <code>validShape</code> , <code>alignedShape</code> 和 <code>stride</code> 表示。</p>
<ul>
<li><code>validShape</code> 是有效的shape；</li>
<li><code>alignedShape</code> 是满足对齐要求的shape, 由于硬件特性， <code>alignedShape</code> 均由四维数据表示；</li>
<li><code>stride</code> 表示 <code>validShape</code> 各维度的步长，其中，NV12输入的模型比较特殊，其 <code>stride</code> 均为0，因为NV12输入的模型只要求W 16对齐。</li>
</ul>
<p><strong>目前四维模型的张量可以通过 <code>validShape</code> 和 <code>alignedShape</code> 获取正确的数据排布，大于四维模型的张量可以通过 <code>validShape</code> 和 <code>stride</code> 获取正确的数据排布。</strong></p>
<p>在后续场景使用时，考虑到对齐要求，建议按照 <code>alignedByteSize</code> 大小来申请内存空间。</p>
<h5 id="NV12介绍"><a href="#NV12介绍" class="headerlink" title="NV12介绍"></a>NV12介绍</h5><blockquote>
<p>YUV格式</p>
</blockquote>
<p><strong>YUV格式主要用于优化彩色视频信号的传输。</strong></p>
<p>YUV分为三个分量：Y表示明亮度，也就是灰度值；而U和V表示的则是色度，作用是描述影像色彩及饱和度，用于指定像素的颜色。</p>
<blockquote>
<p>NV12排布</p>
</blockquote>
<p>NV12图像格式属于YUV颜色空间中的YUV420SP格式，<strong>每四个Y分量共用一组U分量和V分量，Y连续排序，U与V交叉排序。</strong></p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/2023/04/13/J5/image-20230523161450735.png"
                      class="" title="image-20230523161450735"
                >



<h4 id="错误码"><a href="#错误码" class="headerlink" title="错误码"></a>错误码</h4><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">HB_DNN_SUCCESS = 0                   // 执行成功</span><br><span class="line">HB_DNN_INVALID_ARGUMENT              // 非法参数</span><br><span class="line">HB_DNN_INVALID_MODEL                 // 非法模型</span><br><span class="line">HB_DNN_MODEL_NUMBER_EXCEED_LIMIT     // 模型个数超过限制</span><br><span class="line">HB_DNN_INVALID_PACKED_DNN_HANDLE     // 非法packed handle</span><br><span class="line">HB_DNN_INVALID_DNN_HANDLE            // 非法handle</span><br><span class="line">HB_DNN_CAN_NOT_OPEN_FILE             // 文件不存在</span><br><span class="line">HB_DNN_OUT_OF_MEMORY                 // 没有足够的内存</span><br><span class="line">HB_DNN_TIMEOUT                       // 超时</span><br><span class="line">HB_DNN_TASK_NUM_EXCEED_LIMIT         // 任务数量超限制</span><br><span class="line">HB_DNN_TASK_BATCH_SIZE_EXCEED_LIMIT  // 多任务处理数量超限制</span><br><span class="line">HB_DNN_INVALID_TASK_HANDLE           // 非法task handle</span><br><span class="line">HB_DNN_RUN_TASK_FAILED               // 任务执行失败</span><br><span class="line">HB_DNN_MODEL_IS_RUNNING              // 任务执行中</span><br><span class="line">HB_DNN_INCOMPATIBLE_MODEL            // 不兼容的模型</span><br><span class="line">HB_DNN_API_USE_ERROR                 // 接口使用错误</span><br><span class="line"></span><br><span class="line">HB_SYS_SUCCESS                       // 执行成功</span><br><span class="line">HB_SYS_INVALID_ARGUMENT              // 非法参数</span><br><span class="line">HB_SYS_OUT_OF_MEMORY                 // 没有足够的内存</span><br><span class="line">HB_SYS_REGISTER_MEM_FAILED           // 注册内存失败</span><br></pre></td></tr></table></figure></div>



<h4 id="配置信息"><a href="#配置信息" class="headerlink" title="配置信息"></a>配置信息</h4><h5 id="常用环境变量"><a href="#常用环境变量" class="headerlink" title="常用环境变量"></a>常用环境变量</h5><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">HB_DNN_LOG_LEVEL                // 设置日志等级。</span><br><span class="line">HB_DNN_CONV_MAP_PATH            // 模型卷积层配置文件路径；编译参数layer_out_dump为true时产生的json文件。</span><br><span class="line">HB_DNN_DUMP_PATH                // 模型卷积层结果输出路径，与HB_DNN_CONV_MAP_PATH配合使用。</span><br><span class="line">HB_DNN_PLUGIN_PATH              // 自定义CPU算子动态链接库所在目录。</span><br><span class="line">HB_DNN_PROFILER_LOG_PATH        // 模型运行各阶段耗时统计信息dump路径。</span><br><span class="line">HB_DNN_SIM_PLATFORM             // x86模拟器模拟平台设置。</span><br><span class="line">HB_DNN_SIM_BPU_MEM_SIZE         // x86模拟器设置BPU内存大小，单位MB。</span><br><span class="line">HB_DNN_ENABLE_DSP               // 使能DSP模块，仅J5可用。</span><br></pre></td></tr></table></figure></div>



<h5 id="日志等级设置说明"><a href="#日志等级设置说明" class="headerlink" title="日志等级设置说明"></a>日志等级设置说明</h5><ol>
<li>日志等级。 <code>dnn</code> 中的日志主要分为4个等级：<ul>
<li><code>HB_DNN_LOG_NONE = 0</code>，不输出日志；</li>
<li><code>HB_DNN_LOG_WARNING = 3</code>，该等级主要用来输出代码中的告警信息；</li>
<li><code>HB_DNN_LOG_ERROR = 4</code>，该等级主要用来输出代码中的报错信息；</li>
<li><code>HB_DNN_LOG_FATAL = 5</code>，该等级主要用来输出代码中的导致退出的错误信息。</li>
</ul>
</li>
<li>日志等级设置规则：<ul>
<li>若发生的LOG等级 &gt;&#x3D; 设置的等级，则该LOG可以被打印，反之被屏蔽；</li>
<li>设置的LOG等级越小，打印信息越多（等级0除外，0不输出日志）。 例如：设置LOG等级为3，即为 <code>WARNING</code> 级别，则3,4,5等级的LOG均可以被打印； 预测库默认LOG等级为 <code>HB_DNN_LOG_WARNING</code> ，则以下LOG级别的信息可以被打印： <code>WARNING</code> 、 <code>ERROR</code> 、 <code>FATAL</code>。</li>
</ul>
</li>
</ol>
<h5 id="x86模拟器模拟平台配置说明"><a href="#x86模拟器模拟平台配置说明" class="headerlink" title="x86模拟器模拟平台配置说明"></a>x86模拟器模拟平台配置说明</h5><ol>
<li>x86模拟器通过设置不同的选项模拟地平线不同的芯片架构，其中：<ul>
<li><code>export HB_DNN_SIM_PLATFORM=BERNOULLI</code> ，表示模拟地平线 <code>xj2</code> 平台；</li>
<li><code>export HB_DNN_SIM_PLATFORM=BERNOULLI2</code> ，表示模拟地平线 <code>xj3</code> 平台；</li>
<li><code>export HB_DNN_SIM_PLATFORM=BAYES</code> ，表示模拟地平线 <code>j5</code> 平台。</li>
</ul>
</li>
<li>如果不设置 <code>HB_DNN_SIM_PLATFORM</code> 环境变量，会根据第一次加载的模型架构来设置模拟器平台，例如：第一次加载的模型是 <code>BAYES</code> 架构，则程序默认设置的平台为 <code>j5</code>。</li>
</ol>
<h3 id="基础示例包使用说明"><a href="#基础示例包使用说明" class="headerlink" title="基础示例包使用说明"></a>基础示例包使用说明</h3><p>基础示例包主要提供了三个方面的示例：</p>
<ol>
<li><code>dnn</code> API教学示例。</li>
<li>自定义算子（custom OP）等特殊功能示例。</li>
<li>非NV12输入模型的杂项示例。</li>
</ol>
<p>开发者可以体验并基于这些示例进行应用开发，降低开发门槛。</p>
<p>交付物主要包括以下内容：</p>
<table>
<thead>
<tr>
<th align="left">名称</th>
<th align="left">内容</th>
</tr>
</thead>
<tbody><tr>
<td align="left">horizon_runtime_sample</td>
<td align="left">包含示例源代码和运行脚本。</td>
</tr>
</tbody></table>
<h4 id="示例包代码包"><a href="#示例包代码包" class="headerlink" title="示例包代码包"></a>示例包代码包</h4><p>注意：上板模型需要先在OE包的 <code>ddk/samples/ai_toolchain/model_zoo/runtime/horizon_runtime_sample</code> 目录下执行 <code>resolve_runtime_sample.sh</code> 脚本进行获取。</p>
<p>示例包结构如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">+---horizon_runtime_sample</span><br><span class="line">├── code                        # 示例源码</span><br><span class="line">│   ├── 00_quick_start          # 快速入门示例，用mobilenetv1读取单张图片进行推理的示例代码</span><br><span class="line">│   │   ├── CMakeLists.txt</span><br><span class="line">│   │   ├── CMakeLists_x86.txt</span><br><span class="line">│   │   └── src</span><br><span class="line">│   ├── 01_api_tutorial         # BPU SDK API使用示例代码</span><br><span class="line">│   │   ├── CMakeLists.txt</span><br><span class="line">│   │   ├── mem</span><br><span class="line">│   │   ├── model</span><br><span class="line">│   │   ├── roi_infer</span><br><span class="line">│   │   └── tensor</span><br><span class="line">│   ├── 02_advanced_samples     # 特殊功能示例</span><br><span class="line">│   │   ├── CMakeLists.txt</span><br><span class="line">│   │   ├── custom_identity</span><br><span class="line">│   │   ├── multi_input</span><br><span class="line">│   │   ├── multi_model_batch</span><br><span class="line">│   │   └── nv12_batch</span><br><span class="line">│   ├── 03_misc                 # 杂项示例</span><br><span class="line">│   │   ├── CMakeLists.txt</span><br><span class="line">│   │   ├── lenet_gray</span><br><span class="line">│   │   └── resnet_feature</span><br><span class="line">│   ├── build_j5.sh             # 编译脚本</span><br><span class="line">│   ├── build_x86.sh            # x86仿真平台编译脚本</span><br><span class="line">│   ├── CMakeLists.txt</span><br><span class="line">│   ├── CMakeLists_x86.txt</span><br><span class="line">│   └── deps_gcc9.3             # 编译依赖库</span><br><span class="line">│       ├── aarch64</span><br><span class="line">│       └── x86</span><br><span class="line">├── j5</span><br><span class="line">│   ├── data                    # 预置数据文件</span><br><span class="line">│   │   ├── cls_images</span><br><span class="line">│   │   ├── det_images</span><br><span class="line">│   │   ├── misc_data</span><br><span class="line">│   │   ├── custom_identity_data</span><br><span class="line">│   ├── model</span><br><span class="line">│   │   ├── README.md</span><br><span class="line">│   │   └── runtime -&gt; ../../../model_zoo/runtime/horizon_runtime_sample   # 软链接指向OE包中的模型，板端运行环境需要自行指定模型路径</span><br><span class="line">│   └── script                  # aarch64示例运行脚本</span><br><span class="line">│   │   ├── 00_quick_start</span><br><span class="line">│   │   ├── 01_api_tutorial</span><br><span class="line">│   │   ├── 02_advanced_samples</span><br><span class="line">│   │   ├── 03_misc</span><br><span class="line">│   │   ├── aarch64             # 编译产生aarch64可执行程序及依赖库</span><br><span class="line">│   │   └── README.md</span><br><span class="line">│   └── script_x86              # x86示例运行脚本</span><br><span class="line">│       ├── 00_quick_start</span><br><span class="line">│       ├── x86                 # 编译产生x86可执行程序及依赖库</span><br><span class="line">│       └── README.md</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure></div>



<h4 id="环境搭建-1"><a href="#环境搭建-1" class="headerlink" title="环境搭建"></a>环境搭建</h4><h5 id="开发板准备"><a href="#开发板准备" class="headerlink" title="开发板准备"></a>开发板准备</h5><p>1.拿到开发板后，按照 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/hardware/system_image.html" >系统镜像升级 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的说明，升级系统镜像到示例包推荐的系统镜像版本。</p>
<p>2.确保本地开发机和开发板可以远程连接。</p>
<h5 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h5><p>编译需要的步骤如下：</p>
<p>1.当前环境安装好交叉编译工具gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu。</p>
<p>2.然后执行 <strong>horizon_runtime_sample&#x2F;code</strong> 目录下的build_j5.sh脚本即可一键编译真机环境下的可执行程序，可执行程序和对应依赖会自动复制到 <strong>j5&#x2F;script</strong> 目录下的 <strong>aarch64</strong> 目录下。</p>
<p>x86仿真环境下使用 <strong>horizon_runtime_sample&#x2F;code</strong> 目录下的build_x86.sh脚本即可一键编译x86环境下的可执行程序，可执行 程序和对应依赖会自动复制到 <strong>j5&#x2F;script_x86</strong> 目录下的 <strong>x86</strong> 目录下。</p>
<blockquote>
<p><strong>需要注意build_j5.sh脚本里指定的交叉编译工具链的位置是 &#x2F;opt 目录下，用户如果安装在其他位置，可以手动修改下build_j5.sh。</strong></p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CC=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-gcc</span><br><span class="line">export CXX=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-g++</span><br></pre></td></tr></table></figure></div>



<h4 id="示例使用"><a href="#示例使用" class="headerlink" title="示例使用"></a>示例使用</h4><h5 id="basic-samples示例"><a href="#basic-samples示例" class="headerlink" title="basic_samples示例"></a>basic_samples示例</h5><p>示例脚本主要在 <strong>j5&#x2F;script</strong> 和 <strong>j5&#x2F;script_x86</strong> 目录下，编译程序后目录结构如下:</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">script:</span><br><span class="line">├── 00_quick_start</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   └── run_mobilenetV1.sh</span><br><span class="line">├── 01_api_tutorial</span><br><span class="line">│   ├── model.sh</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── roi_infer.sh</span><br><span class="line">│   ├── sys_mem.sh</span><br><span class="line">│   └── tensor.sh</span><br><span class="line">├── 02_advanced_samples</span><br><span class="line">│   ├── plugin</span><br><span class="line">│   │   └── custom_arm_op_custom_identity.sh</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── run_multi_input.sh</span><br><span class="line">│   ├── run_multi_model_batch.sh</span><br><span class="line">│   └── run_nv12_batch.sh</span><br><span class="line">├── 03_misc</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── run_lenet.sh</span><br><span class="line">│   └── run_resnet50_feature.sh</span><br><span class="line">├── aarch64                        # 编译产生可执行程序及依赖库</span><br><span class="line">│   ├── bin</span><br><span class="line">│   │   ├── model_example</span><br><span class="line">│   │   ├── roi_infer</span><br><span class="line">│   │   ├── run_custom_op</span><br><span class="line">│   │   ├── run_lenet_gray</span><br><span class="line">│   │   ├── run_mobileNetV1_224x224</span><br><span class="line">│   │   ├── run_multi_input</span><br><span class="line">│   │   ├── run_multi_model_batch</span><br><span class="line">│   │   ├── run_nv12_batch</span><br><span class="line">│   │   ├── run_resnet_feature</span><br><span class="line">│   │   ├── sys_mem_example</span><br><span class="line">│   │   └── tensor_example</span><br><span class="line">│   └── lib</span><br><span class="line">│       ├── libdnn.so</span><br><span class="line">│       ├── libhbrt_bayes_aarch64.so</span><br><span class="line">│       └── libopencv_world.so.3.4</span><br><span class="line">└── README.md</span><br><span class="line"></span><br><span class="line">script_x86:</span><br><span class="line">├── 00_quick_start</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   └── run_mobilenetV1.sh</span><br><span class="line">├── x86                        # 编译产生可执行程序及依赖库</span><br><span class="line">│   ├── bin</span><br><span class="line">│   │   └── run_mobileNetV1_224x224</span><br><span class="line">│   └── lib</span><br><span class="line">│       ├── libdnn.so</span><br><span class="line">│       ├── libhbdk_sim_x86.so</span><br><span class="line">│       └── libopencv_world.so.3.4</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure></div>

<blockquote>
<ul>
<li><code>horizon_runtime_sample</code> 示例包的模型发布物需要在OE包的 <code>ddk/samples/ai_toolchain/model_zoo/runtime/horizon_runtime_sample</code> 目录下执行 <code>resolve_runtime_sample.sh</code> 脚本进行获取。</li>
<li><code>model</code> 文件夹包含模型所在的路径，x86运行环境下 <code>runtime</code> 文件夹为软链接，链接路径指向 <code>../../../model_zoo/runtime/horizon_runtime_sample</code> ，可直接在OE环境中运行；<strong>板端运行环境下需要将模型发布物放至 <code>model</code> 文件夹下。</strong></li>
</ul>
</blockquote>
<blockquote>
<p>quick_start</p>
</blockquote>
<p><strong>00_quick_start</strong> 目录下的快速开始示例：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">00_quick_start/</span><br><span class="line">├── README.md</span><br><span class="line">└── run_mobilenetV1.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>run_mobilenetV1.sh：该脚本实现使用mobilenetv1读取单张图片进行推理的示例功能。 使用的时候，进入 <strong>00_quick_start</strong> 目录, 然后直接执行 <code>sh run_mobilenetV1.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">root@j5dvb:/userdata/app/horizon/basic_samples/j5/script/00_quick_start# sh run_mobilenetV1.sh</span><br><span class="line">../aarch64/bin/run_mobileNetV1_224x224 --model_file=../../model/runtime/mobilenetv1/mobilenetv1_224x224_nv12.bin --image_file=../../data/cls_images/zebra_cls.jpg --top_k=5</span><br><span class="line">I0000 00:00:00.000000 10765 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,17:51:17.206.804) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">I0411 17:51:17.244180 10765 run_mobileNetV1_224x224.cc:135] DNN runtime version: 1.17.2_(3.15.18 HBRT)</span><br><span class="line">I0411 17:51:17.244376 10765 run_mobileNetV1_224x224.cc:252] input[0] name is data</span><br><span class="line">I0411 17:51:17.244508 10765 run_mobileNetV1_224x224.cc:268] output[0] name is prob</span><br><span class="line">I0411 17:51:17.260176 10765 run_mobileNetV1_224x224.cc:159] read image to tensor as nv12 success</span><br><span class="line">I0411 17:51:17.262075 10765 run_mobileNetV1_224x224.cc:194] TOP 0 result id: 340</span><br><span class="line">I0411 17:51:17.262118 10765 run_mobileNetV1_224x224.cc:194] TOP 1 result id: 292</span><br><span class="line">I0411 17:51:17.262148 10765 run_mobileNetV1_224x224.cc:194] TOP 2 result id: 282</span><br><span class="line">I0411 17:51:17.262177 10765 run_mobileNetV1_224x224.cc:194] TOP 3 result id: 83</span><br><span class="line">I0411 17:51:17.262205 10765 run_mobileNetV1_224x224.cc:194] TOP 4 result id: 290</span><br></pre></td></tr></table></figure></div></li>
</ul>
<blockquote>
<p>api_tutorial</p>
</blockquote>
<p>该示例是指 <strong>01_api_tutorial</strong> 目录内的示例，旨在引导用户使用嵌入式API。其目录包含以下脚本：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">├── model.sh</span><br><span class="line">├── roi_infer.sh</span><br><span class="line">├── sys_mem.sh</span><br><span class="line">└── tensor.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>model.sh：<strong>该脚本主要实现读取模型信息的功能</strong>。 使用的时候，直接进入 <strong>01_api_tutorial</strong> 目录，然后直接执行 <code>sh model.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">root@j5dvb-hynix8G:/userdata/horizon/j5/script/01_api_tutorial# sh model.sh</span><br><span class="line">../aarch64/bin/model_example --model_file_list=../../model/runtime/mobilenetv1/mobilenetv1_224x224_nv12.bin</span><br><span class="line">I0000 00:00:00.000000 10810 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,17:53:28.970.396) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">I0411 17:53:29.007853 10810 model_example.cc:104] model count:1, model[0]: mobilenetv1_224x224_nv12</span><br><span class="line">I0411 17:53:29.007939 10810 model_example.cc:112] hbDNNGetModelHandle [mobilenetv1_224x224_nv12] success!</span><br><span class="line">I0411 17:53:29.008011 10810 model_example.cc:186] [mobilenetv1_224x224_nv12] Model Info:  input num: 1, input[0] validShape: ( 1, 3, 224, 224 ), alignedShape: ( 1, 3, 224, 224 ), tensorType: 1, output num: 1, output[0] validShape: ( 1, 1000, 1, 1 ), alignedShape: ( 1, 1000, 1, 1 ), tensorType: 13</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>roi_infer.sh：该脚本主要引导如何使用 <code>hbDNNRoiInfer</code> 这个API，示例代码实现的功能是<strong>将一张图片转为nv12数据，给定roi框进行infer。</strong> 使用的时候，直接进入 <strong>01_api_tutorial</strong> 目录，然后直接执行 <code>sh roi_infer.sh</code> 即可。</p>
</li>
<li><p>sys_mem.sh：该脚本主要<strong>引导如何使用 <code>hbSysAllocMem</code>、<code>hbSysFlushMem</code> 和 <code>hbSysFreeMem</code> 这几个API</strong>。使用的时候，直接进入 <strong>01_api_tutorial</strong> 目录，执行 <code>sh sys_mem.sh</code> 即可。</p>
</li>
<li><p>tensor.sh<strong>：该脚本主要引导如何准备模型输入和输出的tensor、打印Tensor的属性和数据排布</strong>，以及使用quantizeAxis参数进行反量化。 使用的时候，直接进入 <strong>01_api_tutorial</strong> 目录，执行 <code>sh tensor.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb-hynix8G:/userdata/horizon/j5/script/01_api_tutorial# sh tensor.sh</span><br><span class="line">*****************************test_prepare_free_fn*************************************************</span><br><span class="line">Tensor data type:0, Tensor layout: 2, shape:1x1x721x1836, aligned shape:1x1x721x1840</span><br><span class="line">Tensor data type:1, Tensor layout: 2, shape:1x3x773x329, aligned shape:1x3x773x336</span><br><span class="line">Tensor data type:2, Tensor layout: 2, shape:1x3x108x1297, aligned shape:1x3x108x1312</span><br><span class="line">Tensor data type:5, Tensor layout: 2, shape:1x3x858x477, aligned shape:1x3x858x477</span><br><span class="line">Tensor data type:5, Tensor layout: 0, shape:1x920x102x3, aligned shape:1x920x102x3</span><br><span class="line">Tensor data type:4, Tensor layout: 2, shape:1x3x723x1486, aligned shape:1x3x723x1486</span><br><span class="line">Tensor data type:4, Tensor layout: 0, shape:1x372x366x3, aligned shape:1x372x366x3</span><br><span class="line">Tensor data type:3, Tensor layout: 2, shape:1x3x886x291, aligned shape:1x3x886x291</span><br><span class="line">Tensor data type:3, Tensor layout: 0, shape:1x613x507x3, aligned shape:1x613x507x3</span><br><span class="line">*****************************test_prepare_free_fn************************************************</span><br><span class="line"></span><br><span class="line">*****************************test_info_fn********************************************************</span><br><span class="line">Tensor data type:14, shape:1x1x1x3x2, stride:24x24x24x8x4, ndim: 5, data:</span><br><span class="line">  [[[[[0, 1], [2, 3], [4, 5]]]]]</span><br><span class="line">Tensor data type:9, shape:3x3x1x2x1, stride:6x2x2x1x1, ndim: 5, data:</span><br><span class="line">  [[[[[0], [1]]], [[[2], [3]]], [[[4], [5]]]], [[[[6], [7]]], [[[8], [9]]],</span><br><span class="line">    [[[10], [11]]]], [[[[12], [13]]], [[[14], [15]]], [[[16], [17]]]]]</span><br><span class="line">*****************************test_info_fn********************************************************</span><br><span class="line"></span><br><span class="line">********************test_dequantize_fn***********************************************************</span><br><span class="line">Tensor data type:8, shape:1x1x2x4, ndim: 4, quantiType: 2, quantizeAxis: 1,</span><br><span class="line">  quantizeValue: (0.1,), data: [[[[0, 1, 2, 3], [4, 5, 6, 7]]]],</span><br><span class="line">  dequantize data: [[[[0, 0.1, 0.2, 0.3], [0.4, 0.5, 0.6, 0.7]]]]</span><br><span class="line">Tensor data type:8, shape:2x4x1x1, ndim: 4, quantiType: 2, quantizeAxis: 3,</span><br><span class="line">  quantizeValue: (0.1,),</span><br><span class="line">  data: [[[[0]], [[1]], [[2]], [[3]]], [[[4]], [[5]], [[6]], [[7]]]],</span><br><span class="line">  dequantize data: [[[[0]], [[0.1]], [[0.2]], [[0.3]]], [[[0.4]], [[0.5]], [[0.6]], [[0.7]]]]</span><br><span class="line">********************test_dequantize_fn***********************************************************</span><br></pre></td></tr></table></figure></div></li>
</ul>
<blockquote>
<p>advanced_samples</p>
</blockquote>
<p>该示例是指 <strong>02_advanced_samples</strong> 目录内的示例，介绍了自定义算子特殊功能的使用。其目录包含以下脚本：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">├── plugin</span><br><span class="line">│    └── custom_arm_op_custom_identity.sh</span><br><span class="line">├── README.md</span><br><span class="line">├── run_multi_input.sh</span><br><span class="line">├── run_multi_model_batch.sh</span><br><span class="line">└── run_nv12_batch.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>custom_arm_op_custom_identity.sh：该脚本主要<strong>实现自定义算子模型推理功能</strong>， 使用的时候，进入 <strong>02_advanced_samples</strong> 目录, 然后直接执行 <code>sh custom_arm_op_custom_identity.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb-hynix8G:/userdata/horizon/j5/script/02_advanced_samples# sh custom_arm_op_custom_identity.sh</span><br><span class="line">../../aarch64/bin/run_custom_op --model_file=../../../model/runtime/custom_op/custom_op_featuremap.bin --input_file=../../../data/custom_identity_data/input0.bin,../../../data/custom_identity_data/input1.bin</span><br><span class="line">I0000 00:00:00.000000 10841 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">I0411 17:55:59.928918 10841 main.cpp:212] hbDNNRegisterLayerCreator success</span><br><span class="line">I0411 17:55:59.929064 10841 main.cpp:217] hbDNNRegisterLayerCreator success</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,17:56:00.667.991) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">I0411 17:56:00.676071 10841 main.cpp:232] hbDNNGetModelNameList success</span><br><span class="line">I0411 17:56:00.676204 10841 main.cpp:239] hbDNNGetModelHandle success</span><br><span class="line">I0411 17:56:00.676276 10841 main.cpp:245] hbDNNGetInputCount success</span><br><span class="line">file length: 602112</span><br><span class="line">file length: 602112</span><br><span class="line">I0411 17:56:00.687402 10841 main.cpp:268] hbDNNGetOutputCount success</span><br><span class="line">I0411 17:56:00.687788 10841 main.cpp:297] hbDNNInfer success</span><br><span class="line">I0411 17:56:00.695663 10841 main.cpp:302] task done</span><br><span class="line">I0411 17:56:03.145243 10841 main.cpp:306] write output tensor</span><br></pre></td></tr></table></figure></div>

<p>模型的第一个输出数据保存至 <code>output0.txt</code> 文件。</p>
</li>
<li><p>run_multi_input.sh：该脚本主要<strong>实现多输入模型推理功能</strong>， 使用的时候，进入 <strong>02_advanced_samples</strong> 目录, 然后直接执行 <code>sh run_multi_input.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb:/userdata/chaoliang/j5/script/02_advanced_samples# sh run_multi_input.sh</span><br><span class="line">../aarch64/bin/run_multi_input --model_file=../../model/runtime/mobilenetv2/mobilenetv2_multi_224x224_gray.bin --image_file=../../data/cls_images/zebra_cls.jpg --top_k=5</span><br><span class="line">I0000 00:00:00.000000 10893 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,17:57:03.277.375) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">I0411 17:57:03.327527 10893 multi_input.cc:148] read image to tensor as bgr success</span><br><span class="line">I0411 17:57:03.329546 10893 multi_input.cc:183] TOP 0 result id: 340</span><br><span class="line">I0411 17:57:03.329598 10893 multi_input.cc:183] TOP 1 result id: 292</span><br><span class="line">I0411 17:57:03.329628 10893 multi_input.cc:183] TOP 2 result id: 352</span><br><span class="line">I0411 17:57:03.329656 10893 multi_input.cc:183] TOP 3 result id: 351</span><br><span class="line">I0411 17:57:03.329684 10893 multi_input.cc:183] TOP 4 result id: 282</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>run_multi_model_batch.sh：该脚本主要<strong>实现多个小模型批量推理功能</strong>， 使用的时候，进入 <strong>02_advanced_samples</strong> 目录, 然后直接执行 <code>sh run_multi_model_batch.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb-hynix8G:/userdata/chaoliang/j5/script/02_advanced_samples# sh run_multi_model_batch.sh</span><br><span class="line">../aarch64/bin/run_multi_model_batch --model_file=../../model/runtime/googlenet/googlenet_224x224_nv12.bin,../../model/runtime/mobilenetv2/mobilenetv2_224x224_nv12.bin --input_file=../../data/cls_images/zebra_cls.jpg,../../data/cls_images/zebra_cls.jpg</span><br><span class="line">I0000 00:00:00.000000 10916 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,17:57:43.547.52) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,17:57:51.811.477) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">I0411 17:57:51.844280 10916 main.cpp:117] hbDNNInitializeFromFiles success</span><br><span class="line">I0411 17:57:51.844388 10916 main.cpp:125] hbDNNGetModelNameList success</span><br><span class="line">I0411 17:57:51.844424 10916 main.cpp:139] hbDNNGetModelHandle success</span><br><span class="line">I0411 17:57:51.875140 10916 main.cpp:153] read image to nv12 success</span><br><span class="line">I0411 17:57:51.875686 10916 main.cpp:170] prepare input tensor success</span><br><span class="line">I0411 17:57:51.875875 10916 main.cpp:182] prepare output tensor success</span><br><span class="line">I0411 17:57:51.876082 10916 main.cpp:216] infer success</span><br><span class="line">I0411 17:57:51.878844 10916 main.cpp:221] task done</span><br><span class="line">I0411 17:57:51.878948 10916 main.cpp:226] googlenet class result id: 340</span><br><span class="line">I0411 17:57:51.879084 10916 main.cpp:230] mobilenetv2 class result id: 340</span><br><span class="line">I0411 17:57:51.879177 10916 main.cpp:234] release task success</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>run_nv12_batch.sh：该脚本主要<strong>实现batch模型推理功能</strong>，Infer1是分开设置输入张量每个batch的地址，Infer2是只设置一个地址，包含所有的batch， 使用的时候，进入 <strong>02_advanced_samples</strong> 目录, 然后直接执行 <code>sh run_nv12_batch.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb:/userdata/chaoliang/j5/script/02_advanced_samples# sh run_nv12_batch.sh</span><br><span class="line">../aarch64/bin/run_nv12_batch --model_file=../../model/runtime/googlenet/googlenet_4x224x224_nv12.bin --image_file=../../data/cls_images/zebra_cls.jpg,../../data/cls_images/cat_cls.jpg,../../data/cls_images/zebra_cls.jpg,../../data/cls_images/cat_cls.jpg --top_k=5</span><br><span class="line">I0000 00:00:00.000000 21511 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">I0705 11:39:43.429180 21511 nv12_batch.cc:151] Infer1 start</span><br><span class="line">I0705 11:39:43.488143 21511 nv12_batch.cc:166] read image to tensor as nv12 success</span><br><span class="line">I0705 11:39:43.491156 21511 nv12_batch.cc:201] Batch[0]:</span><br><span class="line">I0705 11:39:43.491211 21511 nv12_batch.cc:203] TOP 0 result id: 340</span><br><span class="line">I0705 11:39:43.491240 21511 nv12_batch.cc:203] TOP 1 result id: 83</span><br><span class="line">I0705 11:39:43.491266 21511 nv12_batch.cc:203] TOP 2 result id: 41</span><br><span class="line">I0705 11:39:43.491298 21511 nv12_batch.cc:203] TOP 3 result id: 912</span><br><span class="line">I0705 11:39:43.491324 21511 nv12_batch.cc:203] TOP 4 result id: 292</span><br><span class="line">I0705 11:39:43.491348 21511 nv12_batch.cc:201] Batch[1]:</span><br><span class="line">I0705 11:39:43.491374 21511 nv12_batch.cc:203] TOP 0 result id: 282</span><br><span class="line">I0705 11:39:43.491398 21511 nv12_batch.cc:203] TOP 1 result id: 281</span><br><span class="line">I0705 11:39:43.491422 21511 nv12_batch.cc:203] TOP 2 result id: 285</span><br><span class="line">I0705 11:39:43.491447 21511 nv12_batch.cc:203] TOP 3 result id: 287</span><br><span class="line">I0705 11:39:43.491472 21511 nv12_batch.cc:203] TOP 4 result id: 283</span><br><span class="line">I0705 11:39:43.491497 21511 nv12_batch.cc:201] Batch[2]:</span><br><span class="line">I0705 11:39:43.491514 21511 nv12_batch.cc:203] TOP 0 result id: 340</span><br><span class="line">I0705 11:39:43.491539 21511 nv12_batch.cc:203] TOP 1 result id: 83</span><br><span class="line">I0705 11:39:43.491564 21511 nv12_batch.cc:203] TOP 2 result id: 41</span><br><span class="line">I0705 11:39:43.491587 21511 nv12_batch.cc:203] TOP 3 result id: 912</span><br><span class="line">I0705 11:39:43.491612 21511 nv12_batch.cc:203] TOP 4 result id: 292</span><br><span class="line">I0705 11:39:43.491637 21511 nv12_batch.cc:201] Batch[3]:</span><br><span class="line">I0705 11:39:43.491662 21511 nv12_batch.cc:203] TOP 0 result id: 282</span><br><span class="line">I0705 11:39:43.491685 21511 nv12_batch.cc:203] TOP 1 result id: 281</span><br><span class="line">I0705 11:39:43.491710 21511 nv12_batch.cc:203] TOP 2 result id: 285</span><br><span class="line">I0705 11:39:43.491734 21511 nv12_batch.cc:203] TOP 3 result id: 287</span><br><span class="line">I0705 11:39:43.491760 21511 nv12_batch.cc:203] TOP 4 result id: 283</span><br><span class="line">I0705 11:39:43.492235 21511 nv12_batch.cc:223] Infer1 end</span><br><span class="line">I0705 11:39:43.492276 21511 nv12_batch.cc:228] Infer2 start</span><br><span class="line">I0705 11:39:43.549713 21511 nv12_batch.cc:243] read image to tensor as nv12 success</span><br><span class="line">I0705 11:39:43.552248 21511 nv12_batch.cc:278] Batch[0]:</span><br><span class="line">I0705 11:39:43.552292 21511 nv12_batch.cc:280] TOP 0 result id: 340</span><br><span class="line">I0705 11:39:43.552320 21511 nv12_batch.cc:280] TOP 1 result id: 83</span><br><span class="line">I0705 11:39:43.552345 21511 nv12_batch.cc:280] TOP 2 result id: 41</span><br><span class="line">I0705 11:39:43.552371 21511 nv12_batch.cc:280] TOP 3 result id: 912</span><br><span class="line">I0705 11:39:43.552397 21511 nv12_batch.cc:280] TOP 4 result id: 292</span><br><span class="line">I0705 11:39:43.552421 21511 nv12_batch.cc:278] Batch[1]:</span><br><span class="line">I0705 11:39:43.552445 21511 nv12_batch.cc:280] TOP 0 result id: 282</span><br><span class="line">I0705 11:39:43.552469 21511 nv12_batch.cc:280] TOP 1 result id: 281</span><br><span class="line">I0705 11:39:43.552495 21511 nv12_batch.cc:280] TOP 2 result id: 285</span><br><span class="line">I0705 11:39:43.552520 21511 nv12_batch.cc:280] TOP 3 result id: 287</span><br><span class="line">I0705 11:39:43.552567 21511 nv12_batch.cc:280] TOP 4 result id: 283</span><br><span class="line">I0705 11:39:43.552592 21511 nv12_batch.cc:278] Batch[2]:</span><br><span class="line">I0705 11:39:43.552616 21511 nv12_batch.cc:280] TOP 0 result id: 340</span><br><span class="line">I0705 11:39:43.552641 21511 nv12_batch.cc:280] TOP 1 result id: 83</span><br><span class="line">I0705 11:39:43.552665 21511 nv12_batch.cc:280] TOP 2 result id: 41</span><br><span class="line">I0705 11:39:43.552690 21511 nv12_batch.cc:280] TOP 3 result id: 912</span><br><span class="line">I0705 11:39:43.552716 21511 nv12_batch.cc:280] TOP 4 result id: 292</span><br><span class="line">I0705 11:39:43.552739 21511 nv12_batch.cc:278] Batch[3]:</span><br><span class="line">I0705 11:39:43.552763 21511 nv12_batch.cc:280] TOP 0 result id: 282</span><br><span class="line">I0705 11:39:43.552788 21511 nv12_batch.cc:280] TOP 1 result id: 281</span><br><span class="line">I0705 11:39:43.552812 21511 nv12_batch.cc:280] TOP 2 result id: 285</span><br><span class="line">I0705 11:39:43.552837 21511 nv12_batch.cc:280] TOP 3 result id: 287</span><br><span class="line">I0705 11:39:43.552861 21511 nv12_batch.cc:280] TOP 4 result id: 283</span><br><span class="line">I0705 11:39:43.553154 21511 nv12_batch.cc:300] Infer2 end</span><br></pre></td></tr></table></figure></div></li>
</ul>
<blockquote>
<p>misc</p>
</blockquote>
<p>该示例是指 <strong>03_misc</strong> 目录内的示例，介绍了非nv12输入模型的使用。其目录包含以下脚本：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">├── run_lenet.sh</span><br><span class="line">└── run_resnet50_feature.sh</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>run_lenet.sh：<strong>该脚本主要实现Y数据输入的lenet模型推理功能</strong>， 使用的时候，进入 <strong>03_misc</strong> 目录, 然后直接执行 <code>sh run_lenet.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb-hynix8G:/userdata/horizon/j5/script/03_misc# sh run_lenet.sh</span><br><span class="line">../aarch64/bin/run_lenet_gray --model_file=../../model/runtime/lenet_gray/lenet_28x28_gray.bin --data_file=../../data/misc_data/7.bin --image_height=28 --image_width=28 --top_k=5</span><br><span class="line">I0000 00:00:00.000000 10979 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,18:02:12.605.436) [HorizonRT] The model builder version = 1.15.0</span><br><span class="line">I0411 18:02:12.613317 10979 run_lenet_gray.cc:128] hbDNNInitializeFromFiles success</span><br><span class="line">I0411 18:02:12.613404 10979 run_lenet_gray.cc:136] hbDNNGetModelNameList success</span><br><span class="line">I0411 18:02:12.613440 10979 run_lenet_gray.cc:143] hbDNNGetModelHandle success</span><br><span class="line">I0411 18:02:12.614181 10979 run_lenet_gray.cc:159] prepare y tensor success</span><br><span class="line">I0411 18:02:12.614310 10979 run_lenet_gray.cc:172] prepare tensor success</span><br><span class="line">I0411 18:02:12.614503 10979 run_lenet_gray.cc:182] infer success</span><br><span class="line">I0411 18:02:12.615538 10979 run_lenet_gray.cc:187] task done</span><br><span class="line">[W][DNN][hb_sys.cpp:108][Mem](2023-04-11,18:02:12.615.583) memory is noncachable, ignore flush operation</span><br><span class="line">I0411 18:02:12.615624 10979 run_lenet_gray.cc:192] task post process finished</span><br><span class="line">I0411 18:02:12.615667 10979 run_lenet_gray.cc:198] TOP 0 result id: 7</span><br><span class="line">I0411 18:02:12.615698 10979 run_lenet_gray.cc:198] TOP 1 result id: 9</span><br><span class="line">I0411 18:02:12.615727 10979 run_lenet_gray.cc:198] TOP 2 result id: 3</span><br><span class="line">I0411 18:02:12.615754 10979 run_lenet_gray.cc:198] TOP 3 result id: 4</span><br><span class="line">I0411 18:02:12.615782 10979 run_lenet_gray.cc:198] TOP 4 result id: 2</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>run_resnet50_feature.sh：<strong>该脚本主要实现feature数据输入的resnet50模型推理功能</strong>。示例代码对feature数据做了quantize和padding以满足模型的输入条件，然后输入到模型进行infer。 使用的时候，进入 <strong>03_misc</strong> 目录, 然后直接执行 <code>sh run_resnet50_feature.sh</code> 即可，如下代码块所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb-hynix8G:/userdata/horizon/j5/script/03_misc# sh run_resnet50_feature.sh</span><br><span class="line">../aarch64/bin/run_resnet_feature --model_file=./resnet50_64x56x56_featuremap_modified.bin --data_file=../../data/misc_data/np_0 --top_k=5</span><br><span class="line">I0000 00:00:00.000000 11024 vlog_is_on.cc:197] RAW: Set VLOG level for &quot;*&quot; to 3</span><br><span class="line">[BPU_PLAT]BPU Platform Version(1.3.3)!</span><br><span class="line">[HBRT] set log level as 0. version = 3.15.18.0</span><br><span class="line">[DNN] Runtime version = 1.17.2_(3.15.18 HBRT)</span><br><span class="line">[A][DNN][packed_model.cpp:225][Model](2023-04-11,18:03:30.317.594) [HorizonRT] The model builder version = 1.15.1</span><br><span class="line">I0411 18:03:30.523054 11024 run_resnet_feature.cc:160] hbDNNInitializeFromFiles success</span><br><span class="line">I0411 18:03:30.523152 11024 run_resnet_feature.cc:168] hbDNNGetModelNameList success</span><br><span class="line">I0411 18:03:30.523188 11024 run_resnet_feature.cc:175] hbDNNGetModelHandle success</span><br><span class="line">I0411 18:03:30.529860 11024 run_resnet_feature.cc:346] input data size: 802816; input valid size: 200704; input aligned size: 229376</span><br><span class="line">I0411 18:03:30.536860 11024 run_resnet_feature.cc:357] tensor padding featuremap success</span><br><span class="line">I0411 18:03:30.536912 11024 run_resnet_feature.cc:190] prepare feature tensor success</span><br><span class="line">I0411 18:03:30.537052 11024 run_resnet_feature.cc:200] prepare tensor success</span><br><span class="line">I0411 18:03:30.537197 11024 run_resnet_feature.cc:210] infer success</span><br><span class="line">I0411 18:03:30.541096 11024 run_resnet_feature.cc:215] task done</span><br><span class="line">[W][DNN][hb_sys.cpp:108][Mem](2023-04-11,18:03:30.541.149) memory is noncachable, ignore flush operation</span><br><span class="line">I0411 18:03:30.541409 11024 run_resnet_feature.cc:220] task post process finished</span><br><span class="line">I0411 18:03:30.541453 11024 run_resnet_feature.cc:226] TOP 0 result id: 74</span><br><span class="line">I0411 18:03:30.541483 11024 run_resnet_feature.cc:226] TOP 1 result id: 815</span><br><span class="line">I0411 18:03:30.541512 11024 run_resnet_feature.cc:226] TOP 2 result id: 73</span><br><span class="line">I0411 18:03:30.541538 11024 run_resnet_feature.cc:226] TOP 3 result id: 78</span><br><span class="line">I0411 18:03:30.541565 11024 run_resnet_feature.cc:226] TOP 4 result id: 72</span><br></pre></td></tr></table></figure></div></li>
</ul>
<h4 id="辅助工具"><a href="#辅助工具" class="headerlink" title="辅助工具"></a>辅助工具</h4><h5 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h5><p>日志主要包括 <strong>示例日志</strong> 和 <strong>dnn日志</strong> 两部分。 其中示例日志是指交付包示例代码中所应用的日志； dnn日志是指嵌入式dnn库中的日志。 用户根据不同的需求可以设置不同的日志。</p>
<blockquote>
<p>示例日志</p>
</blockquote>
<p>示例日志主要采用glog中的vlog，basic_samples所涉及到的示例中，日志内容全部输出。</p>
<blockquote>
<p>dnn 日志</p>
</blockquote>
<p>关于 <code>dnn</code> 日志的配置，请阅读BPU SDK API手册章节中的 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/bpu_sdk_api_doc.html#bpu-sdk-config" >配置信息 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节内容。</p>
<h3 id="AI-Benchmark使用说明"><a href="#AI-Benchmark使用说明" class="headerlink" title="AI-Benchmark使用说明"></a>AI-Benchmark使用说明</h3><p>AI Benchmark示例包提供了嵌入式应用开发常见分类、检测、分割和光流估计模型的性能和精度评测示例。 其中性能评测示例包括单帧延迟评测和多线程评测示例，充分利用调用BPU双核的速度评测。 示例包中预置了源码、可执行程序和评测脚本，开发者可以在地平线开发板上进行体验，并基于这些示例直接进行应用开发，降低开发门槛。</p>
<h4 id="发布物说明"><a href="#发布物说明" class="headerlink" title="发布物说明"></a>发布物说明</h4><p>AI Benchmark示例包位于 <strong>horizon_j5_open_explorer</strong> 发布物的 <code>ddk/samples/ai_benchmark/</code> 路径下，主要包括以下内容：</p>
<table>
<thead>
<tr>
<th align="left"><strong>编号</strong></th>
<th align="left"><strong>名称</strong></th>
<th align="left"><strong>内容</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">1</td>
<td align="left">code</td>
<td align="left">包含示例源代码和编译脚本。</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">j5</td>
<td align="left">示例包上板运行环境。</td>
</tr>
</tbody></table>
<h5 id="示例包结构"><a href="#示例包结构" class="headerlink" title="示例包结构"></a>示例包结构</h5><blockquote>
<p>上板模型需要先在OE包的 <code>ddk/samples/ai_toolchain/model_zoo/runtime/ai_benchmark</code> 目录下的 <code>resolve_ai_benchmark_ptq.sh</code> 和 <code>resolve_ai_benchmark_qat.sh</code> 脚本进行获取。</p>
</blockquote>
<p>示例包结构如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">ai_benchmark/code/                    # 示例源码文件夹</span><br><span class="line">├── build_ptq_j5.sh</span><br><span class="line">├── build_qat_j5.sh</span><br><span class="line">├── CMakeLists.txt</span><br><span class="line">├── deps_gcc9.3                       # 第三方依赖库</span><br><span class="line">│   └── aarch64</span><br><span class="line">├── include                           # 源码头文件</span><br><span class="line">│   ├── base</span><br><span class="line">│   ├── input</span><br><span class="line">│   ├── method</span><br><span class="line">│   ├── output</span><br><span class="line">│   ├── plugin</span><br><span class="line">│   └── utils</span><br><span class="line">├── README.md</span><br><span class="line">└── src                               # 示例源码</span><br><span class="line">    ├── input</span><br><span class="line">    ├── method</span><br><span class="line">    ├── output</span><br><span class="line">    ├── plugin</span><br><span class="line">    ├── simple_example.cc             # 示例主程序</span><br><span class="line">    └── utils</span><br><span class="line"></span><br><span class="line">ai_benchmark/j5                       # 示例包运行环境</span><br><span class="line">├── ptq                               # PTQ方案模型示例</span><br><span class="line">│   ├── data                          # 模型精度评测数据集</span><br><span class="line">│   ├── mini_data                     # 模型性能评测数据集</span><br><span class="line">│   │   ├── cifar10</span><br><span class="line">│   │   ├── cityscapes</span><br><span class="line">│   │   ├── coco</span><br><span class="line">│   │   ├── culane</span><br><span class="line">│   │   ├── flyingchairs</span><br><span class="line">│   │   ├── imagenet</span><br><span class="line">│   │   ├── kitti3d</span><br><span class="line">│   │   ├── nuscenes</span><br><span class="line">│   │   └── voc</span><br><span class="line">│   ├── model                         # PTQ方案nv12模型</span><br><span class="line">│   │   ├── README.md</span><br><span class="line">│   │   └── runtime -&gt; ../../../../model_zoo/runtime/ai_benchmark/ptq   # 软链接指向OE包中的模型，板端运行环境需要自行指定模型路径</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── script                        # 执行脚本</span><br><span class="line">│   │   ├── aarch64                   # 编译产生可执行文件及依赖库</span><br><span class="line">│   │   ├── classification            # 分类模型示例</span><br><span class="line">│   │   │   ├── efficientnasnet_m</span><br><span class="line">│   │   │   ├── efficientnasnet_s</span><br><span class="line">│   │   │   ├── efficientnet_lite0</span><br><span class="line">│   │   │   ├── efficientnet_lite1</span><br><span class="line">│   │   │   ├── efficientnet_lite2</span><br><span class="line">│   │   │   ├── efficientnet_lite3</span><br><span class="line">│   │   │   ├── efficientnet_lite4</span><br><span class="line">│   │   │   ├── googlenet</span><br><span class="line">│   │   │   ├── mobilenetv1</span><br><span class="line">│   │   │   ├── mobilenetv2</span><br><span class="line">│   │   │   ├── resnet18</span><br><span class="line">│   │   │   └── vargconvnet</span><br><span class="line">│   │   ├── config                    # 模型推理配置文件</span><br><span class="line">│   │   │   └── model</span><br><span class="line">│   │   ├── detection                 # 检测模型示例</span><br><span class="line">│   │   │   ├── centernet_resnet101</span><br><span class="line">│   │   │   ├── preq_qat_fcos_efficientnetb0</span><br><span class="line">│   │   │   ├── preq_qat_fcos_efficientnetb2</span><br><span class="line">│   │   │   ├── preq_qat_fcos_efficientnetb3</span><br><span class="line">│   │   │   ├── ssd_mobilenetv1</span><br><span class="line">│   │   │   ├── yolov2_darknet19</span><br><span class="line">│   │   │   ├── yolov3_darknet53</span><br><span class="line">│   │   │   ├── yolov3_vargdarknet</span><br><span class="line">│   │   │   └── yolov5x</span><br><span class="line">│   │   ├── segmentation              # 分割模型示例</span><br><span class="line">│   │   │   ├── deeplabv3plus_efficientnetb0</span><br><span class="line">│   │   │   ├── deeplabv3plus_efficientnetm1</span><br><span class="line">│   │   │   ├── deeplabv3plus_efficientnetm2</span><br><span class="line">│   │   │   └── fastscnn_efficientnetb0</span><br><span class="line">│   │   ├── env.sh                    # 基础环境脚本</span><br><span class="line">│   │   └── README.md</span><br><span class="line">│   └── tools                         # 精度评测工具</span><br><span class="line">│       ├── python_tools</span><br><span class="line">│       └── README.md</span><br><span class="line">└── qat                               # QAT方案模型示例</span><br><span class="line">    ├── data                          # 模型精度评测数据集</span><br><span class="line">    ├── mini_data                     # 模型性能评测数据集</span><br><span class="line">    ├── model                         # QAT方案nv12模型</span><br><span class="line">    │   ├── README.md</span><br><span class="line">    │   └── runtime -&gt; ../../../../model_zoo/runtime/ai_benchmark/qat    # 软链接指向OE包中的模型，板端运行环境需要自行指定模型路径</span><br><span class="line">    ├── README.md</span><br><span class="line">    ├── script                        # 执行脚本</span><br><span class="line">    │   ├── aarch64                   # 编译产生可执行文件及依赖库</span><br><span class="line">    │   ├── classification            # 分类模型示例</span><br><span class="line">    │   │   ├── mixvargenet</span><br><span class="line">    │   │   ├── mobilenetv1</span><br><span class="line">    │   │   ├── mobilenetv2</span><br><span class="line">    │   │   ├── resnet18</span><br><span class="line">    │   │   ├── resnet50</span><br><span class="line">    │   │   ├── swint</span><br><span class="line">    │   │   └── vargnetv2</span><br><span class="line">    │   ├── config                    # 模型推理配置文件</span><br><span class="line">    │   │   └── model</span><br><span class="line">    │   ├── detection                 # 检测模型示例</span><br><span class="line">    │   │   ├── detr_efficientnetb3</span><br><span class="line">    │   │   ├── detr_resnet50</span><br><span class="line">    │   │   ├── fcos_efficientnetb0</span><br><span class="line">    │   │   ├── fcos3d_efficientnetb0</span><br><span class="line">    │   │   ├── ganet</span><br><span class="line">    │   │   ├── retinanet</span><br><span class="line">    │   │   ├── pointpillars_kitti_car</span><br><span class="line">    │   │   └── yolov3_mobilenetv1</span><br><span class="line">    │   ├── opticalflow               # 光流模型示例</span><br><span class="line">    │   │   └── pwcnet_opticalflow</span><br><span class="line">    │   ├── segmentation              # 分割模型示例</span><br><span class="line">    │   │   └── mobilenet_unet</span><br><span class="line">    │   ├── env.sh                    # 基础环境脚本</span><br><span class="line">    │   └── README.md</span><br><span class="line">    └── tools                         # 前处理及精度评测工具</span><br><span class="line">        ├── eval_preprocess</span><br><span class="line">        ├── python_tools</span><br><span class="line">        └── README.md</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p><strong>code</strong>：该目录内是评测程序的源码，用来进行模型性能和精度评测。</p>
</li>
<li><p><strong>j5</strong>：该目录内提供了已经编译好的应用程序，以及各种评测脚本，用来测试多种模型在地平线BPU上运行的性能和精度等。</p>
</li>
<li><p><strong>build_ptq_j5.sh</strong>：PTQ真机程序一键编译脚本。</p>
</li>
<li><p><strong>build_qat_j5.sh</strong>：QAT真机程序一键编译脚本。</p>
</li>
<li><p><strong>deps_gcc9.3</strong>：示例代码所需要的依赖，主要如下所示:</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appsdk  gflags  glog  hobotlog  nlohmann  opencv  rapidjson</span><br></pre></td></tr></table></figure></div></li>
</ul>
<h5 id="示例模型"><a href="#示例模型" class="headerlink" title="示例模型"></a>示例模型</h5><p>AI Benchmark示例包的PTQ模型和QAT模型发布物model_zoo分别位于 <code>horizon_j5_open_explorer</code> 发布物的 <code>ddk/samples/ai_toolchain/model_zoo/runtime/ai_benchmark/ptq</code> 和 <code>ddk/samples/ai_toolchain/model_zoo/runtime/ai_benchmark/qat</code> 路径下， 里面包含常用的分类、检测、分割和光流预测模型，模型的命名规则为： <code>&#123;model_name&#125;_&#123;backbone&#125;_&#123;input_size&#125;_&#123;input_type&#125;</code>。 model_zoo里的PTQ模型都是通过PTQ模型转换示例包（即： <code>ddk/samples/ai_toolchain/horizon_model_convert_sample/</code>）编译出来的。 原始模型详细信息可以查看PTQ模型转换示例包中各模型自路径下的README文档或阅读 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_sample/ptq_sample.html" >PTQ模型转换示例手册 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 了解更多。</p>
<table>
<thead>
<tr>
<th align="left">PTQMODEL</th>
<th align="left">MODEL NAME</th>
</tr>
</thead>
<tbody><tr>
<td align="left">centernet_resnet101</td>
<td align="left">centernet_resnet101_512x512_nv12.bin</td>
</tr>
<tr>
<td align="left">deeplabv3plus_efficientnetb0</td>
<td align="left">deeplabv3plus_efficientnetb0_1024x2048_nv12.bin</td>
</tr>
<tr>
<td align="left">deeplabv3plus_efficientnetm1</td>
<td align="left">deeplabv3plus_efficientnetm1_1024x2048_nv12.bin</td>
</tr>
<tr>
<td align="left">deeplabv3plus_efficientnetm2</td>
<td align="left">deeplabv3plus_efficientnetm2_1024x2048_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnasnet_m</td>
<td align="left">efficientnasnet_m_300x300_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnasnet_s</td>
<td align="left">efficientnasnet_s_280x280_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnet_lite0</td>
<td align="left">efficientnet_lite0_224x224_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnet_lite1</td>
<td align="left">efficientnet_lite1_240x240_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnet_lite2</td>
<td align="left">efficientnet_lite2_260x260_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnet_lite3</td>
<td align="left">efficientnet_lite3_280x280_nv12.bin</td>
</tr>
<tr>
<td align="left">efficientnet_lite4</td>
<td align="left">efficientnet_lite4_300x300_nv12.bin</td>
</tr>
<tr>
<td align="left">fastscnn_efficientnetb0</td>
<td align="left">fastscnn_efficientnetb0_1024x2048_nv12.bin</td>
</tr>
<tr>
<td align="left">preq_qat_fcos_efficientnetb0</td>
<td align="left">fcos_efficientnetb0_512x512_nv12.bin</td>
</tr>
<tr>
<td align="left">preq_qat_fcos_efficientnetb2</td>
<td align="left">fcos_efficientnetb2_768x768_nv12.bin</td>
</tr>
<tr>
<td align="left">preq_qat_fcos_efficientnetb3</td>
<td align="left">fcos_efficientnetb3_896x896_nv12.bin</td>
</tr>
<tr>
<td align="left">googlenet</td>
<td align="left">googlenet_224x224_nv12.bin</td>
</tr>
<tr>
<td align="left">mobilenetv1</td>
<td align="left">mobilenetv1_224x224_nv12.bin</td>
</tr>
<tr>
<td align="left">mobilenetv1_128x128_resizer_nv12.bin</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">mobilenetv2</td>
<td align="left">mobilenetv2_224x224_nv12.bin</td>
</tr>
<tr>
<td align="left">resnet18</td>
<td align="left">resnet18_224x224_nv12.bin</td>
</tr>
<tr>
<td align="left">ssd_mobilenetv1</td>
<td align="left">ssd_mobilenetv1_300x300_nv12.bin</td>
</tr>
<tr>
<td align="left">vargconvnet</td>
<td align="left">vargconvnet_224x224_nv12.bin</td>
</tr>
<tr>
<td align="left">yolov2_darknet19</td>
<td align="left">yolov2_darknet19_608x608_nv12.bin</td>
</tr>
<tr>
<td align="left">yolov3_darknet53</td>
<td align="left">yolov3_darknet53_416x416_nv12.bin</td>
</tr>
<tr>
<td align="left">yolov3_vargdarknet</td>
<td align="left">yolov3_vargdarknet_416x416_nv12.bin</td>
</tr>
<tr>
<td align="left">yolov5x</td>
<td align="left">yolov5x_672x672_nv12.bin</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="left">QATMODEL</th>
<th align="left">MODEL NAME</th>
</tr>
</thead>
<tbody><tr>
<td align="left">detr_efficientnetb3</td>
<td align="left">detr_efficientnetb3_mscoco&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">detr_resnet50</td>
<td align="left">detr_resnet50_mscoco&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">fcos_efficientnetb0</td>
<td align="left">fcos_efficientnetb0_mscoco&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">fcos3d_efficientnetb0</td>
<td align="left">fcos3d_efficientnetb0_nuscenes&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">ganet</td>
<td align="left">ganet_mixvargenet_culane&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">mixvargenet</td>
<td align="left">mixvargenet_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">mobilenet_unet</td>
<td align="left">dwunet_seg&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">mobilenetv1</td>
<td align="left">mobilenetv1_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">mobilenetv2</td>
<td align="left">mobilenetv2_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">pwcnet_opticalflow</td>
<td align="left">pwcnet_opticalflow&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">resnet18</td>
<td align="left">resnet18_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">resnet50</td>
<td align="left">resnet50_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">retinanet</td>
<td align="left">retinanet_vargnetv2_fpn_mscoco&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">swint</td>
<td align="left">horizon_swin_transformer_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">vargnetv2</td>
<td align="left">vargnetv2_cls&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">yolov3_mobilenetv1</td>
<td align="left">yolo_mobilenetv1_det&#x2F;compile&#x2F;model.hbm</td>
</tr>
<tr>
<td align="left">pointpillars_kitti_car</td>
<td align="left">pointpillars_kitti_car&#x2F;compile&#x2F;model.hbm</td>
</tr>
</tbody></table>
<h5 id="公共数据集"><a href="#公共数据集" class="headerlink" title="公共数据集"></a>公共数据集</h5><p>示例中用到的数据集主要有VOC数据集、COCO数据集、ImageNet数据集、Cityscapes数据集、FlyingChairs数据集、KITTI数据集、Culane数据集和Nuscenes数据集。 获取方式如下，数据准备过程中如遇问题请联系地平线。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">VOC：http://host.robots.ox.ac.uk/pascal/VOC/  （使用VOC2012版本）</span><br><span class="line">COCO：https://cocodataset.org/#download</span><br><span class="line">ImageNet：https://www.image-net.org/download.php</span><br><span class="line">Cityscapes：https://github.com/mcordts/cityscapesScripts</span><br><span class="line">FlyingChairs：https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html</span><br><span class="line">KITTI3D：https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d</span><br><span class="line">CULane：https://xingangpan.github.io/projects/CULane.html</span><br><span class="line">nuScenes：https://www.nuscenes.org/nuscenes#download</span><br></pre></td></tr></table></figure></div>



<h4 id="环境构建"><a href="#环境构建" class="headerlink" title="环境构建"></a>环境构建</h4><h5 id="开发板准备-1"><a href="#开发板准备-1" class="headerlink" title="开发板准备"></a>开发板准备</h5><p>1.拿到开发板后，按照 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/appendix/hardware/system_image.html" >系统镜像升级 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 中的说明，升级系统镜像到示例包推荐的系统镜像版本。</p>
<p>2.确保本地开发机和开发板可以远程连接。</p>
<h5 id="编译-1"><a href="#编译-1" class="headerlink" title="编译"></a>编译</h5><p>编译需要当前环境安装好交叉编译工具gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu。 然后执行 <strong>code</strong> 目录下的<code>build_ptq_j5.sh</code>脚本即可一键编译真机环境下的可执行程序，可执行 程序和对应依赖会自动复制到 <strong>j5&#x2F;ptq&#x2F;script</strong> 目录下的 <strong>aarch64</strong> 目录下。</p>
<blockquote>
<p>要注意build_ptq_j5.sh脚本里指定的交叉编译工具链的位置是 <strong>&#x2F;opt</strong> 目录下，用户如果安装在其他位置，需要手动修改下build_ptq_j5.sh。</p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export CC=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-gcc</span><br><span class="line">export CXX=/opt/gcc-ubuntu-9.3.0-2020.03-x86_64-aarch64-linux-gnu/bin/aarch64-linux-gnu-g++</span><br></pre></td></tr></table></figure></div>



<h4 id="示例使用-1"><a href="#示例使用-1" class="headerlink" title="示例使用"></a>示例使用</h4><h5 id="评测示例"><a href="#评测示例" class="headerlink" title="评测示例"></a>评测示例</h5><p>评测示例脚本主要在 <strong>script</strong> 和 <strong>tools</strong> 目录下。 <strong>script</strong> 是板上运行的<strong>评测脚本</strong>，包括常见分类、检测、分割和光流预测模型。 每个模型下面有以下三个脚本：</p>
<ul>
<li>fps.sh：实现多线程fps统计（多线程调度，用户可以根据需求自由设置线程数）。</li>
<li>latency.sh：实现单帧延迟性能统计（一个线程，单帧）。</li>
<li>accuracy.sh：用于精度评测。</li>
</ul>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">script:</span><br><span class="line"></span><br><span class="line">├── aarch64                     # 编译产生的可执行文件及依赖库</span><br><span class="line">│   ├── bin</span><br><span class="line">│   └── lib</span><br><span class="line">├── env.sh                      # 基础配置</span><br><span class="line">├── config                      # image_name配置文件</span><br><span class="line">│   └── model</span><br><span class="line">│       └── data_name_list</span><br><span class="line">├── detection                   # 检测模型</span><br><span class="line">│   ├── fcos_efficientnetb0     # 在此目录中还有其他模型, 仅以此模型目录为参考</span><br><span class="line">│   │   ├── accuracy.sh</span><br><span class="line">│   │   ├── fps.sh</span><br><span class="line">│   │   ├── latency.sh</span><br><span class="line">│   │   ├── workflow_accuracy.json</span><br><span class="line">│   │   ├── workflow_fps.json</span><br><span class="line">│   │   ├── workflow_latency.json</span><br><span class="line">│   ......</span><br><span class="line">├── classification              # 分类模型</span><br><span class="line">├── segmentation                # 分割模型</span><br><span class="line">├── opticalflow                 # 光流模型(qat)</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure></div>

<p><strong>(PTQ)tools</strong> PTQ目录下<strong>精度评测</strong>需要的脚本。主要包括 <strong>python_tools</strong> 下的精度计算脚本。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tools:</span><br><span class="line"></span><br><span class="line">python_tools</span><br><span class="line">  └── accuracy_tools</span><br><span class="line">      ├── cityscapes_metric.py</span><br><span class="line">      ├── cls_eval.py</span><br><span class="line">      ├── coco_metric.py</span><br><span class="line">      ├── config.py</span><br><span class="line">      ├── coco_det_eval.py</span><br><span class="line">      ├── parsing_eval.py</span><br><span class="line">      └── voc_det_eval.py</span><br><span class="line">      └── voc_metric.py</span><br></pre></td></tr></table></figure></div>

<p><strong>(QAT)tools</strong> QAT目录下精度评测需要的脚本。主要包括前处理脚本及精度计算脚本。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">tools:</span><br><span class="line"></span><br><span class="line">tools/</span><br><span class="line">  ├── eval_preprocess</span><br><span class="line">  │     ├── detr_process.py</span><br><span class="line">  │     ├── fcos_process.py</span><br><span class="line">  │     ├── fcos3d_process.py</span><br><span class="line">  │     ├── ganet_process.py</span><br><span class="line">  │     ├── imagenet.py</span><br><span class="line">  │     ├── pwcnet_process.py</span><br><span class="line">  │     ├── retinanet_process.py</span><br><span class="line">  │     ├── pointpillars_process.py</span><br><span class="line">  │     └── voc.py</span><br><span class="line">  ├── python_tools</span><br><span class="line">  │     └── accuracy_tools</span><br><span class="line">  │         ├── cityscapes_metric.py</span><br><span class="line">  │         ├── cls_eval.py</span><br><span class="line">  │         ├── coco_metric.py</span><br><span class="line">  │         ├── config.py</span><br><span class="line">  │         ├── detr_eval.py</span><br><span class="line">  │         ├── fcos_eval.py</span><br><span class="line">  │         ├── fcos3d_eval.py</span><br><span class="line">  │         ├── ganet_eval.py</span><br><span class="line">  │         ├── parsing_eval.py</span><br><span class="line">  │         ├── pwcnet_eval.py</span><br><span class="line">  │         └── retinanet_eval.py</span><br><span class="line">  │         └── voc_metric.py</span><br><span class="line">  │         └── kitti3d_metric.py</span><br><span class="line">  │         └── pointpillars_eval.py</span><br><span class="line">  │         └── yolov3_eval.py</span><br><span class="line">  └── README.md</span><br></pre></td></tr></table></figure></div>

<p><strong>注意：评测前需要执行以下命令，将 ptq （ qat ） 目录拷贝到开发板上。</strong></p>
<blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r ddk/samples/ai_benchmark/j5/ptq root@192.168.1.1:/userdata/ptq/</span><br><span class="line">scp -r ddk/samples/ai_benchmark/j5/qat root@192.168.1.1:/userdata/qat/</span><br></pre></td></tr></table></figure></div>
</blockquote>
<h5 id="性能评测"><a href="#性能评测" class="headerlink" title="性能评测"></a>性能评测</h5><p>性能评测分为latency和fps两方面。</p>
<blockquote>
<p>使用说明</p>
</blockquote>
<p>latency:</p>
<p>进入到需要评测的模型目录下，执行 <code>sh latency.sh</code> 即可测试出单帧延迟。如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I0419 02:35:07.041095 39124 output_plugin.cc:80]  Infer latency:  [avg:  13.124ms,  max:  13.946ms,  min:  13.048ms], Post process latency: [avg:  3.584ms,  max:  3.650ms,  min:  3.498ms].</span><br></pre></td></tr></table></figure></div>

<p>注意：</p>
<ul>
<li><code>infer</code> 表示模型推理耗时。</li>
<li><code>Post process</code> 表示后处理耗时。</li>
</ul>
<p>fps：该功能采用多线程并发方式，旨在让模型可以在BPU上达到极致的性能。由于多线程并发及数据采样的原因，在程序启动阶段帧率值会较低，之后帧率会上升并逐渐趋于稳定，帧率的浮动范围控制在0.5%之内。 进入到需要评测的模型目录下执行 <code>sh fps.sh</code> 即可测试出帧率。如下所示：<code>I0419 02:35:00.044417 39094 output_plugin.cc:109]  Throughput: 1129.39fps      # 模型帧率</code></p>
<blockquote>
<p>命令行参数说明</p>
</blockquote>
<p>该功能采用多线程并发方式，旨在让模型可以在BPU上达到极致的性能。由于多线程并发及数据采样的原因，在程序启动阶段帧率值会较低，之后帧率会上升并逐渐趋于稳定，帧率的浮动范围控制在0.5%之内。 进入到需要评测的模型目录下执行 <code>sh fps.sh</code> 即可测试出帧率。如下所示：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I0419 02:35:00.044417 39094 output_plugin.cc:109]  Throughput: 1129.39fps      # 模型帧率</span><br></pre></td></tr></table></figure></div>

<h6 id="命令行参数说明"><a href="#命令行参数说明" class="headerlink" title="命令行参数说明"></a>命令行参数说明</h6><p>fps.sh脚本内容如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">source ../../env.sh</span><br><span class="line">export SHOW_FPS_LOG=1</span><br><span class="line">export STAT_CYCLE=100                             # 设置环境变量，FPS 统计周期</span><br><span class="line"></span><br><span class="line">$&#123;app&#125; \</span><br><span class="line">  --config_file=workflow_fps.json \</span><br><span class="line">  --log_level=1</span><br></pre></td></tr></table></figure></div>

<p>latency.sh脚本内容如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">source ../../env.sh</span><br><span class="line">export SHOW_LATENCY_LOG=1                         # 设置环境变量，打印 LATENCY 级别log</span><br><span class="line">export STAT_CYCLE=50                              # 设置环境变量，LATENCY 统计周期</span><br><span class="line"></span><br><span class="line">$&#123;app&#125; \</span><br><span class="line">  --config_file=workflow_latency.json \</span><br><span class="line">  --log_level=1</span><br></pre></td></tr></table></figure></div>



<h6 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h6><blockquote>
<p>注意：max_cache参数生效时会预处理图片并读取到内存中，为保障您的程序稳定运行，请不要设置过大的值，建议您的数值设置不超过30。</p>
</blockquote>
<p>以centernet_resnet101模型为例，workflow_fps.json配置文件内容如下：</p>
<div class="highlight-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;input_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;input_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image&quot;</span><span class="punctuation">,</span>                                  # 输入数据格式，支持图像或者bin文件</span><br><span class="line">    <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span>                                          # 输入数据高度</span><br><span class="line">    <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span>                                           # 输入数据宽度</span><br><span class="line">    <span class="attr">&quot;data_type&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span>                                         # 输入数据类型：HB_DNN_IMG_TYPE_NV12</span><br><span class="line">    <span class="attr">&quot;image_list_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../../mini_data/coco/coco.lst&quot;</span><span class="punctuation">,</span>  # 预处理数据集lst文件所在路径</span><br><span class="line">    <span class="attr">&quot;need_pre_load&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span>                                  # 是否使用预加载方式读取数据集</span><br><span class="line">    <span class="attr">&quot;limit&quot;</span><span class="punctuation">:</span> <span class="number">12</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;need_loop&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span>                                      # 是否循环读取数据进行评测</span><br><span class="line">    <span class="attr">&quot;max_cache&quot;</span><span class="punctuation">:</span> <span class="number">10</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;output_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image&quot;</span><span class="punctuation">,</span>                                 # 可视化输出数据类型</span><br><span class="line">    <span class="attr">&quot;image_list_enable&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;in_order&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span>                                       # 是否按顺序输出</span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;workflow&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;method_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;InferMethod&quot;</span><span class="punctuation">,</span>                         # Infer推理方式</span><br><span class="line">      <span class="attr">&quot;unique_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;InferMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;core&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span>                                          # 推理core id</span><br><span class="line">        <span class="attr">&quot;model_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../../model/runtime/centernet_resnet101/centernet_resnet101_512x512_nv12.bin&quot;</span> # 模型文件</span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;thread_count&quot;</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span>                                    # 后处理线程数</span><br><span class="line">      <span class="attr">&quot;method_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PTQCenternetPostProcessMethod&quot;</span><span class="punctuation">,</span>       # 后处理方法</span><br><span class="line">      <span class="attr">&quot;unique_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PTQCenternetPostProcessMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>                                    # 后处理参数</span><br><span class="line">        <span class="attr">&quot;class_num&quot;</span><span class="punctuation">:</span> <span class="number">80</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;score_threshold&quot;</span><span class="punctuation">:</span> <span class="number">0.4</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;topk&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;det_name_list&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../config/model/data_name_list/coco_classes.names&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></div>

<p>workflow_latency.json 如下：</p>
<div class="highlight-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;input_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;input_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;data_type&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;image_list_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../../mini_data/coco/coco.lst&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;need_pre_load&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;limit&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;need_loop&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_cache&quot;</span><span class="punctuation">:</span> <span class="number">10</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;output_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;image_list_enable&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;workflow&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;method_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;InferMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;unique_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;InferMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;core&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;model_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../../model/runtime/centernet_resnet101/centernet_resnet101_512x512_nv12.bin&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;thread_count&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PTQCenternetPostProcessMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;unique_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PTQCenternetPostProcessMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;class_num&quot;</span><span class="punctuation">:</span> <span class="number">80</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;score_threshold&quot;</span><span class="punctuation">:</span> <span class="number">0.4</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;topk&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;det_name_list&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../config/model/data_name_list/coco_classes.names&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></div>



<h5 id="精度评测"><a href="#精度评测" class="headerlink" title="精度评测"></a>精度评测</h5><p>模型评测分为五步：</p>
<p>1.数据预处理。</p>
<p>2.数据挂载。</p>
<p>3.生成lst文件。</p>
<p>4.模型推理。</p>
<p>5.精度计算。</p>
<h6 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h6><blockquote>
<p>PTQ模型数据预处理</p>
</blockquote>
<p>PTQ模型数据预处理需要在x86仿真环境下运行 <code>hb_eval_preprocess</code> 工具，对数据集进行预处理。 所谓预处理是指图片数据在送入模型之前的特定处理操作。比如：图片resize、crop和padding等。 该工具集成于 <code>horizon_tc_ui</code> 工具中，安装过相应install脚本即可使用， 原始数据集经过工具预处理之后，会生成模型对应的前处理二进制文件.bin文件集。 直接运行 <code>hb_eval_preprocess --help</code> 可以查看工具使用规则。</p>
<p><strong>关于 <code>hb_eval_preprocess</code> 工具命令行参数，可键入 <code>hb_eval_preprocess -h</code>， 或查看 PTQ工具文档中的 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/oe_mapper/source/ptq/ptq_tool/hb_eval_preprocess.html" >hb_eval_preprocess工具 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节内容。</strong></p>
<p>下面将详细介绍示例包中每一个模型对应的数据集，以及对应数据集的预处理操作。</p>
<p><strong>VOC数据集</strong></p>
<p>VOC数据集用于ssd_mobilenetv1检测模型的评测。 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/" >VOC数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您将下载的数据集解压成如下结构，数据准备过程中如遇问题请联系地平线，示例中主要用到 <strong>Main</strong> 文件下的val.txt文件， <strong>JPEGImages</strong> 中的源图片和 <strong>Annotations</strong> 中的标注数据：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">└── VOCdevkit                  # 根目录</span><br><span class="line">    └── VOC2012                # 不同年份的数据集，这里只下载了2012的，还有2007等其它年份的</span><br><span class="line">        ├── Annotations        # 存放xml文件，与JPEGImages中的图片一一对应，解释图片的内容等等</span><br><span class="line">        ├── ImageSets          # 该目录下存放的都是txt文件，txt文件中每一行包含一个图片的名称，末尾会加上±1表示正负样本</span><br><span class="line">        │   ├── Action</span><br><span class="line">        │   ├── Layout</span><br><span class="line">        │   ├── Main</span><br><span class="line">        │   └── Segmentation</span><br><span class="line">        ├── JPEGImages         # 存放源图片</span><br><span class="line">        ├── SegmentationClass  # 存放的是图片，语义分割相关</span><br><span class="line">        └── SegmentationObject # 存放的是图片，实例分割相关</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_eval_preprocess -m ssd_mobilenetv1 -i VOCdevkit/VOC2012/JPEGImages -v VOCdevkit/VOC2012/ImageSets/Main/val.txt -o ./pre_ssd_mobilenetv1</span><br></pre></td></tr></table></figure></div>



<p><strong>COCO数据集</strong></p>
<p>COCO数据集用于centernet_resnet101、detr_efficientnetb3、detr_resnet50、yolov2_darknet19、yolov3_darknet53、yolov3_vargdarknet、yolov5x、preq_qat_fcos_efficientnetb0、preq_qat_fcos_efficientnetb2和preq_qat_fcos_efficientnetb3<strong>检测模型</strong>的评测， 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="https://cocodataset.org/#download" >COCO数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您将下载的数据集解压成如下结构，数据准备过程中如遇问题请联系地平线，示例中主要用到 <strong>annotations</strong> 文件夹下的instances_val2017.json标注文件和 <strong>images</strong> 中的图片：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── annotations    # 存放标注数据</span><br><span class="line">└── images         # 存放源图片</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_eval_preprocess -m model_name -i coco/coco_val2017/images -o ./pre_model_name</span><br></pre></td></tr></table></figure></div>



<p><strong>IMAGENET数据集</strong></p>
<p>ImageNet数据集用于efficientnasnet_m、efficientnasnet_s、efficientnet_lite0、 efficientnet_lite1、efficientnet_lite2、efficientnet_lite3、efficientnet_lite4、googlenet、 mobilenetv1、mobilenetv2、resnet18和vargconvnet<strong>分类模型</strong>的评测， 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="https://www.image-net.org/download.php" >ImageNet数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您将下载的数据集解压成如下结构，数据准备过程中如遇问题请联系地平线，示例中主要用到了标注文件val.txt 和 <strong>val</strong> 目录中的源图片:</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── val.txt</span><br><span class="line">└── val</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_eval_preprocess -m model_name -i imagenet/val -o ./pre_model_name</span><br></pre></td></tr></table></figure></div>



<p><strong>CITYSCAPES数据集</strong></p>
<p>Cityscapes数据集用于deeplabv3plus_efficientnetb0、deeplabv3plus_efficientnetm1、 deeplabv3plus_efficientnetm2和fastscnn_efficientnetb0模型的评测。 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="https://github.com/mcordts/cityscapesScripts" >Cityscapes数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您将下载的数据集解压成如下结构，数据准备过程中如遇问题请联系地平线，示例中主要用到了 <strong>.&#x2F;gtFine&#x2F;val</strong> 中的标注文件和 <strong>.&#x2F;leftImg8bit&#x2F;val</strong> 中的源图片。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── gtFine</span><br><span class="line">│   └── val</span><br><span class="line">│       ├── frankfurt</span><br><span class="line">│       ├── lindau</span><br><span class="line">│       └── munster</span><br><span class="line">└── leftImg8bit</span><br><span class="line">    └── val</span><br><span class="line">        ├── frankfurt</span><br><span class="line">        ├── lindau</span><br><span class="line">        └── munster</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hb_eval_preprocess -m model_name -i cityscapes/leftImg8bit/val -o ./pre_model_name</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p>QAT数据包预处理</p>
</blockquote>
<p>QAT模型数据预处理需要在x86仿真环境下 执行 <code>ai_benchmark_j5/j5/qat/tools/eval_preprocess</code> 中的前处理脚本。 下面将详细介绍示例包中每一个模型对应的数据集，以及对应数据集的预处理操作。</p>
<p><strong>FLYINGCHAIRS数据集</strong></p>
<p>FlyingChairs数据集用于pwcnet_opticalflow光流模型的评测。 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html" >FlyingChairs数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您将下载的数据集解压成如下结构，数据准备过程中如遇问题请联系地平线， 示例中主要用到了 <strong>FlyingChairs_release&#x2F;data</strong> 中的数据和 <strong>.&#x2F;FlyingChairs_train_val.txt</strong> 标注文件。 {id}_img1.ppm和{id}_img2.ppm是一个图像对，图像宽度大小是512，高度大小是384； id是从00001至22872的序号，每一图像对的标签是{id}_flow.flo。其中 <strong>FlyingChairs_train_val</strong> 文件是用于划分训练集和验证集，标签值为2表示验证集。</p>
<blockquote>
<p>光流模型是计算机视觉领域中用于描述图像中运动物体运动情况的一种模型。它基于图像中相邻帧之间的像素值差异，计算出像素点在时间上的位移，从而推断出物体在时间上的运动状态。</p>
</blockquote>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── FlyingChairs_release</span><br><span class="line">│   └── data</span><br><span class="line">│       ├── 00001_img1.ppm</span><br><span class="line">│       ├── 00001_img2.ppm</span><br><span class="line">│       └── 00001_flow.ppm</span><br><span class="line">├── FlyingChairs_train_val.txt</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 pwcnet_process.py --input_path=./flyingchairs/FlyingChairs_release/data/  --val_file=./flyingchairs/FlyingChairs_train_val.txt --output_path=./pre_pwcnet_opticalflow</span><br></pre></td></tr></table></figure></div>



<blockquote>
<p>IMAGENET数据集</p>
</blockquote>
<p>ImageNet数据集用于QAT分类模型mixvargenet、mobilenetv1、mobilenetv2、resnet50、swint和vargnetv2的评测。</p>
<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 imagenet.py --image-path=./standard_imagenet/val/ --save-path=./pre_model_name</span><br></pre></td></tr></table></figure></div>



<p><strong>CITYSPACE数据集</strong></p>
<p>Cityscapes数据集用于QAT分割模型mobilenet_unet的评测，不需要前处理直接使用验证集数据即可。</p>
<p><strong>VOC数据集</strong></p>
<p>VOC数据集用于检测模型yolov3_mobilenetv1的评测。</p>
<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 voc.py --image-path=./VOCdevkit/VOC2012/JPEGImages/ --save-path=./pre_yolov3_mobilenetv1</span><br></pre></td></tr></table></figure></div>



<p><strong>COCO数据集</strong></p>
<p>COCO该数据集用于QAT检测模型fcos_efficientnetb0和retinanet的评测。</p>
<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 fcos_process.py --image-path=./mscoco/images/val2017/  --label-path=./mscoco/images/annotations/instances_val2017.json --save-path=./pre_fcos_efficientnetb0</span><br><span class="line"></span><br><span class="line">python3 retinanet_process.py --image-path=./mscoco/images/val2017/  --label-path=./mscoco/images/annotations/instances_val2017.json --save-path=./pre_retinanet</span><br></pre></td></tr></table></figure></div>



<p><strong>KITTI3D数据集</strong></p>
<p>kitti3d数据集用于QAT检测模型pointpillars_kitti_car的评测。 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d" >kitti3d数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您下载以下压缩包，数据准备过程中如遇问题请联系地平线。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── kitti3d</span><br><span class="line">    ├── data_object_calib.zip        # camera calibration matrices of object data set</span><br><span class="line">    ├── data_object_image_2.zip      # left color images of object data set</span><br><span class="line">    ├── data_object_label_2.zip      # taining labels of object data set</span><br><span class="line">    └── data_object_veloodyne.zip    # velodyne point cloud</span><br></pre></td></tr></table></figure></div>

<p>建议您将下载的数据集解压成如下结构：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── kitti3d_origin</span><br><span class="line">    ├── ImageSets</span><br><span class="line">    │   ├── test.txt</span><br><span class="line">    │   ├── train.txt</span><br><span class="line">    │   ├── trainval.txt</span><br><span class="line">    │   └── val.txt</span><br><span class="line">    ├── testing</span><br><span class="line">    │   ├── calib</span><br><span class="line">    │   ├── image_2</span><br><span class="line">    │   └── velodyne</span><br><span class="line">    └── training</span><br><span class="line">        ├── calib</span><br><span class="line">        ├── image_2</span><br><span class="line">        ├── label_2</span><br><span class="line">        └── velodyne</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 pointpillars_process.py --data-path=./kitti3d_origin  --save-path=./pre_kitti3d</span><br></pre></td></tr></table></figure></div>



<p><strong>CULANE数据集</strong></p>
<p>culane数据集用于QAT检测模型ganet的评测。 本数据集您可以从官网下载：<a class="link"   target="_blank" rel="noopener" href="https://xingangpan.github.io/projects/CULane.html" >culane数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 我们建议您下载以下压缩包，数据准备过程中如遇问题请联系地平线。</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── culane</span><br><span class="line">    ├── annotations_new.tar.gz</span><br><span class="line">    ├── driver_23_30frame.tar.gz</span><br><span class="line">    ├── driver_37_30frame.tar.gz</span><br><span class="line">    ├── driver_100_30frame.tar.gz</span><br><span class="line">    ├── driver_161_90frame.tar.gz</span><br><span class="line">    ├── driver_182_30frame.tar.gz</span><br><span class="line">    ├── driver_193_90frame.tar.gz</span><br><span class="line">    ├── laneseg_label_w16.tar.gz</span><br><span class="line">    └── list.tar.gz</span><br></pre></td></tr></table></figure></div>

<p>其中 <strong>annotations_new.tar.gz</strong> 需要最后解压，以对原始的注释文件进行更正，建议您将下载的数据集解压成如下结构：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── culane                     # 根目录</span><br><span class="line">    ├── driver_23_30frame      # 数据集和注释</span><br><span class="line">    │   ├── 05151640_0419.MP4  # 数据集的一段，包含每一帧图片</span><br><span class="line">    │   │   ├──00000.jpg       # 源图片</span><br><span class="line">    │   │   ├──00000.lines.txt # 注释文件，其中每个行给出车道标记关键点的x，y坐标</span><br><span class="line">    │   ......</span><br><span class="line">    ├── driver_37_30frame</span><br><span class="line">    ├── driver_100_30frame</span><br><span class="line">    ├── driver_161_90frame</span><br><span class="line">    ├── driver_182_30frame</span><br><span class="line">    ├── driver_193_90frame</span><br><span class="line">    ├── laneseg_label_w16      # 车道分段标签</span><br><span class="line">    └── list                   # 训练，验证，测试列表</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 ganet_process.py --image_path=./culane  --save_path=./pre_culan</span><br></pre></td></tr></table></figure></div>



<p><strong>NUSCENES数据集</strong></p>
<p>nuscenes数据集用于QAT检测模型fcos3d的评测。 本数据集您可以从官网下载： <a class="link"   target="_blank" rel="noopener" href="https://www.nuscenes.org/nuscenes#download" >nuscenes数据集官网下载地址 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> ， 数据准备过程中如遇问题请联系地平线，我们建议您下载以下压缩包：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">├── Nuscenes</span><br><span class="line">    ├── nuScenes-map-expansion-v1.3.zip</span><br><span class="line">    ├── nuScenes-map-expansion-v1.2.zip</span><br><span class="line">    ├── nuScenes-map-expansion-v1.1.zip</span><br><span class="line">    ├── nuScenes-map-expansion-v1.0.zip</span><br><span class="line">    ├── v1.0-mini.tar</span><br><span class="line">    ├── v1.0-test_blobs.tar</span><br><span class="line">    ├── v1.0-test_meta.tar</span><br><span class="line">    ├── v1.0-trainval01_blobs.tar</span><br><span class="line">    ├── v1.0-trainval02_blobs.tar</span><br><span class="line">    ├── v1.0-trainval03_blobs.tar</span><br><span class="line">    ├── v1.0-trainval04_blobs.tar</span><br><span class="line">    ├── v1.0-trainval05_blobs.tar</span><br><span class="line">    ├── v1.0-trainval06_blobs.tar</span><br><span class="line">    ├── v1.0-trainval07_blobs.tar</span><br><span class="line">    ├── v1.0-trainval08_blobs.tar</span><br><span class="line">    ├── v1.0-trainval09_blobs.tar</span><br><span class="line">    ├── v1.0-trainval10_blobs.tar</span><br><span class="line">    └── v1.0-trainval_meta.tar</span><br></pre></td></tr></table></figure></div>

<p>建议您将下载的数据集解压成如下结构：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── Nuscenes</span><br><span class="line">    ├── can_bus</span><br><span class="line">    ├── maps</span><br><span class="line">    ├── nuscenes</span><br><span class="line">    │   └── meta</span><br><span class="line">    │       ├── maps</span><br><span class="line">    │       ├── v1.0-mini</span><br><span class="line">    │       └── v1.0-trainval</span><br><span class="line">    ├── samples</span><br><span class="line">    ├── sweeps</span><br><span class="line">    ├── v1.0-mini</span><br><span class="line">    └── v1.0-trainval</span><br></pre></td></tr></table></figure></div>

<p>对数据集进行预处理：</p>
<p> <strong>注意：脚本除了生成预处理图片外，还会对待使用的相机内参进行处理，生成相应的相机内参配置文件。</strong></p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 fcos3d_process.py --src-data-dir=./Nuscenes --file-path=../../script/config/model/data_name_list/nuscenes_names.txt --save-path=./processed_fcos3d_images</span><br></pre></td></tr></table></figure></div>

<p><u>使用前需要修改脚本中的数据集路径及保存路径使脚本正常运行。</u></p>
<h6 id="数据挂载"><a href="#数据挂载" class="headerlink" title="数据挂载"></a>数据挂载</h6><blockquote>
<p>&#x2F;etc&#x2F;exports 是 Linux 系统下用于配置 NFS（Network File System，网络文件系统）共享服务的配置文件。该文件用于定义本地文件系统的共享目录，并且可以指定允许哪些客户端或者主机访问该共享目录。在 NFS 服务启动时，系统会读取该文件中的配置信息，并在启动过程中使用这些信息来创建共享目录，以便其他主机可以通过网络访问它们。</p>
<p>具体来说，&#x2F;etc&#x2F;exports 文件中每一行都代表一个共享目录的定义，每行包含一个本地共享目录的路径和一组允许访问共享目录的参数。</p>
</blockquote>
<p>由于数据集相对较大，不适合直接放在开发板上，可以采用挂载的方式供开发板读取。</p>
<p><u>服务器PC端：</u></p>
<ol>
<li>编辑 &#x2F;etc&#x2F;exports, 增加一行： <code>/nfs *(insecure,rw,sync,all_squash,anonuid=1000,anongid=1000,no_subtree_check)</code>。 <code>/nfs</code> 表示本机挂载路径，可替换为用户指定目录。</li>
<li>执行命令 <code>exportfs -a -r</code>，使&#x2F;etc&#x2F;exports 生效。</li>
</ol>
<p><u>板端：</u></p>
<ol>
<li>创建需要挂载的目录： <code>mkdir -p /mnt</code>。</li>
<li><code>mount -t nfs &#123;PC端IP&#125;:/nfs /mnt -o nolock</code>。</li>
</ol>
<p>完成将PC端的 <strong>&#x2F;nfs</strong> 文件夹挂载至板端 <strong>&#x2F;mnt</strong> 文件夹。 <strong>按照此方式，将包含预处理数据的文件夹挂载至板端， 并将 &#x2F;data 目录软链接至板端 &#x2F;ptq 或 &#x2F;qat 目录下，与 &#x2F;script 同级目录。</strong></p>
<blockquote>
<p>生成lst文件</p>
</blockquote>
<p>示例中精度计算脚本的运行流程是：</p>
<p>1.根据 <code>workflow_accurary.json</code> 中的 <code>image_list_file</code> 参数值，去寻找对应数据集的 <code>lst</code> 文件。</p>
<p>2.根据 <strong><code>lst</code> 文件存储的前处理文件路径信息，去加载每一个前处理文件，然后进行推理。</strong></p>
<p>因此生成预处理文件之后，需要生成对应的lst文件，将每一张前处理文件的路径写入到lst文件中，而这个路径与数据集在板端的存放位置有关。 这里我们推荐其存放位置与 <code>./data/dataset_name/pre_model_name</code> 预处理数据文件夹同级目录。</p>
<p>PTQ预处理数据集结构如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">|-- ptq</span><br><span class="line">|   |-- data</span><br><span class="line">|   |   |-- cityscapes</span><br><span class="line">|   |   |   |-- pre_deeplabv3plus_efficientnetb0</span><br><span class="line">|   |   |   |   |-- xxxx.bin                            # 前处理好的二进制文件</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_deeplabv3plus_efficientnetb0.lst    # lst文件：记录每一个前处理文件的路径</span><br><span class="line">|   |   |   |-- pre_deeplabv3plus_efficientnetm1</span><br><span class="line">|   |   |   |-- pre_deeplabv3plus_efficientnetm1.lst</span><br><span class="line">|   |   |   |-- pre_deeplabv3plus_efficientnetm2</span><br><span class="line">|   |   |   |-- pre_deeplabv3plus_efficientnetm2.lst</span><br><span class="line">|   |   |   |-- pre_fastscnn_efficientnetb0</span><br><span class="line">|   |   |   |-- pre_fastscnn_efficientnetb0.lst</span><br><span class="line">|   |   |-- coco</span><br><span class="line">|   |   |   |-- pre_centernet_resnet101</span><br><span class="line">|   |   |   |   |-- xxxx.bin</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_centernet_resnet101.lst</span><br><span class="line">|   |   |   |-- pre_yolov2_darknet19</span><br><span class="line">|   |   |   |-- pre_yolov2_darknet19.lst</span><br><span class="line">|   |   |   |-- pre_yolov3_darknet53</span><br><span class="line">|   |   |   |-- pre_yolov3_darknet53.lst</span><br><span class="line">|   |   |   |-- pre_yolov3_vargdarknet</span><br><span class="line">|   |   |   |-- pre_yolov3_vargdarknet.lst</span><br><span class="line">|   |   |   |-- pre_yolov5x</span><br><span class="line">|   |   |   |-- pre_yolov5x.lst</span><br><span class="line">|   |   |   |-- pre_preq_qat_fcos_efficientnetb0</span><br><span class="line">|   |   |   |-- pre_preq_qat_fcos_efficientnetb0.lst</span><br><span class="line">|   |   |   |-- pre_preq_qat_fcos_efficientnetb2</span><br><span class="line">|   |   |   |-- pre_preq_qat_fcos_efficientnetb2.lst</span><br><span class="line">|   |   |   |-- pre_preq_qat_fcos_efficientnetb3</span><br><span class="line">|   |   |   |-- pre_preq_qat_fcos_efficientnetb3.lst</span><br><span class="line">|   |   |-- imagenet</span><br><span class="line">|   |   |   |-- pre_efficientnasnet_m</span><br><span class="line">|   |   |   |   |-- xxxx.bin</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_efficientnasnet_m.lst</span><br><span class="line">|   |   |   |-- pre_efficientnasnet_s</span><br><span class="line">|   |   |   |-- pre_efficientnasnet_s.lst</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite0</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite0.lst</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite1</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite1.lst</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite2</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite2.lst</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite3</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite3.lst</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite4</span><br><span class="line">|   |   |   |-- pre_efficientnet_lite4.lst</span><br><span class="line">|   |   |   |-- pre_googlenet</span><br><span class="line">|   |   |   |-- pre_googlenet.lst</span><br><span class="line">|   |   |   |-- pre_mobilenetv1</span><br><span class="line">|   |   |   |-- pre_mobilenetv1.lst</span><br><span class="line">|   |   |   |-- pre_mobilenetv2</span><br><span class="line">|   |   |   |-- pre_mobilenetv2.lst</span><br><span class="line">|   |   |   |-- pre_resnet18</span><br><span class="line">|   |   |   |-- pre_resnet18.lst</span><br><span class="line">|   |   |   |-- pre_vargconvnet</span><br><span class="line">|   |   |   |-- pre_vargconvnet.lst</span><br><span class="line">|   |   |-- voc</span><br><span class="line">|   |   |   |-- pre_ssd_mobilenetv1</span><br><span class="line">|   |   |   |   |-- xxxx.bin</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_ssd_mobilenetv1.lst</span><br><span class="line">|   |-- model</span><br><span class="line">|   |   |-- ...</span><br><span class="line">|   |-- script</span><br><span class="line">|   |   |-- ...</span><br></pre></td></tr></table></figure></div>

<p>QAT预处理数据集结构如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">|-- qat</span><br><span class="line">|   |-- data</span><br><span class="line">|   |   |-- cityscapes</span><br><span class="line">|   |   |   |-- pre_mobilenet_unet</span><br><span class="line">|   |   |   |   |-- xxxx                   # 前处理好的数据</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_mobilenet_unet .lst    # lst文件：记录每一个前处理文件的路径</span><br><span class="line">|   |   |-- coco</span><br><span class="line">|   |   |   |-- pre_detr_efficientnetb3</span><br><span class="line">|   |   |   |   |-- xxxx</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_detr_efficientnetb3.lst</span><br><span class="line">|   |   |   |-- pre_detr_resnet50</span><br><span class="line">|   |   |   |-- pre_detr_resnet50.lst</span><br><span class="line">|   |   |   |-- pre_fcos_efficientnetb0</span><br><span class="line">|   |   |   |-- pre_fcos_efficientnetb0.lst</span><br><span class="line">|   |   |   |-- pre_retinanet</span><br><span class="line">|   |   |   |-- pre_retinanet.lst</span><br><span class="line">|   |   |-- imagenet</span><br><span class="line">|   |   |   |-- pre_mixvargenet</span><br><span class="line">|   |   |   |   |-- xxxx</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_mixvargenet.lst</span><br><span class="line">|   |   |   |-- pre_mobilenetv1</span><br><span class="line">|   |   |   |-- pre_mobilenetv1.lst</span><br><span class="line">|   |   |   |-- pre_mobilenetv2</span><br><span class="line">|   |   |   |-- pre_mobilenetv2.lst</span><br><span class="line">|   |   |   |-- pre_resnet50</span><br><span class="line">|   |   |   |-- pre_resnet50.lst</span><br><span class="line">|   |   |   |-- pre_swint</span><br><span class="line">|   |   |   |-- pre_swint.lst</span><br><span class="line">|   |   |   |-- pre_vargnetv2</span><br><span class="line">|   |   |   |-- pre_vargnetv2.lst</span><br><span class="line">|   |   |-- flyingchairs</span><br><span class="line">|   |   |   |-- pre_pwcnet_opticalflow</span><br><span class="line">|   |   |   |   |-- xxxx.bin</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_pwcnet_opticalflow.lst</span><br><span class="line">|   |   |-- kitti3d</span><br><span class="line">|   |   |   |-- pre_pointpillars_kitti_car</span><br><span class="line">|   |   |   |   |-- xxxx.bin</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_pointpillars_kitti_car.lst</span><br><span class="line">|   |   |-- voc</span><br><span class="line">|   |   |   |-- pre_yolov3_mobilenetv1</span><br><span class="line">|   |   |   |   |-- xxxx</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_yolov3_mobilenetv1.lst</span><br><span class="line">|   |   |-- culane</span><br><span class="line">|   |   |   |-- pre_ganet</span><br><span class="line">|   |   |   |   |-- xxxx</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_ganet.lst</span><br><span class="line">|   |   |-- nuscenes</span><br><span class="line">|   |   |   |-- pre_nuscenes</span><br><span class="line">|   |   |   |   |-- xxxx</span><br><span class="line">|   |   |   |   |-- ....</span><br><span class="line">|   |   |   |-- pre_nuscenes.lst</span><br><span class="line">|   |   |   |-- fcos3d_nuscenes_camconfig.txt</span><br><span class="line">|   |-- model</span><br><span class="line">|   |   |-- ...</span><br><span class="line">|   |-- script</span><br><span class="line">|   |   |-- ...</span><br></pre></td></tr></table></figure></div>

<p>与之对应的lst文件，参考生成方式如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find ../../../data/coco/pre_centernet_resnet101 -name &quot;*bin*&quot; &gt; ../../../data/coco/pre_centernet_resnet101.lst</span><br></pre></td></tr></table></figure></div>

<p>这样生成的lst文件中存储的路径为一个相对路径： <code>../../../data/coco/pre_centernet_resnet101/</code> ， 可以与 <code>workflow_accuracy.json</code> 默认的配置路径吻合。 如果需要更改前处理数据集的存放位置，则需要确保对应的 <code>lst</code> 文件可以被 <code>workflow_accuracy.json</code> 读取到； 其次需要确保程序根据 <code>lst</code> 中的路径信息，能读取到对应的前处理文件。</p>
<blockquote>
<p>模型推理</p>
</blockquote>
<p><strong>命令行参数说明</strong></p>
<p>accuracy.sh脚本内容如下：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ../../env.sh                              <span class="comment"># 加载基础配置</span></span><br><span class="line"><span class="built_in">export</span> SHOW_FPS_LOG=1                            <span class="comment"># 设置环境变量，打印fps级别log</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;app&#125;</span> \                                         <span class="comment"># 可执行程序，在accuracy.sh脚本中定义</span></span><br><span class="line">  --config_file=workflow_accuracy.json \         <span class="comment"># 加载精度测试workflow配置文件</span></span><br><span class="line">  --log_level=2                                  <span class="comment"># 设置log等级</span></span><br></pre></td></tr></table></figure></div>



<p><strong>配置文件说明</strong></p>
<p>以centernet_resnet101模型为例，workflow_accuracy.json 配置文件内容如下：</p>
<div class="highlight-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;input_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;input_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;preprocessed_image&quot;</span><span class="punctuation">,</span>         # 输入数据类型，支持图像或者bin文件，精度评测时使用预处理后的数据</span><br><span class="line">    <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">512</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;data_type&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;image_list_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../../data/coco/coco.lst&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;need_pre_load&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;limit&quot;</span><span class="punctuation">:</span> <span class="number">14</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;need_loop&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_cache&quot;</span><span class="punctuation">:</span> <span class="number">10</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;output_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;eval&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eval_enable&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;./eval.log&quot;</span>                  # 预测结果文件</span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;workflow&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;method_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;InferMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;unique_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;InferMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;core&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;model_file&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../../model/runtime/centernet_resnet101/centernet_resnet101_512x512_nv12.bin&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;thread_count&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PTQCenternetPostProcessMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;unique_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PTQCenternetPostProcessMethod&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method_config&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;class_num&quot;</span><span class="punctuation">:</span> <span class="number">80</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;score_threshold&quot;</span><span class="punctuation">:</span> <span class="number">0.0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;topk&quot;</span><span class="punctuation">:</span> <span class="number">100</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;det_name_list&quot;</span><span class="punctuation">:</span> <span class="string">&quot;../../config/model/data_name_list/coco_classes.names&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></div>

<p>挂载完数据后，登录开发板，执行 <strong>centernet_resnet101&#x2F;</strong> 目录下的accuracy.sh脚本，如下所示：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@j5dvb-hynix8G:/userdata/ptq/script/detection/centernet_resnet101<span class="comment"># sh accuracy.sh</span></span><br><span class="line">../../aarch64/bin/example --config_file=workflow_accuracy.json --log_level=2</span><br><span class="line">...</span><br><span class="line">I0419 03:14:51.158655 39555 infer_method.cc:107] Predict DoProcess finished.</span><br><span class="line">I0419 03:14:51.187361 39556 ptq_centernet_post_process_method.cc:558] PTQCenternetPostProcessMethod DoProcess finished, predict result: [&#123;<span class="string">&quot;bbox&quot;</span>:[-1.518860,71.691170,574.934631,638.294922],<span class="string">&quot;prob&quot;</span>:0.750647,<span class="string">&quot;label&quot;</span>:21,<span class="string">&quot;class_name&quot;</span>:<span class="string">&quot;</span></span><br><span class="line"><span class="string">I0118 14:02:43.636204 24782 ptq_centernet_post_process_method.cc:558] PTQCenternetPostProcessMethod DoProcess finished, predict result: [&#123;&quot;</span>bbox<span class="string">&quot;:[3.432283,164.936249,157.480042,264.276825],&quot;</span>prob<span class="string">&quot;:0.544454,&quot;</span>label<span class="string">&quot;:62,&quot;</span>class_name<span class="string">&quot;:&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>

<p>板端程序会在当前目录生成eval.log文件，该文件就是预测结果文件。</p>
<h6 id="精度计算"><a href="#精度计算" class="headerlink" title="精度计算"></a>精度计算</h6><p><strong>注意：精度计算部分请在docker环境或linux环境下操作。</strong></p>
<blockquote>
<p>PTQ模型精度计算</p>
</blockquote>
<p>PTQ模型其精度计算的脚本在 <strong>ptq&#x2F;tools&#x2F;python_tools</strong> 目录下，包括 <strong>accuracy_tools</strong> 中的：</p>
<ul>
<li>cls_eval.py是用来计算分类模型的精度；</li>
<li>coco_det_eval.py是用来计算使用COCO数据集评测的检测模型的精度；</li>
<li>parsing_eval.py是用来计算使用Cityscapes数据集评测的分割模型的精度；</li>
<li>voc_det_eval.py是用来计算使用VOC数据集评测的检测模型的精度。</li>
</ul>
<p><strong>分类模型</strong></p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 cls_eval.py --log_file=eval.log --gt_file=val.txt</span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>log_file</code>：分类模型的预测结果文件。</li>
<li><code>gt_file</code>：CIFAR-10和ImageNet数据集的标注文件。</li>
</ul>
<p><strong>检测模型</strong></p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用COCO数据集的检测模型精度计算方式如下：</span></span><br><span class="line">python3 coco_det_eval.py --eval_result_path=eval.log --annotation_path=instances_val2017.json		<span class="comment">#eval_result_path：检测模型的预测结果文件。annotation_path：COCO数据集的标注文件。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用VOC数据集的检测模型精度计算方式如下：</span></span><br><span class="line">python3 voc_det_eval.py --eval_result_path=eval.log --annotation_path=../Annotations --val_txt_path=../val.txt			<span class="comment">#eval_result_path：检测模型的预测结果文件。annotation_path：VOC数据集的标注文件。val_txt_path：VOC数据集中ImageSets/Main文件夹下的val.txt文件。</span></span><br></pre></td></tr></table></figure></div>



<p><strong>分割模型</strong></p>
<ul>
<li>使用Cityscapes数据集的分割模型精度计算方式如下：</li>
</ul>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 parsing_eval.py --log_file=eval.log --gt_path=cityscapes/gtFine/val</span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>log_file</code>：分割模型的预测结果文件。</li>
<li><code>gt_path</code>：Cityscapes数据集的标注文件。</li>
</ul>
<blockquote>
<p>QAT模型精度计算</p>
</blockquote>
<p>QAT模型其精度计算的脚本在 <strong>qat&#x2F;tools&#x2F;python_tools&#x2F;</strong> 目录下，包括 <strong>accuracy_tools</strong> 中的：</p>
<ul>
<li>cls_eval.py是用来计算分类模型的精度；</li>
<li>detr_eval.py是用来计算detr检测模型的精度；</li>
<li>retinanet_eval.py是用来计算retinanet检测模型的精度；</li>
<li>fcos_eval.py是用来计算fcos检测模型的精度；</li>
<li>parsing_eval.py是用来计算使用Cityscapes数据集评测的分割模型的精度；</li>
<li>pwcnet_eval.py是用来计算使用FlyingChairs数据集评测的光流模型的精度；</li>
<li>yolov3_eval.py是用来计算yolov3检测模型的精度；</li>
<li>pointpillars_eval.py是用来计算pointpillars检测模型的精度；</li>
<li>ganet_eval.py是用来计算ganet检测模型的精度。</li>
<li>fcos3d_eval.py是用来计算fcos3d检测模型的精度。</li>
</ul>
<p><strong>分类模型</strong></p>
<p>使用CIFAR-10数据集和ImageNet数据集的分类模型计算方式如下：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 cls_eval.py --log_file=eval.log --gt_file=val.txt</span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>log_file</code>：分类模型的预测结果文件。</li>
<li><code>gt_file</code>：CIFAR-10和ImageNet数据集的标注文件。</li>
</ul>
<p><strong>检测模型</strong></p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用COCO数据集的检测模型精度计算方式示例如下：</span></span><br><span class="line">python3 fcos_eval.py --eval_result_path=eval.log --annotation_path=instances_val2017.json  --image_path=./mscoco/images/val2017/</span><br><span class="line"><span class="comment">#eval_result_path：fcos检测模型的预测结果文件。annotation_path：COCO数据集的标注文件。image_path：COCO原始数据集。</span></span><br><span class="line">python3 retinanet_eval.py --eval_result_path=eval.log --annotation_path=instances_val2017.json --image_path=./mscoco/images/val2017/		<span class="comment">#eval_result_path：retinanet检测模型的预测结果文件。annotation_path：COCO数据集的标注文件。image_path：COCO原始数据集。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用VOC数据集的检测模型精度计算方式示例如下：</span></span><br><span class="line">python3 yolov3_eval.py --eval_result_path=eval.log --annotation_path=../Annotations --val_txt_path=../val.txt --image_height=416  --image_width=416		<span class="comment">#eval_result_path：检测模型的预测结果文件。annotation_path：VOC数据集的标注文件。val_txt_path：VOC数据集中ImageSets/Main文件夹下的val.txt文件。image_height: 图像的高度。image_width: 图像的宽度。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用KITTI数据集的检测模型精度计算方式如下：</span></span><br><span class="line">python3 pointpillars_eval.py --eval_result_path=eval.log --annotation_path=./val_gt_infos.pkl		<span class="comment">#eval_result_path：检测模型的预测结果文件。annotation_path：预处理过程中生成的kitti3d数据集的标注文件val_gt_infos.pkl。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用culane数据集的检测模型精度计算方式如下：</span></span><br><span class="line">python3 ganet_eval.py --eval_path=eval.log --image_path=./culane		<span class="comment">#eval_path：检测模型的预测结果文件。image_path：culane数据集。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用nuscenes数据集的检测模型精度计算方式如下：</span></span><br><span class="line">python3 fcos3d_eval.py --eval_result_path=eval.log --image_path=./Nuscenes		<span class="comment">#eval_result_path：检测模型的预测结果文件。image_path：nuscenes数据集。</span></span><br></pre></td></tr></table></figure></div>



<p><strong>分割模型</strong></p>
<p>使用Cityscapes数据集的分割模型精度计算方式如下：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 parsing_eval.py --log_file=eval.log --gt_path=cityscapes/gtFine/val</span><br></pre></td></tr></table></figure></div>

<ul>
<li><code>log_file</code>：分割模型的预测结果文件。</li>
<li><code>gt_path</code>：Cityscapes数据集的标注文件。</li>
</ul>
<p><strong>光流模型</strong></p>
<p>使用FlyingChairs数据集的光流模型精度计算方式如下：</p>
<div class="highlight-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">python3 parsing_eval.py --log_file=eval.log --gt_path=./flyingchairs/FlyingChairs_release/data/  --val_file=./flyingchairs/FlyingChairs_train_val.txt</span><br></pre></td></tr></table></figure></div>

<p>注解</p>
<ul>
<li><code>log_file</code>：光流模型的预测结果文件。</li>
<li><code>val_file</code>：FlyingChairs数据集标签文件。</li>
<li><code>gt_path</code>：FlyingChairs数据集原始文件。</li>
</ul>
<h4 id="模型集成"><a href="#模型集成" class="headerlink" title="模型集成"></a>模型集成</h4><p>后处理集成主要有2个步骤，以CenterNet模型集成为例：</p>
<p>1.增加后处理文件ptq_centernet_post_process_method.cc，以及头文件ptq_centernet_post_process_method.h。</p>
<p>2.增加模型运行脚本及配置文件。</p>
<h5 id="后处理文件添加"><a href="#后处理文件添加" class="headerlink" title="后处理文件添加"></a>后处理文件添加</h5><p>后处理代码文件可直接复用src&#x2F;method目录下任意后处理文件，主要修改 <code>InitFromJsonString</code> 函数，以及 <code>PostProcess</code> 函数即可。</p>
<p><code>InitFromJsonString</code> 函数主要是读取workflow.json中的后处理相关的参数配置，用户可自定义设置相应的输入参数。 <code>PostProcess</code> 函数主要完成后处理的逻辑。</p>
<p>后处理 <code>.cc文件</code> 放置于 <strong>ai_benchmark&#x2F;code&#x2F;src&#x2F;method&#x2F;</strong> 路径下， <code>.h头文件</code> 放置于 <strong>ai_benchmark&#x2F;code&#x2F;include&#x2F;method&#x2F;</strong> 路径下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">|--ai_benchmark</span><br><span class="line">|  |--code                                                 # 示例源码</span><br><span class="line">|  |  |--include</span><br><span class="line">|  |  |  |--method                                         # 在此文件夹中添加头文件</span><br><span class="line">|  |  |  |  |--qat_fcos_post_process_method.h</span><br><span class="line">|  |  |  |  |--......</span><br><span class="line">|  |  |--src</span><br><span class="line">|  |  |  |--method                                         # 在此文件夹中添加后处理.cc文件</span><br><span class="line">|  |  |  |  |--qat_fcos_post_process_method.cc</span><br><span class="line">|  |  |  |  |--......</span><br></pre></td></tr></table></figure></div>



<h5 id="增加模型运行脚本及配置文件"><a href="#增加模型运行脚本及配置文件" class="headerlink" title="增加模型运行脚本及配置文件"></a>增加模型运行脚本及配置文件</h5><p>脚本目录结构如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">|--ai_benchmark</span><br><span class="line">|  |--j5/ptq/script                                       # 示例脚本文件夹</span><br><span class="line">|  |  |--detection</span><br><span class="line">|  |  |  |--centernet_resnet101</span><br><span class="line">|  |  |  |  |--accuracy.sh                                # 精度测试脚本</span><br><span class="line">|  |  |  |  |--fps.sh                                     # 性能测试脚本</span><br><span class="line">|  |  |  |  |--latency.sh                                 # 单帧延时示例脚本</span><br><span class="line">|  |  |  |  |--workflow_accuracy.json                     # 精度配置文件</span><br><span class="line">|  |  |  |  |--workflow_fps.json                          # 性能配置文件</span><br><span class="line">|  |  |  |  |--workflow_latency.json                      # 单帧延时配置文件</span><br></pre></td></tr></table></figure></div>



<h4 id="辅助工具-1"><a href="#辅助工具-1" class="headerlink" title="辅助工具"></a>辅助工具</h4><h5 id="日志-1"><a href="#日志-1" class="headerlink" title="日志"></a>日志</h5><p>日志主要包括 <strong>示例日志</strong> 和 <strong>DNN日志</strong> 两部分。 其中示例日志是指交付包示例代码中所应用的日志， DNN日志是指嵌入式runtime库中的日志。 用户根据不同的需求可以设置不同的日志。</p>
<h6 id="示例日志"><a href="#示例日志" class="headerlink" title="示例日志"></a>示例日志</h6><p>1.日志等级。</p>
<p>示例日志主要采用glog中的vlog，主要分为四个自定义等级：</p>
<ul>
<li><code>0</code> (SYSTEM)，该等级主要用来输出报错信息；</li>
<li><code>1</code> (REPORT)，该等级在示例代码中主要用来输出性能数据；</li>
<li><code>2</code> (DETAIL)，该等级在示例代码中主要用来输出系统当前状态信息；</li>
<li><code>3</code> (DEBUG)，该等级在示例代码中主要用来输出调试信息。</li>
</ul>
<p>日志等级设置规则：假设设置了级别为 <code>P</code>，如果发生了一个级别 <code>Q</code> 比 <code>P</code> 低， 则可以启动，否则屏蔽掉；默认DEBUG&gt;DETAIL&gt;REPORT&gt;SYSTEM。</p>
<p>2.日志等级设置。</p>
<p>通过 <code>log_level</code> 参数来设置日志等级，在运行示例的时候，指定 <code>log_level</code> 参数来设置等级， 比如指定 <code>log_level=0</code>，即输出SYSTEM日志；如果指定 <code>log_level=3</code>，则输出DEBUG、DETAIL、REPORT和SYSTEM日志。</p>
<h6 id="dnn日志"><a href="#dnn日志" class="headerlink" title="dnn日志"></a>dnn日志</h6><p>关于 <code>dnn</code> 日志的配置，请阅读BPU SDK API手册中的 <a class="link"   target="_blank" rel="noopener" href="https://developer.horizon.ai/api/v1/fileData/horizon_j5_open_explorer_cn_doc/runtime/source/bpu_sdk_api/source/bpu_sdk_api_doc.html#bpu-sdk-config" >配置信息 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 一节内容。</p>
<h5 id="算子耗时"><a href="#算子耗时" class="headerlink" title="算子耗时"></a>算子耗时</h5><p>对OP性能的统计是通过设置 <code>HB_DNN_PROFILER_LOG_PATH</code> 环境变量实现的。 对该变量的类型和取值说明如下：</p>
<p><code>HB_DNN_PROFILER_LOG_PATH=$&#123;path&#125;</code>：表示OP节点dump的输出路径，程序正常运行完退出后，产生profiler.log文件。</p>
<p>以下代码块以mobilenetv1模型为例，开启单线程同时RunModel，设置 <code>export HB_DNN_PROFILER_LOG_PATH=./</code>，则统计输出的信息如下：</p>
<div class="highlight-container" data-rel="Json"><figure class="iseeu highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">1</span><span class="punctuation">&#123;</span></span><br><span class="line"> <span class="number">2</span>  <span class="attr">&quot;perf_result&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"> <span class="number">3</span>    <span class="attr">&quot;FPS&quot;</span><span class="punctuation">:</span> <span class="number">3492.5347070636512</span><span class="punctuation">,</span></span><br><span class="line"> <span class="number">4</span>    <span class="attr">&quot;average_latency&quot;</span><span class="punctuation">:</span> <span class="number">2.1842353343963623</span></span><br><span class="line"> <span class="number">5</span>  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="number">6</span>  <span class="attr">&quot;running_condition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"> <span class="number">7</span>    <span class="attr">&quot;core_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"> <span class="number">8</span>    <span class="attr">&quot;frame_count&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span></span><br><span class="line"> <span class="number">9</span>    <span class="attr">&quot;model_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/jenkins/workspace/oolchain_tc_sys_release_j5_1.7.0/j5_toolchain/samples/03_classification/01_mobilenet/mapper/model_output/mobilenetv1_224x224_nv12&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">10</span>    <span class="attr">&quot;run_time&quot;</span><span class="punctuation">:</span> <span class="number">57.265</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">11</span>    <span class="attr">&quot;thread_num&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"><span class="number">12</span>  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="number">13</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="number">14</span>***</span><br><span class="line"><span class="number">15</span><span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">16</span>  <span class="attr">&quot;chip_latency&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">17</span>    <span class="attr">&quot;BPU_inference_time_cost&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">18</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">1.985635</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">19</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">2.055</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">20</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">1.047</span></span><br><span class="line"><span class="number">21</span>    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">22</span>    <span class="attr">&quot;CPU_inference_time_cost&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">23</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">0.07651</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">24</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">0.23300000000000004</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">25</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">0.069</span></span><br><span class="line"><span class="number">26</span>    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="number">27</span>  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">28</span>  <span class="attr">&quot;model_latency&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">29</span>    <span class="attr">&quot;BPU_MOBILENET_subgraph_0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">30</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">1.985635</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">31</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">2.055</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">32</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">1.047</span></span><br><span class="line"><span class="number">33</span>    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">34</span>    <span class="attr">&quot;Dequantize_fc7_1_HzDequantize&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">35</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">0.03118</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">36</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">0.081</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">37</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">0.029</span></span><br><span class="line"><span class="number">38</span>    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">39</span>    <span class="attr">&quot;MOBILENET_subgraph_0_output_layout_convert&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">40</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">0.009460000000000001</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">41</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">0.033</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">42</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">0.008</span></span><br><span class="line"><span class="number">43</span>    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">44</span>    <span class="attr">&quot;Preprocess&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">45</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">0.005860000000000001</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">46</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">0.037</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">47</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">0.004</span></span><br><span class="line"><span class="number">48</span>    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">49</span>    <span class="attr">&quot;Softmax_prob&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">50</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">0.030010000000000002</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">51</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">0.082</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">52</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">0.028</span></span><br><span class="line"><span class="number">53</span>    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="number">54</span>  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">55</span>  <span class="attr">&quot;task_latency&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">56</span>    <span class="attr">&quot;TaskPendingTime&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">57</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">0.019245</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">58</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">0.145</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">59</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">0.008</span></span><br><span class="line"><span class="number">60</span>    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">61</span>    <span class="attr">&quot;TaskRunningTime&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="number">62</span>      <span class="attr">&quot;avg_time&quot;</span><span class="punctuation">:</span> <span class="number">2.12983</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">63</span>      <span class="attr">&quot;max_time&quot;</span><span class="punctuation">:</span> <span class="number">2.208</span><span class="punctuation">,</span></span><br><span class="line"><span class="number">64</span>      <span class="attr">&quot;min_time&quot;</span><span class="punctuation">:</span> <span class="number">1.427</span></span><br><span class="line"><span class="number">65</span>    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="number">66</span>  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="number">67</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></div>

<p>以上输出了 <code>model_latency</code> 和 <code>task_latency</code>。其 中model_latency中输出了模型每个OP运行所需要的耗时情况，task_latency中输出了模型运行中各个task模块的耗时情况。</p>
<h5 id="dump工具"><a href="#dump工具" class="headerlink" title="dump工具"></a>dump工具</h5><p>通过开启 <code>HB_DNN_DUMP_PATH</code> 这个环境变量可以dump出模型推理过程中每个节点的输入和输出。 通过dump工具，可以排查模拟器和真机是否存在一致性问题：即相同模型，相同输入，真机和模拟器的输出结果是否完全相同。</p>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li><strong>标题:</strong> J5</li>
        <li><strong>作者:</strong> Airex Yu</li>
        <li><strong>创建于:</strong> 2023-04-13 15:49:21</li>
        
            <li>
                <strong>更新于:</strong> 2023-07-04 12:04:28
            </li>
        
        <li>
            <strong>链接:</strong> http://example.com/2023/04/13/J5/
        </li>
        <li>
            <strong>版权声明:</strong> 本文章采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a> 进行许可。
        </li>
    </ul>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/ONNX/">#ONNX</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/J5/">#J5</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/ISP/">#ISP</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E9%A1%B9%E7%9B%AE/">#项目</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E7%83%A7%E5%86%99%E9%95%9C%E5%83%8F/">#烧写镜像</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/PTQ/">#PTQ</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/Docker/">#Docker</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%BC%80%E5%8F%91/">#嵌入式开发</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E6%B5%AE%E7%82%B9%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%AE%9A%E7%82%B9%E6%A8%A1%E5%9E%8B/">#浮点模型转定点模型</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/%E5%9C%B0%E5%B9%B3%E7%BA%BF/">#地平线</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2023/05/26/Docker/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">Docker</span>
                                    <span class="post-nav-item">上一篇</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/04/06/MPI/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">MPI</span>
                                    <span class="post-nav-item">下一篇</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
                <div class="comment-container">
                    <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;评论
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-pjax>
        import { init } from 'https://evan.beee.top/js/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">此页目录</div>
        <div class="page-title">J5</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#J5-ISP%E8%BD%AF%E7%A1%AC%E4%BB%B6%E6%80%BB%E4%BD%93%E4%BB%8B%E7%BB%8D"><span class="nav-text">J5 ISP软硬件总体介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A"><span class="nav-text">ISP名词解释</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP-pipeline%E4%BB%8B%E7%BB%8D"><span class="nav-text">ISP pipeline介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#J5%E6%B5%81%E7%A8%8B"><span class="nav-text">J5流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#J5-ISP-feature"><span class="nav-text">J5 ISP feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#J5-ISP%E6%80%A7%E8%83%BD"><span class="nav-text">J5 ISP性能</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E7%A1%AC%E4%BB%B6%E5%8E%9F%E7%90%86"><span class="nav-text">ISP硬件原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">ISP工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%BC%8F"><span class="nav-text">ISP调度模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E5%85%B8%E5%9E%8B%E4%B8%AD%E6%96%AD%E6%97%B6%E5%BA%8F"><span class="nav-text">ISP典型中断时序</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84"><span class="nav-text">ISP软件架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84overview"><span class="nav-text">ISP 软件架构overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E8%BD%AF%E4%BB%B6feature"><span class="nav-text">ISP软件feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E8%BD%AF%E4%BB%B6%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%8E%E6%8E%A7%E5%88%B6%E6%B5%81"><span class="nav-text">ISP软件数据流与控制流</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-firmware%E7%9B%B8%E4%BA%92%E5%85%B3%E7%B3%BB"><span class="nav-text">ISP firmware相互关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E8%BD%AF%E4%BB%B6%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP软件流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E8%BD%AF%E4%BB%B6%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP软件初始化与工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-2A-amp-ISP-kernel-drv%E7%9A%84%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP 2A &amp; ISP kernel drv的交互流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E5%AF%B9%E5%A4%96API%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP对外API使用流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E5%AF%B9%E5%A4%96API"><span class="nav-text">ISP对外API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JSP%E5%9C%A8%E7%BA%BFtuning%E6%B5%81%E7%A8%8B"><span class="nav-text">JSP在线tuning流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#J5-ISP%E7%B3%BB%E7%BB%9F%E9%A9%B1%E5%8A%A8%E5%AE%9E%E7%8E%B0%E4%BB%8B%E7%BB%8D"><span class="nav-text">J5 ISP系统驱动实现介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E8%BD%AF%E4%BB%B6%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"><span class="nav-text">ISP驱动软件整体框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E6%A1%86%E6%9E%B6"><span class="nav-text">ISP驱动框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-%E8%AE%BE%E5%A4%87%E6%8E%A5%E5%85%A5%E6%80%BB%E4%BD%93%E9%80%9A%E8%B7%AF"><span class="nav-text">ISP 设备接入总体通路</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E4%BA%8B%E4%BB%B6%E3%80%81%E7%8A%B6%E6%80%81%E6%9C%BA%E3%80%81%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E4%BB%8B%E7%BB%8D"><span class="nav-text">ISP驱动事件、状态机、线程调度介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E4%B8%AD%E6%96%AD%E4%BA%8B%E4%BB%B6"><span class="nav-text">ISP驱动中断事件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-FSM%E7%8A%B6%E6%80%81%E6%9C%BA%E8%BD%AE%E8%BD%AC"><span class="nav-text">ISP FSM状态机轮转</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E4%BA%8B%E4%BB%B6%E8%BD%AE%E8%BD%AC"><span class="nav-text">ISP事件轮转</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E7%BA%BF%E7%A8%8B"><span class="nav-text">ISP驱动线程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-text">ISP内存管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4"><span class="nav-text">ISP驱动内存空间</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP数据处理流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP统计数据更新流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-command-API%E6%B5%81%E7%A8%8B%EF%BC%88%E6%8E%A8%E5%8A%A8%E4%BA%8B%E4%BB%B6%EF%BC%8C%E6%B7%BB%E5%8A%A0%E4%BA%8B%E4%BB%B6%EF%BC%89"><span class="nav-text">ISP command API流程（推动事件，添加事件）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-command-api%E7%B1%BB%E5%9E%8B"><span class="nav-text">ISP command api类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP%E9%A9%B1%E5%8A%A8%E5%A4%84%E7%90%86%E6%97%B6%E5%BA%8F%E6%B5%81%E7%A8%8B"><span class="nav-text">ISP驱动处理时序流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#J5-Tuning%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%E4%BB%8B%E7%BB%8D"><span class="nav-text">J5 Tuning准备工作介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#AE-x2F-AWB%E4%BB%8B%E7%BB%8D"><span class="nav-text">AE&#x2F;AWB介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE"><span class="nav-text">统计数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AE%E4%BB%8B%E7%BB%8D"><span class="nav-text">AE介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AE%E6%B5%8B%E5%85%89%E6%96%B9%E5%BC%8F"><span class="nav-text">AE测光方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AWB%E4%BB%8B%E7%BB%8D"><span class="nav-text">AWB介绍</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sensor%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E5%92%8C%E9%AA%8C%E8%AF%81"><span class="nav-text">sensor驱动开发和验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sensor%E9%A9%B1%E5%8A%A8%E5%AE%9E%E7%8E%B0"><span class="nav-text">sensor驱动实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sensor%E9%A9%B1%E5%8A%A8%E4%BB%8B%E7%BB%8D"><span class="nav-text">sensor驱动介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A9%B1%E5%8A%A8%E5%B1%82%E6%8E%A7%E5%88%B6%E5%AE%9E%E7%8E%B0"><span class="nav-text">驱动层控制实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E5%B1%82%E6%8E%A7%E5%88%B6%E5%AE%9E%E7%8E%B0"><span class="nav-text">用户层控制实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sensor%E9%A9%B1%E5%8A%A8%E9%AA%8C%E8%AF%81"><span class="nav-text">sensor驱动验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tuning%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D"><span class="nav-text">Tuning工具使用介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Control-Tool"><span class="nav-text">Control Tool</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HobotPlayer"><span class="nav-text">HobotPlayer</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tuning%E5%8F%82%E6%95%B0%E9%83%A8%E7%BD%B2"><span class="nav-text">Tuning参数部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Tuning%E5%8F%82%E6%95%B0"><span class="nav-text">Tuning参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tuning%E5%8F%82%E6%95%B0%E7%BC%96%E8%AF%91"><span class="nav-text">Tuning参数编译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tuning%E5%8F%82%E6%95%B0%E9%83%A8%E7%BD%B2-1"><span class="nav-text">Tuning参数部署</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tuning%E5%AE%9E%E6%88%98%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB"><span class="nav-text">Tuning实战经验分享</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ISP-Feature-x2F-Pipeline%E5%8F%8A%E5%AE%A2%E8%A7%82%E7%9F%AB%E6%AD%A3"><span class="nav-text">ISP Feature&#x2F;Pipeline及客观矫正</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-Feature"><span class="nav-text">ISP Feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ISP-Algorithm-block-diagram-part"><span class="nav-text">ISP Algorithm block diagram-part</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#J5-%E8%B0%83%E8%AF%95%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E4%BB%8B%E7%BB%8D"><span class="nav-text">J5 调试环境及基本操作介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hobot-player"><span class="nav-text">Hobot player</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Control-Tool-1"><span class="nav-text">Control Tool</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tuning%E5%8F%82%E6%95%B0%E7%BC%96%E8%AF%91-1"><span class="nav-text">Tuning参数编译</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Color%E6%A8%A1%E5%9D%97-AWB-x2F-CCM"><span class="nav-text">Color模块-AWB&#x2F;CCM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AWB-Auto-white-balance-algorithm"><span class="nav-text">AWB - Auto white balance algorithm</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D-x3D"><span class="nav-text">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#J5-EVM%E5%BC%80%E5%8F%91%E5%A5%97%E4%BB%B6%E7%94%A8%E6%88%B7%E6%89%8B%E5%86%8C"><span class="nav-text">J5 EVM开发套件用户手册</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A1%AC%E4%BB%B6%E5%B9%B3%E5%8F%B0%E4%BB%8B%E7%BB%8D"><span class="nav-text">硬件平台介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8A%AF%E7%89%87%E6%A1%86%E5%9B%BE"><span class="nav-text">芯片框图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%8F%91%E6%9D%BF%E5%AE%9E%E7%89%A9%E5%9B%BE"><span class="nav-text">开发板实物图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%96%E8%AE%BE%E5%AE%89%E8%A3%85"><span class="nav-text">外设安装</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7"><span class="nav-text">软件开发工具</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E6%A1%86%E5%9B%BE"><span class="nav-text">系统框图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="nav-text">开发工具目录结构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%BF%E7%AB%AF%E8%BF%9E%E6%8E%A5%E6%96%B9%E6%B3%95"><span class="nav-text">板端连接方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E5%8F%A3%E8%BF%9E%E6%8E%A5"><span class="nav-text">网口连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%B2%E5%8F%A3%E6%8E%A5%E5%8F%A3"><span class="nav-text">串口接口</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E9%95%9C%E5%83%8F%E8%AF%B4%E6%98%8E"><span class="nav-text">编译镜像说明</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-text">环境搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E5%91%BD%E4%BB%A4"><span class="nav-text">编译命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0"><span class="nav-text">编译参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E9%85%8D%E7%BD%AE"><span class="nav-text">编译配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E8%BE%93%E5%87%BA"><span class="nav-text">编译输出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AD%BE%E5%90%8D%E5%8A%A0%E5%AF%86"><span class="nav-text">签名加密</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9D%97%E7%BC%96%E8%AF%91"><span class="nav-text">模块编译</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%83%A7%E5%86%99%E9%95%9C%E5%83%8F%E8%AF%B4%E6%98%8E"><span class="nav-text">烧写镜像说明</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%B0%E5%B9%B3%E7%BA%BF%E7%83%A7%E5%86%99%E5%B7%A5%E5%85%B7"><span class="nav-text">地平线烧写工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UART"><span class="nav-text">UART</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Uboot-1"><span class="nav-text">Uboot</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SD"><span class="nav-text">SD</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E6%A3%80%E6%9F%A5"><span class="nav-text">验证检查</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E7%89%88%E6%9C%AC"><span class="nav-text">系统版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8A%B6%E6%80%81%E6%A3%80%E6%9F%A5%EF%BC%9AMCore"><span class="nav-text">状态检查：MCore</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7"><span class="nav-text">常用工具</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9C%B0%E5%B9%B3%E7%BA%BF%E5%BE%81%E7%A8%8B5-%E8%8A%AF%E7%89%87%E7%AE%97%E6%B3%95%E5%B7%A5%E5%85%B7%E9%93%BE"><span class="nav-text">地平线征程5 芯片算法工具链</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A7%E5%93%81%E7%AE%80%E4%BB%8B"><span class="nav-text">产品简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="nav-text">环境安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"><span class="nav-text">快速入门</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%AE%E7%82%B9%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%AE%9A%E7%82%B9%E6%A8%A1%E5%9E%8B%E6%89%8B%E5%86%8C"><span class="nav-text">浮点模型转定点模型手册</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2021-04-21-11-13-08-337-INFO-Convert-to-runtime-bin-file-successfully-2021-04-21-11-13-08-337-INFO-End-Model-Convert"><span class="nav-text">2021-04-21 11:13:08,337 INFO Convert to runtime bin file successfully!2021-04-21 11:13:08,337 INFO End Model Convert123*相似度信息也存在于 &#96;makertbin&#96; 的控制台输出内容中，在 &#96;makertbin&#96; 状态信息之前，其内容形式如下：*</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Node-ON-Subgraph-Type-Cosine-Similarity-Threshold"><span class="nav-text">Node    ON   Subgraph  Type     Cosine Similarity  Threshold</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%EF%BC%88runtime%EF%BC%89%E6%89%8B%E5%86%8C"><span class="nav-text">嵌入式应用开发（runtime）手册</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%8C%87%E5%AF%BC"><span class="nav-text">嵌入式应用开发指导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BPU-SDK-API%E6%89%8B%E5%86%8C"><span class="nav-text">BPU SDK API手册</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%A4%BA%E4%BE%8B%E5%8C%85%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"><span class="nav-text">基础示例包使用说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AI-Benchmark%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"><span class="nav-text">AI-Benchmark使用说明</span></a></li></ol></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2023</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Airex Yu</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        总访问量&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a> 驱动</span>
                <br>
            <span class="theme-version-container">主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.1.5</a>
        </div>
        
        
        
            <div id="start_div" style="display:none">
                2023/01/05 11:45:14
            </div>
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fa-solid fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fa-solid fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/navbarShrink.js"></script>

<script src="/js/tools/scrollTopBottom.js"></script>

<script src="/js/tools/lightDarkSwitch.js"></script>



    
<script src="/js/tools/localSearch.js"></script>




    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/libs/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>




    
<script src="/js/libs/mermaid.min.js"></script>

    
<script src="/js/plugins/mermaid.js"></script>





<div class="post-scripts pjax">
    
        
<script src="/js/tools/tocToggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
